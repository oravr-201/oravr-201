<Treepad version 3.0>
dt=Text
<node>
CNA Stuffs
0

-- Toad Lic. Key
1-04801-18516-45930-68123
CNA INSURANCE


CREDS:
DFW-Midrange-DBA@atosorigin.com     
Qazws@123

dl-oracle-cna@atos.net
Atos$2020

--- support.oracle.com
chandrakant.nirmal@atos.net
--> : Chandu@143


dl-oracle-cna@atos.net


Support Identifier
1873399
19819557


-- environment variable setting
rundll32.exe sysdm.cpl,EditEnvironmentVariables

<end node> 5P9i0s8y19Z
dt=Text
<node>
ATOS - DBAs
1
DBAs Name				ATOS		     CAN-IDs		CAN - DBs
-------------------------------------------------------------
Samuel Fung			A528432		CAE0418		CAE0418P
Monica Rios Saldana		A470113		CAE0489		CAE0489P
Max Cerna Flores		A462128		CAE0490		CAE0490P
Kulbhushan Pawar		A186526		CAE0720		CAE0720P
Tushar Warulkar		A569880		CAE0728		CAE0728P
Manoj Shardul			A591590		CAE0729		CAE0729P
Prashant Lokhande		A636730		CAE0747		CAE0747P
Rahul Chaudhari		A649491		CAE0748		CAE0748P
Chandrakant Nirmal		A435715		CAE0749		CAE0749P
Vijay Bolisetty		A567548		CAE0750		CAE0750P


cn8383cn

<end node> 5P9i0s8y19Z
dt=Text
<node>
CNA - Emails
1
-- unix team
UNIX_IAM_Manual@cnahardy.com
dl-cna-unix-support <dl-cna-unix-support@atos.net>; dl-oracle-cna <dl-oracle-cna@atos.net>; Parmar, Khushal <khushal.parmar@atos.net> 

--ITSO team ka email id
UNIX_IAM_Manual@cnahardy.com (file://unix_iam_manual@cnahardy.com/) 


-- Unix Team Members
Khushal Parmar - Unix Linux Lead
Siddhesh Raut
Kiran Choughule
Libio REbello


-- Do Not create ROLE directly, first ask to Gilberto
-- for exadata
Gilberto.Medina@cna.com 

<end node> 5P9i0s8y19Z
dt=Text
<node>
OEM stuffs
1
alter user dbsnmp identified by fun8park 


ALTER USER dbsnmp PROFILE DDEFPROFILE;
ALTER USER dbsnmp IDENTIFIED BY fun8park;
ALTER USER dbsnmp PROFILE DPROFILE;
alter user dbsnmp account unlock;


-- found on exadata prod 2 server
#### END Added by Configuration Utility ####
# OEM 12c Hosts
10.12.40.189    lrau1p19.cna.com lrau1p19
# END OEM 12c Hosts


DBSNMP/fun8park 
user: sysman
pass: byki2kau 


PROD OEM
prod - https://oemcloud.cna.com/em

pre-prod OEM
Link - https://oemdrt.cna.com/em/  
https://oemdrt.cna.com/em/

OEM 12C Prod database.
oem12cp

OEM 12C Pre-prod database.
oem12cr  

-----------------------------------------------------------------------------
username: cna_dba
-->: Cnadba123#

http://lrau1p19.cna.com:8080/ords/f?p=100:16

-----------------------------------------------------------------------------


-- non prod 
-- https://lrau1p19.cna.com:7802/em --- not working 

https://lrch1d37.cna.com:7802/em/

<end node> 5P9i0s8y19Z
dt=Text
<node>
Email - write
1
as giving access to whole database is prohibited under audit rules 

Folks on the "to" line above and in the table below, please note that the USERS tablespace in Merlin is a bit constrained 
and while we look to improve the situation from a capacity standpoint we are asking for your assistance in freeing up 
space by removing old, no longer needed data sets. The below table is a pivot, by user, of the usage stats that were sent last week.

Your assistance is appreciated! And apologies for the repeated emails to those who have already taken action and/or do not
 have any data which can be purged.


Database is running fine for days. We have received no alert of any kind on this database. how can we conclude its issue at 
database end. When was the last time stats collected on the underlying tables/objects ? at what frequency is 
stats collection job scheduled?

-- below 2 lines
Please note as per performance tuning guidelines of Oracle database, code has to be periodically reviewed for performance and tune as per nature/cardinality of data being processed. 

Oracle DBA Team can only help with minimal checks, as our scope is limited to support database as infrastructure service. We do not have any understanding of the code being executed or understand's the performance factors of code executed in database using application, We can only provide you the Locking/Blocking schema list….


If you require, we can help you get access to performance charts of database to help you monitor your code
performance more accurately so you can pinpoint the cause with better understanding of the code being executed.  
 
From: Chaudhari,Rahul (ATOS) (Contractor) 
Sent: Thursday, August 08, 2019 8:33 PM
To: LG,Ram (TCS) (Contractor); CNA_TCS_ITIS_Database_Oracle
Cc: Kumaravel,Jayasubha (Contractor); Prasanna,Midhun (TCS) (Contractor); Chaudhari,Rahul (ATOS) (Contractor)
Subject: RE: Incident INC0949099 has been opened

Hi Ram,

Database is running fine. We have received no alert for any database reletaed issues our failure.

Please note as per performance tuning guidelines of Oracle database, code has to be periodically reviewed for performance and tune as per nature/cardinality of data being processed.

DBA team cannot help with this as our scope is limited to support database's as infrastructure service. We do not have any business related functionality knowledge or how it's being executed in database. We can only check the database level performance and not object level performance.

So let us know if you required the reports on the any schema/locking/blocking, session issues reports which we can provide and you have to check for the performance on it.

We are returning the ticket to you as it doesn't belong to us. You might be have to check with application development team for the same.

Regards,
Rahul Chaudhari
Oracle DBA - Pune/India
----------------------------------------------------------------------

Please raise an RITM request, we no more process service requests on incident ticket. we are cancelling the ticket

<end node> 5P9i0s8y19Z
dt=Text
<node>
rough work
1

-- sch1h904
pcint : pc1nt_pctr
pcsystem : pc5ystem_pctr
---------------------------------------------

select p.spid, s.sid, s.serial#, s.sql_id,s.schemaname, s.machine, s.osuser
from v$session s, v$process p
where s.paddr = p.addr 
  and s.schemaname in ('BMCDBMON','EZFEED_MODIFY','EZFEED','EZFEED','EZFEED','EZFEED','EZFEED_MODIFY')

select p.spid, s.sid, s.serial#, s.schemaname, s.machine, s.osuser
from v$session s, v$process p
where s.paddr = p.addr
  and p.addr=15136

'alter system kill session '||sid||','||s.serial#||'@'||s.inst_id||' immediate;',

select p.spid, s.sid, s.serial#,  'alter system kill session '''||s.sid||','||s.serial#||'''@'||s.inst_id||' immediate;'
from gv$session s, v$process p
where s.paddr = p.addr
  and status='SNIPED' 



-- check the startup of instance
select inst_id, instance_name, to_char(startup_time, 'mm/dd/yyyy hh24:mi:Ss') "Startup time" from gv$instance;


-- sql query to check profiles
select *
FROM dba_profiles 
WHERE resource_name='PASSWORD_VERIFY_FUNCTION'
AND LIMIT='NULL';



------------------------------------------------------------------------
REQ0507804 

 
269276
269270

 


529977-269280 ?


REQ0507804

cac1108


Step-1 (Assign to Oracle team)

Please create the required tables manually for Insbridge DRT2 upgrade.

Database scripts are available at
\\cnaw2k\shared\public\ERE\Production_Support\Insbridge\Insbridge5.5 upgrade\Oracle scripts to be run in IBSS env

cnapre2r

Database details for point 1 to 3:
Database server: CNAPRE2R 
Database Name: LRCH1D34 /LRCH1D35
Schema name: IBSR
Database user id: ers_modify

Sequence
1.	DDLs in ALL_LOB.zip
IBSR_DDL_DT5040101 - 5.5 Auto.sql
IBSR_DDL_DT200101 - 5.5 WC.sql
IBSR_DDL_DT140101 - 5.5 GL.sql
IBSR_DDL_DT1260101 - 5.5 DBA.sql
IBSR_DDL_DT2020101 - 5.5 comm Property.sql
IBSR_DDL_DT1040101 - 5.5 UMB.sql
IBSR_DDL_DT180101 - 5.5 PKG.sql
IBSR_DDL_DT2030101 - 5.5 comm crime.sql
IBSR_DDL_DT1020101 - 5.5 Connect.sql
IBSR_DDL_DT5020101 - 5.5HAP_AS.sql
IBSR_DDL_DT5020101 - 5.5management lib.sql
IBSR_DDL_DT5010101 - 5.5 medcon lib.sql
IBSR_DDL_DT2040101 - 5.5 sp med lib.sql
IBSR_DDL_DT2010101 - 5.5 TestLOb.sql


2.	oracle_schema_change.sql
3.	alter system set optimizer_features_enable = '11.2.0.4';

Database details for point 4 :

Database server: CNAPRE2R 
Database Name: LRCH1D34 /LRCH1D35
Schema name: ibsr_batch
Database user id: ers_modify


4.	Run below SQL logging in service account ers_modify from IBSS50B20.16.zip
CleanUpTable.sql 
IBSS50B20.16 Schema.sql
IBSS50B20.16 Procs.sql



IBSR_DDL_DT5040101 - 5.5 Auto.sql
IBSR_DDL_DT200101 - 5.5 WC.sql
IBSR_DDL_DT140101 - 5.5 GL.sql
IBSR_DDL_DT1260101 - 5.5 DBA.sql
IBSR_DDL_DT2020101 - 5.5 comm Property.sql
IBSR_DDL_DT1040101 - 5.5 UMB.sql
IBSR_DDL_DT180101 - 5.5 PKG.sql
IBSR_DDL_DT2030101 - 5.5 comm crime.sql
IBSR_DDL_DT1020101 - 5.5 Connect.sql
IBSR_DDL_DT5020101 - 5.5HAP_AS.sql
IBSR_DDL_DT5020101 - 5.5management lib.sql
IBSR_DDL_DT5010101 - 5.5 medcon lib.sql
IBSR_DDL_DT2040101 - 5.5 sp med lib.sql
IBSR_DDL_DT2010101 - 5.5 TestLOb.sql

CTASK0014377 CTASK0014379

prompt
prompt "Started - IBSS50B20.16 Procs.sql"
prompt



 select username, account_status, lock_date from dba_users where username='DBSNMP'


PROD_SUPPORT_ROLE,DNB_SELECT,DNB_EXECUTE



Access Request ID

dba_mail="manoj.shardul@cna.com"
dba_cid=CAE0729P
work_dir=/home/CAE0729


Except MERWH4E/MERWH5C/MERWH5E/MERDM5C/MERDM5E

/csapps/oracle/product/10.2.0.4/network/admin
/csapps/oracle/product/10.2.0.4/network/admin

dba_mail="MohammedJaved.Imam@cna.com"
dba_cid=CAE0727P
work_dir=/home/CAE0727


cp /depot/oracle/scripts/usercreate/notify_group_template_exceptions /home/CAE0727
cp /depot/oracle/scripts/usercreate/notify_user_template_exceptions /home/CAE0727
cp /depot/oracle/scripts/usercreate/user_exists_template /home/CAE0727
cp /depot/oracle/scripts/usercreate/user_exists_template_group /home/CAE0727
cp /depot/oracle/scripts/usercreate/notify_group_template /home/CAE0727
cp /depot/oracle/scripts/usercreate/notify_user_template /home/CAE0727
cp /depot/oracle/scripts/usercreate/new_user_template /home/CAE0727
cp /depot/oracle/scripts/usercreate/new_group_template /home/CAE0727
cp /depot/oracle/scripts/usercreate/create_user /home/CAE0727


./create_user -s ecfr -u CAC1992 -c 532688-269733 -i CAC1992 -r CLIENT_ENRICHING_DATA_DELETE,CLIENT_ENRICHING_DATA_EXECUTE,CLIENT_ENRICHING_DATA_INSERT,CLIENT_ENRICHING_DATA_SELECT,CLIENT_ENRICHING_DATA_UPDATE
------------------------------------------------------------------------


Targert Server 
lrch1d43.cna.com:Oracle:rapidn1c:/shared/expdp001/rapidn2c

->pwd
/shared/expdp001/rapidn2c

lrch1d43.cna.com:Oracle:rapidn1c:/shared/expdp001/rapidn2c

->ls -alrt
total 165407136
drwxrwxr-x 37 grid   dba         8192 May 12 04:07 ..
-rw-r--r--  1 oracle dba       205641 Sep 11 09:29 clean14.sql
-rw-------  1 oracle dba          659 Sep 11 09:30 nohup.out
drwxrwx---  2 oracle dba         8192 Oct 17 11:23 .
-rw-r-----  1 oracle dba 169374007296 Oct 17 11:49 expdprapidnp_201810152135.dmp
lrch1d43.cna.com:Oracle:rapidn1c:/shared/expdp001/rapidn2c 
 


Application Testing options
Master table "SYS"."SYS_IMPORT_SCHEMA_01" successfully loaded/unloaded
Starting "SYS"."SYS_IMPORT_SCHEMA_01":  "/******** AS SYSDBA" directory=datapump1 dumpfile=expdprapidnp_201810152135.dmp logfile=imprapidnp_201810152135.log schemas=UPS table_exists_action=replace


select directory_name, directory_path from dba_directories where directory_name='DATAPUMP1'

exec DBMS_UTILITY.COMPILE_SCHEMA('UPS');


nohup impdp "'/as sysdba'" directory=DATA_DUMP_DIR dumpfile=expdprapidnp_201810152135.dmp logfile=impdp_rapidn2c_201810152135.log schemas=UPS table_exists_action=replace &


--------------------------------------------------------------------------------------
-- check LOCKS

SELECT Oracle_Username Username, owner Object_Owner, Object_Name, Object_Type, s.osuser, s.SID SID,
    s.SERIAL# SERIAL,S.MACHINE,s.module,DECODE(l.BLOCK, 0, 'Not Blocking', 1, 'Blocking', 2, 'Global') STATUS,
    DECODE(v.locked_mode, 0, 'None', 1, 'Null', 2, 'Row-S (SS)', 3, 'Row-X (SX)', 4, 'Share', 5, 'S/Row-X (SSX)', 6, 'Exclusive', TO_CHAR(lmode) ) MODE_HELD
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s
WHERE v.object_id = d.object_id
  AND (v.object_id = l.id1)
  AND v.session_id = s.SID
ORDER BY oracle_username, session_id;


 col oracle_username for a15
 col OS_USER_NAME for a10
 col OBJECT_NAME for a30
select a.oracle_username, a.os_user_name, a.locked_mode, b.object_name, b.object_type
from v$locked_object a, dba_objects b
where a.object_id = b.object_id

select do.object_name, row_wait_obj#, row_wait_file#, 
	row_wait_block#, row_wait_row#, dbms_rowid.rowid_create (1, ROW_WAIT_OBJ#, ROW_WAIT_FILE#, ROW_WAIT_BLOCK#, ROW_WAIT_ROW#)
from v$session s, dba_objects do
where sid=&sid
and s.ROW_WAIT_OBJ# = do.OBJECT_ID


-- view all currently locked objects: 
SELECT username U_NAME, owner OBJ_OWNER,
object_name, object_type, s.osuser,
DECODE(l.block,
  0, 'Not Blocking',
  1, 'Blocking',
  2, 'Global') STATUS,
  DECODE(v.locked_mode,
    0, 'None',
    1, 'Null',
    2, 'Row-S (SS)',
    3, 'Row-X (SX)',
    4, 'Share',
    5, 'S/Row-X (SSX)',
    6, 'Exclusive', TO_CHAR(lmode)
  ) MODE_HELD
FROM gv$locked_object v, dba_objects d,
gv$lock l, gv$session s
WHERE v.object_id = d.object_id
AND (v.object_id = l.id1)
AND v.session_id = s.sid
ORDER BY username, session_id;
 
 
-- list current locks 
SELECT session_id,lock_type, 
  mode_held, 
  mode_requested, 
  blocking_others, 
  lock_id1
FROM dba_lock l
WHERE lock_type NOT IN ('Media Recovery', 'Redo Thread');

SELECT username U_NAME, owner OBJ_OWNER,
object_name, object_type, s.osuser,
DECODE(l.block,
  0, 'Not Blocking',
  1, 'Blocking',
  2, 'Global') STATUS,
  DECODE(v.locked_mode,
    0, 'None',
    1, 'Null',
    2, 'Row-S (SS)',
    3, 'Row-X (SX)',
    4, 'Share',
    5, 'S/Row-X (SSX)',
    6, 'Exclusive', TO_CHAR(lmode)
  ) MODE_HELD
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s
WHERE v.object_id = d.object_id
AND (v.object_id = l.id1)
AND v.session_id = s.sid
ORDER BY username, session_id;
--------------------------------------------------------------------------------------

select owner, segment_name, sum(bytes/1024/1024)Size_in_MB 
from dba_segments 
where owner='MIS_DM' 
and segment_name in (select table_name from dba_tables where table_name like 'D_UMB_%')
group by owner, segment_name
order by 3 desc;


In most cases, ORA-01013: user requested cancel of current operation should not be difficult to resolve with a few changes in Oracle settings. This may have been intentional if you decided to cancel running the code mid--operation by pressing Control+C or by some front-end application. 


Hi Samuel,

We are not supporting DB2 database and just supporting Oracle. Please let us know if you required any assistance in Oracle and we will help you

Regards,
Rahul Chaudhari
-------------------------------------------------------------------------------------------------
-- sample script of create_DBA_User.ksh

->cat /depot/oracle/temp/create_DBA_User.ksh
ALL_DATABASES=`ps -ef|grep ora_smon_ |grep -v grep|awk -F"_" '{print $3 " " $4}'|sort`
#ALL_DATABASES=`cat /etc/oratab|grep -v "^#"|grep -v "N$"|cut -f1 -d: -s`
for DB in $ALL_DATABASES
do
   unset  TWO_TASK
   export ORACLE_SID=$DB
   export ORACLE_HOME=`grep "^${DB}:" /etc/oratab|cut -d: -f2 -s`
   export PATH=$ORACLE_HOME/bin:$PATH
   echo "---> Database $ORACLE_SID, using home $ORACLE_HOME"
   sqlplus -s "/as sysdba" <<ENDofSQL
create user $1 identified by $2;
grant DBA to $1;
alter user $1 profile dprofile;

ENDofSQL
done
sch1h018:oracle:seed:/csapps/oracle
-------------------------------------------------------------------------------------------------
select dg.name dg_name, dg.state dg_state, dg.type,d.DISK_NUMBER dsk_no, d.MOUNT_STATUS, d.HEADER_STATUS, d.MODE_STATUS,d.STATE, d.PATH, d.FAILGROUP  FROM V$ASM_DISK d, v$asm_diskgroup dg where dg.group_number(+)=d.group_number  order by dg_name, dsk_no;

CAE0737P KP2525kp


------------------------------------------------------------------------------------------------------------

-- AIX command to display the lines 
grep -n 'stack' flow.txt | cut -d':' -f1 |  xargs  -n1 -I % awk 'NR<=%+3 && NR>=%-2' flow.txt

grep -n 'ORA-27063' alert_ecfp1.log | cut -d':' -f1 |  xargs  -n1 -I % awk 'NR<=%+8 && NR>=%-8' alert_ecfp1.log

grep -n 'ORA-27063' alert_clmedip1.log | cut -d':' -f1 |  xargs  -n1 -I % awk 'NR<=%+3 && NR>=%-2' alert_clmedip1.log

<end node> 5P9i0s8y19Z
dt=Text
<node>
CNA alias Profile
1
->cat /csapps/oracle/cnascripts/aliassh
#!/bin/ksh

alias dir='ls -lt|more'
alias lc='ls -FC'
alias ll='ls -l'
alias lt='ls -lt'
alias lth='ls -lt | head'
alias ltrh='ls -ltr | head'
alias ldir='ls -ltr | grep ^d'
alias his=history
alias clr='tput clear'
alias cls='tput clear'
alias rd=rmdir
alias md=mkdir
alias goora='cd $ORACLE_HOME'
alias gosid='cd $ORACLE_BASE/admin/$ORACLE_SID'
alias godba='cd $ORACLE_BASE/admin/$ORACLE_SID/dba'
alias gobin='cd /csapps/oracle/dbascripts/$ORACLE_SID'
alias gobinc='cd /csapps/oracle/cnascripts'
alias gobind='cd /csapps/oracle/dbascripts'
alias gotns='cd $(grep ^listener: /csapps/oracle/input/listener_tab|awk -F: "{print \$2}")/network/admin'
alias gotrc='gotns;cd ../trace'
alias golog='gotns;cd ../log'
alias goback='cd $ORACLE_BASE/backup/scripts'
alias gonblog='cd /usr/openv/netbackup/logs/user_ops/dbext/logs'
alias lsalert='ls -l $ORACLE_BASE/admin/*/bdump/alert_*.log'
alias gocr='cd $ORACLE_BASE/admin/$ORACLE_SID/create'
alias goexp='cd $ORACLE_BASE/admin/$ORACLE_SID/exp'
alias gob='cd $ORACLE_BASE/admin/$ORACLE_SID/bdump'
alias goc='cd $ORACLE_BASE/admin/$ORACLE_SID/cdump'
alias gou='cd $ORACLE_BASE/admin/$ORACLE_SID/udump'
alias gop='cd $ORACLE_BASE/admin/$ORACLE_SID/pfile'
alias godbs='cd $ORACLE_HOME/dbs'
alias cnabdf='df -kP | sort +5 | more'
alias bdf='df -kP | sort +5 | more'
alias newsid='. newsid'
alias psora='ps -ef|grep ora|grep -v -e ksh -e X11 -e grep -e "ps -ef" |sort|grep -v -e sort -e more'
alias pssid='ps -ef|grep ora|grep $ORACLE_SID|grep -v -e ksh -e X11 -e grep -e "ps -ef"|sort|grep -v -e sort -e more'
alias godepot='cd /depot/oracle'
alias goa='cd $ORACLE_BASE/admin/$ORACLE_SID/bdump;view alert*.log'
alias lof='/csapps/oracle/cnascripts/operation/dba_work_log.sh lof'
alias lon='/csapps/oracle/cnascripts/operation/dba_work_log.sh lon'
alias lman='/csapps/oracle/cnascripts/operation/dba_work_log.sh man'
alias lcmt='/csapps/oracle/cnascripts/operation/dba_work_log.sh cmt'
sch1h020:oracle:v97app:/csapps/oracle

<end node> 5P9i0s8y19Z
dt=Text
<node>
CNA - Oracle
1
--- history location
/var/log/hist/oracle/sh_history.sau1h644.fr.cae0720.to.oracle

-- Oracle catalog DB name
rcat1p catalog

-- rman catalog
rman/mud@rcat1p
rman/mu2d@rcat2p


-- All DB those are present in below server list are working and should be up and running
-- if the db name is prefixed by #, it means it is decimossioned
sch1h018:/csapps/oracle/cnaconfig/full_source.cfg

nohup /csapps/oracle/cnascripts/./cna_dbstart -A &

-- preksha shah
cae0726/S@@xon_Preksha_jan  @ hardy servers

DBMS_UTILITY.COMPILE_SCHEMA('SENATOR');
-----------------------------------------------------------------------------------------
-- Share Doc URL	
https://itcollab.cna.com/itsmtransition/SitePages/Home.aspx

-- IIQ	
https://identityiq.cna.com/identityiq/manage/workItems/workItems.jsf 
 
-- CNA Snow
https://cnaprod.service-now.com	 

--IT Inventory Portal	
https://w3.cna.com/itinventory/ITInventoryWeb   

https://w3.cna.com/itinventory/ITInventoryWeb/ 

-- main server
sch1h018

-- To login all databases
cae0748P
Kjdrt113e
point1978 -- lrch1d47

script location : /depot/oracle/temp

on some servers direct sudo is not working 
so /usr/local/bin/sudo su - oracle  can be done


-- reset the password cid cae0748P
DBA_account_pwd_reset.ksh <<CAE0748P>> <<new_password>>


-- sudo su - exadba (DDL application server)
exadata is only used for DDL migration purpose on some application servers


-- sudo su - oracle (login to exadata oracle DBs)
in exadata sudo su - oracle and you can use cae0748 user to login to DB..


-- service account (Application schemas) are created manually
-- service account need not required to share the account password
-- it required to go through etl admin team (ETL_ADMIN team)
CREATE USER  ETL_PROCEDE identified by "ETl2018PRoc" 
DEFAULT TABLESPACE USERS
TEMPORARY TABLESPACE TEMP
PROFILE APPSPROFILE
ACCOUNT UNLOCK; 

grant create session to ETL_PROCEDE ;

grant EPCINT_FEEDS_SELECT,EPCINT_FEEDS_INSERT,EPCINT_FEEDS_UPDATE,EPCINT_FEEDS_DELETE  to ETL_PROCEDE ;

-- once the service account is created password required to be entired into the below file
-- if you modify the password of service account update the password here
-- The file is common on every database server
/csapps/oracle/input/dba_cmds.schema_env

<database_name>:(service_account>:(password> which required to updates in the above file

papcintp:ETL_PROCEDE:ETl2018PRoc

-- service account password required to stored here
-- below path is common in every server
/csapps/oracle/input/dba_cmds.schema_env 

/csapps/oracle/input
/csapps/oracle/admin/cedm1c/create

/csapps/oracle/admin/pmlte/create/users/mis_dm_user.sql

-- find the db list in asending order
ps -ef|grep ora_smon_ |grep -v grep|awk -F"_" '{print $3 " " $4}'|sort


-- to find a specific db process
ps -ef |grep ora_smon_ |grep rapidn2e
---------------------------------------------------------------------------------------------------

col owner for a10
col table_name for a30
select owner, table_name, last_analyzed 
from dba_tables 
where owner='CLAIMODS' 
  and table_name ='D_ACTIVITY' in ('RPT_ODS_ASSIGNMENT_DETAIL','RPT_ODS_ASSIGNMENT_DTL_SNAP')
---------------------------------------------------------------------------------------------------

<end node> 5P9i0s8y19Z
dt=Text
<node>
Oracle - stuffs
2


--------------------------------------------------------------------------------

-- Oracle DBA Support, It has everyone from ATOS team and TCS team
OracleDBASupport@cna.com

-- SharePoint Location for CNA documents
https://sp2013.myatos.net/sites/msNAO/ds/Shared%20Documents1/Forms/AllItems.aspx?RootFolder=%2Fsites%2FmsNAO%2Fds%2FShared%20Documents1%2FCNA%2FProjects%2FExadata%2FProject%20Midway%2FCNA%20Exadata%20Documents&FolderCTID=0x0120006D156A7B0D0B96439015AD00A7BEB32B&View=%7B431B44DB%2D3A99%2D4D14%2D9E5D%2DA7497E4FEB12%7D&InitialTabId=Ribbon%2ERead&VisibilityContext=WSSTabPersistence

--------------------------------------------------------------------------------
--- VM Details
-- Virtual Machine Host Name
VW7MSPATSP1158

-- You will need to contact the CNA IT Service Desk at 312-822-HELP or 800-CNA-SERV option 3 to 
-- receive your initial password to log into the CNA network.  Below is your CNA user information 
-- you will need when contacting the Service Desk.
-- please contact CNA at 1-800-CNA-5910 (1-800-262-5910)

CID: CAE0748/RC0807rc
Employee Id:  238921
rahul.chaudhari@cna.com

port number : 2245

sudo su - oracle
same password CID as above

newsid <<database_name>> and we can set the DB env. + ORACLE_HOME will be working

-- Login to CNA from outside not URA
https://passage.cna.com

-- using ura
https://securemail.cna.com/tok/DMydUcM14U85n2DEUsHlnlI7/DQAAAWUTvU2M0xV-cM95mPYJdF55FmZD6It5dec1?c=c2&h=h-1885722855 

Dummy SSN: 777-02-4189

inc0651776 -- ticket number

for any software goto start in run type sccm and click on it
--------------------------------------------------------------------------------

select nodeid,owner,author,cmdline,descript, jobname,
       schedtab, wdaystr scheday, fromtime hour
  from ctmuser.cms_jobdef
 where jobname='P70208SRUMS' 


-- 8i critical database
DB Name : cmdp -- 8i version

-- CNA service-now ticketing tool
https://cnaprod.service-now.com

19361589 (Continental Casualty Company  Inc.) 



-- once the service account is created password required to be entired into the below file
-- if you modify the password of service account update the password here
-- The file is common on every database server
-- service account password required to stored here
/csapps/oracle/input/dba_cmds.schema_env

<database_name>:<service_account>:<password> which required to updates in the above file


/csapps/oracle/input
/csapps/oracle/admin/hypr/create

/csapps/oracle/admin/pmlte/create/users/mis_dm_user.sql

** IID Access account for DML operations
and this IID access remains only 24 hrs and it will be dropped automatically after 24 hrs
sometime it will not drop due some issues and you will get the email alert for the same.
if you have such emails, just go and locked that IID account.
-- do not drop the IID accounts
once the account is locked we required to close the ticket


-- 06-Aug/2018
CTASK - 1544

Change Controls will be only on weekends (every friday after 08PM)

--- KT session Video and CAN Oracle Document.
https://sp2013.myatos.net/sites/msNAO/ds/Shared%20Documents1/Forms/AllItems.aspx?RootFolder=%2Fsites%2FmsNAO%2Fds%2FShared%20Documents1%2FCNA%2FProjects%2FOracle%2FProject%20Midway&FolderCTID=0x0120006D156A7B0D0B96439015AD00A7BEB32B&View=%7B431B44DB%2D3A99%2D4D14%2D9E5D%2DA7497E4FEB12%7D&InitialTabId=Ribbon%2EDocument&VisibilityContext=WSSTabPersistence    

-- cna inventory documents on share-point
https://sp2013.myatos.net/sites/msNAO/ds/Shared%20Documents1/Forms/AllItems.aspx
--------------------------------------------------------------------------------


-- OEM Details:

DBSNMP/fun8park        
sysman/byki2kau

user: sysman
pass: byki2kau 


PROD OEM
prod - https://oemcloud.cna.com/em/ 

pre-prod OEM
Link - https://oemdrt.cna.com/em/ 

--------------------------------------------------------------------------------
-- ticket url
https://identityiq.cna.com/identityiq/workitem/workItem.jsf

Seceurity request --> other (request type) ---> self request and in comment "Please provide access to service now"

to raise a ticket server access
group name : DBA (IT.TCS-I.Database Engineering - Oracle.DBA and IT.TCS-I.Database Engineering - Oracle IN)

Assurity server has to be filled a forms for access
this will not work from iiq url


-- How to configure software on jumphost
has to request an approvals for installing/configuring any software
open an iiq request ticket
--------------------------------------------------------------------------------

----control-m details:-
lrau1p24 server and DB name is cm90p

-- it is same for every server
location:-/csapps/oracle/backup/logs/dbname

-- scripts
$ORACLE_HOME/backup/scripts/<SID>/oracle/backup/scripts/


-- refresh related and this is security exception
-- security execption to check
https://rsam.cna.com/RSAM/RSAM_DEFAULT.aspx

--------------------------------------------------------------------------------
-- required email ids 
Backup-Recovery <Backup-Recovery@cna.com (Backup-Recovery%40cna.com)>; 
ETL_ADMIN <ETL_ADMIN@cna.com (ETL_ADMIN%40cna.com)>; 
CNA_TCS_ITIS_Database_All <CNA_TCS_ITIS_Database_All@cna.com (CNA_TCS_ITIS_Database_All%40cna.com)>; 
CNA_TCS_ITIS_UNIX_All <CNA_TCS_ITIS_UNIX_All@cna.com (CNA_TCS_ITIS_UNIX_All%40cna.com)> 
Network Support <NetSpt@cnasurety.com (NetSpt%40cnasurety.com)> 



sarath.ratnala@cna.com (sarath.ratnala%40cna.com)  
sandhini.gopalan@cna.com (sandhini.gopalan%40cna.com) 
Bhargav.Koneni@cna.com (Bhargav.Koneni%40cna.com)> 
Richard.Adaikalanathan@cna.com (Richard.Adaikalanathan%40cna.com
sandhini.gopalan@cna.com (sandhini.gopalan%40cna.com)> 
vanitha.subramani@cna.com (vanitha.subramani%40cna.com) 

CNA_TCS_ITIS_Database_All@cna.com (CNA_TCS_ITIS_Database_All%40cna.com)

--- Date 15-Aug-2018
-- Share Doc URL
https://itcollab.cna.com/itsmtransition/SitePages/Home.aspx

-- IIQ    
https://identityiq.cna.com/identityiq/manage/workItems/workItems.jsf 

--IT Inventory Portal  
https://w3.cna.com/itinventory/ITInventoryWeb   

-- CNA Servicenow 
https://cnaprod.service-now.com <https://cnaprod.service-now.com/>              

OR 

-- From here also we can connect service now
https://cna.okta.com/app/UserHome#

click on servicenow 

-- description to raise a ticket for viewing service-now
Please provide ITIL servicenow view access

-- DBA groups (This 2 groups required in both servicenow and identityiq)
IT.TCS-I.Database Engineering - Oracle.DBA
IT.TCS-I.Database Engineering - Oracle.IN

-- We should be added into this group 
-- email group for DBAs
CNA_TCS_ITIS_Database_All <CNA_TCS_ITIS_Database_All@cna.com>
CNA_TCS_ITIS_Database_Oracle <CNATCSITISDBOracle@cna.com>

--------------------------------------------------------------------------------

-- if asked to kill the user, below query will help
select sid||','||serial# "sid,serial#",machine,process,osuser,username,
  schemaname,status,lockwait,module,to_char(logon_time,'dd-mon-yy hh24:mi:Ss') as logon_time 
 from gv$session 
 where username is not null 
   and username='EID01' 
   and osuser is not null 
order by machine,osuser,username,schemaname,status,module;

---------------------------------------------------------------------------------
-- To rest the password 

The below scripts available in /depot/oracle/temp 
----> use all_servers script to create/reset in all servers from sch1h018

-rwx--x---    1 oracle   dba            7126 Dec 12 14:36 DBA_pwd_reset_all_servers.ksh 
-rwx--x---    1 oracle   dba             564 Dec 13 11:46 DBA_account_pwd_reset.ksh 
-rwx--x---    1 oracle   dba             535 Dec 13 11:52 create_DBA_User.ksh 
-rwx--x---    1 oracle   dba            6556 Dec 13 11:53 create_DBA_User_All_Servers.ksh 

HOWTO reset Password : scriptname CIDwithp password
---------------------------------------------------------------------------------

-- 24-Aug/2018

-- Location of DB files to start
/csapps/oracle/cnascripts 
---------------------------------------------------------------------------------

sudo su - oracle
sudo su - grid
sudo su - ibmcdc
sudo su - dbadm
sudo su - exadba
---------------------------------------------------------------------------------

<end node> 5P9i0s8y19Z
dt=Text
<node>
goexp - goexpn
2
->cat /csapps/oracle/cnascripts/oragel_control_file
CNAOMON nc?hk4n~n4a
CNAOETERM bi8kx2o!x9y
CNAOSTART pd~oz5i+l4f
CNAOAUD rg!dz0k+y9t
CNAOIMP db+am2jw6v
STATUS run

--- just transfer the export dumpfile for the mentioned DB
-- modify the source dumpfile name in target's below menitoned file
-- then you can execute the file using nohup /csapps/oracle/dbascripts/sie1e/ctlm/impms2.ksh & and monitoring the logs
/csapps/oracle/dbascripts/sie1e/ctlm/impms2.ksh


------------------------------------------------------------------------------
-- RE: j76aec datarefresh TDM :  REQ0507767 
Schema Name : Senator

nohup expdp 

-- go to DB servers
-- newsid <<db_sid>>
goexp  ----- this will tel the information of export details
location of the export on sch1h020:/csapps/oracle/admin/j76app/exp


-- is just an alias to get you to the export directory so you don't have to search for it.  
-- /csapps/oracle/admin/SID/exp is a soft link to the physical export directory, 
-- which is exp -> /shared071/exp001/j76aec 
goexp or goexpn 

-- sau1h133 Monthly jobs 
->cat expdp_IM_OWNER_monthly.par
directory=dpump1
dumpfile=expdp_IM_OWNER_16feb2019_%U.dmp
logfile=expdp_IM_OWNER_16feb2019.log
schemas=IM_OWNER
parallel=6

nohup expdp "'/as sysdba'" parfile=expdp_IM_OWNER_monthly.par &


nohup expdp "'/as sysdba'" parfile=expdp_IM_OWNER_monthly_job.par.par job_name=DnB_MolyJob_23Jul2020 &


nohup expdp "'/as sysdba'" directory=SHARED dumpfile=expdp_RITM0545158_Merwhp_28Aug2020_%U.dmp logfile=expdp_RITM0545158_Merwhp_28Aug2020_logs.log tables=STAGING.SF_DISTRIBUTOR_ACCOUNT,STAGING.SF_OPPORTUNITIES,STAGING.SF_SALESCALL_BU,STAGING.SF_SALES_PLANS_INDIVIDUALS,STAGING.SF_DISTRIBUTOR_DATA exclude=statistics parallel=6 &

nohup impdp "'/as sysdba'" directory=SHARED dumpfile=expdp_RITM0545158_Merwhp_28Aug2020_%U.dmp logfile=impdp_expdp_RITM0545158_Merwh2c_28Aug2020_logs.log tables=STAGING.SF_DISTRIBUTOR_ACCOUNT,STAGING.SF_OPPORTUNITIES,STAGING.SF_SALESCALL_BU,STAGING.SF_SALES_PLANS_INDIVIDUALS,STAGING.SF_DISTRIBUTOR_DATA table_exists_action=replace parallel=6 &

nohup expdp "'/as sysdba'" directory=DATA_PUMP_DIR dumpfile=expdp_CHG0533906_DNBRR_26Jul2020_%U.dmp logfile=expdp_CHG0533906_DNBRR_26Jul2020_logs.log schemas=IM_OWNER parallel=5 exclude=statistics &

-- dnbrr sch1h648/649
nohup expdp "'/as sysdba'" directory=DATA_PUMP_DIR dumpfile=expdp_CTASK0055821_DNBRR_17Jan2021_%U.dmp logfile=expdp_CTASK0055821_DNBRR_17Jan2021_logs.log schemas=IM_OWNER parallel=5 exclude=statistics &

nohup expdp "'/as sysdba'" directory=DATA_PUMP_DIR dumpfile=expdp_CHG0532689_DNBRR_14Jun2020_%U.dmp logfile=expdp_CHG0532689_DNBRR_14Jun2020_logs.log schemas=IM_OWNER parallel=5 exclude=statistics &

nohup impdp "'/as sysdba'" directory=DATA_PUMP_DIR dumpfile=expdpcnacp_202008132357.dmp logfile=impdp_CNACP_CNAC1E_15AUG2020_v2.log schemas=STF,AISS table_exists_action=replace exclude=statistics parallel=10 &

nohup impdp "'/as sysdba'" directory=DATA_PUMP_DIR dumpfile=expdprstgp_202008172312.dmp logfile=impdp_expdprstgp_202008172312_rstg3c_logs.log schemas=RST,RST_ARCHIVAL table_exists_action=replace exclude=statistics parallel=6 &

nohup expdp "'/as sysdba'" directory=dpump dumpfile=expdp_RITM0545736_PAPC2E_papcuser_01SEP2020_%U.dmp logfile=expdp_RITM0545736_PAPC2E_papcuser_01SEP2020_logs.log schemas=papcuser exclude=index,constraint,statistics version=12.1 parallel=5 &

nohup expdp "'/as sysdba'" directory=DATA_PUMP_DIR dumpfile=expdp_CTASK0063931_DNBRP_24Apr2021_%U.dmp logfile=expdp_CTASK0063931_DNBRP_24Apr2021_logs.log schemas=IM_OWNER parallel=5 exclude=statistics &

nohup expdp "'/as sysdba'" directory=DATA_PUMP_DIR dumpfile=expdp_ibmcdc_18Dec2020_rstgpcdc.dmp logfile=expdp_ibmcdc_18Dec2020_rstgpcdc.log schemas=ibmcdc parallel=5 &

-- from the schema expdp, just restore one table with different name.
nohup impdp "'/as sysdba'" directory=DATA_PUMP_DIR dumpfile=expdp_ibmcdc_18Dec2020_rstgpcdc_%U.dmp logfile=impdp_expdp_ibmcdc_18Dec2020_rstgpcdc_ts_auth.log tables=ibmcdc.ts_auth remap_table=ts_auth:ts_auth_old parallel=5

=====================================================================================
-- you can directly do export and import even though the .dmp file is in .dmp.gz (compressed) format
-- using below format

-- export
mknod exp_brptp_tbls.dmp p
gzip < exp_brptp_tbls.dmp > /shared068/exp004/brptp/exp_RITM0538534_brptp_11Jun2020.dmp.gz &
nohup exp userid=\'/ as sysdba\' file=exp_brptp_tbls.dmp parfile=brptp_tables.par &

-- export
cd /shared/exp901/infmtr/
mkdir TASK003966400_Decom_infmtr
mknod exp_infmtr.dmp p
gzip < exp_infmtr.dmp > /shared/exp901/infmtr/TASK003966400_Decom_infmtr/exp_TASK003966400_Decom_efiler_30May2020.dmp.gz  &
nohup exp userid=\'/ as sysdba\' file=exp_infmtr.dmp log=exp_TASK003966400_Decom_efiler_30May2020.log full=y & 

--  import 
mknod imp_pipe.dmp p
nohup gunzip -c < exppaeusp_201805152000.dmp.gz > imp_pipe.dmp  &  
nohup imp userid=\'/ as sysdba\' fromuser=SENATOR touser=SENATOR file=imp_pipe.dmp log=import_PAEUS2E.log buffer=999999999 commit=y resumable=y  analyze=n & 

or
  
mknod imp_siep_sie1e.dmp p
nohup gunzip -c < expsiep_201901170100.dmp.gz > imp_siep_sie1e.dmp  &  
nohup imp userid=\'/ as sysdba\' fromuser=ezfeed,mrl touser=ezfeed,mrl file=imp_siep_sie1e.dmp log=import_siep_sie1e_21Jan2019.log buffer=999999999 commit=y resumable=y  analyze=n &

OR


mknod imp_senator_sept202111.dmp p
nohup gunzip -c < expj76app_202109012127.dmp.gz > imp_senator_sept202111.dmp  & 
nohup imp userid=\'/ as sysdba\' ignore=y fromuser=senator touser=senator file=imp_senator_sept202111.dmp log=imp_senator_sept2021_logs11.log rows=n INDEXES=n COMPILE=Y STATISTICS=none &

OR

mkfifo imp_siep_sie1e.dmp
gzip -c -d expsiep_201901170100.dmp.gz > imp_siep_sie1e.dmp &
nohup imp userid=\'/ as sysdba\' fromuser=ezfeed,mrl touser=ezfeed,mrl file=imp_siep_sie1e.dmp log=import_siep_sie1e_21Jan2019.log buffer=999999999 commit=y resumable=y  analyze=n &

OR

->more imp_tables.ksh
#
# script set up specifically to import 1 table listed below.
#
ORAENV_ASK=NO; export ORAENV_ASK
ORACLE_SID=pctrar; export ORACLE_SID
PATH=$PATH:/usr/local/bin
. oraenv

mkfifo exp.dmp
gzip -c -d PCTRT_DBEXPORT_TABLES_200809081019.dmp.gz > exp.dmp &
$ORACLE_HOME/bin/imp / file=exp.dmp log=imp_tables.log fromuser=pcsystem tables=pcx_cnadnbdata full=n commit=y ignore=y buffer=33554432 constraints=n grants=n indexes=n

sch1h904:oracle:pctrar:/csapps/oracle/admin/pctrar/exp
-> 
=====================================================================================

before this, drop objects of senator in target and transfer dump file from source to target

-- main script for import (Refresh)
-- this script also does scp of the target dumpfile
/csapps/oracle/dbascripts/<<sid>>/ctlm/impms2.ksh

on sch1h071, i already have an import script you can use - /csapps/oracle/dbascripts/j76aec/ctlm/impms2.ksh.  
 you would only need to change 1 parameter and replace it with the current export file name for j76app:  
export IMPORT_FILE=expj76app_201604132130.dmp.gz 


sch1h071:oracle:j76aec:/csapps071/oracle/admin/j76aec/exp/expj76app_201810102130.dmp.gz


==========================================================================================


mknod imp_pipe.dmp p
nohup gunzip -c < PCTRAR_DBEXPORT_201809140400.dmp.gz > imp_pipe.dmp  &  
nohup imp userid=\'/ as sysdba\' fromuser=PCSYSTEM touser=PCSYSTEM file=imp_pipe.dmp log=imp_pctrar_pcsystem_15NOV2018.log buffer=999999999 commit=y resumable=y analyze=n &

<end node> 5P9i0s8y19Z
dt=Text
<node>
ibmcdc - Agent info
2
PAPCP IIDR 11.3 –

This is a source agent.
For IIDR 11.3 on lrau1p17 (need to connect directly to lrau1p17):


--then select option 1 and you should see a status of “running”, but this sometimes takes a few tries.

1) check if the user IBMCDC is not locked in both source and target databses.
2) Kill any defunct processes
3) Bringing target down
4) Bringing Source down
5) Clean both out
6) then start the source, Wait for it to come up
7) Then start the target
======================================================================================

--- stop
dmshutdown -I clmccp

-- start
nohup dmts64 -I papcp &

nohup dmts64 -I papcp &

dmgetsubscriptionstatus -I papce -A

-- To check the status of the IIDR 11.3 agent:
-- STATUS
sudo su - ibmcdc


dmshutdown -I clmccp
dmshutdown -I merwhppol
-- start
nohup dmts64 -I merwhppol &

nohup dmts64 -I clmccp &

-- check the status of the subscription 
dmgetsubscriptionstatus -I merwh2cpol -A
dmgetsubscriptionstatus -I merwhpclm -A


newsid papcp
cd /csapps/ibmcdc/IIDR113/install/bin
dmconfigurets

-- To stop the IIDR 11.3 agent:
-- STOP
sudo su - ibmcdc

newsid papcp
cd /csapps/ibmcdc/IIDR113/install/bin
dmshutdown -I merwhppol

-- To start the IIDR 11.3 agent:
-- START
sudo su - ibmcdc

newsid papcp
REMOVE ANY FILES in /csapps/ibmcdc/IIDR113/install/instance/spcr/stagingstore
REMOVE ANY FILES in /csapps/ibmcdc/IIDR113/install/instance/spcp/tmp
REMOVE any TXQ* files in /csapps/ibmcdc/IIDR113/install/instance/spcp/txnstore
cd /csapps/ibmcdc/IIDR113/install/bin
nohup dmts64 -I merwhrsur &


Target Agent : merwhp_newepc
Host name : vslrau1p017
Port : 11007

-- to stop/start/status for merwhpepc on vslrau1p017
/csapps/ibmcdc/IIDR113-4/install/instance/merwhpepc/stagingstore
/csapps/ibmcdc/IIDR113-4/install/instance/merwhpepc/tmp

cd /csapps/ibmcdc/IIDR113-4/install/bin
nohup dmts64 -I merwhpepc &
======================================================================================

-- lrch1d34.cna.com:ibmcdc:papcr1:/csapps/ibmcdc/IIDR113/install/bin
dmshutdown –I papcr 
cd /csapps/ibmcdc/IIDR113/install/instance/papcr/stagingstore (remove all files)
cd /csapps/ibmcdc/IIDR113-4/install/instance/papcr/tmp
cd /csapps/ibmcdc/IIDR113/install/instance/papcr/txnstore
nohup dmts64 -I papcr &

-- vclch1e0198.cna.com:ibmcdc:?:/csapps/ibmcdc/IIDR113-2/install/bin
nohup dmts64 -I merwh2cpol &
======================================================================================

newsid clmcc1r

cd /csapps/ibmcdc/IIDR113/install/bin
dmconfigurets 

dmshutdown –I clmcc1r
REMOVE ANY FILES in /csapps/ibmcdc/IIDR113/install/instance/clmcc1r/stagingstore
REMOVE ANY FILES in /csapps/ibmcdc/IIDR113/install/instance/clmcc1r/tmp
REMOVE any TXQ* files in /csapps/ibmcdc/IIDR113/install/instance/clmcc1r/txnstore

cd /csapps/ibmcdc/IIDR113/install/bin
nohup dmts64 -I clmcc1r &

dmconfigurets
======================================================================================

newsid clmcm1r

cd /csapps/ibmcdc/IIDR113/install/bin
dmconfigurets 

dmshutdown –I clmcm1r
REMOVE ANY FILES in /csapps/ibmcdc/IIDR113/install/instance/clmcm1r/stagingstore
REMOVE ANY FILES in /csapps/ibmcdc/IIDR113/install/instance/clmcm1r/tmp
REMOVE any TXQ* files in /csapps/ibmcdc/IIDR113/install/instance/clmcm1r/txnstore

cd /csapps/ibmcdc/IIDR113/install/bin
nohup dmts64 -I merwhpepc &

dmconfigurets



clmccp


REMOVE ANY FILES in /csapps/ibmcdc/IIDR113/install/instance/clmccp/stagingstore
REMOVE ANY FILES in /csapps/ibmcdc/IIDR113/install/instance/clmccp/tmp
REMOVE any TXQ* files in /csapps/ibmcdc/IIDR113/install/instance/clmccp/txnstore
  
   
REMOVE ANY FILES in /csapps/ibmcdc/IIDR113/install/instance/clmcmp/stagingstore
REMOVE ANY FILES in /csapps/ibmcdc/IIDR113/install/instance/clmcmp/tmp
REMOVE any TXQ* files in /csapps/ibmcdc/IIDR113/install/instance/clmcmp/txnstore
  
Name: clmccp_cc8
host name:lrau1p17-vip.cna.com
port:11009
Name: clmcmp_cm8
host name:lrau1p17-vip.cna.com
port:11008 
 
[?11/?9/?2018 3:08 PM]  
ok working 
let me connect them 

<end node> 5P9i0s8y19Z
dt=Text
<node>
ibmcdc - sch1h020/071
2
For CDC on sch1h071 (j76adc) and sch1h020 (j76app):

To stop the listener agent:

sudo ibmcdc

newsid j76adc
cd /csapps/ibmcdc/bin
stopListener

Then kill any remaining IBMCDC processes manually (kill -9).  

Then run the below command for clean-up
/csapps/ibmcdc/bin/tsclean (twice).

To start the listener agent:

sudo ibmcdc

newsid j76adc
cd /csapps/ibmcdc/bin
startListener

------------------------------------------------------------------------------------------------------
Please follow below steps for CDC listener issues

1)Stop j76app listener and let us know. 
2) kill all remaining IBMCDC processes manually.
3) ran /csapps/ibmcdc/bin/tsclean (twice).
4)start j76app listener

Note: 
Please make sure to run tsclean up script(twice) after CDC listener restarted.

------------------------------------------------------------------------------------------------------

Example of a startListener:

sch1h071:c61105:seed92:/home/c61105
->sudo su - ibmcdc
Password: 
sch1h071:ibmcdc:seed92:/home/ibmcdc 
->newsid j76adc
sch1h071:ibmcdc:j76adc:/home/ibmcdc
->ps -eaf |grep ibmcdc
  ibmcdc 2445496 2945154   6 07:45:48  pts/4  0:00 ps -eaf 
  ibmcdc 2945154 2973754   2 07:45:40  pts/4  0:00 -ksh 
sch1h071:ibmcdc:j76adc:/home/ibmcdc
->cd /csapps/ibmcdc/bin
sch1h071:ibmcdc:j76adc:/csapps/ibmcdc/bin
->startListener  (and hit the enter key – it automatically goes to nohup)
TS Listener successfully started
sch1h071:ibmcdc:j76adc:/csapps/ibmcdc/bin
->Sending nohup output to nohup.out.

sch1h071:ibmcdc:j76adc:/csapps/ibmcdc/bin
->ps -eaf |grep ibmcdc
  ibmcdc 2031828 2945154   4 07:46:33  pts/4  0:00 ps -eaf 
  ibmcdc 2445528       1   0 07:46:12  pts/4  0:00 /csapps/ibmcdc/bin/dmktl 10103 
  ibmcdc 2945154 2973754   2 07:45:40  pts/4  0:00 -ksh 
  ibmcdc 2961448       1   0 07:46:13      -  0:00 /csapps/ibmcdc/bin/ad_listener /csapps/ibmcdc 2222 
sch1h071:ibmcdc:j76adc:/csapps/ibmcdc/bin

<end node> 5P9i0s8y19Z
dt=Text
<node>
shut - start DBs
2
-- to startup DBs using script
/csapps/oracle/cnascripts/cna_dbstart -A

-- to shutdown DBs using script
/csapps/oracle/cnascripts/cna_dbshut -A


-- check the below script created by Vishal B
ls -lart /depot/oracle/temp/*start*

--- scripts for shutdown and startup DBs and oids
ls -larts /csapps/oracle/cnascripts/*shut*
ls -larts /csapps/oracle/cnascripts/*start*

cd /csapps/oracle/cnascripts


--**Are you planning on bringing the HACMP databases down manually prior to the server shutdown?   
-- I’m sure you know this, but the database shutdown script for HACMP is 
/csapps/oracle/cnascripts/cna_oracle_cluster_shutdown resourcegroupname

So, for sau1h644 it would be:
/csapps/oracle/cnascripts/cna_oracle_cluster_shutdown  pcprdsvc2
/csapps/oracle/cnascripts/cna_oracle_cluster_startup  pcprdsvc2
The script to check db status after startup should be
/csapps/oracle/cnascripts/checkdb

For standalone servers:
/csapps/oracle/cnascripts/cna_oracle_shutdown
/csapps/oracle/cnascripts/cna_oracle_startup
The script to check db status after startup should be
/csapps/oracle/cnascripts/checkdb 


----------------------------------------------------------------------------------------
-- to start all DBs except # and N in /etc/oratab file

cat /etc/oratab |grep -v "^#"|grep -v "^+"|cut -f1 -d: -s

ps -ef|grep ora_smon_ |grep -v grep|awk -F"_" '{print $3 " " $4}'|sort


->cat dbstart.ksh

ALL_DATABASES=`ps -ef|grep ora_smon_ |grep -v grep|awk -F"_" '{print $3 " " $4}'|sort`
#ALL_DATABASES=`cat /etc/oratab|grep -v "^#"|grep -v "N$"|cut -f1 -d: -s`
for DB in $ALL_DATABASES
do
   unset  TWO_TASK
   export ORACLE_SID=$DB
   export ORACLE_HOME=`grep "^${DB}:" /etc/oratab|cut -d: -f2 -s`
   export PATH=$ORACLE_HOME/bin:$PATH
   echo "---> Database $ORACLE_SID, using home $ORACLE_HOME"
   sqlplus -s "/as sysdba" <<ENDofSQL
startup;
set sqlprompt "_date':'_user'@'_connect_identifier> "
set linesize 190
set pages 1000
set long 32000
COLUMN id_plus_exp FORMAT 990 HEADING i
COLUMN parent_id_plus_exp FORMAT 990 HEADING p
COLUMN plan_plus_exp FORMAT a60
COLUMN object_node_plus_exp FORMAT a8
COLUMN other_tag_plus_exp FORMAT a29
COLUMN other_plus_exp FORMAT a44
col HOSTNAME for a18
col BLOCKED for a7
col STARTUP_TIME for a19
select I.instance_name INS_NAME,I.host_name HOSTNAME,I.STATUS,I.DATABASE_STATUS DB_STATUS,D.open_mode,D.database_role,I.LOGINS,
to_char(I.STARTUP_TIME,'DD-MON-YY HH24:MI:SS') STARTUP_TIME from v\$instance I ,v\$database D ;

ENDofSQL
done
----------------------------------------------------------------------------------------


->cat dbshut.ksh
ALL_DATABASES=`ps -ef|grep ora_smon_ |grep -v grep|awk -F"_" '{print $3 " " $4}'|sort`
#ALL_DATABASES=`cat /etc/oratab|grep -v "^#"|grep -v "N$"|cut -f1 -d: -s`
ps -ef |grep pmon
ps -ef |grep tns
for DB in $ALL_DATABASES
do
   unset  TWO_TASK
   export ORACLE_SID=$DB
   export ORACLE_HOME=`grep "^${DB}:" /etc/oratab|cut -d: -f2 -s`
   export PATH=$ORACLE_HOME/bin:$PATH
   echo "---> Database $ORACLE_SID, using home $ORACLE_HOME"
   sqlplus -s "/as sysdba" <<ENDofSQL
   set sqlprompt "_date':'_user'@'_connect_identifier> "
set linesize 190
set pages 1000
set long 32000
COLUMN id_plus_exp FORMAT 990 HEADING i
COLUMN parent_id_plus_exp FORMAT 990 HEADING p
COLUMN plan_plus_exp FORMAT a60
COLUMN object_node_plus_exp FORMAT a8
COLUMN other_tag_plus_exp FORMAT a29
COLUMN other_plus_exp FORMAT a44
col HOSTNAME for a18
col BLOCKED for a7
col STARTUP_TIME for a19
select I.instance_name INS_NAME,I.host_name HOSTNAME,I.STATUS,
           I.DATABASE_STATUS DB_STATUS,D.open_mode,D.database_role,
           I.LOGINS, to_char(I.STARTUP_TIME,'DD-MON-YY HH24:MI:SS') STARTUP_TIME
from v\$instance I ,v\$database D ;

--- Please remove -- from below shutdown immediate script, this will be shutdown
-- all the dbs which are in pmon list
shutdown immediate;

ENDofSQL
done
/csapps/oracle/agent12c/core/12.1.0.4.0/bin/./emctl status agent
/csapps/oracle/agent12c/core/12.1.0.4.0/bin/./emctl stop agent
sch1h232:oracle:caoc:/depot/oracle/temp

<end node> 5P9i0s8y19Z
dt=Text
<node>
bu RMAN scrp
2

-- rman catalog
rman/mud@rcat1p
rman/mu2d@rcat2p

-- I fixed the first issue with trying to delete archive logs for you.  If you manually remove logs, you have to sync the catalog:
/csapps/oracle/backup/bin/bu –o fixarchdel –s itinvp 


-- archivelog backups for dnbrp
nohup /csapps/oracle/backup/scripts/do_dnbrp_archdel.ksh &


newsid dnbrr -- sch1h649
/csapps/oracle/backup/scripts/do_dnbrr_archdel.ksh &

newsid dnbrr
rman target / catalog rman/rman2tst@rcat2t
run {
    set command id to '163102665108';
   allocate channel t0 type 'sbt_tape';
   allocate channel t1 type 'sbt_tape';
   allocate channel t2 type 'sbt_tape';
    send 'NSR_ENV=(NSR_SERVER=lrch1d50,NSR_GROUP=CNAPROD_ORA)';
   sql 'alter system switch logfile';
    sql 'alter system archive log current';
    backup tag dnbrr_A_D_ON_2021083011448
       filesperset 300
       format 'rmanArchD_%d_%s_%p_%t_D_163102665108'
       (archivelog all delete input);
}


--- oracle 8i (RMAN-06429: RCVCAT database is not compatible with this version of RMAN)
connect catalog rmancat/Kjdrt103e@rcat1p

rman target / catalog rmancat/Kjdrt103e@rcat1p

rman target / catalog rman/mu2d@rcat2p

rman target /
crosscheck archivelog all;
delete expired archivelog all;
crosscheck backup;

--- backup tap servers used for ETE DBs
lrch1d50
--- backup tap servers used for development DBs
sch1h549
--- backup tap server used for the production DBs
lrau1p26 or nwprdsvc1
-- Archive log backups
date '+%Y%m%d%H%M%S'
-- Archive log backups

run
{
	allocate channel t0 type 'sbt_tape';
	allocate channel t1 type 'sbt_tape';
	#send 'NSR_ENV=(NSR_SERVER=nwprdsvc1,NSR_GROUP=CNAPROD_ORA_5_Weeks)';
	#send 'NSR_ENV=(NSR_SERVER=lrch1d50,NSR_GROUP=CNAPROD_ORA)';
	#send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA)';
	send 'NSR_ENV=(NSR_SERVER=sch1h549,NSR_GROUP=CNAPROD_ORA)';
  crosscheck archivelog all;
  BACKUP ARCHIVELOG ALL tag winr_A_20201119165306
  format 'rmanArchD_%d_%s_%p_%t_D_20201119165306' FILESPERSET 10 DELETE INPUT;
} 

connect target /
 connect rcvcat rman/mu2d@rcat2p;
---Full backup script example
rman target / catalog rmancat/Kjdrt103e@rcat1p
-- Full BRMAN Backup script
run
{
   set command id to 'FullRMAN_Backup_RUAUDP';
   sql 'alter system checkpoint local';
   allocate channel t0 type 'sbt_tape';
   allocate channel t1 type 'sbt_tape';
   allocate channel t2 type 'sbt_tape';
   allocate channel t3 type 'sbt_tape';
   #Always check the nsr_client and nsr_server
   #send 'NSR_ENV=(NSR_SERVER=nwprdsvc1,NSR_GROUP=CNAPROD_ORA,NSR_CLIENT=sch1h234)';
   send 'NSR_ENV=(NSR_SERVER=sch1h549,NSR_GROUP=CNAPROD_ORA)';
   backup 
     database
      skip inaccessible tag winr_H_D_ON_20201118083900
      filesperset 20 format 'rmanDBFull_%d_%s_%p_%t_D_20201118083900'
      (database);
   sql 'alter system switch logfile';
   sql 'alter system archive log current';
   crosscheck archivelog all;
   backup tag winr_H_D_ON_20201118083900
      filesperset 100 format 'rmanArchD_%d_%s_%p_%t_D_20200612071539'
      (archivelog all delete input);	  
	backup spfile tag winr_H_D_ON_20201118083900 
	  format 'rmanSPfile_%d_%s_%p_%t_D_20201118083900'; 
	backup current controlfile tag winr_H_D_ON_20201118083900 
	   format 'rmanCntrlFile_%d_%s_%p_%t_D_20201118083900'; 
   delete expired archivelog all;
   release channel t0;
   release channel t1;
   release channel t2;
   release channel t3;
}

backup archivelog all not backed up 1 times tag 'ecfp_A_D_ON_20181119023018';

-- below the location of the backup script
/csapps/oracle/backup/bin/bu --- bu is the script for rman back, required to pass some params

/csapps/oracle/backup/bin/bu -s j76adc -o archdelnday 1 -N 2 -L 1-E rahul.chaudhari@atos.net
/csapps/oracle/backup/bin/bu -s ecfp -o archdelnday 1 -N 2 -L 1-E rahul.chaudhari@atos.net

ORACLE_SID=vtaped
max_drives=2
min_drives=1

timestamp=$(date '+%Y%m%d%H%M%S')
umask 027
#Cleanup up old logs
find /csapps/oracle/backup/logs/${ORACLE_SID} -mtime +30 -exec rm -f {} \;
#run the backup (Virtual onsite)
bu_operation=hot
/csapps/oracle/backup/bin/bu -s ${ORACLE_SID} -o $bu_operation \
   -C Oracle -S Daily_VTL -m mailfail -B \
   -N $max_drives -L $min_drives -w 60 -F\
   >/csapps/oracle/backup/logs/${ORACLE_SID}/$timestamp.do_${ORACLE_SID}_${bu_operation}_offsite.kshlog \
   2>&1

   
#!/bin/ksh

ORACLE_SID=v97adc
bu_operation=cold
max_drives=2
min_drives=1

timestamp=$(date '+%Y%m%d%H%M%S')
umask 027
#Cleanup up old logs
find /csapps/oracle/backup/logs/${ORACLE_SID} -mtime +30 -exec rm -f {} \;
#run the backup
/csapps/oracle/backup/bin/bu -s ${ORACLE_SID} -o $bu_operation -E Carole.Rocco@cna.com\
   -C Oracle_sch1h071 -S Daily -m mailfail -B \
   -N $max_drives -L $min_drives \
   >/csapps/oracle/backup/logs/${ORACLE_SID}/$timestamp.do_${ORACLE_SID}_${bu_operation}.kshlog \
   2>&1

   j76adc (sch1h071) 
   /csapps/oracle/backup/bin/bu -s j76adc -o archdelnday 1 -N 2 -L 1-E rahul.chaudhari@atos.net\
   
   bu  -s test805 -o hotdelarchnday 1
   
    bu -s test805 -o archdel
	
	 bu -s test805 -o fixarchdel
   
   hotdelarch
   
   archdel
   
   PESDBO
   
   
   /csapps071/oracle/backup/bin/rman_connect_file.rcat1p
   
   Select owner, object_name, object_type, status from dba_objects where STATUS = 'INVALID' and owner = 'PESDBO'; 
======================================================================================================

-- sch1h649 
newsid dnbrr
rman target / catalog rman/rman2tst@rcat2t
run {
    set command id to '16302665108';
   allocate channel t0 type 'sbt_tape';
   allocate channel t1 type 'sbt_tape';
   allocate channel t2 type 'sbt_tape';
    send 'NSR_ENV=(NSR_SERVER=lrch1d50,NSR_GROUP=CNAPROD_ORA)';
   sql 'alter system switch logfile';
    sql 'alter system archive log current';
    backup tag dnbrr_A_D_ON_202108301448
       filesperset 300
       format 'rmanArchD_%d_%s_%p_%t_D_16302665108'
       (archivelog all delete input);
} 
======================================================================================================

---examples of the bu scripts
->ps -ef |grep bu
  oracle 19202276 58589460   0 19:41:23      -  0:00 tee -a /csapps/oracle/backup/logs/pshcmp/20181118190000_hotdelarchnday_bu.log
  oracle 30212152    66236   0 01:44:08  pts/4  0:00 grep bu
  oracle 58589460 66912618   0 19:00:00      -  0:00 /bin/ksh /csapps/oracle/backup/bin/bu -s pshcmp -o hotdelarchnday 1 -C sau1h134 -p nwprdsvc1 -S Daily -m mailstat -N 6 -L 0 -w 45 -d 20 -a 100 -R /csapps/oracle/backup/bin/rman_connect_file.rcat2p -E zahmed@us.ibm.com
  oracle 66060682 55509342   0   Nov 17      -  0:00 /bin/ksh /csapps/oracle/backup/bin/bu -s cedmp -o archdel -G CNAPROD_ORA -m mailstat -R /csapps/oracle/backup/bin/rman_connect_file.rcat2p -N 2 -L 0 -a 300 -w 60
  oracle  3801756  1508304   0 01:38:42  pts/3  0:00 /bin/ksh /csapps/oracle/backup/bin/bu -s ecfp -o archdelnday 1 -R /csapps/oracle/backup/bin/rman_connect_file.rcat2p -N 7 -L 1 -E rahul.chaudhari@atos.net -d 20 -a 300 -w 60
  oracle 11076236 11993890   0   Nov 18      -  0:00 tee -a /csapps/oracle/backup/logs/livcycp/20181118002021_hotdelarchnday_bu.log
  oracle  7472096 11993890   0   Nov 18      -  0:00 /bin/ksh /csapps/oracle/backup/bin/bu -s livcycp -o hotdelarchnday 2 -G CNAPROD_ORA -m mailstat -R /csapps/oracle/backup/bin/rman_connect_file.rcat2p -N 2 -L 0 -d 20 -a 300 -w 60
  oracle 10748918 58589460   0 19:41:23      -  0:00 /bin/ksh /csapps/oracle/backup/bin/bu -s pshcmp -o hotdelarchnday 1 -C sau1h134 -p nwprdsvc1 -S Daily -m mailstat -N 6 -L 0 -w 45 -d 20 -a 100 -R /csapps/oracle/backup/bin/rman_connect_file.rcat2p -E zahmed@us.ibm.com
  oracle 11993890 64553038   0   Nov 18      -  0:00 /bin/ksh /csapps/oracle/backup/bin/bu -s livcycp -o hotdelarchnday 2 -G CNAPROD_ORA -m mailstat -R /csapps/oracle/backup/bin/rman_connect_file.rcat2p -N 2 -L 0 -d 20 -a 300 -w 60
sau1h134:oracle:seed11g1:/csapps/oracle/backup/logs/ecfp
=======================================================================================================


/bin/ksh /csapps/oracle/backup/bin/bu -s cedmp -o archdel -G CNAPROD_ORA -m mailstat -R /csapps/oracle/backup/bin/rman_connect_file.rcat2p -N 2 -L 0 -a 300 -w 60


/bin/ksh /csapps/oracle/backup/bin/bu -s ecfp -o archdel -G CNAPROD_ORA -m mailstat -R /csapps/oracle/backup/bin/rman_connect_file.rcat2p -N 2 -L 0 -a 300 -w 60 > /csapps/oracle/backup/logs/ecfp/ecfp_do_ecfp_19Nov2018013736126.kshlog 2>&1


/bin/ksh /csapps/oracle/backup/bin/bu -s ecfp -o hotdelarchnday 1 -C sau1h134 -p nwprdsvc1 -S Daily -m mailstat -N 6 -L 0 -w 45 -d 20 -a 100 -R /csapps/oracle/backup/bin/rman_connect_file.rcat2p -E zahmed@us.ibm.com

--- rman cmd command script can found like
/csapps/oracle/backup/logs/ecfp/tmp/archdel_rman_arch_or_hotarch.cmd

 run {
    allocate channel t0 type 'sbt_tape';
    allocate channel t1 type 'sbt_tape';
     send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA)';
    sql 'alter system switch logfile';
    sql 'alter system archive log current';
   backup tag ecfp_A_D_ON_201811190150
     filesperset 300
   format 'rmanArchD_%d_%s_%p_%t_D_1542613857'
      (archivelog all delete input);
  }

===============================================================================================

-- execute the bloew command to check the date and replace in tag option below
date '+%Y%m%d%H%M%S'
20181119023018

-- take the sid for which archive log's abckup has to be ran
-- replace the below into rman command
<<SID_NAME>>_A_D_ON_20181119023018


rman target /

connect catalog rman/mu2d@rcat2p

connected to recovery catalog database

run {
  allocate channel t0 type 'sbt_tape';
  allocate channel t1 type 'sbt_tape';
  send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA)';
  sql 'alter system switch logfile';
  sql 'alter system archive log current';
  backup tag cnaprep_A_D_ON_20181122034001
  filesperset 300
  format 'rmanArchD_%d_%s_%p_%t_D_20181122034001'
  (archivelog all delete input);
}

===============================================================================================

--- bu HOT backup

connect target /;
connect rcvcat rman/mu2d@rcat2p ;
run {
    set command id to '1542589200';
   sql 'alter system checkpoint local';
   allocate channel t0 type 'sbt_tape';
   allocate channel t1 type 'sbt_tape';
   allocate channel t2 type 'sbt_tape';
   allocate channel t3 type 'sbt_tape';
   allocate channel t4 type 'sbt_tape';
   allocate channel t5 type 'sbt_tape';
   send 'NSR_ENV=(NSR_SERVER=nwprdsvc1,NSR_GROUP=CNAPROD_ORA)';
   backup incremental level 0
      skip inaccessible tag pshcmp_H_D_ON_201811181900
      filesperset 20
      format 'rmanHotD_%d_%s_%p_%t_D_1542589200'
      (database include current controlfile);
   sql 'alter system switch logfile';
   sql 'alter system archive log current';
   backup tag pshcmp_H_D_ON_201811181900
      filesperset 100
      format 'rmanArchD_%d_%s_%p_%t_D_1542589200'
      (archivelog all);
   backup tag pshcmp_H_D_ON_201811181900
      filesperset 100
      format 'rmanArchD_%d_%s_%p_%t_D_1542589200'
      (archivelog
       until time 'SYSDATE - 1'
       delete input);
   }


 
run { 
 allocate channel ch1 type Disk maxpiecesize = 1900M FORMAT '/path/hbk_%t_set%s_piece%p_dbid%I.rman'; 
 backup incremental level 0 
 tag cold_db_f 
 filesperset 1 
 (database); 
 backup archivelog all delete all input FORMAT '/path/hbk_%t_set%s_piece%p_dbid%I.rman'; 
 backup spfile format '/oradata/orcl/rmanb/spfile_%d_%s_%T_dbid%I.rman'; 
 backup current controlfile format '/path/ctl_%t_dbid%I.rman'; 
} 
 


RUN
{
  ALLOCATE CHANNEL ch11 TYPE DISK MAXPIECESIZE 10G;
  BACKUP
  FORMAT '/u03/app/oracle/TEST/%d_D_%T_%u_s%s_p%p'
  DATABASE
  CURRENT CONTROLFILE
  FORMAT '/u03/app/oracle/TEST/%d_C_%T_%u'
  SPFILE
  FORMAT '/u03/app/oracle/TEST/%d_S_%T_%u'
  PLUS ARCHIVELOG
  FORMAT '/u03/app/oracle/TEST/%d_A_%T_%u_s%s_p%p';
  RELEASE CHANNEL ch11;
}

==============================================================================

-- ecfp

sau1h133:oracle:ecfp1:/csapps/oracle/backup/logs/ecfp
->vi 20190114000031_hotdelarchnday_bu_all.log
sau1h133:oracle:ecfp1:/csapps/oracle/backup/logs/ecfp
->cat /csapps/oracle/backup/bin/rman_connect_file.rcat2p
rman/mu2d@rcat2p
sau1h133:oracle:ecfp1:/csapps/oracle/backup/logs/ecfp
->vi 20190114000031_hotdelarchnday_bu_all.log
sau1h133:oracle:ecfp1:/csapps/oracle/backup/logs/ecfp
->cat /csapps/oracle/backup/logs/ecfp/tmp/hotdelarchnday_rman_arch_or_hotarch.cmd
connect target /;
connect rcvcat rman/mu2d@rcat2p ;
run {
    set command id to '1547532028';
   sql 'alter system checkpoint local';
   allocate channel t0 type 'sbt_tape';
   allocate channel t1 type 'sbt_tape';
   allocate channel t2 type 'sbt_tape';
   allocate channel t3 type 'sbt_tape';
    send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA)';
   backup incremental level 1 cumulative
      skip inaccessible tag ecfp_H_D_ON_201901150000
      filesperset 150
      format 'rmanHotD_%d_%s_%p_%t_D_1547532028'
      (database include current controlfile);
   sql 'alter system switch logfile';
   sql 'alter system archive log current';
   backup tag ecfp_H_D_ON_201901150000
      filesperset 200
      format 'rmanArchD_%d_%s_%p_%t_D_1547532028'
      (archivelog all);
   backup tag ecfp_H_D_ON_201901150000
      filesperset 200
      format 'rmanArchD_%d_%s_%p_%t_D_1547532028'
      (archivelog
       until time 'SYSDATE - 1'
       delete input);
   }
==============================================================================




sau1h133:oracle:cedmp1:/csapps/oracle/backup/scripts
->cat do_cedmp_rmancold.ksh
#!/bin/ksh
ORACLE_SID=cedmp
#max_drives=3
max_drives=8
min_drives=0

networker_group=CNAPROD_ORA

timestamp=$(date '+%Y%m%d%H%M%S')
umask 027

#Cleanup up old logs
find /csapps/oracle/backup/logs/${ORACLE_SID} -mtime +30 -exec rm -f {} \;

#run the backup - COLD
bu_operation=cold
##/csapps/oracle/backup/bin/bu -s ${ORACLE_SID} -o $bu_operation \
/csapps/oracle/backup/bin/bu_11g -s ${ORACLE_SID} -o $bu_operation \
   -G $networker_group -m mailstat -R /csapps/oracle/backup/bin/rman_connect_file.rcat2p \
   -N $max_drives -L $min_drives -d 20 -a 100 -w 60 \
   >/csapps/oracle/backup/logs/${ORACLE_SID}/$timestamp.do_${ORACLE_SID}_${bu_operation}.kshlog \
   2>&1
sau1h133:oracle:cedmp1:/csapps/oracle/backup/scripts
-> 


---- register database after modifying the rman catalog 
->cat /depot/oracle/temp/rman_rest_9i.ksh
#ALL_DATABASES=`cat /etc/oratab|grep -v "^#"|grep -v "N$"|cut -f1 -d: -s`
ALL_DATABASES=`ps -ef|grep ora_smon_ |grep -v grep|awk -F"_" '{print $3 " " $4}'|sort`
for DB in $ALL_DATABASES
do
   unset  TWO_TASK
   export ORACLE_SID=$DB
   export ORACLE_HOME=`grep "^${DB}:" /etc/oratab|cut -d: -f2 -s`
   export PATH=$ORACLE_HOME/bin:$PATH
   echo "---> Database $ORACLE_SID, using home $ORACLE_HOME"
   rman target / catalog rmancat/Kjdrt103e@rcat1p <<ENDofSQL
register database;
ENDofSQL
done

<end node> 5P9i0s8y19Z
dt=Text
<node>
backup server
2
backup server (nwprdsvc1)


-- cloning 8i DB server schwkh01
/csapps/oracle/backup/bin/duplicate_chi817_chisenme.ksh 

<end node> 5P9i0s8y19Z
dt=Text
<node>
OEM OMS
2
-- if lrau1p19 and lrau1p20 DB server's are restarting for any OS Patching or DB patching then
-- how to stop and start oem13c DB and oms

Steps to stop oem

As oracle user

Cd /csapps/oracle/oem13c/bin

./emctl stop oms -all

To start oem 13c

As oracle user

Cd /csapps/oracle/oem13c/bin

./emctl start oms

<end node> 5P9i0s8y19Z
dt=Text
<node>
start OID/LDAP
2

From: Surabhi,Aravind (TCS) (Contractor) 
Sent: Wednesday, July 18, 2018 4:19 AM
To: CNA_TCS_ITIS_Database_Oracle
Subject: Steps to start OID/ LDAP services

Hi Team,

It is very important that we start OID/LDAP services whenever Unix team reboots below servers

Lrau1p19
Lrau1p20
Lrch1d36
Lrch1d37
Sch1h020
Sch1h234

-- For latest linux servers follow below process
Go to location -  /csapps/oracle/middleware/asinst_1/bin

-- To check status of OID services - 
/csapps/oracle/middleware/asinst_1/bin/./opmnctl status 

-- To start OID services - 
/csapps/oracle/middleware/asinst_1/bin/./opmnctl startall

-- To check status of OID services - 
/csapps/oracle/middleware/asinst_1/bin/./opmnctl status

-- Check the status multiple times until all processes status becomes 'Alive'

-- For legacy Servers – sch1h020 , sch1h234
cd /csapps/oracle/cnascripts
./cna_oid_startup

./cna_oid_shutdown

ps –ef | grep oid

<end node> 5P9i0s8y19Z
dt=Text
<node>
Policy Center - Monthly Rele.
2

Below is the document to follow for Policy Center  monthly release activity .

-- loging to sau1h644 DB server

newsid pctrap

1. Prior to the monthly release, create a new directory and copy the scripts from the prior month. For example, for July:
mkdir /csapps/oracle/dbascripts/pctrap/builds/Sept2019_Indexes
cd /csapps/oracle/dbascripts/pctrap/builds/Sept2019_Indexes

-- copy the perious month's indexes files to current months
cp /csapps/oracle/dbascripts/pctrap/builds/Aug2019_Indexes/*.sh .

-- copy the perious month's indexes files to current months
cp /csapps/oracle/dbascripts/pctrap/builds/Aug2019_Indexes/*.sql .

2. During the release night, the Policy Center team will notify you after the maint_off script has completed. At this point, 
   they will be ready for you to run the custom indexes. This is usually around midnight CST.

3. You will need to run the following index scripts simultaneously (in parallel). This will take approximately an hour. 
   The cr_indexes1a.sh, cr_indexes2.sh and cr_indexes3.sh scripts will run the longest.

cr_indexes1.sh
cr_indexes1a.sh
cr_indexes2.sh
cr_indexes3.sh
cr_indexes4.sh
cr_indexes5.sh

for example:

newsid pctrap

cd /csapps/oracle/dbascripts/pctrap/builds/Sept2019_Indexes: 

-- execute these 6 scripts in parallel :
nohup  cr_indexes1.sh > cr_indexes1_Sept2019.out & 
nohup cr_indexes1a.sh > cr_indexes1a_Sept2019.out & 
nohup cr_indexes2.sh > cr_indexes2.sh_Sept2019.out & 
nohup cr_indexes3.sh > cr_indexes3.sh_Sept2019.out & 
nohup cr_indexes4.sh > cr_indexes4.sh_Sept2019.out &
nohup cr_indexes5.sh > cr_indexes5.sh_Sept2019.out & 


4. Sometimes the scripts above will complete quickly because the indexes were not dropped during the deployment. 
   That’s fine. The deployment is based on a Guidewire procedure. The typical deployment drops all objects, but there 
   are months when it is not a “typical” deployment. During those times, the indexes will remain and we have it easy. 
   If the indexes still existed, that is the end of what you need to do. At this point, notify the application team 
   that the indexes were not dropped during the deployment and they can resume their activities. You do not need to do anything 
   further than this step.

5. If the indexes do get recreated, when all of the above scripts have successfully completed, notify the application team 
   that the index procedure is done and they can resume their activities. You can verify that all indexes were recreated 
   successfully by running verify_indexes.sql. You should get 29 results.
   
6. Run alter_indexes_logging.sql

login to the db "pctrap" and run the below .sql scripts after completion of jobs 

sqlplus "/as sysdba" 
@verify_indexes.sql  --- : you should get 29 results
@alter_indexes_logging.sql 


-- this is for new indexes, than execute the below script
7. The last thing you need to do is run stats. Just kick them off, as they run a while and check later on that day:
table_stats.sh

Example:

cd /csapps/oracle/dbascripts/pctrap/builds/Sept2019_Indexes:
nohup table_stats.sh > table_stats_Sept2019.out &

<end node> 5P9i0s8y19Z
dt=Text
<node>
Control-M
2
-- controlM backup information required to check from here
cm90p - control M database  -- We can Query this databases for Control-m Job information. 

Control-M  database cm90r for pre-prod databases

Control-M  database cm90p for prod databases 

-- all jobs are logged in on the same server location
/csapps/bmc/ctm/ctm/sysout

ls -larts /csapps/bmc/ctm/ctm/sysout/*PH233HRSMTRRWKLY*

select jobname, nodeid, owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline 
from ctmuser.cms_jobdef 
where jobname in ('PH133EXP','P243CPSPBS','LAP21BCODBPEXPDP','PPRODINT1CSEPX','PLRCH1D34EXP',
'P143CVPTPD','PH231DCNAD','PD25EXP','PH018DBSTA','PH007HPROB','PH025HVAPR',
'D36OID1REXP','PLRAU1P20OID2PST','PLR24ENCAPPH','LAP21BCODBPEXPDP',
'PH234ABPMAP','PBAPRDILP12CPST') ;

select nodeid,owner,author,cmdline,descript, jobname, schedtab, wdaystr scheday, fromtime hour 
from ctmuser.cms_jobdef 
where regexp_like(jobname,'*papcp*','i') 
 and not regexp_like(jobname,'*papcintp*','i') 
order by owner,author;


-- jobs to be find in database for ControlM if failed
select nodeid,owner,author,cmdline,descript, jobname, schedtab, wdaystr scheday, fromtime hour 
from ctmuser.cms_jobdef 

select jobname, nodeid, owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline 
from ctmuser.cms_jobdef 
where jobname ='PBADRSIEEXP'

select jobname, nodeid, owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline 
from ctmuser.cms_jobdef 
where regexp_like(jobname,'*dnbbrp*','i') 


--- if any controlM jobs are failing then we have to check with it
--- include jobname
select nodeid,owner,author,cmdline,descript, jobname, schedtab, wdaystr scheday, fromtime hour 
from ctmuser.cms_jobdef 
where jobname='PLR24ULSNRPIM' ; 

select nodeid,owner,author,cmdline,descript, jobname, schedtab, wdaystr scheday, fromtime hour 
from ctmuser.cms_jobdef 
where jobname='PBCPRDRMWH';

select nodeid,owner,author,cmdline,descript, jobname, schedtab, wdaystr scheday, fromtime hour 
from ctmuser.cms_jobdef 
where jobname like '%PSJPCP%' 
order by owner,author;

select nodeid,owner,author,cmdline,descript, jobname, schedtab, wdaystr scheday, fromtime hour 
from ctmuser.cms_jobdef 
where  upper(nodeid) like  'surfsda701' 
order by owner,author;


-- search with the server and backup scripts
select nodeid,owner,author,cmdline,descript, jobname, schedtab, wdaystr scheday, fromtime hour 
from ctmuser.cms_jobdef 
where  upper(nodeid) like  '%SAU1H133%' 
 and regexp_like(cmdline,'/csapps/oracle/backup','i')
order by owner,author;

select nodeid,owner,author,cmdline,descript, jobname, schedtab, wdaystr scheday, fromtime hour 
from ctmuser.cms_jobdef 
where descript like '%MAX%' 
order by owner,author;


select * 
from ctmuser.cms_jobdef 
where  regexp_like(jobname,'cnacp','i')


select * from ctmuser.cms_jobdef
where jobname='PBAPRHPRIMVAP'


select * 
from ctmuser.cms_jobdef 
where  regexp_like(nodeid,'lrau1p22','i')
 and regexp_like(jobname,'cnacp','i')
order by owner,author;


select * 
from ctmuser.cms_jobdef 
where regexp_like(nodeid,'sch1p148','i')
 -- and creationdatetime like '2018%'
  and regexp_like(descript,'*wrtp*','i')

logs location:
========================================================================================================

-- Need to login controlM DB CM90P@lrau1p24 
-- and below is the script to check any jobs

set pages 1000 lines 320
set linesize 150
col schedtab format a10
col scheday format a15
col jobname format a10
col nodeid format a10
col cmdline format a30
col descript format a25
col author format a8
col owner format a8
col jobname format a15
select nodeid,owner,author,cmdline,descript, jobname, 
       schedtab, wdaystr scheday, fromtime hour 
  from ctmuser.cms_jobdef 
 where jobname like '%P84889MEMC%';


-----------------------------------------------------

select * --jobname, upper(nodeid), owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline,priority,maxdays,maxruns
from ctmuser.cms_jobdef 
where regexp_like(descript,'*export*','i') and 
 schedtab in ('DATABASE_BACKUP_TMP','ORACLE_EXPORTS','ORACLE_UTILITIES','DATABASE_BACKUP','DATABASE_BACKUPS','DATABASE_MAINTENANCE')
--and regexp_like(nodeid,'sau1h644','i')
  and upper(owner) in ('ORACLE','DBADM') -- not in ('cnaw2k/sqlext','cnaw2k/sqlservices','cnaw2k\itcam','susplan')
 -- and upper(nodegrp) in ('LRAU1P17','LRAU1P18','LRAU1P19','LRAU1P20','LRAU1P21','LRAU1P22','LRAU1P23','LRAU1P24','LRAU1P25','LRCH1D35','SAU1H048',
--'SAU1H049','SAU1H053','SAU1H054','SAU1H068','SAU1H069','SAU1H133','SAU1H134','SAU1H137','SAU1H138','SAU1H346','SAU1H347',
--'SAU1H352','SAU1H353','SAU1H371','SAU1H372','SAU1H373','SAU1H374','SAU1H644','SAU1H688','SCH1H020','SCH1H067','SCH1H068',
--'SCH1H231','SCH1H234','SCH1H537','SCH1H538','SCH1H904','SCH1H906','SCH1H907','SCH1P001','SCH1P079','SCH1P144','SCH1P148',
--'SCH1P215','SCH1P233','SCH1P238','SCH1P241','SCH1P245','SCH1P253','SCH1P268','SCH1P492','SCHWKH01','SUKGCH05','SURFSDA112',
--'SURFSDA701','SURFSDA801','SW3L1H03')
and (regexp_like(descript,'*AEMCMP*|*AEMP*|*CDLTP*|*ECMA1P1P*|*ECMA1P2P*|*ECMA1P3P*|*ECMA1P4P*|*ECMFSRP*|*ECMINP*|*ECMP1P3P*','i')
    or regexp_like(descript,'*ECMP1P4P*|*ECMRADRP*|*ECMRDR2P*|*ECMRDR3P*|*ECMRDR4P*|*ESTR2P*|*INFSH96P*|*PAPCINTP*|*PAPCP*|*RECNPP*','i')
    or regexp_like(descript,'*SDMP*|*TRUSTWAP*|*WSRR12P*|*BUDP*|*CLMCCP*|*CLMCMP*|*CNAPREP*|*DOCMAKP*|*ECMP1P2P*|*INFMRL9P*','i')
    or regexp_like(descript,'*OEM12CP*|*SPCP*|*OID1P*|*OID2P*|*DYNATRCP*|*BCODBP*|*DYNARC2P*|*ILP12CP*|*CNACP*|*ECMFNETP*|*ECMKBP*','i')
    or regexp_like(descript,'*ECMP1P1P*|*J071P*|*RTQPCFP*|*ULSNP*|*CYA1FN5P*|*CYA2FN5P*|*ECM1FN5P*|*ECM2FN5P*|*ECMSMP*|*ALIRP*|*BNRP*','i')
    or regexp_like(descript,'*BPPMP*|*CM90LOGP*|*CM90P*|*CM90SURP*|*ECMCONNP*|*EM90P*|*EM90SURP*|*ESBNP*|*IBMUCDP*|*IIBP*|*IIQP*|*SONARP*','i')
    or regexp_like(descript,'*SPD1P*|*SPI12P*|*ULSAUNP*|*ULSNRP*|*CLMPMP*|*CLMXSP*|*COLLQNP*|*DMFP*|*DOCDISTP*|*EFIP*|*ELMP*|*ENCAPP*|*MVRXNP*','i')
    or regexp_like(descript,'*RAPIDNP*|*BOXIAUDP*|*BOXICMSP*|*BOXILCMP*|*BOXITLSP*|*RCAP*|*CAMILP*|*CNACOMP*|*CNACPP*|*CNACPRP*|*INFSHR9P*|*INSCNAFP*','i')
    or regexp_like(descript,'*RCAT2P*|*SSPP*|*WCMSP*|*WMBESBP*|*WPDBP*|*WPDEXTP*|*WPDWCMP*|*WSRXP*|*SSPWCMP*|*UWPAP*|*UWPP*|*INFPSP*|*PSCPCP*|*PSJPCP*','i')
    or regexp_like(descript,'*PSTFNP*|*HYPP*|*PSARCP*|*ARIBYP*|*CEDMP*|*CEDPP*|*CEDRP*|*CLMEDIP*|*CSEP*|*DNBRP*|*EDVP*|*EVTLOGP*|*ITCAMP*|*LIVCYCP*|*OIDP*','i')
    or regexp_like(descript,'*PSHCMP*|*PWDPOLP*|*RSTGP*|*SPINP*|*SURHRP*|*ECFP*|*PDFGENP*|*SPCCONVP*|*SPCINTP*|*TRECAP*|*TRECP*|*DLPP*|*ILP12P*|*RMWVIOP*','i')
    or regexp_like(descript,'*CYA1FNP*|*CYA2FNP*|*ECM1FNP*|*ECM2FNP*|*RTPDSP*|*PMLTP*|*LTCMIP*|*HYPMDP*|*MERLFVP*|*ACBP*|*AGENP*|*BOE3AUDP*|*BOE3CMSP*|*BOE3LCMP*|*BOE3TLSP*','i')
    or regexp_like(descript,'*DNBBRP*|*DOCMKRP*|*ESFMP*|*ESTRP*|*FRMMP*|*GLTCFP*|*IBMD2P*|*IBMDX1P*|*IBMDX2P*|*IBMDX3P*|*MERLAPP*|*MOODYSP*|*MVRXP*|*OPTDIRP*|*PAEUSP*|*PCTRAP*','i')
    or regexp_like(descript,'*PNLRP*|*PRIMAP*|*PRIMVAP*|*PRIMVODP*|*PRIMVSTP*|*PSEPMP*|*PSHRMP*|*PSITE60P*|*PSPRTP*|*RCAT1P*|*RCTP*|*SREP*|*VAPFP*|*VCMFP*|*WBI1P*|*WITCAMP*|*WKINP*','i')
    or regexp_like(descript,'*WMBLP*|*WTDWP*|*ECMPJP*|*FNREP*|*HYPERESP*|*ITINVP*|*J28APP*|*J76APP*|*MMARTP*|*ONDP*|*RMPP*|*SENNICOP*|*SFINSP*|*SOLDP*|*V97APP*|*VAPIP*|*CCDP*|*CDMP*','i')
    or regexp_like(descript,'*CIMFP*|*DBAP*|*ECMISP*|*FDMGTP*|*IPCP*|*LOGP*|*MTRAKP*|*PIRMP*|*PROBIP*|*PSCRP*|*PSITE50P*|*WASSESP*|*XPRP*|*BRPTP*|*NGLAP*|*NGLP*|*NTKP*|*AGUAP*|*BLADEP*','i')
    or regexp_like(descript,'*BLDPRTP*|*BLDWHP*|*COREFP*|*COREFSP*|*DNBBRAP*|*FINACHP*|*ILVP*|*IRISP*|*NTINSP*|*OAPEXP*|*OEMP*|*PRIMVSGP*|*RSMTRP*|*RTPDZP*|*UETP*|*APDLP*|*APESP*|*ASTMBP*','i')
    or regexp_like(descript,'*AXPRP*|*BCFP*|*BCSLGP*|*BLDFRGP*|*BPMAP*|*CASP*|*CMPSP*|*CMTP*|*CNAEDDP*|*COIP*|*COLLQP*|*CRRP*|*DIMP*|*DTCMP*|*ESSOP*|*ESWKP*|*FCACP*|*FNOLSP*|*FRBPMP*','i')
    or regexp_like(descript,'*GLTCCAP*|*HAILSTMP*|*LINOLP*|*LSBP*|*M2TRAKP*|*MAXBP*|*MBPP*|*MONITP*|*MPASP*|*OCIP*|*ONDBP*|*ORVP*|*PAEUSRSP*|*PCTRP*|*PESOP*|*PONGP*|*PRISMXP*|*QACSP*','i')
    or regexp_like(descript,'*RCWRP*|*RECONP*|*RUAUDP*|*SCAP*|*SCHIP*|*SOSBP*|*SSOTP*|*SUBRP*|*SVCTRP*|*TMTRKP*|*CAOP*|*CTRAP*|*FSPFP*|*CTRP*|*ATLASP*|*BOAUD2P*|*BOCMS2P*|*CRESTAP*','i')
    or regexp_like(descript,'*DUNP*|*EDAP*|*EFILEP*|*EUSP*|*IATP*|*IBMDP*|*INFMTP*|*INFOTP*|*INMLP*|*ITIMP*|*PCALEP*|*PMAMLP*|*PMAUDP*|*PMEMLP*|*PX2CWP*|*PX2DAP*|*PX2ESP*|*PX2IDP*','i')
    or regexp_like(descript,'*PX2INP*|*PX2PAP*|*PX2POP*|*PX2SPP*|*PX2SYP*|*PX2WPP*|*RKMRP*|*SIEP*|*SPDP*|*SPIP*|*STFILGP*|*VNCLP*|*VNJGP*|*WBIP*|* C99TPACT*|*C99TPACT*|*C99TPADL*','i')
    or regexp_like(descript,'*C99TPFBC*|*R08TPTMP*|*B89TPGIC*|*G28TPCIR*|*B905PCED*|*B90PQSCH*|*B90PYSCH*|*B90TPAPS*|*B90TPSCH*|*C88TPPOS*|*AAPDP*|*AGLP*|*CARP8*|*CCSPP*|*CMDP*|*CSAP*','i')
    or regexp_like(descript,'*HRCPP*|*J07P*|*PDEP*|*RDMP*|*RS1PP*|*VPTPP*|*WRTP*|*H63TPCOS*|*H63TPDNL*|*R08TPLOC*|*R08TPMDD*|*B88TPTPA*|*C87TPCAM*|*C88TPAAC*|*C88TPAUD*|*G29TPBAM*','i')
    or regexp_like(descript,'*G29TPLCA*|*G29TPLCR*|*H66TPPFC*|*H66TPPLC*|*H66TPPYR*|*CARDSP*|*ETSP*|*MBPP8*|*PCLP*|*PERRP*|*PSPR*|*SLVPRD*|*SMFRP*|*SPNP8*|*TBCLNP*|*CAOP8*|*PSFN*','i')
    or regexp_like(descript,'*ABOREP*|*DIG8P*|*E32P*|*GRCLMSP*|*INMP*|*ISGP*|*H52TPRME*|*H51P1CLM*|*H51P1CPI*|*H51P1CRF*|*H51P1LAS*|*H51P1NAR*|*H51P1RET*|*H51P1TPA*|*H73P1TRN*','i')
    or regexp_like(descript,'*H73TPCLR*|*H73TPWHS*|*CHI817*|*CIEAPP*|*CMSAPP*|*CRCAPP*|*MARAPP*|*UKSNPP*|*DWUAT*|*TPUAT*|*P1DW*|*RCAT*|*P1TP*|*TLPRD*|*ILP12CEP*','i')    )
order by upper(nodeid) asc
;                                           


------------------------------------------------------------------

or regexp_like(descript,'*CYA1FNP*|*CYA2FNP*|*ECM1FNP*|*ECM2FNP*|*RTPDSP*|*PMLTP*|*LTCMIP*|*HYPMDP*|*MERLFVP*|*ACBP*|*AGENP*|*BOE3AUDP*|*BOE3CMSP*|*BOE3LCMP*|*BOE3TLSP*','i')
or regexp_like(descript,'*DNBBRP*|*DOCMKRP*|*ESFMP*|*ESTRP*|*FRMMP*|*GLTCFP*|*IBMD2P*|*IBMDX1P*|*IBMDX2P*|*IBMDX3P*|*MERLAPP*|*MOODYSP*|*MVRXP*|*OPTDIRP*|*PAEUSP*|*PCTRAP*','i')
or regexp_like(descript,'*PNLRP*|*PRIMAP*|*PRIMVAP*|*PRIMVODP*|*PRIMVSTP*|*PSEPMP*|*PSHRMP*|*PSITE60P*|*PSPRTP*|*RCAT1P*|*RCTP*|*SREP*|*VAPFP*|*VCMFP*|*WBI1P*|*WITCAMP*|*WKINP*','i')
or regexp_like(descript,'*WMBLP*|*WTDWP*|*ECMPJP*|*FNREP*|*HYPERESP*|*ITINVP*|*J28APP*|*J76APP*|*MMARTP*|*ONDP*|*RMPP*|*SENNICOP*|*SFINSP*|*SOLDP*|*V97APP*|*VAPIP*|*CCDP*|*CDMP*','i')
or regexp_like(descript,'*CIMFP*|*DBAP*|*ECMISP*|*FDMGTP*|*IPCP*|*LOGP*|*MTRAKP*|*PIRMP*|*PROBIP*|*PSCRP*|*PSITE50P*|*WASSESP*|*XPRP*|*BRPTP*|*NGLAP*|*NGLP*|*NTKP*|*AGUAP*|*BLADEP*','i')
or regexp_like(descript,'*BLDPRTP*|*BLDWHP*|*COREFP*|*COREFSP*|*DNBBRAP*|*FINACHP*|*ILVP*|*IRISP*|*NTINSP*|*OAPEXP*|*OEMP*|*PRIMVSGP*|*RSMTRP*|*RTPDZP*|*UETP*|*APDLP*|*APESP*|*ASTMBP*','i')
or regexp_like(descript,'*AXPRP*|*BCFP*|*BCSLGP*|*BLDFRGP*|*BPMAP*|*CASP*|*CMPSP*|*CMTP*|*CNAEDDP*|*COIP*|*COLLQP*|*CRRP*|*DIMP*|*DTCMP*|*ESSOP*|*ESWKP*|*FCACP*|*FNOLSP*|*FRBPMP*','i')
or regexp_like(descript,'*GLTCCAP*|*HAILSTMP*|*LINOLP*|*LSBP*|*M2TRAKP*|*MAXBP*|*MBPP*|*MONITP*|*MPASP*|*OCIP*|*ONDBP*|*ORVP*|*PAEUSRSP*|*PCTRP*|*PESOP*|*PONGP*|*PRISMXP*|*QACSP*','i')
or regexp_like(descript,'*RCWRP*|*RECONP*|*RUAUDP*|*SCAP*|*SCHIP*|*SOSBP*|*SSOTP*|*SUBRP*|*SVCTRP*|*TMTRKP*|*CAOP*|*CTRAP*|*FSPFP*|*CTRP*|*ATLASP*|*BOAUD2P*|*BOCMS2P*|*CRESTAP*','i')
or regexp_like(descript,'*DUNP*|*EDAP*|*EFILEP*|*EUSP*|*IATP*|*IBMDP*|*INFMTP*|*INFOTP*|*INMLP*|*ITIMP*|*PCALEP*|*PMAMLP*|*PMAUDP*|*PMEMLP*|*PX2CWP*|*PX2DAP*|*PX2ESP*|*PX2IDP*','i')
or regexp_like(descript,'*PX2INP*|*PX2PAP*|*PX2POP*|*PX2SPP*|*PX2SYP*|*PX2WPP*|*RKMRP*|*SIEP*|*SPDP*|*SPIP*|*STFILGP*|*VNCLP*|*VNJGP*|*WBIP*|* C99TPACT*|*C99TPACT*|*C99TPADL*','i')
or regexp_like(descript,'*C99TPFBC*|*R08TPTMP*|*B89TPGIC*|*G28TPCIR*|*B905PCED*|*B90PQSCH*|*B90PYSCH*|*B90TPAPS*|*B90TPSCH*|*C88TPPOS*|*AAPDP*|*AGLP*|*CARP8*|*CCSPP*|*CMDP*|*CSAP*','i')
or regexp_like(descript,'*HRCPP*|*J07P*|*PDEP*|*RDMP*|*RS1PP*|*VPTPP*|*WRTP*|*H63TPCOS*|*H63TPDNL*|*R08TPLOC*|*R08TPMDD*|*B88TPTPA*|*C87TPCAM*|*C88TPAAC*|*C88TPAUD*|*G29TPBAM*','i')
or regexp_like(descript,'*G29TPLCA*|*G29TPLCR*|*H66TPPFC*|*H66TPPLC*|*H66TPPYR*|*CARDSP*|*ETSP*|*MBPP8*|*PCLP*|*PERRP*|*PSPR*|*SLVPRD*|*SMFRP*|*SPNP8*|*TBCLNP*|*CAOP8*|*PSFN*','i')
or regexp_like(descript,'*ABOREP*|*DIG8P*|*E32P*|*GRCLMSP*|*INMP*|*ISGP*|*H52TPRME*|*H51P1CLM*|*H51P1CPI*|*H51P1CRF*|*H51P1LAS*|*H51P1NAR*|*H51P1RET*|*H51P1TPA*|*H73P1TRN*','i')
or regexp_like(descript,'*H73TPCLR*|*H73TPWHS*|*CHI817*|*CIEAPP*|*CMSAPP*|*CRCAPP*|*MARAPP*|*UKSNPP*|*DWUAT*|*TPUAT*|*P1DW*|*RCAT*|*P1TP*|*TLPRD*|*ILP12CEP*','i')





CHG0531509 
CTASK0034568Â  



nohup expdp "'/as sysdba'" directory=DATA_PUMP_DIR dumpfile=expdp_CTASK0034568_CHG0531509_psjpcr_22May2020_%U.dmp logfile=expdp_CTASK0034568_CHG0531509_psjpcr_22May2020_logs.log tables=SYSADM.PS_Z_DAC_MST,SYSADM.PS_Z_DAC_MST_AR_2019 exclude=statistics parallel=5 &



select jobname, nodeid, owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline 
from ctmuser.cms_jobdef 
where regexp_like(descript,'^export*','i')
order by 2 asc;

select unique schedtab from ctmuser.cms_jobdef order by 1 asc;

select jobname, upper(nodeid),nodegrp, owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline,priority,maxdays,maxruns
from ctmuser.cms_jobdef 
where jobname in ('PLRAU1P17EXP','PBAPHGLTCFP','PBAPSGLTCFP','DBAPEGLTCFP','PPCMVRXP');


select * --jobname, upper(nodeid), owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline,priority,maxdays,maxruns
from ctmuser.cms_jobdef 
where regexp_like(descript,'*export*','i') and 
 schedtab in ('DATABASE_BACKUP_TMP','ORACLE_EXPORTS','ORACLE_UTILITIES','DATABASE_BACKUP','DATABASE_BACKUPS','DATABASE_MAINTENANCE')
--and regexp_like(nodeid,'sau1h644','i')
  and upper(owner) in ('ORACLE','DBADM') -- not in ('cnaw2k/sqlext','cnaw2k/sqlservices','cnaw2k\itcam','susplan')
 -- and upper(nodegrp) in ('LRAU1P17','LRAU1P18','LRAU1P19','LRAU1P20','LRAU1P21','LRAU1P22','LRAU1P23','LRAU1P24','LRAU1P25','LRCH1D35','SAU1H048',
--'SAU1H049','SAU1H053','SAU1H054','SAU1H068','SAU1H069','SAU1H133','SAU1H134','SAU1H137','SAU1H138','SAU1H346','SAU1H347',
--'SAU1H352','SAU1H353','SAU1H371','SAU1H372','SAU1H373','SAU1H374','SAU1H644','SAU1H688','SCH1H020','SCH1H067','SCH1H068',
--'SCH1H231','SCH1H234','SCH1H537','SCH1H538','SCH1H904','SCH1H906','SCH1H907','SCH1P001','SCH1P079','SCH1P144','SCH1P148',
--'SCH1P215','SCH1P233','SCH1P238','SCH1P241','SCH1P245','SCH1P253','SCH1P268','SCH1P492','SCHWKH01','SUKGCH05','SURFSDA112',
--'SURFSDA701','SURFSDA801','SW3L1H03')
and (regexp_like(descript,'*AEMCMP*|*AEMP*|*CDLTP*|*ECMA1P1P*|*ECMA1P2P*|*ECMA1P3P*|*ECMA1P4P*|*ECMFSRP*|*ECMINP*|*ECMP1P3P*','i')
    or regexp_like(descript,'*ECMP1P4P*|*ECMRADRP*|*ECMRDR2P*|*ECMRDR3P*|*ECMRDR4P*|*ESTR2P*|*INFSH96P*|*PAPCINTP*|*PAPCP*|*RECNPP*','i')
    or regexp_like(descript,'*SDMP*|*TRUSTWAP*|*WSRR12P*|*BUDP*|*CLMCCP*|*CLMCMP*|*CNAPREP*|*DOCMAKP*|*ECMP1P2P*|*INFMRL9P*','i')
    or regexp_like(descript,'*OEM12CP*|*SPCP*|*OID1P*|*OID2P*|*DYNATRCP*|*BCODBP*|*DYNARC2P*|*ILP12CP*|*CNACP*|*ECMFNETP*|*ECMKBP*','i')
    or regexp_like(descript,'*ECMP1P1P*|*J071P*|*RTQPCFP*|*ULSNP*|*CYA1FN5P*|*CYA2FN5P*|*ECM1FN5P*|*ECM2FN5P*|*ECMSMP*|*ALIRP*|*BNRP*','i')
    or regexp_like(descript,'*BPPMP*|*CM90LOGP*|*CM90P*|*CM90SURP*|*ECMCONNP*|*EM90P*|*EM90SURP*|*ESBNP*|*IBMUCDP*|*IIBP*|*IIQP*|*SONARP*','i')
    or regexp_like(descript,'*SPD1P*|*SPI12P*|*ULSAUNP*|*ULSNRP*|*CLMPMP*|*CLMXSP*|*COLLQNP*|*DMFP*|*DOCDISTP*|*EFIP*|*ELMP*|*ENCAPP*|*MVRXNP*','i')
    or regexp_like(descript,'*RAPIDNP*|*BOXIAUDP*|*BOXICMSP*|*BOXILCMP*|*BOXITLSP*|*RCAP*|*CAMILP*|*CNACOMP*|*CNACPP*|*CNACPRP*|*INFSHR9P*|*INSCNAFP*','i')
    or regexp_like(descript,'*RCAT2P*|*SSPP*|*WCMSP*|*WMBESBP*|*WPDBP*|*WPDEXTP*|*WPDWCMP*|*WSRXP*|*SSPWCMP*|*UWPAP*|*UWPP*|*INFPSP*|*PSCPCP*|*PSJPCP*','i')
    or regexp_like(descript,'*PSTFNP*|*HYPP*|*PSARCP*|*ARIBYP*|*CEDMP*|*CEDPP*|*CEDRP*|*CLMEDIP*|*CSEP*|*DNBRP*|*EDVP*|*EVTLOGP*|*ITCAMP*|*LIVCYCP*|*OIDP*','i')
    or regexp_like(descript,'*PSHCMP*|*PWDPOLP*|*RSTGP*|*SPINP*|*SURHRP*|*ECFP*|*PDFGENP*|*SPCCONVP*|*SPCINTP*|*TRECAP*|*TRECP*|*DLPP*|*ILP12P*|*RMWVIOP*','i')
    or regexp_like(descript,'*CYA1FNP*|*CYA2FNP*|*ECM1FNP*|*ECM2FNP*|*RTPDSP*|*PMLTP*|*LTCMIP*|*HYPMDP*|*MERLFVP*|*ACBP*|*AGENP*|*BOE3AUDP*|*BOE3CMSP*|*BOE3LCMP*|*BOE3TLSP*','i')
    or regexp_like(descript,'*DNBBRP*|*DOCMKRP*|*ESFMP*|*ESTRP*|*FRMMP*|*GLTCFP*|*IBMD2P*|*IBMDX1P*|*IBMDX2P*|*IBMDX3P*|*MERLAPP*|*MOODYSP*|*MVRXP*|*OPTDIRP*|*PAEUSP*|*PCTRAP*','i')
    or regexp_like(descript,'*PNLRP*|*PRIMAP*|*PRIMVAP*|*PRIMVODP*|*PRIMVSTP*|*PSEPMP*|*PSHRMP*|*PSITE60P*|*PSPRTP*|*RCAT1P*|*RCTP*|*SREP*|*VAPFP*|*VCMFP*|*WBI1P*|*WITCAMP*|*WKINP*','i')
    or regexp_like(descript,'*WMBLP*|*WTDWP*|*ECMPJP*|*FNREP*|*HYPERESP*|*ITINVP*|*J28APP*|*J76APP*|*MMARTP*|*ONDP*|*RMPP*|*SENNICOP*|*SFINSP*|*SOLDP*|*V97APP*|*VAPIP*|*CCDP*|*CDMP*','i')
    or regexp_like(descript,'*CIMFP*|*DBAP*|*ECMISP*|*FDMGTP*|*IPCP*|*LOGP*|*MTRAKP*|*PIRMP*|*PROBIP*|*PSCRP*|*PSITE50P*|*WASSESP*|*XPRP*|*BRPTP*|*NGLAP*|*NGLP*|*NTKP*|*AGUAP*|*BLADEP*','i')
    or regexp_like(descript,'*BLDPRTP*|*BLDWHP*|*COREFP*|*COREFSP*|*DNBBRAP*|*FINACHP*|*ILVP*|*IRISP*|*NTINSP*|*OAPEXP*|*OEMP*|*PRIMVSGP*|*RSMTRP*|*RTPDZP*|*UETP*|*APDLP*|*APESP*|*ASTMBP*','i')
    or regexp_like(descript,'*AXPRP*|*BCFP*|*BCSLGP*|*BLDFRGP*|*BPMAP*|*CASP*|*CMPSP*|*CMTP*|*CNAEDDP*|*COIP*|*COLLQP*|*CRRP*|*DIMP*|*DTCMP*|*ESSOP*|*ESWKP*|*FCACP*|*FNOLSP*|*FRBPMP*','i')
    or regexp_like(descript,'*GLTCCAP*|*HAILSTMP*|*LINOLP*|*LSBP*|*M2TRAKP*|*MAXBP*|*MBPP*|*MONITP*|*MPASP*|*OCIP*|*ONDBP*|*ORVP*|*PAEUSRSP*|*PCTRP*|*PESOP*|*PONGP*|*PRISMXP*|*QACSP*','i')
    or regexp_like(descript,'*RCWRP*|*RECONP*|*RUAUDP*|*SCAP*|*SCHIP*|*SOSBP*|*SSOTP*|*SUBRP*|*SVCTRP*|*TMTRKP*|*CAOP*|*CTRAP*|*FSPFP*|*CTRP*|*ATLASP*|*BOAUD2P*|*BOCMS2P*|*CRESTAP*','i')
    or regexp_like(descript,'*DUNP*|*EDAP*|*EFILEP*|*EUSP*|*IATP*|*IBMDP*|*INFMTP*|*INFOTP*|*INMLP*|*ITIMP*|*PCALEP*|*PMAMLP*|*PMAUDP*|*PMEMLP*|*PX2CWP*|*PX2DAP*|*PX2ESP*|*PX2IDP*','i')
    or regexp_like(descript,'*PX2INP*|*PX2PAP*|*PX2POP*|*PX2SPP*|*PX2SYP*|*PX2WPP*|*RKMRP*|*SIEP*|*SPDP*|*SPIP*|*STFILGP*|*VNCLP*|*VNJGP*|*WBIP*|* C99TPACT*|*C99TPACT*|*C99TPADL*','i')
    or regexp_like(descript,'*C99TPFBC*|*R08TPTMP*|*B89TPGIC*|*G28TPCIR*|*B905PCED*|*B90PQSCH*|*B90PYSCH*|*B90TPAPS*|*B90TPSCH*|*C88TPPOS*|*AAPDP*|*AGLP*|*CARP8*|*CCSPP*|*CMDP*|*CSAP*','i')
    or regexp_like(descript,'*HRCPP*|*J07P*|*PDEP*|*RDMP*|*RS1PP*|*VPTPP*|*WRTP*|*H63TPCOS*|*H63TPDNL*|*R08TPLOC*|*R08TPMDD*|*B88TPTPA*|*C87TPCAM*|*C88TPAAC*|*C88TPAUD*|*G29TPBAM*','i')
    or regexp_like(descript,'*G29TPLCA*|*G29TPLCR*|*H66TPPFC*|*H66TPPLC*|*H66TPPYR*|*CARDSP*|*ETSP*|*MBPP8*|*PCLP*|*PERRP*|*PSPR*|*SLVPRD*|*SMFRP*|*SPNP8*|*TBCLNP*|*CAOP8*|*PSFN*','i')
    or regexp_like(descript,'*ABOREP*|*DIG8P*|*E32P*|*GRCLMSP*|*INMP*|*ISGP*|*H52TPRME*|*H51P1CLM*|*H51P1CPI*|*H51P1CRF*|*H51P1LAS*|*H51P1NAR*|*H51P1RET*|*H51P1TPA*|*H73P1TRN*','i')
    or regexp_like(descript,'*H73TPCLR*|*H73TPWHS*|*CHI817*|*CIEAPP*|*CMSAPP*|*CRCAPP*|*MARAPP*|*UKSNPP*|*DWUAT*|*TPUAT*|*P1DW*|*RCAT*|*P1TP*|*TLPRD*|*ILP12CEP*','i')    )
order by upper(nodeid) asc
;



select jobname, nodeid, owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline 
from ctmuser.cms_jobdef 
where regexp_like(descript,'^export*','i')
order by 2 asc;

select unique schedtab from ctmuser.cms_jobdef order by 1 asc;

select jobname, upper(nodeid),nodegrp, owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline,priority,maxdays,maxruns
from ctmuser.cms_jobdef 
where jobname like 'DBAPRD2%' ;--,'PBAPHGLTCFP','PBAPSGLTCFP','DBAPEGLTCFP','PPCMVRXP');


select * --jobname, upper(nodeid), owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline,priority,maxdays,maxruns
from ctmuser.cms_jobdef 
where regexp_like(descript,'*export*','i') and 
 schedtab in ('DATABASE_BACKUP_TMP','ORACLE_EXPORTS','ORACLE_UTILITIES','DATABASE_BACKUP','DATABASE_BACKUPS','DATABASE_MAINTENANCE')
--and regexp_like(nodeid,'sau1h644','i')
  and upper(owner) in ('ORACLE','DBADM') -- not in ('cnaw2k/sqlext','cnaw2k/sqlservices','cnaw2k\itcam','susplan')
 -- and upper(nodegrp) in ('LRAU1P17','LRAU1P18','LRAU1P19','LRAU1P20','LRAU1P21','LRAU1P22','LRAU1P23','LRAU1P24','LRAU1P25','LRCH1D35','SAU1H048',
--'SAU1H049','SAU1H053','SAU1H054','SAU1H068','SAU1H069','SAU1H133','SAU1H134','SAU1H137','SAU1H138','SAU1H346','SAU1H347',
--'SAU1H352','SAU1H353','SAU1H371','SAU1H372','SAU1H373','SAU1H374','SAU1H644','SAU1H688','SCH1H020','SCH1H067','SCH1H068',
--'SCH1H231','SCH1H234','SCH1H537','SCH1H538','SCH1H904','SCH1H906','SCH1H907','SCH1P001','SCH1P079','SCH1P144','SCH1P148',
--'SCH1P215','SCH1P233','SCH1P238','SCH1P241','SCH1P245','SCH1P253','SCH1P268','SCH1P492','SCHWKH01','SUKGCH05','SURFSDA112',
--'SURFSDA701','SURFSDA801','SW3L1H03')
and (regexp_like(descript,'*AEMCMP*|*AEMP*|*CDLTP*|*ECMA1P1P*|*ECMA1P2P*|*ECMA1P3P*|*ECMA1P4P*|*ECMFSRP*|*ECMINP*|*ECMP1P3P*','i')
    or regexp_like(descript,'*ECMP1P4P*|*ECMRADRP*|*ECMRDR2P*|*ECMRDR3P*|*ECMRDR4P*|*ESTR2P*|*INFSH96P*|*PAPCINTP*|*PAPCP*|*RECNPP*','i')
    or regexp_like(descript,'*SDMP*|*TRUSTWAP*|*WSRR12P*|*BUDP*|*CLMCCP*|*CLMCMP*|*CNAPREP*|*DOCMAKP*|*ECMP1P2P*|*INFMRL9P*','i')
    or regexp_like(descript,'*OEM12CP*|*SPCP*|*OID1P*|*OID2P*|*DYNATRCP*|*BCODBP*|*DYNARC2P*|*ILP12CP*|*CNACP*|*ECMFNETP*|*ECMKBP*','i')
    or regexp_like(descript,'*ECMP1P1P*|*J071P*|*RTQPCFP*|*ULSNP*|*CYA1FN5P*|*CYA2FN5P*|*ECM1FN5P*|*ECM2FN5P*|*ECMSMP*|*ALIRP*|*BNRP*','i')
    or regexp_like(descript,'*BPPMP*|*CM90LOGP*|*CM90P*|*CM90SURP*|*ECMCONNP*|*EM90P*|*EM90SURP*|*ESBNP*|*IBMUCDP*|*IIBP*|*IIQP*|*SONARP*','i')
    or regexp_like(descript,'*SPD1P*|*SPI12P*|*ULSAUNP*|*ULSNRP*|*CLMPMP*|*CLMXSP*|*COLLQNP*|*DMFP*|*DOCDISTP*|*EFIP*|*ELMP*|*ENCAPP*|*MVRXNP*','i')
    or regexp_like(descript,'*RAPIDNP*|*BOXIAUDP*|*BOXICMSP*|*BOXILCMP*|*BOXITLSP*|*RCAP*|*CAMILP*|*CNACOMP*|*CNACPP*|*CNACPRP*|*INFSHR9P*|*INSCNAFP*','i')
    or regexp_like(descript,'*RCAT2P*|*SSPP*|*WCMSP*|*WMBESBP*|*WPDBP*|*WPDEXTP*|*WPDWCMP*|*WSRXP*|*SSPWCMP*|*UWPAP*|*UWPP*|*INFPSP*|*PSCPCP*|*PSJPCP*','i')
    or regexp_like(descript,'*PSTFNP*|*HYPP*|*PSARCP*|*ARIBYP*|*CEDMP*|*CEDPP*|*CEDRP*|*CLMEDIP*|*CSEP*|*DNBRP*|*EDVP*|*EVTLOGP*|*ITCAMP*|*LIVCYCP*|*OIDP*','i')
    or regexp_like(descript,'*PSHCMP*|*PWDPOLP*|*RSTGP*|*SPINP*|*SURHRP*|*ECFP*|*PDFGENP*|*SPCCONVP*|*SPCINTP*|*TRECAP*|*TRECP*|*DLPP*|*ILP12P*|*RMWVIOP*','i')
    or regexp_like(descript,'*CYA1FNP*|*CYA2FNP*|*ECM1FNP*|*ECM2FNP*|*RTPDSP*|*PMLTP*|*LTCMIP*|*HYPMDP*|*MERLFVP*|*ACBP*|*AGENP*|*BOE3AUDP*|*BOE3CMSP*|*BOE3LCMP*|*BOE3TLSP*','i')
    or regexp_like(descript,'*DNBBRP*|*DOCMKRP*|*ESFMP*|*ESTRP*|*FRMMP*|*GLTCFP*|*IBMD2P*|*IBMDX1P*|*IBMDX2P*|*IBMDX3P*|*MERLAPP*|*MOODYSP*|*MVRXP*|*OPTDIRP*|*PAEUSP*|*PCTRAP*','i')
    or regexp_like(descript,'*PNLRP*|*PRIMAP*|*PRIMVAP*|*PRIMVODP*|*PRIMVSTP*|*PSEPMP*|*PSHRMP*|*PSITE60P*|*PSPRTP*|*RCAT1P*|*RCTP*|*SREP*|*VAPFP*|*VCMFP*|*WBI1P*|*WITCAMP*|*WKINP*','i')
    or regexp_like(descript,'*WMBLP*|*WTDWP*|*ECMPJP*|*FNREP*|*HYPERESP*|*ITINVP*|*J28APP*|*J76APP*|*MMARTP*|*ONDP*|*RMPP*|*SENNICOP*|*SFINSP*|*SOLDP*|*V97APP*|*VAPIP*|*CCDP*|*CDMP*','i')
    or regexp_like(descript,'*CIMFP*|*DBAP*|*ECMISP*|*FDMGTP*|*IPCP*|*LOGP*|*MTRAKP*|*PIRMP*|*PROBIP*|*PSCRP*|*PSITE50P*|*WASSESP*|*XPRP*|*BRPTP*|*NGLAP*|*NGLP*|*NTKP*|*AGUAP*|*BLADEP*','i')
    or regexp_like(descript,'*BLDPRTP*|*BLDWHP*|*COREFP*|*COREFSP*|*DNBBRAP*|*FINACHP*|*ILVP*|*IRISP*|*NTINSP*|*OAPEXP*|*OEMP*|*PRIMVSGP*|*RSMTRP*|*RTPDZP*|*UETP*|*APDLP*|*APESP*|*ASTMBP*','i')
    or regexp_like(descript,'*AXPRP*|*BCFP*|*BCSLGP*|*BLDFRGP*|*BPMAP*|*CASP*|*CMPSP*|*CMTP*|*CNAEDDP*|*COIP*|*COLLQP*|*CRRP*|*DIMP*|*DTCMP*|*ESSOP*|*ESWKP*|*FCACP*|*FNOLSP*|*FRBPMP*','i')
    or regexp_like(descript,'*GLTCCAP*|*HAILSTMP*|*LINOLP*|*LSBP*|*M2TRAKP*|*MAXBP*|*MBPP*|*MONITP*|*MPASP*|*OCIP*|*ONDBP*|*ORVP*|*PAEUSRSP*|*PCTRP*|*PESOP*|*PONGP*|*PRISMXP*|*QACSP*','i')
    or regexp_like(descript,'*RCWRP*|*RECONP*|*RUAUDP*|*SCAP*|*SCHIP*|*SOSBP*|*SSOTP*|*SUBRP*|*SVCTRP*|*TMTRKP*|*CAOP*|*CTRAP*|*FSPFP*|*CTRP*|*ATLASP*|*BOAUD2P*|*BOCMS2P*|*CRESTAP*','i')
    or regexp_like(descript,'*DUNP*|*EDAP*|*EFILEP*|*EUSP*|*IATP*|*IBMDP*|*INFMTP*|*INFOTP*|*INMLP*|*ITIMP*|*PCALEP*|*PMAMLP*|*PMAUDP*|*PMEMLP*|*PX2CWP*|*PX2DAP*|*PX2ESP*|*PX2IDP*','i')
    or regexp_like(descript,'*PX2INP*|*PX2PAP*|*PX2POP*|*PX2SPP*|*PX2SYP*|*PX2WPP*|*RKMRP*|*SIEP*|*SPDP*|*SPIP*|*STFILGP*|*VNCLP*|*VNJGP*|*WBIP*|* C99TPACT*|*C99TPACT*|*C99TPADL*','i')
    or regexp_like(descript,'*C99TPFBC*|*R08TPTMP*|*B89TPGIC*|*G28TPCIR*|*B905PCED*|*B90PQSCH*|*B90PYSCH*|*B90TPAPS*|*B90TPSCH*|*C88TPPOS*|*AAPDP*|*AGLP*|*CARP8*|*CCSPP*|*CMDP*|*CSAP*','i')
    or regexp_like(descript,'*HRCPP*|*J07P*|*PDEP*|*RDMP*|*RS1PP*|*VPTPP*|*WRTP*|*H63TPCOS*|*H63TPDNL*|*R08TPLOC*|*R08TPMDD*|*B88TPTPA*|*C87TPCAM*|*C88TPAAC*|*C88TPAUD*|*G29TPBAM*','i')
    or regexp_like(descript,'*G29TPLCA*|*G29TPLCR*|*H66TPPFC*|*H66TPPLC*|*H66TPPYR*|*CARDSP*|*ETSP*|*MBPP8*|*PCLP*|*PERRP*|*PSPR*|*SLVPRD*|*SMFRP*|*SPNP8*|*TBCLNP*|*CAOP8*|*PSFN*','i')
    or regexp_like(descript,'*ABOREP*|*DIG8P*|*E32P*|*GRCLMSP*|*INMP*|*ISGP*|*H52TPRME*|*H51P1CLM*|*H51P1CPI*|*H51P1CRF*|*H51P1LAS*|*H51P1NAR*|*H51P1RET*|*H51P1TPA*|*H73P1TRN*','i')
    or regexp_like(descript,'*H73TPCLR*|*H73TPWHS*|*CHI817*|*CIEAPP*|*CMSAPP*|*CRCAPP*|*MARAPP*|*UKSNPP*|*DWUAT*|*TPUAT*|*P1DW*|*RCAT*|*P1TP*|*TLPRD*|*ILP12CEP*','i')    )
order by upper(nodeid) asc
;



select * --jobname, upper(nodeid), owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline,priority,maxdays,maxruns
from ctmuser.cms_jobdef 
where --regexp_like(descript,'*export*','i') and 
 --schedtab in ('DATABASE_BACKUP_TMP','ORACLE_EXPORTS','ORACLE_UTILITIES','DATABASE_BACKUP','DATABASE_BACKUPS','DATABASE_MAINTENANCE')
--and regexp_like(nodeid,'sau1h644','i')
  --and upper(owner) in ('ORACLE','DBADM')

<end node> 5P9i0s8y19Z
dt=Text
<node>
service acct passwd
2
->cat /csapps/oracle/cnascripts/oragel_control_file
CNAOMON nc?hk4n~n4a
CNAOETERM bi8kx2o!x9y
CNAOSTART pd~oz5i+l4f
CNAOAUD rg!dz0k+y9t
CNAOIMP db+am2jw6v
STATUS run


-- service account (Application schemas) are created manually
-- service account need not required to share the account password
-- it required to go through etl admin team (ETL_ADMIN team)
CREATE USER "IIB_ADMIN" identified by "BAf0TZ5K" 
      DEFAULT TABLESPACE "USERS" 
      TEMPORARY TABLESPACE "TEMP" 
      PROFILE "APPSPROFILE" 
      ACCOUNT UNLOCK;  

grant create session to IIB_ADMIN;

-- once the service account is created password required to be entired into the below file
-- if you modify the password of service account update the password here
-- The file is common on every database server
-- service account password required to stored here
/csapps/oracle/input/dba_cmds.schema_env

<database_name>:<service_account>:<password> which required to updates in the above file


/csapps/oracle/input
/csapps/oracle/admin/hypr/create

---- sometime user will ask to enter the password in unix_authent file
--- most of the service account should have unix authent.
CUT - Vslrch1d031,
ETE - Vslrch1d032,
DRT - Vslrch1d033 
-r--r-----   1 oracle  dba   28509 Sep 21 16:18 dba_cmds.schema_env
-r--r-----   1 oracle  dba   11273 Oct  4 17:31 schema_password.unix_authent
vslrch1d031.cna.com:oracle:seed12:/csapps/oracle/input

<end node> 5P9i0s8y19Z
dt=Text
<node>
sevrety DB
2
Chandu
sevrety server
from sch1h018 make 
sudo su - oracle

cae0749/AB1212ab --- sch1h018 & sudo su - oracle

sqlplus cae0749@<<sevrety_SID_DBs>>
Kjdrt103e is the DB pass.

<end node> 5P9i0s8y19Z
dt=Text
<node>
HP-UX Disk size
2

-- below script is only for HP-UX disk checking in reable format
df -Pk | awk '{ 
 if ( NR == 1 ) { next } 
 if ( NF == 6 ) { print } 
 if ( NF == 5 ) { next } 
 if ( NF == 1 ) { 
 getline record; 
 $0 = $0 record 
 print $0 
 } 
 }' | awk '
BEGIN {print "Filesystem                                    Mount Point                 Total GB   Avail GB    Used GB  Used"
       print "--------------------------------------------- ------------------------- ---------- ---------- ---------- -----"}
END {print ""}
/dev/ || /^[0-9a-zA-Z.]*:\// {
printf ("%-45.45s %-25s %10.2f %10.2f %10.2f %4.0f%\n",$1,$6,$2/1024/1024,$4/1024/1024,$3/1024/1024,$5)
}'

<end node> 5P9i0s8y19Z
dt=Text
<node>
cna refresh jobs
2
-- RE: IMPORT Script SW3MNH05 uksndr
Source DB: uksnpp
Source Server Name: sukgch05

Target DB:  uksndr
Target Server Name: sw3mnh05

SUKGCH05:oracle:seed:/csapps/oracle/backup/scripts/
->cat /csapps/oracle/backup/scripts/uksnpp_swiss_army_export
export NLS_LANG=AMERICAN_AMERICA.WE8PC850
/csapps/oracle/backup/bin/swiss_army_export -S uksnpp -V 6 -M carole.rocco@cna.com,CNA_TCS_ITIS_Database_All@cna.com -C gzip -s -d
/csapps/oracle/dbascripts/uksnpp/ctlm/sftp_exp.ksh >/csapps/oracle/dbascripts/uksnpp/ctlm/logs/sftp_exp.log
SUKGCH05:oracle:seed:/csapps/oracle/backup/scripts
-> 
/csapps/oracle/dbascripts/uksnpp/ctlm/sftp_exp.ksh >/csapps/oracle/dbascripts/uksnpp/ctlm/logs/sftp_exp.log 



/opt/quest/bin/sftp robocopyeu@kw3l1p35 <<!EOF
cd uksnpp
put ${SOURCE_EXP_PATH}/${IMPORT_FILE}
bye
!EOF



SW3MNH05:oracle:seed:/csappskh02/oracle/dbascripts/uksndr/ctlm 

<end node> 5P9i0s8y19Z
dt=Text
<node>
uksnpp archive
2

cd /csappsh05/oracle/admin/uksnpp/arch

df -g /csappsh05/oracle/admin/uksnpp/arch

run 
{
 crosscheck archivelog all;
 delete noprompt archivelog until time 'sysdate-1';
}

<end node> 5P9i0s8y19Z
dt=Text
<node>
DB Link
2
CREATE public DATABASE LINK alirp
CONNECT TO alir IDENTIFIED BY "nh+1t3+o9nk"
USING 'alirp';

-- sie1e to ESTR4E (sch1h219)
CREATE DATABASE LINK to_estr
CONNECT TO ezfeed IDENTIFIED BY "siee"
USING 'estr4e';

create database link dnbrp
connect to cae0748p identified by "action201"
using 'dnbrp'

CREATE DATABASE LINK trecp1
CONNECT TO cae0748p IDENTIFIED BY "action201"
USING 'trecp';

s4roXxJf

CREATE DATABASE LINK efip
CONNECT TO cac8552 IDENTIFIED BY "s4roXxJf"
USING 'EFIP';

CREATE DATABASE LINK papcp
CONNECT TO ocr_reptng IDENTIFIED BY "P17cNcp1T2g"
USING 'papcp'

create database link efip1
connect to cac8552 identified by "s4roXxJf"
using 'efip'

CREATE public DATABASE LINK efip3
CONNECT TO cae0748p IDENTIFIED BY "point1978"
USING 'efip';

-- password less db link
-- you have to be sure for password which should be same on both target and source schema@db
create database link TO_MERLIN 
using 'merwh2c';



-- DB Link Script
CREATE  DATABASE LINK pr3_41
 CONNECT TO dba_batch
 IDENTIFIED BY "UvTuRQyNvJ1L"
 USING '(DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = mobras41.la.ds.monsanto.com)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = PR3.monsanto.com)))';
===============================================================================================

CREATE public DATABASE LINK MIS_MERWHP
CONNECT TO MIS IDENTIFIED BY "bear0spot"
USING 'MERWHP';

CREATE public DATABASE LINK MR_PRELD_MERWHP
CONNECT TO MR_PRELOAD IDENTIFIED BY "bzIzWzxN10)"
USING 'MERWHP';

CREATE public DATABASE LINK MIS_DM_MERDMP
CONNECT TO MIS_DM IDENTIFIED BY "probe8ice"
USING 'MERDMP';


CREATE DATABASE LINK efip3
CONNECT TO cac8552 IDENTIFIED BY "s4roXxJf"
USING 'lrch1d41.cna.com:1522/efip1';

-- sie3c(sch1h217) to estr24c(lrch1d47)
create database link to_estr
connect to ezfeed identified by "sied"
using 'estr24c'


Database	Schema	Cab ID's	Password
cad0312/c4D1321PsUsd@ALIRP	ALIR	cad0312/c4D1321PsUsd
ALIRP	ALIR	cae2403	Z2xTmoqY

2. Target DB name along with schema name and password where the database link needs to be pointed to.
			
Database	Schema	Cab ID's	Password
PAPCINTP	EPCINT_FEEDS	cad0312	c4D1321PsUsd
PAPCINTP	EPCINT_FEEDS	cae2403	Og9iMRoj
papcintp



create database link ALIRP_EPCP
connect to EPCINT_FEEDS identified by "ltfq+_q7qz"
using 'papcintp'

<end node> 5P9i0s8y19Z
dt=Text
<node>
reset password
2
---> Database edar, using home /csapps/oracle/product/10.2.0.3

/depot/oracle/temp/./reset_DBA_acct_pass.ksh

create user cae0748p identified by point1978;
grant create session,dba to cae0748p;

alter profile default limit PASSWORD_VERIFY_FUNCTION null;
alter user cae0748p profile default;
ALTER USER CAE0748P IDENTIFIED BY "action201" account unlock;
alter profile default limit PASSWORD_VERIFY_FUNCTION VERIFY_FUNCTION;
ALTER USER CAE0748P PROFILE DPROFILE;
ALTER USER CAE0748P ACCOUNT UNLOCK;

--- will change and reset the password 
set lines 320 pages 1000
col profile for a10
select * from dba_profiles where profile='DEFAULT';
alter profile DEFAULT limit PASSWORD_REUSE_MAX UNLIMITED PASSWORD_VERIFY_FUNCTION null;
alter user cae0748p profile default;
ALTER USER CAE0748P IDENTIFIED BY "action201" account unlock ;
ALTER USER CAE0748P PROFILE DPROFILE;
--alter profile default limit PASSWORD_VERIFY_FUNCTION VERIFY_FUNCTION;
alter profile DEFAULT limit PASSWORD_REUSE_MAX 5;
select * from dba_profiles where profile='DEFAULT';


--- Non-exadata
ALTER USER CAE0748P PROFILE DDEFPROFILE;
ALTER USER CAE0748P IDENTIFIED BY action201;
ALTER USER CAE0748P PROFILE DPROFILE;
ALTER USER CAE0748P ACCOUNT UNLOCK;

ALTER USER CAE0748P PROFILE default;
ALTER USER CAE0748P IDENTIFIED BY action201;
ALTER USER CAE0748P PROFILE DPROFILE;
ALTER USER CAE0748P ACCOUNT UNLOCK;

--- exadata
ALTER USER CAE0748 PROFILE DDEFPROFILE;
ALTER USER CAE0748 IDENTIFIED BY action201;
ALTER USER CAE0748 PROFILE DPROFILE;
ALTER USER CAE0748 ACCOUNT UNLOCK;


ALTER USER cnaoimp PROFILE DDEFPROFILE;
alter user cnaoimp identified by "db+am2jw6v";
ALTER USER cnaoimp PROFILE DPROFILE;
ALTER USER cnaoimp ACCOUNT UNLOCK;

ALTER USER dbsnmp PROFILE DDEFPROFILE;
ALTER USER dbsnmp IDENTIFIED BY fun8park;
ALTER USER dbsnmp PROFILE OAPPPROFILE;
ALTER USER dbsnmp ACCOUNT UNLOCK;


select user_id,username, account_status, lock_date, to_char(expiry_date,'mm/dd/yyyy hh24:mi:ss')expiry_date,
    created, profile, su.ctime, su.ptime, to_char(su.exptime,'mm/dd/yyyy hh24:mi:ss')exptime, su.ltime
from dba_users du, sys.user$ su
where du.user_id=su.user# 
  and du.username='CAE4896P';


col username for a20
col ACCOUNT_STATUS for a16
col expiry_date for a25
SELECT username,account_status,TO_CHAR(expiry_date,'mm/dd/yyyy hh24:mi:ss')expiry_date 
  FROM DBA_USERS 
 WHERE REGEXP_LIKE(username,'^cna*','i');


set serveroutput on;
BEGIN
	FOR i IN (
				SELECT username, dp.profile mstr_profile, su.password password, du.profile assign_profile
				FROM dba_users du, sys.user$ su, 
					(SELECT PROFILE 
					   FROM (
							  SELECT  PROFILE, RANK() OVER(ORDER BY PROFILE) AS rn
								FROM dba_profiles 
							   WHERE resource_name='PASSWORD_VERIFY_FUNCTION'
								 AND LIMIT='NULL' 
							)WHERE rn=1) dp
				WHERE du.username = su.NAME
				  AND du.username IN ('CNAOSEC1','CNAOSTART','CNAOAUD','CNAOETERM','CNAOMON','CNAOIMP')
				ORDER BY username ASC
			)
	  LOOP
		 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' PROFILE '||i.mstr_profile);
		 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' IDENTIFIED BY VALUES '''||i.PASSWORD||'''');
		 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' PROFILE '||i.assign_profile);
		 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' ACCOUNT UNLOCK');

		 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' PROFILE '||i.mstr_profile);
		 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' IDENTIFIED BY VALUES '''||i.PASSWORD||'''');
		 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' PROFILE '||i.assign_profile);
		 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' ACCOUNT UNLOCK');
	  END LOOP;
END;
/

->cat reset_DBA_acct_pass.ksh
#ALL_DATABASES=`cat /etc/oratab|grep -v "^#"|grep -v "N$"|cut -f1 -d: -s`
ALL_DATABASES=`ps -ef|grep ora_smon_ |grep -v grep|awk -F"_" '{print $3 " " $4}'|sort`
for DB in $ALL_DATABASES
do
   unset  TWO_TASK
   export ORACLE_SID=$DB
   export ORACLE_HOME=`grep "^${DB}:" /etc/oratab|cut -d: -f2 -s`
   export PATH=$ORACLE_HOME/bin:$PATH
   echo "---> Database $ORACLE_SID, using home $ORACLE_HOME"
   sqlplus -s "/as sysdba" <<ENDofSQL
set serveroutput on
BEGIN
        FOR i IN (
                                SELECT username, dp.profile mstr_profile, su.password password, du.profile assign_profile
                                FROM dba_users du, sys.user$ su,
                                        (SELECT PROFILE
                                           FROM (
                                                          SELECT  PROFILE, RANK() OVER(ORDER BY PROFILE) AS rn
                                                                FROM dba_profiles
                                                           WHERE resource_name='PASSWORD_VERIFY_FUNCTION'
                                                                 AND LIMIT='NULL'
                                                        )WHERE rn=1) dp
                                WHERE du.username = su.NAME
                                  AND du.username = 'CAE0748P'
                                ORDER BY username ASC
                        )
          LOOP
                 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' PROFILE '||i.mstr_profile);
                 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' IDENTIFIED BY VALUES '''||i.PASSWORD||'''');
                 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' PROFILE '||i.assign_profile);
                 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' ACCOUNT UNLOCK');
                 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' PROFILE '||i.mstr_profile);
                 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' IDENTIFIED BY VALUES '''||i.PASSWORD||'''');
                 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' PROFILE '||i.assign_profile);
                 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' ACCOUNT UNLOCK');
          END LOOP;
END;
/
ENDofSQL
done


-------------------------------------------------------------------
set serveroutput on
BEGIN
	FOR i IN (
				SELECT username, dp.profile mstr_profile, su.password password, du.profile assign_profile
				FROM dba_users du, sys.user$ su, 
					(SELECT PROFILE 
					   FROM (
							  SELECT  PROFILE, RANK() OVER(ORDER BY PROFILE) AS rn
								FROM dba_profiles 
							   WHERE resource_name='PASSWORD_VERIFY_FUNCTION'
								 AND LIMIT='NULL' 
							)WHERE rn=1) dp
				WHERE du.username = su.NAME
				  AND du.username = 'QUALYS_SCAN'
				ORDER BY username ASC
			)
	  LOOP
		 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' PROFILE '||i.mstr_profile);
		 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' IDENTIFIED BY qu52857LsYM');
		 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' PROFILE '||i.assign_profile);
		 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' ACCOUNT UNLOCK');

		 dbms_utility.exec_ddl_statement(' ALTER PROFILE QUALYS_PROFILE LIMIT PASSWORD_LIFE_TIME UNLIMITED');
		 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' PROFILE '||i.mstr_profile);
		 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' IDENTIFIED BY qu52857LsYM');
		 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' PROFILE QUALYS_PROFILE');
		 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' ACCOUNT UNLOCK');
	  END LOOP;
END;
/


==================================================================================================

col username for a12
col mstr_profile for a15
col password for a30
col assign_profile for a17
SELECT username, dp.profile mstr_profile, su.password password, du.profile assign_profile,
'alter user '||username||' profile '||dp.profile ||';' ||chr(10)||
'alter user '||username||' identified by "point1978"'||';' ||chr(10)||
'alter user '||username||' profile '||du.profile ||';' ||chr(10)||
'alter user '||username||' account unlock;' command
FROM dba_users du, sys.user$ su,
	(SELECT PROFILE
	   FROM (
			  SELECT  PROFILE, RANK() OVER(ORDER BY PROFILE) AS rn
					FROM dba_profiles
			   WHERE resource_name='PASSWORD_VERIFY_FUNCTION'
					 AND LIMIT='NULL'
			)WHERE rn=1) dp
WHERE du.username = su.NAME
  AND du.username = 'CAE0748P'
ORDER BY username ASC;

alter user CAD9410 profile DDEFPROFILE;
alter user CAD9410 identified by "caD$9410";
alter user CAD9410 profile CPROFILE;
alter user CAD9410 account unlock;






	SELECT username, dp.profile mstr_profile, su.password password, du.profile assign_profile
				FROM dba_users du, sys.user$ su, 
					(SELECT PROFILE 
					   FROM (
							  SELECT  PROFILE, RANK() OVER(ORDER BY PROFILE) AS rn
								FROM dba_profiles 
							   WHERE resource_name='PASSWORD_VERIFY_FUNCTION'
								 AND LIMIT='NULL' 
							)WHERE rn=1) dp
				WHERE du.username = su.NAME
				  AND du.username IN ('CAE0748P')
				ORDER BY username ASC
=======================================================================================

set lines 320 pages 1000
col profile for a10
col limit for a30
select PROFILE,RESOURCE_NAME,LIMIT 
from dba_profiles 
where profile='DEFAULT'
and resource_name in ('PASSWORD_VERIFY_FUNCTION','PASSWORD_REUSE_MAX')
;
set serverout on 
declare 
  v_pass_verify  varchar2(100);
  v_pass_reuse_max varchar2(100);
  v_build_stmt_PRM   varchar2(32000);
  v_build_stmt_PVF   varchar2(32000);
begin 
		select limit into v_pass_verify 
		  from dba_profiles 
		 where profile='DEFAULT' 
		   and resource_name='PASSWORD_VERIFY_FUNCTION';
		
		select limit into v_pass_reuse_max 
		  from dba_profiles 
		 where profile='DEFAULT' 
		   and resource_name='PASSWORD_REUSE_MAX';
		   
		if v_pass_verify <> 'NULL' then
		  -- check the password_verify_function value
			v_build_stmt_PVF:='alter profile default limit PASSWORD_VERIFY_FUNCTION '||v_pass_verify;
		else
			v_build_stmt_PVF:='alter profile default limit PASSWORD_VERIFY_FUNCTION NULL';
		end if;
		
		if v_pass_reuse_max <> 'UNLIMITED' then
		  -- check the password_resuse_max value
			v_build_stmt_PRM:='alter profile DEFAULT limit PASSWORD_REUSE_MAX '||v_pass_reuse_max;
		else
			v_build_stmt_PRM:='alter profile DEFAULT limit PASSWORD_REUSE_MAX UNLIMITED';
	   	end if;
		
        dbms_output.put_line ('alter profile default limit PASSWORD_REUSE_MAX UNLIMITED PASSWORD_VERIFY_FUNCTION NULL');
		dbms_output.put_line ('alter profile default limit PASSWORD_VERIFY_FUNCTION NULL');
		dbms_output.put_line ('alter user profile default');
		dbms_output.put_line ('alter user cae0748p identified by action201 account unlock');
		dbms_output.put_line ('alter user cae0748p profile dprofile');
		dbms_output.put_line (v_build_stmt_PRM);
		dbms_output.put_line (v_build_stmt_PVF);
		dbms_utility.exec_ddl_statement ('alter profile default limit PASSWORD_REUSE_MAX UNLIMITED PASSWORD_VERIFY_FUNCTION NULL');
		dbms_utility.exec_ddl_statement ('alter user cae0748p profile default');
		dbms_utility.exec_ddl_statement ('alter user cae0748p identified by action201 account unlock');
		dbms_utility.exec_ddl_statement ('alter user cae0748p profile dprofile');
		dbms_utility.exec_ddl_statement (v_build_stmt_PRM);
		dbms_utility.exec_ddl_statement (v_build_stmt_PVF);
end;
/
select PROFILE,RESOURCE_NAME,LIMIT 
from dba_profiles 
where profile='DEFAULT'
and resource_name in ('PASSWORD_VERIFY_FUNCTION','PASSWORD_REUSE_MAX')
;
=======================================================================================


ALL_DATABASES=`ps -ef|grep ora_smon_ |grep -v grep|awk -F"_" '{print $3 " " $4}'|sort`
#ALL_DATABASES=`cat /etc/oratab|grep -v "^#"|grep -v "N$"|cut -f1 -d: -s`
for DB in $ALL_DATABASES
do
   unset  TWO_TASK
   export ORACLE_SID=$DB
   export ORACLE_HOME=`grep "^${DB}:" /etc/oratab|cut -d: -f2 -s`
   export PATH=$ORACLE_HOME/bin:$PATH
   echo "---> Database $ORACLE_SID, using home $ORACLE_HOME"
   sqlplus -s "/as sysdba" <<ENDofSQL
set echo on;
col profile for a10;
col LIMIT for a30
select PROFILE,RESOURCE_NAME,LIMIT 
from dba_profiles 
where profile='DEFAULT'
and resource_name in ('PASSWORD_VERIFY_FUNCTION','PASSWORD_REUSE_MAX')
;
set serverout on 
declare 
  v_pass_verify  varchar2(100);
  v_pass_reuse_max varchar2(100);
  v_build_stmt_PRM   varchar2(32000);
  v_build_stmt_PVF   varchar2(32000);
begin 
		select limit into v_pass_verify 
		  from dba_profiles 
		 where profile='DEFAULT' 
		   and resource_name='PASSWORD_VERIFY_FUNCTION';
		
		select limit into v_pass_reuse_max 
		  from dba_profiles 
		 where profile='DEFAULT' 
		   and resource_name='PASSWORD_REUSE_MAX';
		   
		if v_pass_verify <> 'NULL' then
		  -- check the password_verify_function value
			v_build_stmt_PVF:='alter profile default limit PASSWORD_VERIFY_FUNCTION '||v_pass_verify;
		else
			v_build_stmt_PVF:='alter profile default limit PASSWORD_VERIFY_FUNCTION NULL';
		end if;
		
		if v_pass_reuse_max <> 'UNLIMITED' then
		  -- check the password_resuse_max value
			v_build_stmt_PRM:='alter profile DEFAULT limit PASSWORD_REUSE_MAX '||v_pass_reuse_max;
		else
			v_build_stmt_PRM:='alter profile DEFAULT limit PASSWORD_REUSE_MAX UNLIMITED';
	   	end if;
		
        dbms_output.put_line ('alter profile default limit PASSWORD_REUSE_MAX UNLIMITED PASSWORD_VERIFY_FUNCTION NULL');
		dbms_output.put_line ('alter profile default limit PASSWORD_VERIFY_FUNCTION NULL');
		dbms_output.put_line ('alter user profile default');
		dbms_output.put_line ('alter user cae0748p identified by action201 account unlock');
		dbms_output.put_line ('alter user cae0748p profile dprofile');
		dbms_output.put_line (v_build_stmt_PRM);
		dbms_output.put_line (v_build_stmt_PVF);
		dbms_utility.exec_ddl_statement ('alter profile default limit PASSWORD_REUSE_MAX UNLIMITED PASSWORD_VERIFY_FUNCTION NULL');
		dbms_utility.exec_ddl_statement ('alter user cae0748p profile default');
		dbms_utility.exec_ddl_statement ('alter user cae0748p identified by action201 account unlock');
		dbms_utility.exec_ddl_statement ('alter user cae0748p profile dprofile');
		dbms_utility.exec_ddl_statement (v_build_stmt_PRM);
		dbms_utility.exec_ddl_statement (v_build_stmt_PVF);
end;
/
select PROFILE,RESOURCE_NAME,LIMIT 
from dba_profiles 
where profile='DEFAULT'
and resource_name in ('PASSWORD_VERIFY_FUNCTION','PASSWORD_REUSE_MAX')
;
ENDofSQL
done

<end node> 5P9i0s8y19Z
dt=Text
<node>
omsr DB connection
2
-- All CNA database backup information goes here in OMSR database

cat /csapps/oracle/backup/bin/bkp

export CONNECT_BACKUP="backup_mon/B1ckup_mon@omsr"

sqlplus -S "${CONNECT_BACKUP}"<< EOF
  insert into backup_mon.backup_history values ('${backup_script}', '${HOST}', '${ORACLE_SID}', TO_DATE('$STARTTIME', 'mm/dd/yy hh24:mi'),'${ISSUCCESS}',sysdate,'${JO
BERRORS}','',TO_DATE('$jobstarttime', 'mm/dd/yy hh24:mi'),'${inp_operation_type}');
  exit;
EOF



backup_mon/B1ckup_mon@omsr



-- check in backup_mon/B1ckup_mon@omsr database - sch1h757:oracle:omsr
select username, account_status, to_char(expiry_date,'mm/dd/yyyy hh24:mi:ss')expiry_date
from dba_users 
where username like '%CNA%' or username='BACKUP_MON'


set serveroutput on;
BEGIN
	FOR i IN (
				SELECT username, dp.profile mstr_profile, su.password password, du.profile assign_profile
				FROM dba_users du, sys.user$ su, 
					(SELECT PROFILE 
					   FROM (
							  SELECT  PROFILE, RANK() OVER(ORDER BY PROFILE) AS rn
								FROM dba_profiles 
							   WHERE resource_name='PASSWORD_VERIFY_FUNCTION'
								 AND LIMIT='NULL' 
							)WHERE rn=1) dp
				WHERE du.username = su.NAME
				  AND du.username IN ('BACKUP_MON')
				ORDER BY username ASC
			)
	  LOOP
		 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' PROFILE '||i.mstr_profile);
		 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' IDENTIFIED BY VALUES '''||i.PASSWORD||'''');
		 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' PROFILE '||i.assign_profile);
		 dbms_output.put_line (' ALTER USER '||i.USERNAME|| ' ACCOUNT UNLOCK');

		 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' PROFILE '||i.mstr_profile);
		 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' IDENTIFIED BY VALUES '''||i.PASSWORD||'''');
		 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' PROFILE '||i.assign_profile);
		 dbms_utility.exec_ddl_statement(' ALTER USER '||i.USERNAME|| ' ACCOUNT UNLOCK');
	  END LOOP;
END;
/

<end node> 5P9i0s8y19Z
dt=Text
<node>
refresh schema
2
select owner, object_type, status, count(*)
from dba_objects 
where owner in ('RST','RST_NOTIFY','RST_ARCHIVAL')
 -- and object_type in ('VIEW','TRIGGER','PROCEDURE','FUNCTION','PACKAGE','PACKAGE BODY','SEQUENCE','MATERIALIZED VIEW')
 group  by owner, object_type,status
ORDER BY OWNER, OBJECT_TYPE ASC;


SELECT
  'alter system kill session ' || ''''|| s.sid || ',' || s.serial# || ',@'||s.inst_id ||''' immediate;'  "Kill_Command"
FROM  gv$session s
WHERE s.schemaname in ('RST','RST_NOTIFY','RST_ARCHIVAL')
;

set serveroutput on
declare 
	v_SqlSTMT  varchar2(32000);
begin
FOR i IN (select owner, object_type, object_name
			from dba_objects 
			where owner in ('RST','RST_NOTIFY','RST_ARCHIVAL')
			  and object_type in ('TABLE','VIEW','TRIGGER','PROCEDURE','FUNCTION','PACKAGE','PACKAGE BODY','SEQUENCE','MATERIALIZED VIEW')
			ORDER BY OWNER, OBJECT_TYPE ASC)
loop
	begin 
	  if i.object_type='TABLE' then
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME||' cascade constraint';
	  else
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME;
	  end if;
		execute immediate v_SqlSTMT;
	exception
	  when others then
	  	null;
	end;
	dbms_output.put_line(v_SqlSTMT);
end loop;
end;
/

--------------------------------------------------------------------------------------
-- One-Shot Script
with uname as 
(
    select username 
    from dba_users 
    where username in ('RST','RST_NOTIFY','RST_ARCHIVAL')
)
SELECT -- grantee, owner, table_name, grantor, 
        DECODE(grantable, 'YES', 'grant '||(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||' WITH GRANT OPTION;',
                                 'grant '||(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||';') privs_grant
from dba_tab_privs dtp,uname usr
where (dtp.grantee =usr.username 
        or
       dtp.grantor =usr.username)
union all
-- generate the synonym script merwhp and execute the same on merwhr
select 'create or replace synonym '||owner||'.'||synonym_name||' for '||table_owner||'.'||table_name||';'
from dba_synonyms ds, uname usr
where ds.owner =usr.username
union all
select 'create or replace public synonym '||synonym_name||' for '||table_owner||'.'||table_name||';'
from dba_synonyms dps, uname usr
where dps.table_owner =usr.username
;

-- original script
SELECT -- grantee, owner, table_name, grantor, 
        DECODE(grantable, 'YES', 'grant '||(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||' WITH GRANT OPTION;',
                                 'grant '||(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||';') privs_grant
from dba_tab_privs
where (grantee in ('RST','RST_NOTIFY','RST_ARCHIVAL')
        or
       grantor in ('RST','RST_NOTIFY','RST_ARCHIVAL'))
union all
-- generate the synonym script merwhp and execute the same on merwhr
select 'create or replace synonym '||owner||'.'||synonym_name||' for '||table_owner||'.'||table_name||';'
from dba_synonyms
where owner in
	('RST','RST_NOTIFY','RST_ARCHIVAL')
union all
select 'create or replace public synonym '||synonym_name||' for '||table_owner||'.'||table_name||';'
from dba_synonyms
where table_owner in
	('RST','RST_NOTIFY','RST_ARCHIVAL')
;

--------------------------------------------------------------------------------------
set serveroutput on
declare 
	v_SqlSTMT  varchar2(32000);
begin
FOR i IN (select owner, object_type, object_name
			from dba_objects 
			where owner in ('PESDBO','CEDEBAT','CEDECODE','BATCHUSER','CEDELITE','CEDEACCESS')
			  and object_type in ('TABLE','VIEW','TRIGGER','PROCEDURE','FUNCTION','PACKAGE','PACKAGE BODY','SEQUENCE','MATERIALIZED VIEW')
			ORDER BY OWNER, OBJECT_TYPE ASC)
loop
	begin 
	  if i.object_type='TABLE' then
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME||' cascade constraint';
	  else
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME;
	  end if;
		execute immediate v_SqlSTMT;
	exception
	  when others then
	  	null;
	end;
	dbms_output.put_line(v_SqlSTMT);
end loop;
end;
/

select owner, object_type, count(*)
from dba_objects 
where owner in ('MR_LANDING')
 -- and object_type in ('VIEW','TRIGGER','PROCEDURE','FUNCTION','PACKAGE','PACKAGE BODY','SEQUENCE','MATERIALIZED VIEW')
 group  by owner, object_type
ORDER BY OWNER, OBJECT_TYPE ASC;



select 'DROP table '||OWNER||'.'||TABLE_NAME||' cascade constraint;' drop_statms
from dba_tables
where owner in ('ULS','DLPDM')





-- generate the grant privilleges script from merwhp and execute it on merwhr
SELECT -- grantee, owner, table_name, grantor, 
        DECODE(grantable, 'YES', 'grant '||(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||' WITH GRANT OPTION;',
                                 'grant '||(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||';') privs_grant
from dba_tab_privs
where grantee in
	('AV2','AV2_CC')
union all
-- generate the synonym script merwhp and execute the same on merwhr
select 'create or replace synonym '||owner||'.'||synonym_name||' for '||table_owner||'.'||table_name||';'
from dba_synonyms
where owner in
	('AV2','AV2_CC')
union all
select 'create or replace public synonym '||synonym_name||' for '||table_owner||'.'||table_name||';'
from dba_synonyms
where table_owner in
	('AV2','AV2_CC')
;

-- Once the aboce script of Grant s and Synonyms are executed on merwhr
-- Compile all the required schemas
select 'exec dbms_utility.compile_schema(schema=>'''||username||''');'
  from dba_users
 where username in 
	('RST','RST_ARCHIVAL')
order by username asc
;


SELECT UNIQUE table_owner, table_name, listagg(column_name,',')within group (order by column_position) column_name, 
        index_name, mixs
  FROM
  (
    SELECT i.table_owner, i.table_name, i.column_name, i.index_name, i.column_position,
        NVL2((SELECT UNIQUE dic.table_name FROM dba_ind_columns dic WHERE DIC.TABLE_NAME = i.table_name AND dic.table_owner = i.table_owner AND dic.column_name = i.column_name),'Y','N') mixs
       FROM
        (
            SELECT table_owner, index_owner, index_name, table_name, column_name, column_position
              FROM DBA_ind_columns@merwhp
             WHERE index_owner = 'MIS'
               and not regexp_like(table_name,'BIN$*','i') --and table_name like 'CNAC_UNDERW%'
   --          group by index_owner, index_name, table_name
             ORDER BY table_owner, index_owner, index_name, table_name ASC
        )i
  )
WHERE mixs='N'
group by table_owner, index_name, table_name,mixs
ORDER BY 1,2,3 ASC
;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Auditing sql Query
2
select /*+ FIRST_ROWS */ *
from unified_audit_trail
where event_timestamp between to_date('07/01/2019 00:00:00','mm/dd/yyyy hh24:mi:ss')
                          and to_date('09/30/2019 23:59:59','mm/dd/yyyy hh24:mi:ss')

<end node> 5P9i0s8y19Z
dt=Text
<node>
sau1h644-688 file system
2
cat /csapps/oracle/input/cluster_xref_db_storgrp |grep pctrap

<end node> 5P9i0s8y19Z
dt=Text
<node>
IIQs on sch1h018
2
-- so all request are required managers approvals

-- create user scripts
./create_user -s rstgp -u CAD1616 -c 406576-213566 -i CAD8084 -r RST_SELECT

OR

-- giving multiple roles to signle new account
./create_user -s iib4e -u CAE0646 -c 475904-247117 -i CAE0646 -r EPCINT_FEEDS_SELECT

-- should not use sysdba access 
users should not loggin as sysdba, they should login with cad* id ()

-- creating DBA user in all database servers
-- use sch1h018 centralize server to process the user creation 
create_DBA_All_Servers.ksh <account_id> <password>

-- is the file where password required to put and we can login directly
-- location : /home/<cad*_ID>
-- the password will be only for executing the scripts, which will not required to mentioned
.mypwd 


https://identityiq.cna.com/identityiq/workitem/workItem.jsf

-- check the DBs
-- it will search all DBs for the mentioned account's information
https://w3.cna.com/itinventory/ITInventoryWeb/CsGateway


-- induvidual accounts
CREATE USER "CAD8664" identified by "BAf0TZ5K" 
      DEFAULT TABLESPACE "USERS" 
      TEMPORARY TABLESPACE "TEMP" 
      PROFILE "CPROFILE" 
      ACCOUNT UNLOCK;  

grant create session to CAD8664;

-- 2 accounts access
CAD id (Individual accounts)
service access (Application Accounts)

-- User creation should be raised using iiq's only and not by service now
-- if any service now present for User creation you can ask the user to open a 
-- ticket in iiq's with manager's approve

-- service account (Application schemas) are created manually
-- service account need not required to share the account password
-- it required to go through etl admin team (ETL_ADMIN team)
CREATE USER "IIB_ADMIN" identified by "BAf0TZ5K" 
      DEFAULT TABLESPACE "USERS" 
      TEMPORARY TABLESPACE "TEMP" 
      PROFILE "APPSPROFILE" 
      ACCOUNT UNLOCK;  

grant create session to IIB_ADMIN;



CNA_TCS_ITIS_Database_Oracle <CNATCSITISDBOracle@cna.com>; dl-oracle-cna@atos.net

Security Request Id IIQ : Request ID 527334-268858

We have granted required access as per raised IIQ, Please validate the same…

We are closing the ticket
Paeusrsr

Please provide the role name or schema name to which you required the read only 
access 

Regards, 
Rahul Chaudhari 
Oracle DBA 


Below all information is mandatory while raising any IIQ.. Please let us know the missing information to proceed with the raised IIQ

Database Name:?
Application Schema Name or Role Name you required: ?
For which Account you required the role/access : ?

Regards, 
Rahul Chaudhari 
Oracle DBA 


User created and Password has been send over the email

If the User was exists already then new password would have been generated and send over the email Please check and validate the DB connectivity

IIQ Request Completed

Regards,
Rahul Chaudhari
Oracle/Exadata DBA

srinivas.karra@accenture.com

--- for DBA accounts
./create_user -s AEMCMP,AEMP,budp,CDLTP,CLMCCIP,clmccp,clmcmp,cnaprep,docmakp,ECMA1P1P,ECMA1P2P,ECMA1P3P,ECMA1P4P,ECMFSRP,ECMINP,ecmp1p2p,ECMP1P3P,ECMP1P4P,ECMRADRP,ECMRDR2P,ECMRDR3P,ECMRDR4P,ESTR2P,infmrl9p,INFSH96P,oem12cp,PAPCINTP,PAPCP,RECNPP,SDMP,spcp,trustwap,TRUSTWAP,WSRR12P,oid1p,oid2p,bcodbp,dynarc2p,DYNATRCP,ilp12cp,CNACP,cya1fn5p,cya2fn5p,ecm1fn5p,ecm2fn5p,ECMFNETP,ECMKBP,ECMP1P1P,ecmsmp,J071P,RTQPCFP,ULSNP,aerep,ALIRP,BNRP,BPPMP,CLMECMP,clmpmp,clmxsp,CM90LOGP,CM90P,CM90SURP,collqnp,dmfp,docdistp,ECMCONNP,efip,elmp,EM90P,EM90SURP,encapp,ESBNP,FDMTP,IBMUCDP,IIBP,IIQP,mvrxnp,PCDMP,PCDPP,PCDRP,rapidnp,SONARP,SPD1P,SPI12P,ULSAUNP,ULSNRP,WINP,AERE1E,AERE2E,bud2e,bud4e,clmcc2e,clmcc3e,clmcc4e,clmcc5e,CLMCCi2E,clmcci3e,clmcci5e,clmcm2e,clmcm3e,clmcm4e,clmcm5e,identityiqe,IIB6E,PAPC2E,PAPC3E,PAPC4E,papc5e,PAPC6E,PAPCE,PAPCINT2E,PAPCINT3E,PAPCINT4E,PAPCINT5E,PAPCINT6E,PAPCINTE,PAPCINTTR,PAPCTRR,recnp3e,RECNPE,spc1e,spc3e,aere2c,clmcc1c,clmcc1d,clmcc2c,clmcc3c,clmcc4c,clmcci3c,clmcm1c,clmcm1d,clmcm2c,clmcm3c,clmcm4c,FDMTD,identityiqc,MIG12C,PAPC2C,PAPC3C,PAPC4C,PAPC5C,PAPC6C,PAPCC,PAPCINT2C,PAPCINT3C,PAPCINT4C,PAPCINT5C,PAPCINT6C,PAPCINTC,PCDM1C,PCDM1D,PCDP1C,PCDP1D,PCDR1C,PCDR1D,spct,AEMCMR,AEMR,budr,cdltr,clmcc1r,clmcc1t,CLMCCi1R,clmcm1r,clmcm1t,cnapre1r,cnapre2r,docmakr,ecmfsrd,ecmind,ecmp1p2d,ecmp1p3d,ecmp1p4d,ESTR2R,INFMRL9R,INFSH96R,JBRMSR,oem12cr,PAPC2R,PAPCIN2R,PAPCINTR,PAPCR,priar,recnp2r,RECNPR,SDM1R,SPCR,WSRR12R,oid1r,oid2r,bcodbr,dynatrc2r,CNAC2R,CNACR,CYA1FN5R,cya2fn5r,ecm1fn5r,ecm2fn5r,ECMFNETD,ecmkbd,ECMP1P1D,ECMSMR,RTQPCFR,ULSN2R,ULSNR,aere1r,ALIRR,BNRR,BPPMR,clmpm1r,clmxsr,CM90R,CM90SURR,collqnr,DMF2R,dmfr,DOCDISTR,ECMCONND,efir,elmr,EM90R,EM90SURR,encapr,ESBNR,IIB1R,IIB2R,IIQR,mvrxnr,PCDMR,PCDPR,PCDRR,PJDR,RAPIDNR,SPD1R,spi12r,ULSAUN2R,ULSAUNR,WINR,ALIR4C,ALIRC,BNR2C,CDLT1C,CDLTC,clmcci1c,clmcci2c,clmcci4c,CLMECM2C,clmxs1c,collqn2c,collqn4c,DMF1C,DMF2C,DMF3C,DOCDISTC,DOCMAK1C,DOCMAK2C,DOCMAK3C,DOCMAK4C,ESBNC,FNOLT2C,IBMUCDC,\
MVRXNC,RAPIDN1C,RAPIDN2C,RECNP2C,RECNP3C,RECNPC,SPD1C,spi12c,v1alm1c,AEMC,AERE1C,BUD2C,BUD4C,clmcc5c,clmcci1t,clmcci5c,clmcm5c,CLMECM4C,CLMECM5C,CNAPRE1C,CNAPRE2C,CNAPRE3C,CNAPRE4C,CNAPRE5C,ECM1FN5C,ecm1p1pc,ECM2FN5C,ECMCONNC,ECMFNETC,ECMINC,ECMP1P1C,ECMP1P2C,ECMP1P3C,ECMP1P4C,ECMP2P1C,ECMP2P2C,ECMP2P3C,ECMP2P4C,elm1c,ENCAPC,FNOLT4C,SDM1C,WINC,clmcci4e,CNAPRE1E,CNAPRE2E,CNAPRE3E,CNAPRE4E,collqn2e,collqn4e,ECM1FN5E,ECM2FN5E,ECMCONNE,ECMFNETE,ECMINE,ECMP1P1E,ECMP1P2E,ECMP1P3E,ECMP1P4E,ECMP2P1E,ECMP2P2E,ECMP2P3E,ECMP2P4E,elm1e,ESBNE,pcdm1e,pcdp1e,AEME,ALIR4E,ALIRE,CDLT1E,CDLTE,DMF1E,DMF2E,DMF3E,DOCDISTE,DOCMAK1E,DOCMAK2E,DOCMAK3E,DOCMAK4E,EFI4E,EFIE,ENCAPE,J071E,MVRXNE,pcdr1e,RAPIDN1E,RAPIDN2E,SDM1E,SPD1E,CNAC1C,CNAC2C,CNAC3C,CNAC4C,CNAC4D,CNAC5C,EFI4C,EFIC,ESTR22C,ESTR24C,IIB1C,IIB2C,IIB3C,IIB4C,INFMRL9C,INFSH96C,JBRMSC,PETIC,ULSN1C,ULSN2C,ULSN3C,ULSN4C,ULSN4D,ULSN5C,WSRR12C,CLMFI5E,CNAC1E,CNAC2E,CNAC3E,CNAC4E,CNAC5E,ESTR22E,ESTR24E,IIB1E,IIB2E,IIB3E,IIB4E,IIB5E,IIB6E,INFMRL9E,INFSH96E,SPI12E,ULSN1E,ULSN2E,ULSN3E,ULSN4E,ULSN5E,WSRR12E,BOXIAUDP,BOXICMSP,BOXILCMP,BOXITLSP,RCAP,CAMILP,CNACOMP,CNACPP,CNACPRP,INFSHR9P,INSCNAFP,RCAT2P,SSPP,sspwcmp,uwpap,uwpp,WCMSP,WMBESBP,WPDBP,WPDEXTP,WPDWCMP,WSRXP,hypp,INFPSP,psarcp,PSJPCP,PSTFNP,ARIBYP,CEDMP,CEDPP,CEDRP,CLMEDIP,DNBRP,ecfp,EDVP,EVTLOGP,ITCAMP,itcamp,LIVCYCP,OIDP,PDFGEN2P,pdfgenp,PSHCMP,PWDPOLP,RSTGP,spcconvp,spcintp,SURHRP,DLPP,ILP12P,RMWVIOP,CYA1FNP,CYA2FNP,ECM1FNP,ECM2FNP,PMLTP,HYPMDP,ACBP,AGENP,BOE3AUDP,BOE3CMSP,BOE3LCMP,BOE3TLSP,DNBBRP,DOCMKRP,ESFMP,ESTRP,FRMMP,IBMD2P,IBMDX1P,IBMDX2P,IBMDX3P,MERLAPP,MOODYSP,OPTDIRP,PAEUSP,PCTRAP,PNLRP,PSEPMP,PSHRMP,PSITE60P,PSPRTP,RCAT1P,RCTP,SREP,VAPFP,VCMFP,WBI1P,WITCAMP,WKINP,WMBLP,WTDWP,CIMFD,ECMISD,ECMIST,ITINVD,PIRMD,PROBID,PSITED,RESTST2,ECMPJP,FNREP,HYPERESP,ITINVP,J28APP,J76APP,MMARTP,ONDP,RMPP,SENNICOP,SFINSP,V97APP,VAPIP,BRPTR,CDMR,ECMISR,ITINVDR,ITINVR,LOGR,PIRMR,PROBIDR,PSCRR,RMPR,RSTMT,RSTR,SOLDR,VAPIR,VAPR,VCMER,XPRR,CCDP,CDMP,\
CIMFP,DBAP,ECMISP,FDMGTP,IPCP,LOGP,MTRAKP,PIRMP,PROBIP,PSCRP,PSITE50P,WASSESP,XPRP,BRPTP,NGLAP,NGLP,NTKP,BRPT1E,BRPT2E,BRPT4E,CDM3E,ECMISE,ECMPJE,FDMGTE,ITINV4E,ITINVE,PSCR3E,PSCR4E,PSITEU,RMPE,SOLD3E,SOLD4E,VAPAE,VAPE4E,VCME4E,XPR2E,XPR3E,BOCMSM,BRPT2C,FNREC,ITINV4C,J28ACC,J28ADC,J28AEC,J76ACC,J76ADC,J76AEC,MMARTD,RST1C,RST4C,RST4D,SENRENC,SENRENE,SENRENUE,SENRENZE,SFINSD,SOLD3C,SOLD4C,V97ACC,V97ADC,V97AEC,V97AEE,V97AUE,V97AZE,VAPE4C,VCME4C,BRE3C,BRPT4C,CDM3C,ECMISC,ECMISTC,ECMPJC,FDMGTC,MTRAKC,PSCR4C,RST2C,RST3C,XPR2C,XPR3C,APES4C,ATLASC,BLADEC,BLADED,BOAUD2C,BOCMS2C,BPMA1C,CMTC,COIC,CRESTAC,CRRC,DNBBRAC,DNBBRC,DUNC,EDAC,EDAD,ESFMD,ESTR4C,ESTR4D,ESWKC,FMSTC,FMSTD,FRBPMC,FRMMD,IATC,IBMDC,INM1C,INM2C,INM4C,INM4D,IRISD,ITCAMD,ITIM2C,ITIMC,ITIMD,LINOL1C,LINOL2C,LINOLC,MIDD,MONITC2,MONITORC,MOODYSC,OEMC,PCAD8,PCTR2C,PCTR3C,PCTR4C,PCTR4D,PCTRC,PESOC,PNLRC,PONGC,PSEPM1C,PSEPM1D,PSEPM2C,PSEPM2D,PSEPM3C,PSEPM3D,PSEPM4C,PSEPM4D,PSEPMO,PSEPMS,PSEPMX,PSHRM1C,PSHRM1D,PSHRM2C,PSHRM2D,PSHRM3C,PSHRM4C,PSHRM4D,PSHRMG,PSHRMO,PSHRMS,PSHRMSC,PSHRMSN,PSHRMU,PSHRMX,PSPRT1C,PSPRT1D,PSPRT2C,PSPRT2D,PSPRT4C,PSPRT4D,QACSC,RECOND,RSMTRC,SCAC,SCHIC,SIE1C,SIE2C,SIE3C,SIED,SOSC,SPECM2D,SPECM3D,SRE4C,SREC,STFILGC,SUBRC,TDWD,UETC,VNCL4C,WBI4C,WBIC,WKINC,WMBL4C,APES4E,BNR2E,BOAUD2E,BOCMS2E,BPMA1E,CCLE,CMTE,CRESTAE,CRRE,DNBBRE,ESFME,ESTR2E,ESTR4E,EUS1E,EUS2E,EUS4E,FMSTE,FNOLS2E,FNOLS4E,IATE,INM2E,INM4E,INM7E,ITIME,NSRME,PCTR2E,PCTR3E,PCTR4E,PCTRE,PCTRT,PESOE,PNLRE,PONGE,PSEPM1E,PSEPM2E,PSEPM4E,PSHRM2E,PSHRM3E,PSHRM4E,PSPRT1E,PSPRT2E,PSPRT4E,RKME,RSMPE,RSMTRE,SBME,SCHIE,SIE1E,SIE2E,SIE3E,SOSE,SRE4E,SREE,STATE,STATGE,STFILGE,SUBRE,UDDIE,UETE,VNCL4E,WBI1E,WBI2E,WBI3E,WBI4E,WBIE,WITCAME,WKINE,WMBL1E,WMBL2E,WMBL3E,WMBL4E,WTDWE,AGUAP,BLADEP,BLDPRTP,BLDWHP,COREFP,COREFSP,DNBBRAP,FINACHP,ILVP,IRISP,NTINSP,OAPEXP,OEMP,RTPDZP,UETP,ACBC,AGENC,AGUAC,AIPSPOC,APDLC,BLDPRTC,BLDPRTD,BLDWHC,BLDWHD,BOXIAUDC,BOXICMSC,BOXILCMC,BOXITLSC,CAOC,CAOD,CCLC,CMT1C,CNAEDDC,CRR1C,\
DMKRC,DOCMKRC,ECFPOC2C,EUS1C,EUS2C,EUS2E,EUS4C,FNOLS1C,FNOLS2C,FNOLS4C,HAILSTMC,IBMDX1C,IBMDX2C,ILMC,LINOL4C,M2TRAKC,MEDCC,OAPEX1C,OAPEX4C,OAPEXC,OCIC,PAEUS1C,PAEUS2C,PAEUS3C,PAEUSC,PRISMXD,RCA2C,RCA4C,RCT2C,RCT4C,RMDMRTD,SSOTD,SUBR1C,SVCTRC,UDDIC,WBI1C,WBI2C,WBI3C,WMBL1C,WMBL2C,WMBL3C,APDLR,APESR,APESR2,CMTR,CNAEDDR,COIR,CRRR,DNBBRR,DOCMKRR,FINACHR,FNOLS2R,FNOLSR,IATR,INMDR,LINOL2R,LINOLR,MONITR,NTINSR,OCIR,PAEUSRSR,PATROLD,PESOR,PXNTR,QACSR,RSMTRR,SCAR,SCHIR,SOSR,SUBRR,UETR,WBI1DR,wbi1dr,WMBLDR,wmbldr,APDLP,APESP,BCSLGP,CASP,CMTP,CNAEDDP,COIP,CRRP,ESWKP,FNOLSP,FRBPMP,HAILSTMP,LINOLP,M2TRAKP,MONITP,OCIP,ONDBP,ORVP,PAEUSRSP,PCTRP,PESOP,PONGP,PRISMXP,QACSP,RECONP,SCAP,SCHIP,SSOTP,SUBRP,SVCTRP,BOXIAUDR,BOXICMSR,BOXILCMR,BOXITLSR,CASR,ECM1FNC,ECM2FNC,RTPDSC,SMINVC,ECM1FNE,ECM2FNE,CYA1FNR,CYA2FNR,ECM1FNR,ECM2FNR,RTPDSR,FSPF1C,FSPF4C,FSPFD,PSFIN1E,HYPMD4C,MRLNAP4C,MRLNAP2C,ACBE,AGENE,CLFSE,clmc2e,CMT1E,CONC2E,CRR1E,DOCMKRE,FINACHE,LINOL2E,LINOL4E,LINOLE,MONITE,OAPEX4E,OAPEXE,OCIE,PAEUS1E,PAEUS2E,PAEUS3E,PAEUSE,RCAT10GT,RCT1E,RCT2E,RCT4E,SUBR1E,MRLNAP1E,MRLNAP3C,MRLNAP4E,CAOR,FSPFR,CAOP,FSPFP,HYPMDR,CEDMR,CEDPR,CEDRR,CLMEDIR,DNBRR,ecfr,EVTLOGR,ITCAMR,LIVCYCR,OIDR,pdfgen1r,pdfgen2r,PWDPOLR,RCAT2T,rstg2r,RSTGMT,RSTGR,spcintr,sspintr,pscjc4d,PSJPC1C,PSJPC1D,PSJPC3C,PSJPC3D,PSJPC4D,psjpc4d,psjpcu,PSTFN4D,pstfn4d,INFPSE,PSJPC1E,psjpc2e,psjpc3e,PSJPC4E,PSTFN1E,PSTFN2E,PSTFN3E,PSTFN4E,STATCPCE,STATEE,STATJPCE,STATPE,STATTFNE,CAMILC,CEDM1C,CEDM1D,CEDM2C,CEDM2D,CEDM3C,CEDM3D,CEDM4C,CEDP1C,CEDP1D,CEDP2C,CEDP2D,CEDP3C,CEDP3D,CEDP4C,CEDR1C,CEDR1D,CEDR2D,CLMEDI2C,CLMEDI4C,CNACOMC,cnacp2c,CSEC,DLP3C,DLP4C,DNBECFC,dnbecfc,DNBPOCC,DOCUMKRC,ecf2c,ecf4c,ecfc,ECMAUDC,EDVC,EVTLOG2C,EVTLOG4C,EVTLOGC,INFASHRC,infashrc,INFPSC,INSCNAFC,LIVCYCC,livcycc,LIVCYCD,livcycd,pdfgen4c,PSHCM4C,PSHCM4D,PSHCMG,PSHCMO,PSHCMSB,PSHCMU,pshrms1d,PWDPOL1C,PWDPOL2C,rcat11gt,RMWVIO4C,RSTG1C,RSTG2C,RSTG3C,RSTG4C,RSTG4D,rstg5c,SPCINT2C,SPCINT4C,SPCINTT,SSPC,SURHRC,\
UWPC,WMBESBC,WPDB2C,WPDBC,wpdbc,wsrrxc,WSRXC,wsrxc,CAMILE,CEDM1E,CEDP1E,CEDR1E,CLMEDI2E,CLMEDI4E,CNACOME,cnacp2e,CSEE,DLP3E,DLP4E,DLPSE,ecf4e,EVTLOG2E,EVTLOG3E,evtlog4e,INFASHRE,livcyce,pdfgen4e,PMLTE,PSHCM1E,PSHCM2E,PSHCM4E,PWDPOL1E,PWDPOL2E,RMWVIO4E,RSTG1E,RSTG2E,RSTG3E,RSTG4E,rstg5e,RSTGTR,spcint1e,SPCINT2E,spcint3e,SPCINT4E,SSPE,SURHRE,UWPE,WMBESBE,WPDBE,WSRXE,CAMILR,CNACOMR,CNACPR,INFSHR9R,INSCNAFR,PSHCMR,RCAT2T,sspextr,SSPR,UWPAR,UWPR,WMBESBR,WPDBR,WPDEXTR,WPDWCMR,WSRGR,WSRXR,DLPR,ILP12R,RMWVIOR,INFPSR,psarcr,PSJPCR,pstfnr,OMSR,acbr,AGENR,BOAUD2R,BOCMS2R,CRESTAR,DBOIDB,EDAR,ESTRR,EUSR,INML1R,INMLR,ITIMR,MERLAPR,MOODYSR,OAPEXR,OIDR,PAEUSR,PCAPUAT,PCTRAR,PCTRR2,PNLRR,PONGR,PSEPMR,PSEPMT,PSPRTR,PSPRTT,PXCW2R,PXCWR,PXDAR,PXESR,PXIDR,PXINR,PXPAR,PXPOR,PXSPR,PXSYR,PXWPR,RCAT1P,RCAT1T,RCTR,SIER,SRER,STFILGR,UDDIR,VAPFR,VCMFR,VNCLR,WBI1R,WBIR,WMBLR,BOAUD2P,BOCMS2P,CRESTAP,DUNP,EDAP,EUSP,IATP,IBMDP,INMLP,ITIMP,PCALEP,PMAMLP,PMAUDP,PMEMLP,PX2CWP,PX2DAP,PX2ESP,PX2IDP,PX2INP,PX2PAP,PX2POP,PX2SPP,PX2SYP,PX2WPP,SIEP,STFILGP,VNCLP,VNJGP,WBIP,CAOT8,CCSPD,CCSPE,CMD3D,HRWPD,INMD,INMR,INMT,J07D,MR2PD,PRISMD,SLVDEV,SLVQAT,SMFRD,VPTPD,VPTPE,CARDST,CARDSU,HRWPT,AAPDP,CARP8,CARU8,CCSPP,CMDP,CSAP,HRCPP,PDEP,RDMP,RS1PP,SLVUAT,VPTPP,WRTP,AGLD,CADE8,CARD8,CART8,PDED,WRTD,CARDSP,ETSP,PCLP,PERRP,PSPR,SLVPRD,SMFRP,TBCLNP,PSFN,ABOREP,DIG8P,E32P,GRCLMSP,INMP,ISGP,CHI817,CHISENME,CHISENTS,CHISENYE,CHIUPRTS,LONSENPR,CIEAPP,CMSAPP,CRCAPP,MARAPP,UKSNPP,DWINT,DWINT2,TPINT,TPINT2,tpint3,DWUAT,TPUAT,DWDEV,DWDEV2,SBOX,TPDEV,TPDEV2,P1DW,RCAT,P1TP,TLPRD,ilp12cep,CIEACC,CIEADC,MARACC,MARADC,UKSD2C,UKSNCC,UKSNDC,UKSNDR,UKSNEC  -u cae8692 -c 1038591-488935 -i cae8692 -r dba,connec


./create_user_exa -s merwhp -u cae3109 -c 1060496-499312 -i cae3109 -r rststage_Select

./create_user_exa -s merwhp -u cae8654 -c 1059317-499367 -i cae8654 -r JOB_WH_PCORBUSINESS,BETS_READ,MIS_DM_RPT_SELECT,MIS_RPT_DEV_SELECT

./create_user_exa -s merwhp -u cae7276 -c 1064242-501475 -i cae7276 -r mis_Select

./create_user_exa -s merdmp -u cae7901 -c 1064557-501485 -i cae7901 -r MIS_DM_SELECT

./create_user_exa -s merdmp -u cae8891 -c 1080557-508548 -i cae8891 -r MIS_DM_SELECT

./create_user_exa -s merdm3c -u cae8953 -c 1071436-504678 -i cae8953 -r MIS_DM_SELECT

./create_user_exa -s merwh3c -u cae7276 -c 1064232-500808 -i cae7276 -r mis_Select

./create_user_exa -s MERDM5E,MERDM5C -u cae9214 -c 1089664-511719 -i cae9214 -r job_dm_rtb_wv

./create_user_exa -s merwhp -u cae8235,cae8108,cae7025,cae7901,cae7276 -c 1064230-500806 -i cae8235 -r mis_Select

./create_user_exa -s merwhp,merwhr,merwh4c,merwh2c,merwh5e,merwh5c,merwh3c -u cab9161 -c 1059251-497791 -i cab9161 -r job_wh_rtb_surety

./create_user_exa -s merwhp,merwhr,merwh4c,merwh2c -u cae7862 -c 1059028-497835 -i cae7862 -r JOB_DM_WHBUSINESS

./create_user -s cnac1c,cnac2c,cnac3c,cnac4c,cnac1e,cnac2e,cnac3e,cnac4e,cnac5e,cnacr,cnac2r -u cae8720 -c 1045397-493648 -i cae8720 -r AISS_SELECT

./create_user_exa -s merwhp -u cae4738 -c 1056672-497535 -i cae4738 -r job_wh_general

./create_user_exa -s merwhp -u cae8654 -c 1056671-498217 -i cae8654 -r job_wh_general

./create_user_exa -s merdmp -u cae8860 -c 1058993-498860 -i cae8860 -r job_dm_fvbusiness

./create_user_exa -s merdmp -u ca744 -c 1056676-496822 -i ca744 -r job_dm_whbusiness

./create_user_exa -s merwhp,merwh3c -u cae5942 -c 1058752-499098 -i cae5942 -r mis_select_sensitive

./create_user_exa -s MERWHP,MERWHR,MERWH2C,MERWH3C,MERWH4C,MERWH5C,MERWH5E -u cae8710 -c 1038591-488935 -i cae8710  -r job_wm_dba


./create_user_exa -s MERDMP,MERDMR,MERDM5C,MERDM5E,MERDM2C,MERDM3C,MERDM4C,MERDM4E -u cae8710 -c 1038591-488935 -i cae8710 -r job_dm_dba

./create_user_exa -s  merwhr -u cae8086 -c 1048078-493955 -i cae8086 -r tapods_select,claimdms_select,claimods_select,mis_select,mis_dm_Select

./create_user_exa -s merwhp -u cae8815 -c 1044376-492694 -i cae8815 -r esight_Admin_select,mis_select

./create_user -s caop -u cac6639 -c 1044502-493257 -i cac6639 -r BETS_SELECT

./create_user -s paeusc -u cae8660 -c 1039089-490869 -i cae8660 -r DNB_DELETE,DNB_EXECUTE,DNB_INSERT,DNB_SELECT,PROD_SUPPORT_ROLE,DNB_UPDATE,CREATE SESSION,UNLIMITED TABLESPACE

./create_user -s spc2e -u cac8062 -c 1029612-487128 -i cac8062 -r spcuser_select,spcuser_update

./create_user -s elm1e -u cae8603 -c 1005696-476909 -i cae8315 -r ELMCAT_SELECT,ELMCAT_UPDATE,ELMCAT_INSERT,ELMCAT_DELETE

./create_user -s cnac1e,cnac2e,cnac3e,cnac4e,cnac5e,cnac1c,cnac2c,cnac3c,cnac4c,cnac5c,cnacr,cnac2r -u cae8603 -c 1024705-483528 -i cae8603 -r AISS_SELECT,AISS_INSERT,AISS_UPDATE,AISS_DELETE,AISS_EXECUTE,STF_EXECUTE,STF_SELECT,STF_INSERT,STF_UPDATE,STF_DELETE

./create_user -s CLMEDI2C -u cae8332 -c 1002119-474478 -i cae8332 -r wcedi_select,wcedi_insert,wcedi_update,wcedi_delete
./create_user -s CLMEDI2C -u cae8359 -c 1002118-474479 -i cae8359 -r wcedi_select,wcedi_insert,wcedi_update,wcedi_delete
./create_user -s CLMEDI2C -u cae7862 -c 1002114-474476 -i cae7862 -r wcedi_select,wcedi_insert,wcedi_update,wcedi_delete

./create_user -s eswkc -u cae8232 -c 998150-466959 -i cae8232 -r esrp_select,esrp_insert,esrp_update,esrp_delete

./create_user -s papc2r -u cae7827 -c 999591-473460 -i cae7827 -r papcuser_select

./create_user -s fmstc -u cae7827 -c 999578-473455 -i cae7827 -r papcuser_select

./create_user -s fmstc -u cae8201 -c 1001904-473524 -i cae8201 -r fms_Select,fms_insert,fms_update,fms_delete
./create_user -s infsh96r -u cae8156 -c 991325-467995 -i cae8156 -r cls_select,pcad_Select

./create_user -s docmkrr -u cae8315 -c 990907-470146 -i cae8315 -r DOCCM_select,DOCCM_insert,DOCCM_delete,DOCCM_execute,DOCCM_update

./create_user -s docmkrp -u cae7770 -c 998079-470638 -i cae7770 -r DOCCM_select,DOCCM_insert,DOCCM_delete,DOCCM_execute,DOCCM_update
./create_user -s docmkrr -u cae7770 -c 990876-470636 -i cae7770 -r DOCCM_select,DOCCM_insert,DOCCM_delete,DOCCM_execute,DOCCM_update
./create_user -s rstg1c,rstg2c,rstg3c,rstg4c,rstg5c,rstg1e,rstg2e,rstg3e,rstg4e,rstgr,rstg2r -u cae8315 -c 991192-471257 -i cae8315 -r rst_select,rst_insert,rst_update,rst_delete

./create_user -s ecf4c -u cae8087 -c 996074-473432 -i cae8087 -r TRANSACTION_DELETE,TRANSACTION_EXECUTE,TRANSACTION_INSERT,TRANSACTION_SELECT,TRANSACTION_UPDATE,ecf_update,ecf_insert,ecf_delete,ecf_execute,ecf_select,staging_Select,staging_insert,staging_update,staging_delete,staging_execute,staging_archive_select,staging_archive_insert,staging_archive_update,staging_archive_delete,staging_archive_execute,feedsout_execute,feedsout_select,feedsout_insert,feedsout_update,feedsout_delete

./create_user -s j28app,j76app,v97app,j28acc,j76acc,v97acc,j28adc,j76adc,v97adc,j28aec,j76aec,v97aec -u cae7862 -c 999948-470166 -i cae7862 -r cls_select,pcad_Select
 
./create_user -s pcalep -u cae7862 -c 985202-468030 -i cae7862 -r cls_select,pcad_Select
 
 ./create_user -s pcalep -u cae7862 -c 985202-468030 -i cae7862 -r cls_select,pcad_Select
./create_user -s pcalep -u cae7862 -c 985201-468029 -i cae7862 -r cls_select,pcad_Select
./create_user -s pcapuat -u cae7862 -c 985186-468002 -i cae7862 -r cls_select,pcad_Select

./create_user -s pcad8 -u cae7862 -c 985182-468001 -i cae7862 -r cls_select,pcad_Select
./create_user -s ecf4c -u cae8042 -c 985066-468582 -i cae8042 -r FEEDSOUT_SELECT

./create_user -s ecmpjc -u cae7829 -c 984786-468318 -i cae7829 -r PJOB_SELECT

./create_user -s ecmpjp -u cae7831 -c 984787-468345 -i cae7831 -r PJOB_SELECT

./create_user -s ecmpjp -u cae7814 -c 984780-468351 -i cae7814 -r PJOB_SELECT

./create_user -s ecmpje -u cae7831 -c 984776-468331 -i cae7831 -r PJOB_SELECT

./create_user -s ecmpje -u cae7814 -c 984772-468336 -i cae7814 -r PJOB_SELECT

./create_user -s ecmpje -u cae7829 -c 984771-468330 -i cae7829 -r PJOB_SELECT

./create_user -s ecmpjp -u cae7829 -c 984769-468346 -i cae7829 -r PJOB_SELECT
./create_user -s ecmpje -u cae8164 -c 984763-468338 -i cae8164 -r PJOB_SELECT
./create_user -s ecmpjp -u cae8164 -c 984762-468353 -i cae8164 -r PJOB_SELECT

./create_user -s papcint4c,papcint2c,papcint6c,papcint3c,papcintr,papcintp,papcint5c,papcintc,papcint2e,papcint6e,papcint3e,papcint4e,papcint5e,papcinte -u cae8075 -c 979341-466216 -i cae8075 -r EPCINT_FEEDS_SELECT

./create_user -s mtrakc -u cae7788 -c 965076-459853 -i cae7788 -r MTRAK_SELECT
./create_user -s mtrakc -u cae7808 -c 965075-459852 -i cae7808 -r MTRAK_SELECT
./create_user -s clmcc3e -u cae8217 -c 992750-470775 -i cae8217 -r CCSYSTEM_SELECT,PROD_SUPPORT_ROLE
./create_user -s ecfp -u cae8217 -c 980498-466881 -i cae8217 -r FEEDSOUT_SELECT,ECF_SELECT

./create_user -s p1dw -u cae3944 -c 991971-471506 -i cae3944 -r CMJOB_SELECT,ODS_SELECT
./create_user -s p1tp -u cae3944 -c 991969-471505 -i cae3944 -r OLTP_SELECT,CLAIMS_SELECT,SSPA_SELECT
./create_user -s tpuat -u cae3944 -c 991972-471504 -i cae3944 -r OLTP_SELECT,OLTP_INSERT,OLTP_UPDATE,OLTP_DELETE,OLTP_EXECUTE,CLAIMS_SELECT,CLAIMS_INSERT,CLAIMS_UPDATE,CLAIMS_DELETE,CLAIMS_EXECUTE,SSPA_SELECT,SSPA_INSERT,SSPA_UPDATE,SSPA_DELETE,SSPA_EXECUTE

./create_user -s TPINT -u cae3944 -c 991968-471503 -i cae3944 -r OLTP_SELECT,OLTP_INSERT,OLTP_UPDATE,OLTP_DELETE,OLTP_EXECUTE,CLAIMS_SELECT,CLAIMS_INSERT,CLAIMS_UPDATE,CLAIMS_DELETE,CLAIMS_EXECUTE,SSPA_SELECT,SSPA_INSERT,SSPA_UPDATE,SSPA_DELETE,SSPA_EXECUTE

./create_user -s tpdev -u cae3944 -c 991970-471491 -i cae3944 -r OLTP_SELECT,OLTP_INSERT,OLTP_UPDATE,OLTP_DELETE,OLTP_EXECUTE,CLAIMS_SELECT,CLAIMS_INSERT,CLAIMS_UPDATE,CLAIMS_DELETE,CLAIMS_EXECUTE,SSPA_SELECT,SSPA_INSERT,SSPA_UPDATE,SSPA_DELETE,SSPA_EXECUTE
./create_user -s papcint2c -u cac3021 -c 979161-465922 -i cac3021 -r EPCINT_FEEDS_SELECT

./create_user -s cnacr,cnac2r -u cae8127 -c 979079-466227 -i cae8127 -r AISS_SELECT,AISS_INSERT,AISS_UPDATE,AISS_DELETE,AISS_EXECUTE,STF_EXECUTE,STF_SELECT,STF_INSERT,STF_UPDATE,STF_DELETE

./create_user -s cnac1e,cnac2e,cnac3e,cnac4e,cnac5e -u cae8127 -c 979079-466227 -i cae8127 -r AISS_SELECT,AISS_INSERT,AISS_UPDATE,AISS_DELETE,AISS_EXECUTE,STF_EXECUTE,STF_SELECT,STF_INSERT,STF_UPDATE,STF_DELETE

./create_user -s cnac1c,cnac2c,cnac3c,cnac4c,cnac5c,cnacr,cnac2r -u cae8127 -c 979079-466227 -i cae8127 -r AISS_SELECT,AISS_INSERT,AISS_UPDATE,AISS_DELETE,AISS_EXECUTE,STF_EXECUTE,STF_SELECT,STF_INSERT,STF_UPDATE,STF_DELETE

./create_user -s iib1c,iib2c,iib3c,iib4c,iib1e,iib2e,iib3e,iib5e,iib6e,iib1r,iib2r -u cae8075 -c 979067-466214 -i cae8075 -r BRIDJE_OWNER

./create_user -s rapidnr -u cae7848 -c 965863-460117 -i cae7848 -r UPS_SELECT

./create_user -s alirp -u cac5962 -c 958030-457097 -i cac5962 -r ALIR_SELECT

./create_user -s spcr -u CAE6109 -c 946002-452360 -i CAE6109 -r SPCUSER_SELECT

./create_user -s cnacp -u CAE6055 -c 945920-452478 -i CAE6055 -r STF_SELECT,AISS_SELECT

./create_user -s spc4e -u CAE4536 -c 946003-452303 -i CAE4536 -r SPCUSER_SELECT

./create_user -s spc2e -u CAE6109 -c 946007-452294 -i CAE6109 -r SPCUSER_SELECT


./create_user -s dmfr -u CAE7958 -c 948542-453412 -i CAE7958 -r SPECM_SELECT,TRANSACTION_SELECT,FEEDSOUT_SELECT,STAGING_SELECT

./create_user -s dmf2c -u CAE7958 -c 948554-453452 -i CAE7958 -r SPECM_SELECT,TRANSACTION_SELECT,FEEDSOUT_SELECT,STAGING_SELECT

./create_user -s dmf3e -u CAE7889 -c 948555-453444 -i CAE7889 -r SPECM_SELECT,TRANSACTION_SELECT,FEEDSOUT_SELECT,STAGING_SELECT


./create_user -s dmf3e -u CAE7958 -c 948553-453443 -i CAE7958 -r SPECM_SELECT,TRANSACTION_SELECT,FEEDSOUT_SELECT,STAGING_SELECT


./create_user -s dmf2C -u CAE7889 -c 948550-453453 -i CAE7889 -r SPECM_SELECT,TRANSACTION_SELECT,FEEDSOUT_SELECT,STAGING_SELECT


./create_user -s dmf3e -u CAE7958 -c 948551-453430 -i CAE7958 -r SPECM_SELECT,TRANSACTION_SELECT,FEEDSOUT_SELECT,STAGING_SELECT


./create_user -s dmf -u CAE7958 -c 948543-453427 -i CAE7889 -r SPECM_SELECT,SPECM_INSERT,SPECM_UPDATE,SPECM_DELETE,TRANSACTION_SELECT,TRANSACTION_INSERT,TRANSACTION_UPDATE,TRANSACTION_DELETE,FEEDSOUT_SELECT,FEEDSOUT_INSERT,FEEDSOUT_UPDATE,FEEDSOUT_DELETE,STAGING_SELECT,STAGING_INSERT,STAGING_UPDATE,STAGING_DELETE

./create_user -s dmfp -u CAE8062 -c 953765-455705 -i CAE8062 -r SPECM_SELECT,TRANSACTION_SELECT,FEEDSOUT_SELECT,STAGING_SELECT


./create_user -s dmfp -u CAE8020 -c 958968-457575 -i CAE8020 -r APERS_SELECT

./create_user -s elmp -u CAE7884 -c 945925-451271 -i CAE7884 -r ELM_HAZARD_SELECT

./create_user -s estr2p -u CAE7884 -c 945924-451279 -i CAE7884 -r ESTR_SELECT
-- user creation process
  ./create_user -s MERWHR -u CAE1754 -c 541291-272382 -i CAE1754 -r CLAIMODS_SELECT


./create_user -s Paeusrsr -u CAD2176 -c 529976-269270 -i CAD2176 -r PROD_SUPPORT_ROLE,CMDSTBLS_DELETE,CMDSTBLS_EXECUTE,CMDSTBLS_INSERT,CMDSTBLS_SELECT,CMDSTBLS_UPDATE,EUS_CONTROL_DELETE,EUS_CONTROL_EXECUTE,EUS_CONTROL_INSERT,EUS_CONTROL_SELECT,EUS_CONTROL_UPDATE,EUS_STAGE_DELETE,EUS_STAGE_EXECUTE,EUS_STAGE_INSERT,EUS_STAGE_SELECT,EUS_STAGE_UPDATE,PA_SE_ARCHIVE_DELETE,PA_SE_ARCHIVE_EXECUTE,PA_SE_ARCHIVE_INSERT,PA_SE_ARCHIVE_SELECT,PA_SE_ARCHIVE_UPDATE,PA_SE_INPUT_DELETE,PA_SE_INPUT_EXECUTE,PA_SE_INPUT_INSERT,PA_SE_INPUT_SELECT,PA_SE_INPUT_UPDATE,PA_SE_MON_DELETE,PA_SE_MON_INSERT,PA_SE_MON_SELECT,PA_SE_MON_UPDATE,PA_SE_REF_DELETE,PA_SE_REF_EXECUTE,PA_SE_REF_INSERT,PA_SE_REF_SELECT,PA_SE_REF_UPDATE



./create_user -s paeusc,paeuse,paeus1c,paeus1e,paeus2c,paeus3c,paeus2e,paeus3e,paeusr -u CAD2176 -c 529978-269276 -i CAD2176 -r PROD_SUPPORT_ROLE,CMDSTBLS_DELETE,CMDSTBLS_EXECUTE,CMDSTBLS_INSERT,CMDSTBLS_SELECT,CMDSTBLS_UPDATE,EUS_CONTROL_DELETE,EUS_CONTROL_EXECUTE,EUS_CONTROL_INSERT,EUS_CONTROL_SELECT,EUS_CONTROL_UPDATE,EUS_STAGE_DELETE,EUS_STAGE_EXECUTE,EUS_STAGE_INSERT,EUS_STAGE_SELECT,EUS_STAGE_UPDATE,PA_SE_ARCHIVE_DELETE,PA_SE_ARCHIVE_EXECUTE,PA_SE_ARCHIVE_INSERT,PA_SE_ARCHIVE_SELECT,PA_SE_ARCHIVE_UPDATE,PA_SE_INPUT_DELETE,PA_SE_INPUT_EXECUTE,PA_SE_INPUT_INSERT,PA_SE_INPUT_SELECT,PA_SE_INPUT_UPDATE,PA_SE_MON_DELETE,PA_SE_MON_INSERT,PA_SE_MON_SELECT,PA_SE_MON_UPDATE,PA_SE_REF_DELETE,PA_SE_REF_EXECUTE,PA_SE_REF_INSERT,PA_SE_REF_SELECT,PA_SE_REF_UPDATE


./create_user -s dnbbrp -u CAD2176 -c 529977-269280 -i CAD2176 -r PROD_SUPPORT_ROLE,DNB_SELECT,DNB_EXECUTE

./create_user -s papcintp -u cae1773 -c 655512-323600 -i cae1773 -r EPCINT_FEEDS_SELECT
 
./create_user -s camilR -u CAE1167 -c 527522-268699 -i CAD8056 -r CNAPA_PPMS_SELECT,CNAPA_PC_SELECT,CNAPA_PS_SELECT,CNAPA_PPMC_SELECT,CNAPA_SEQ_SELECT,CNAPA_SYS_SELECT,CNAPA_UDIR_SELECT,CNAPA_USR_SELECT,CNAWB_PC_SELECT,CNAWB_PS_SELECT,CNAWB_PPMC_SELECT,CNAWB_PPMS_SELECT,CNAWB_SEQ_SELECT,CNAWB_SYS_SELECT,CNAWB_UDIR_SELECT,CNAWB_USR_SELECT


-- create user on multiple dbs
./create_user -s pshrm2d,pshrm2c,bncrp2c,bncrpr,bncrpp -u cab5678 -c 7689876-890 -i c029879 -r role1,role2,role3


./create_user -s papcr -u cad7944 -c 526302-268357 -i cac4559 -r PAPCUSER_SELECT


./create_user -s papcr -u cad0551 -c 526297-268378 -i cac4559 -r PAPCUSER_SELECT

./create_user -s papc5e -u cad0551 -c 526297-268378 -i cac4559 -r PAPCUSER_SELECT

cp /depot/oracle/scripts/usercreate/notify_group_template_exceptions /home/CAE0729
cp /depot/oracle/scripts/usercreate/notify_user_template_exceptions /home/CAE0729
cp /depot/oracle/scripts/usercreate/user_exists_template /home/CAE0729
cp /depot/oracle/scripts/usercreate/user_exists_template_group /home/CAE0729 
cp /depot/oracle/scripts/usercreate/notify_group_template /home/CAE0729
cp /depot/oracle/scripts/usercreate/notify_user_template /home/CAE0729
cp /depot/oracle/scripts/usercreate/new_user_template /home/CAE0729
cp /depot/oracle/scripts/usercreate/new_group_template /home/CAE0729
cp /depot/oracle/scripts/usercreate/create_user /home/CAE0729





ssh lrau1p17  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrau1p18  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrau1p19  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrau1p20  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrau1p21  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrau1p22  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrau1p23  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrau1p24  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrau1p25  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d25  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d27  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d34  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d35  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d36  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d37  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d38  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d39  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d40  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d41  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d42  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d43  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d44  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d45  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d46  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d47  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh lrch1d48  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h048  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h049  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h053  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h054  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h068  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h069  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h133  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h134  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h137  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h138  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h346  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h347  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h352  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h353  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h644  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sau1h688  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h007  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h020  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h025  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h067  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h068  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h070  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h071  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h072  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h136  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h217  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h219  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h231  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h232  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h233  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h234  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h346  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h347  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h348  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h349  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h384  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h385  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h389  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h390  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h392  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h395  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h477  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h478  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h537  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h538  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h578  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h648  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h649  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h661  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h665  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h672  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h673  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h674  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h675  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h722  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h723  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h755  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h756  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h757  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h758  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h904  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h906  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1h907  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p001  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p143  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p144  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p146  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p148  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p182  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p191  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p215  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p232  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p233  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p238  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p245  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p253  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p266  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p491  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sch1p492  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh schwkh01  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sukgch05  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh surfsda109  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh surfsda112  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh surfsda208  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh surfsda701  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh surfsda801  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sw3l1h03  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 
ssh sw3mnh05  /depot/oracle/temp/DBA_Account_rest_0748p.ksh 

<end node> 5P9i0s8y19Z
dt=Text
<node>
EID Process
2
/csapps/oracle/cnascripts/geneid.sh <<sid>>

-- To handle EID01 account to kill if inactive

Raise RITM by Application Team to share the EID password
SCTask is been created in CNA for Middrange team
Middrange team runs the jobs of EID process which create eid account with password
Call Service Desk to get the Password if at-all Service desk is not responding then follow the below steps to get the password generated

Search the JOB name in cm90p DB for EID
-- e.g 
DLR17CLMCCP -> for clmccp
PRDORAINT1CLMCCIPEID -> for clmccip

select nodeid,owner,author,cmdline,descript, jobname, schedtab, wdaystr scheday, fromtime hour 
from ctmuser.cms_jobdef 
where jobname in ('DLR17CLMCCP','PRDORAINT1CLMCCIPEID'); 


-- check the job's logs for EID process
/csapps/bmc/ctm/ctm/sysout/

-- the script for eid process just passw the database name 
+ /csapps/oracle/cnascripts/geneid.sh clmccp

-- search the log and check the password for eod01
/csapps/dbadm/tmp/greid$datetime$ORACLE_SID.log


--- You might have to kill the account if that's connected to DB
-- kill intactive sessions
col database_name for a12
col username for a13
col session_status for a14
col account_status for a14
col logonm_time for a20
col timestamp for a20
set lines 32000
select sys_context('USERENV','DB_NAME')Database_Name, ds.username, gs.status session_status, ds.account_status, 
   to_char(gs.logon_time,'dd/mm/yyyy hh24:mi:ss') logonm_time, to_char(sysdate,'mm/dd/yyyy hh24:mi:ss')timestamp
from gv$session  gs, dba_users ds
where gs.username = ds.username
 and gs.username is not null and gs.username='EID01'

col account_lock for a50
select 'alter user '||ds.username||' account lock;' account_lock,
  'alter system disconnect session '''||sid||','||serial#||',@'||inst_id||''';' kill_Sess_script
from gv$session  gs, dba_users ds
where gs.username = ds.username
 and gs.username is not null and gs.username='EID01'

-- if required 
select sid, serial#,username,schemaname,status,inst_id,to_char(logon_time,'dd/mm/yyyy hh24:mi:ss') logonm_time
from gv$session 
where username is not null and username='EID01' and status='INACTIVE';

<end node> 5P9i0s8y19Z
dt=Text
<node>
pcdpp - pcd scrubing data
2
--- start the import using the below script to take of masking and scurbing
/csapps/oracle/dbascripts/pcdp1c/run_refresh_schemas_DP_pcdp1c.ksh


lrch1d27.cna.com:oracle:pcdp1c:/csapps/oracle/dbascripts/pcdp1c/ctlm/sql
->post_import_masking.sql

lrch1d27.cna.com:oracle:pcdp1c:/csapps/oracle/dbascripts/pcdp1c/ctlm/sql
->cat post_import.sql
set echo off
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/trueup.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/trueup_body.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/trueup1.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/trueup1_body.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/trueup2.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/trueup2_body.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/trueup3.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/trueup3_body.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/trueup4.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/trueup4_body.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/trueup5.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/trueup5_body.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/bnr48115.sql
@/csapps/oracle/dbascripts/pcdp1c/ctlm/sql/bnr48115_body.sql
lrch1d27.cna.com:oracle:pcdp1c:/csapps/oracle/dbascripts/pcdp1c/ctlm/sql
->cat post_import_masking.sql
Update pesdbo.AffiliatePreference Set SavedDocPath = '\\CNAW2K\Shared\public\ProcedePrintTest';
  commit;
  select distinct SavedDocPath from pesdbo.AffiliatePreference;

  -------------------------------------
  -- Script to Scrub Pre-Prod database
  -------------------------------------

  ----------------------------------------
  -- LossDescription is Red Data
  ----------------------------------------
  Update pesdbo.Claim clm
  Set clm.LossDescription = '**SCRUBBED LOSS DESCRIPTION**'
  Where 1 = 1;
  commit;
  select distinct LossDescription from pesdbo.Claim;

  ----------------------------------------
  -- ClaimantName is Red Data
  ----------------------------------------
  Update pesdbo.ClaimFeature cf
  Set cf.ClaimantName = '**SCRUBBED CLAIMANT NAME**'
  Where 1 = 1;
  commit;
  select distinct ClaimantName from pesdbo.ClaimFeature;

lrch1d27.cna.com:oracle:pcdp1c:/csapps/oracle/dbascripts/pcdp1c/ctlm/sql
->post_import_masking.sql

<end node> 5P9i0s8y19Z
dt=Text
<node>
exp-imp scrub scripts
2

SEQUENCE,PROCEDURE,PACKAGE,PACKAGE_BODY,TRIGGER,MATERIALIZED_VIEW,FUNCTION,TABLE,VIEW

SEQUENCE,PROCEDURE,PACKAGE,PACKAGE_BODY,TRIGGER,MATERIALIZED_VIEW,FUNCTION,TABLE,VIEW

select owner, object_type, status, count(*)
from dba_objects 
where owner in ('CCSYSTEM','CCETL','CCINT')
 -- and object_type in ('VIEW','TRIGGER','PROCEDURE','FUNCTION','PACKAGE','PACKAGE BODY','SEQUENCE','MATERIALIZED VIEW')
 group  by owner, object_type,status
ORDER BY OWNER, OBJECT_TYPE ASC;


SELECT
  'alter system kill session ' || ''''|| s.sid || ',' || s.serial# || ',@'||s.inst_id ||''' immediate;'  "Kill_Command"
FROM  gv$session s
WHERE s.schemaname in ('CCSYSTEM','CCETL','CCINT');

set serveroutput on
declare 
	v_SqlSTMT  varchar2(32000);
begin
FOR i IN (select owner, object_type, object_name
			from dba_objects 
			where owner in ('CCSYSTEM','CCETL','CCINT')
			  and object_type in ('TABLE','VIEW','TRIGGER','PROCEDURE','FUNCTION','PACKAGE','PACKAGE BODY','SEQUENCE','MATERIALIZED VIEW')
			ORDER BY OWNER, OBJECT_TYPE ASC)
loop
	begin 
	  if i.object_type='TABLE' then
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME||' cascade constraint';
	  else
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME;
	  end if;
		execute immediate v_SqlSTMT;
	exception
	  when others then
	  	null;
	end;
	dbms_output.put_line(v_SqlSTMT);
end loop;
end;
/


/csapps/oracle/dbascripts/clmcc1c/ctlm/sql/users/clmcc_all_users.sql

nohup impdp "'/as sysdba'" directory=DATA_PUMP_DIR DUMPFILE=expdpclmccp_202108232313.dmp_%U.dmp logfile=PLR27CLMCC1CIMP_17Sept2021.log SCHEMAS=ccsystem,ccetl,ccint full=n exclude=user exclude=statistics parallel=16 &


$SQL_FILE_PATH=/csapps/oracle/dbascripts/clmcc1c/ctlm/sql

cp /depot/oracle/claims_scripts/scrub_master.sql /csapps/oracle/dbascripts/clmcc1c/ctlm/sql/claims_scrub_master_12.sql

function run_post_import_sql {
cp /depot/oracle/claims_scripts/scrub_master.sql $SQL_FILE_PATH/claims_scrub_master.sql
sqlplus -s <<!EOF
ccsystem/$(schema_password -s clmcc1c -o ccsystem)


set feedback on
set termout on
spool /csapps/oracle/dbascripts/clmcc1c/ctlm/sql/post_import_sql.log
select to_char(sysdate,'YYYY-MM-DD-HH24:MI:SS') ||'  Masking script starting ...' from dual;
set heading on
alter system set parallel_min_servers=0;
alter system set parallel_max_servers=6;
alter system set parallel_min_servers=4;
set timing on
alter session enable parallel dml;
alter session enable parallel query;
start /csapps/oracle/dbascripts/clmcc1c/ctlm/sql/claims_scrub_master_12.sql
set timing off
set pages 90 lines 132
column name format a56
column value format a30
select NAME,VALUE from  v$parameter where name like 'parallel_m%';
alter system set parallel_min_servers=0;
alter system set parallel_max_servers=0;
select NAME,VALUE from  v$parameter where name like 'parallel_m%';
set heading off
select to_char(sysdate,'YYYY-MM-DD-HH24:MI:SS') ||'  Masking script done ' from dual;
set heading on
spool off


exit;
!EOF

<end node> 5P9i0s8y19Z
dt=Text
<node>
CNA - Exadata
1
sys/byki2kau sysasm


-- ddl trigger
alter trigger SYSTEM.AUDIT_DDL_TRG disable; 

alter trigger SYSTEM.AUDIT_DDL_TRG disable;  
--  $ORACLE_HOME/OPatch/datapatch -verbose 
alter trigger SYSTEM.AUDIT_DDL_TRG enable;  
 
stg_set12/AC_STAGING@merwh2c

Robert.Schassburger@cna.com

-- command to clear the failed logins in exadata
-- login with root and clear the failed logsin and change the password
pam_tally2 

pam_tally2 -u cae0748 -r

pam_tally2

---------------------------------------------------------------------------------


CREATE BIGFILE TABLESPACE SHIFT_01 DATAFILE '+DATA_WH' SIZE 3g
AUTOEXTEND ON NEXT 2g MAXSIZE 5g
LOGGING ONLINE PERMANENT BLOCKSIZE 8192
EXTENT MANAGEMENT LOCAL AUTOALLOCATE DEFAULT 
NOCOMPRESS  SEGMENT SPACE MANAGEMENT AUTO;

CREATE USER  ETL_PROCEDE identified by "ETl2018PRoc" 
DEFAULT TABLESPACE USERS
TEMPORARY TABLESPACE TEMP
PROFILE APPSPROFILE
ACCOUNT UNLOCK; 

CREATE USER CAE4725 IDENTIFIED BY "caE4$725"
DEFAULT TABLESPACE "USERS"
TEMPORARY TABLESPACE "TEMP"
PROFILE "CPROFILE"

grant create session,job_dm_whbusiness to CAE4725 


CREATE USER  SHIFT identified by "L$vel2019Shift" 
DEFAULT TABLESPACE SHIFT_01
TEMPORARY TABLESPACE TEMP
PROFILE APPSPROFILE
ACCOUNT UNLOCK; 

grant connect,unlimited tablespace to shift;
alter user shift quota unlimited on shift_01;


CREATE BIGFILE TABLESPACE carpe_t01 DATAFILE '+DATA_WH' SIZE 3g
AUTOEXTEND ON NEXT 2g MAXSIZE 5g
LOGGING ONLINE PERMANENT BLOCKSIZE 8192
EXTENT MANAGEMENT LOCAL AUTOALLOCATE DEFAULT 
NOCOMPRESS  SEGMENT SPACE MANAGEMENT AUTO;


CREATE USER carpe identified by "ca$9102pe"
DEFAULT TABLESPACE carpe_t01
TEMPORARY TABLESPACE TEMP
PROFILE APPSPROFILE
ACCOUNT UNLOCK;

CREATE USER SHIFT identified by "L$vel2019Shift"
DEFAULT TABLESPACE SHIFT_01
TEMPORARY TABLESPACE TEMP
PROFILE APPSPROFILE
ACCOUNT UNLOCK;


create role TRECS_ARCHIVE_SELECT;

CREATE BIGFILE TABLESPACE TRECS_ARCHIVE_01 DATAFILE '+DATA_WH' SIZE 400g
AUTOEXTEND ON NEXT 500g MAXSIZE 925G
LOGGING ONLINE PERMANENT BLOCKSIZE 8192
EXTENT MANAGEMENT LOCAL AUTOALLOCATE DEFAULT 
NOCOMPRESS  SEGMENT SPACE MANAGEMENT AUTO;

CREATE USER  TRECS_ARCHIVE identified by "TreC$2019$$ArChIvE" 
DEFAULT TABLESPACE TRECS_ARCHIVE_01
TEMPORARY TABLESPACE TEMP
PROFILE APPSPROFILE
ACCOUNT UNLOCK; 

grant connect,unlimited tablespace to TRECS_ARCHIVE;
alter user TRECS_ARCHIVE quota unlimited on TRECS_ARCHIVE_01;


CREATE BIGFILE TABLESPACE striim_user_tables DATAFILE '+DATA_WH' SIZE 3g
AUTOEXTEND ON NEXT 2g MAXSIZE 5g
LOGGING ONLINE PERMANENT BLOCKSIZE 8192
EXTENT MANAGEMENT LOCAL AUTOALLOCATE DEFAULT 
NOCOMPRESS  SEGMENT SPACE MANAGEMENT AUTO;

create role striim_privs;

grant create session, create table, create view, create procedure, create sequence, create public synonym, create trigger,select_catalog_role, execute_catalog_role,select any transaction,select any dictionary to striim_privs;
grant execute on sys.dbms_metadata to striim_privs;
grant execute on sys.dbms_random to striim_privs;
grant select on system.logmnr_col$ to striim_privs;
grant select on system.logmnr_obj$ to striim_privs;
grant select on system.logmnr_user$ to striim_privs;
grant select on system.logmnr_uid$ to STRIIM_PRIVS;
grant logmining to striim_privs;


CREATE USER  striim_user identified by "Str$am2020WHP" 
DEFAULT TABLESPACE striim_user_tables
TEMPORARY TABLESPACE TEMP
PROFILE oappprofile
ACCOUNT UNLOCK; 

grant connect,unlimited tablespace to striim_user;
alter user striim_user quota unlimited on STRIIM_USER_TABLES;
grant striim_privs to striim_user;
grant mis_select to striim_user;
grant tapods_select to striim_privs;



-- this sql query gives the date of the role creation
select name,to_char(ctime,'mm/dd/yyyy hh24:mi:ss')role_create_date, decode(type#,0,'ROLE',1,'USER')resource_type
from sys.user$
where name ='TRECS_ARCHIVE_SELECT' -- like 'TRECS%'

select sys_context('USERENV','DB_NAME')DB_Name, tablespace_name, sum(maxbytes/1024/1024/1024)||'GB' Allowcated_Size
from dba_data_files
where tablespace_name='SHIFT_01'
group by tablespace_name

select sys_context('USERENV','DB_NAME')DB_Name,
    username, account_status, to_char(created,'mm/dd/yyyy hh24:mi:ss')created,default_tablespace
from dba_users 
where username='SHIFT'

select sys_context('USERENV','DB_NAME')DB_Name,
    grantee, granted_role
from dba_role_privs 
where grantee='SHIFT'

--  merwhp1
 rman target / @/home/oracle/dba/bin/rman/log/backup_merwhp_24c_l0_monthly_20190903.rman

<end node> 5P9i0s8y19Z
dt=Text
<node>
Info Exadata
2
-- Exadata – Scope of Support 
* End to End support, All Patchings (OS, DB, SelfServer), Maintenance Purpose like HWD issues
 and Hardware replacement will be taken care by Oracle
 
-- Exadata Server and DB list
* 2 Prod DBs only MERWHP and MERDMP for exadata DBs
-- standby DBs
MERWHPS DB for MERWHP (2 RAC NODE)
MERDMPS DB for MERDMP (2 RAC Node)

PROD : Production Env. (RMAN is only for PROD DBs)
ETE (END to END): is the testing env.
DRT (Data Ready Test): Development kind of env.

-- Daily/Weekly/Months Operations
*
-- Monitoring Alerts
*
-- Backup Checks
*
-- SOX Compliance


----------------------------------------------------------------
* Exadata JS Date : 06/Sept/2018

** SNOW (Service now ticketing tool) for Exadata

-- Current Ticket Count (06/Sept/2018)
Incident: 3 
Change: 3


-- To set filter the tickets, Assigment Groups
-- It might be different for ATOS when full handover it completed
IT.Accenture-l.Merlin_Exadata_pre-prod_operation
IT.Accenture-l.Exadata_Admin

sciprts for incidents are coming in emails and ticket inc is created.
DDL's scripts are executed using incident for non-prods

for Prod there is a change request raised for DDLs

-- no sysdba login allowed
sysdba is not allowed, for any reason if we have to use sysdba login
we have to open a snow ticket to our team and meantion the description 
like for what purpose sysdba has been used

as per SNOX compliance, if any DBA user account is locked we have to create a SNOW
ticket for unlocking account ...

-- if existing DBA account required to drop or leaves company, the script is automated
-- to drop the such account
* User termination is handled by automated script on weekly basis.
* Account is locked for 90 days and then drop from database (managed by the script). 

---> Vyas, Swati A will provide the document related to User Termination

if any one requesting the OS level access for Exadata, ask them to create PDR 913 request
PDR 913 is raised only for Creating Account on Exadata server (OS level Access)

For Dropping the same server from OS level just mentioned in same request in which you will be 
creating for dropping DB accounts.

service account (Application schema) creation and dropping is also required PDR 913 request which should be raised
by requestor and approved by leaders from CNA or ATOS

** Accenture Team (CNA - Exadata), will schedule a KT session for DDL scripts when coming in.

----------------------------------------------------------------

-- 20-SEP-2018 JS Session
JS Session Agenda
	Daily/Weekly/Monthly Operations
	Adhoc Support or Activities
	Incident/IIQ/Problem/Change Management 
	Monitoring Alerts
	Backup Checks
	SOX Compliance & Reports
	Patching (Exadata Storage Server, Exadata DB Server & InfiniBand Switch)


CID: CAE0748/ RC0807rc
Employee Id:  238921
rahul.chaudhari@cna.com

-- CAE username / Password	
Exadata DB server will have different password, username will be same CAE0748

-- port to login 
Port 22  -- exadata servers
Port 2245 -- application servers for DDL migrations

-- Oracle access
sudo su - oracle

-- root access
sudo su - 

root user password will be requested from tpam tool... This is time bond and justification should be given for accessing root password

-- 20th Sep-2018
Tikcet COUNT
INC - 5
Change - 4

-- DDL migrations on prod should have change and approval in place
-- Application Team is opening the change

-- for non-prod DB no change and no approvals required we can execute any day/date/time


-- even DMLs should have change requested and apporval in place

-- for non-prod no change and no approvals are required


Day to Day 
How to check Backup 
DDL migration --- server list document for application servers 
tablespace related


----------------------------------------------------------------

pre-prod OEM		
https://oemdrt.cna.com/em/ 		
		
prod oem		
https://oemcloud.cna.com/em/ 

-- OEM for exadata           
sysman/byki2kau

<end node> 5P9i0s8y19Z
dt=Text
<node>
DDL - Migrations
2
For Migration purpose, You have to login to Target Applicatios server

ca0748/RC1010rc

sudo su - exadba
RC1010rc


login to target server for ddl migration

cd /apps/exadba/ddl_moves

--- 2 conditions
1) Source and Target might be same
2) Source and Target might be different

1) Source and Target might be same
-- Then use below commands syntax for DDL migration

cd /apps/exadba/ddl_moves


-- file name format should be
-- date{yyyymmddhh24miss}.{sourceDB}.{targetDB}.{schema_name}


vi 20181001084951.merdm2c.merdm2c.mis_dm

$ cat 20181001084951.merdm2c.merdm2c.mis_dm
d_npo_bapp_forms.sql tables execute
--                     Y     Y conditions provided in email of excle ot tickets


./ddl_moves_v2.ksh -f {file location/name we prepaire for migration} -o schema_name -s {source location till schema name} -t target DB name

./ddl_moves_v2.ksh -f /apps/exadba/ddl_moves/20181001084951.merdm2c.merdm2c.mis_dm -o mis_dm -s /apps/merlin2c/Staging/dba_cmds/merdm2c/mis_dm -t merdm2c
			{File name we prepaire}					      (schema_name)   source_path till schema name		   target DB

./ddl_moves_v2.ksh -f /apps/exadba/ddl_moves/20191101090851.merdm2c.merdm2c.mis_dm -o mis_dm -s /apps/merlin2c/Staging/dba_cmds/merdm2c/mis_dm -t merdm2c

../bin/./ddl_moves_v2.ksh -f /apps/exadba/ddl_moves/20190111092226.merdm2c.merdmr.mis_dm -s vslrch1d011:/apps/exadba/dba_cmds/merdm2c/mis_dm -t merdmr



-- once the migration is completed, copy the last lines and send email
1. First migrate from MERDM2C to MERDM2C.

There were no errors.
1 files marked for execution.
1 executed successful.
0 executed with errors.
------------------------------------------------------------------------------------------------------------------------------

( -- When any such things are mentioned in Email it does mean Y N.... menas no execute in command
Team,

Please migrate  below.

Note: Do not execute the sqls

$ cat 20181001084951.merdm2c.merdm2c.mis_dm
d_npo_bapp_forms.sql tables execute
--                     Y     N conditions provided in email of excle ot tickets

)


2) Source and Target might be different
-- Then use below command syntax for DDL Migration

cd /apps/exadba/ddl_moves


-- file name format should be
-- date{yyyymmddhh24miss}.{sourceDB}.{targetDB}.{schema_name}

vi 20181001084951.merdm2c.merdmr.mis_dm

d_npo_bapp_forms.sql tables execute



/apps/exadba/ddl_moves/20181001084951.merdm2c.merdmr.mis_dm

cd /apps/exadba/bin

./ddl_moves_v2.ksh -f /apps/exadba/ddl_moves/20181001084951.merdm2c.merdmr.mis_dm -o mis_dm -s merdm2c -t merdmr

OR 


./ddl_moves_v2.ksh -f /apps/exadba/ddl_moves/20181001084951.merdm2c.merdmr.mis_dm -o mis_dm -s vslrch1d011:/apps/exadba/dba_cmds/merdm2c/mis_dm -t merdmr


execute the command


go to path /apps/exadba/ddl_moves/20181018094928.merdm2c.merdmr.mis_dm (this path will given at the end of the script.. folder will be created automatically)
 
cd /apps/exadba/ddl_moves/20181018094928.merdm2c.merdmr.mis_dm

STEP12_run_ddl.failures


2.	Then migrate from MERDM2C to MERDMR.

There were no errors.
1 files marked for execution.
1 executed successful.
0 executed with errors.

----------------------------------------------------------------------------------------------------------

-- 21-OCT-2018 (2nd Shift)

login to target server for ddl migration

1) CUT – DR DDL Migration

cae0748/


sudo su - exadba


cd /apps/exadba/ddl_moves

date -- yyyymmddhh24miss.sourceDB.TargetDB.schema_name as file name

vi 201810113607.merwh2c.merwhr.mis_dm_rpt

fpa_plan_source_2.sql tables
fpa_plan_spec_comm_wrk.sql tables


cd ../bin

-- execute the command in target server
./ddl_moves_v2.ksh -f /apps/exadba/ddl_moves/201810113607.merwh2c.merwhr.mis_dm_rpt -o mis_dm_rpt -s VSLRCH1D011:/apps/rapid_reporting/channel2/dba_cmds/merwh2c/mis_dm_rpt -t merwhr



There were no errors.
0 files marked for execution.
0 executed successful.
0 executed with errors.
2018-10-21-12:00:16 ddl_moves_v2.ksh Most of the files produced by this script can be found in /apps/exadba/ddl_moves/20181021115947.app_dir.merwhr.mis_dm_rpt.
2018-10-21-12:00:16 ddl_moves_v2.ksh Exiting with RC 0.


----------------------------------------------------------------------------------------------------------

DR - PROD


login to VSLRAU1P015/2245

cae0748/

sudo su - exadba

cd /apps/exadba/ddl_moves



vi 20181021120211.merwhr.merwhp.mis_dm_rpt

fpa_plan_source_2.sql tables
fpa_plan_spec_comm_wrk.sql tables


cd ../bin

./ddl_moves_v2.ksh -f /apps/exadba/ddl_moves/20181021120211.merwhr.merwhp.mis_dm_rpt -o mis_dm_rpt -s VSLRCH1D028:/apps/exadba/dba_cmds/merwhr/mis_dm_rpt -t merwhp

-- send the output of the all mentioned DDL migrations to requestor and we can close the ticket

1) CUT – DR DDL Migration
There were no errors.
0 files marked for execution.
0 executed successful.
0 executed with errors.
2018-10-21-12:00:16 ddl_moves_v2.ksh Most of the files produced by this script can be found in /apps/exadba/ddl_moves/20181021115947.app_dir.merwhr.mis_dm_rpt.
2018-10-21-12:00:16 ddl_moves_v2.ksh Exiting with RC 0.

2) DR – PROD DDL Migration
There were no errors.
0 files marked for execution.
0 executed successful.
0 executed with errors.
2018-10-21-12:15:45 ddl_moves_v2.ksh Most of the files produced by this script can be found in /apps/exadba/ddl_moves/20181021121525.app_dir.merwhp.mis_dm_rpt.
2018-10-21-12:15:45 ddl_moves_v2.ksh Exiting with RC 0.

<end node> 5P9i0s8y19Z
dt=Text
<node>
ILOM - Access
2

Your account is created for the PROD-ILOM .
PFB the credentials :

root / M3ss3gs! or m3ssgs!

Username :        cae0748
Password :        Welcome34 - RC1212rc

I am creating account in DRT and CUT/ETE server and will update you same.
Kindly check from your end and let me know if you face any issue.

PROD :
https://mrlnprddbadm01-ilom.cna.com
https://mrlnprddbadm02-ilom.cna.com
https://mrlnprddbadm03-ilom.cna.com
https://mrlnprddbadm04-ilom.cna.com


https://mrlnprdceladm01-ilom.cna.com
https://mrlnprdceladm02-ilom.cna.com
https://mrlnprdceladm03-ilom.cna.com
https://mrlnprdceladm04-ilom.cna.com
https://mrlnprdceladm05-ilom.cna.com
https://mrlnprdceladm06-ilom.cna.com
https://mrlnprdceladm07-ilom.cna.com
https://mrlnprdceladm08-ilom.cna.com


----------------------------------------

Storage Machine ILOMs

ZFS ILOM :
 https://mrlnprdzfsadm01.cna.com:215, 
 https://mrlnprdzfsadm02.cna.com:215

DRT ZFS Login - 
 https://mrlndrtzfsadm01.cna.com:215, 
 https://mrlndrtzfsadm02.cna.com:215 


Your account is created for the PROD-ILOM .
PFB the credentials :


Username :        cae0748
Password :        Welcome34 - RC1212rc

I am creating account in DRT and CUT/ETE server and will update you same.
Kindly check from your end and let me know if you face any issue.

PROD :
https://mrlnprddbadm01-ilom.cna.com
https://mrlnprddbadm02-ilom.cna.com
https://mrlnprddbadm03-ilom.cna.com
https://mrlnprddbadm04-ilom.cna.com


https://mrlnprdceladm01-ilom.cna.com
https://mrlnprdceladm02-ilom.cna.com
https://mrlnprdceladm03-ilom.cna.com
https://mrlnprdceladm04-ilom.cna.com
https://mrlnprdceladm05-ilom.cna.com
https://mrlnprdceladm06-ilom.cna.com
https://mrlnprdceladm07-ilom.cna.com
https://mrlnprdceladm08-ilom.cna.com


----------------------------------------

Storage Machine ILOMs

ZFS ILOM :
 https://mrlnprdzfsadm01.cna.com:215, 
 https://mrlnprdzfsadm02.cna.com:215

DRT ZFS Login - 
 https://mrlndrtzfsadm01.cna.com:215, 
 https://mrlndrtzfsadm02.cna.com:215 







You can use one of the bellow option:

Using FTPS to upload a file

$ curl -T <path_and_filename>” -u "<userID>" ftps://transport.oracle.com/issue/<sr_number>/

Example: curl –T /u02/files/bigfile.zip –u MOSuserID@company.com ftps://transport.oracle.com/issue/3-1234567890/



Using HTTPS to upload a file

$ curl -T <path_and_filename>” -u "<userID>" https://transport.oracle.com/upload/issue/<sr-number>/

Example: curl -T D:\data\bigfile.tar -u MOSuserID@company.com https://transport.oracle.com/upload/issue/3-1234567890/

Example: curl -T D:\data\tar-u MOSuserID@company.com https://transport.oracle.com/upload/issue/3-1083550/

Renaming during send also works

Example: curl -T D:\data\tar -u MOSuserID@company.com https://transport.oracle.com/upload/issue/3-1083550/NotSoBig.tar


Non-Proxy
curl -L -T <file_location>/<file> -u <sso user id> https://transport.oracle.com/upload/issue/<SR#>/

Proxy
curl -L -T <file_location>/<file> -u <sso user id> -x <proxy host>:<port> https://transport.oracle.com/upload/issue/<SR#>/

Proxy with user
curl -L -T <file_location>/<file> -u <sso user id> -U <proxy user>:<proxy password> -x <proxy host>:<port> https://transport.oracle.com/upload/issue/<SR#>/
Please note that if the user uploading the data differs from the ASR Registration, those users will be required to be on the CSI for the SR that was opened for the issue.


Your account is created for the PROD-ILOM .
PFB the credentials :


Username :        cae0748
Password :        Welcome34 - RC1212rc

I am creating account in DRT and CUT/ETE server and will update you same.
Kindly check from your end and let me know if you face any issue.

PROD :
https://mrlnprddbadm01-ilom.cna.com
https://mrlnprddbadm02-ilom.cna.com
https://mrlnprddbadm03-ilom.cna.com
https://mrlnprddbadm04-ilom.cna.com


https://mrlnprdceladm01-ilom.cna.com
https://mrlnprdceladm02-ilom.cna.com
https://mrlnprdceladm03-ilom.cna.com
https://mrlnprdceladm04-ilom.cna.com
https://mrlnprdceladm05-ilom.cna.com
https://mrlnprdceladm06-ilom.cna.com
https://mrlnprdceladm07-ilom.cna.com
https://mrlnprdceladm08-ilom.cna.com


----------------------------------------

Storage Machine ILOMs

ZFS ILOM :
 https://mrlnprdzfsadm01.cna.com:215, 
 https://mrlnprdzfsadm02.cna.com:215

DRT ZFS Login - 
 https://mrlndrtzfsadm01.cna.com:215, 
 https://mrlndrtzfsadm02.cna.com:215 


---- executed on mrlnprdzfsadm01 server
maintenance hardware list

maintenance problems show

maintenance hardware show



You can use one of the bellow option:

Using FTPS to upload a file

$ curl -T <path_and_filename>” -u "<userID>" ftps://transport.oracle.com/issue/<sr_number>/

Example: curl –T /u02/files/bigfile.zip –u MOSuserID@company.com ftps://transport.oracle.com/issue/3-1234567890/



Using HTTPS to upload a file

$ curl -T <path_and_filename>” -u "<userID>" https://transport.oracle.com/upload/issue/<sr-number>/

Example: curl -T D:\data\bigfile.tar -u MOSuserID@company.com https://transport.oracle.com/upload/issue/3-1234567890/

Example: curl -T D:\data\tar-u MOSuserID@company.com https://transport.oracle.com/upload/issue/3-1083550/

Renaming during send also works

Example: curl -T D:\data\tar -u MOSuserID@company.com https://transport.oracle.com/upload/issue/3-1083550/NotSoBig.tar


Non-Proxy
curl -L -T <file_location>/<file> -u <sso user id> https://transport.oracle.com/upload/issue/<SR#>/

Proxy
curl -L -T <file_location>/<file> -u <sso user id> -x <proxy host>:<port> https://transport.oracle.com/upload/issue/<SR#>/

Proxy with user
curl -L -T <file_location>/<file> -u <sso user id> -U <proxy user>:<proxy password> -x <proxy host>:<port> https://transport.oracle.com/upload/issue/<SR#>/
Please note that if the user uploading the data differs from the ASR Registration, those users will be required to be on the CSI for the SR that was opened for the issue.

<end node> 5P9i0s8y19Z
dt=Text
<node>
merwhp - stdby sync
2

-- execute on prod to check the current archive log for thread
select INST_ID, GROUP#, THREAD#,SEQUENCE#,STATUS from  gv$log ; 
 
-- execute on standby to check on which MRP process is hang/waiting
select INST_ID,process,STATUS,GROUP#,THREAD#,SEQUENCE# from  gv$managed_standby; 


ps -ef |grep pmon

. oranev


rman target / catalog exarman/b6a9dRwR@rcat2p 

-- connect catalog exarman/b6a9dRwR@rcat2p 



-- restore the missing archivelogs on perticular nodes
125740 - 125753 -- thread 1
133679 - 133689 -- thread 2

RESTORE ARCHIVELOG SEQUENCE  80159 thread 2;

restore archivelog from sequence 202167 until sequence 202170 thread 2;

restore archivelog from sequence 133680 until sequence 133689 thread 2;


OR 

restore archivelog from logseq=80159 until logseq=80165 thread=2 

-- check the space of the archivelog destination
select free_mb/1024 FREE_GB,total_mb/1024 TOTAL_GB,name from v$asm_diskgroup;

-- check if there is error and not transferring the archivelogs or MRP is not working
select inst_id, process, status, thread#, sequence#, block#, blocks 
from gv$managed_standby 
where process in ('RFS','LNS','MRP0');
--------------------------------------------
[oracle@mrlnprddbadm01 ~]$
[oracle@mrlnprddbadm01 ~]$ rman target /

Recovery Manager: Release 12.1.0.2.0 - Production on Tue Jan 15 07:34:33 2019

Copyright (c) 1982, 2014, Oracle and/or its affiliates.  All rights reserved.

connected to target database: MERWHP (DBID=4172635351)

RMAN> connect catalog exarman/b6a9dRwR@rcat2p

connected to recovery catalog database

RMAN> RESTORE ARCHIVELOG SEQUENCE  80159;
--------------------------------------------



1)
--- merwhp (mrlnprddbadm01)
  stdBY
--- merwhps1 (mrlndrtdbadm01)


SELECT ARCH.THREAD# "Thread", ARCH.SEQUENCE# "Last Sequence Received",
    APPL.SEQUENCE# "Last Sequence Applied", (ARCH.SEQUENCE# - APPL.SEQUENCE#) "Difference"
FROM (SELECT THREAD# ,SEQUENCE#
      FROM V$ARCHIVED_LOG
      WHERE (THREAD#,FIRST_TIME ) IN (SELECT THREAD#,MAX(FIRST_TIME)
                                        FROM V$ARCHIVED_LOG
                                        GROUP BY THREAD#)) ARCH,
      (SELECT THREAD# ,SEQUENCE#
       FROM V$LOG_HISTORY
       WHERE (THREAD#,FIRST_TIME ) IN (SELECT THREAD#,MAX(FIRST_TIME)
                                          FROM V$LOG_HISTORY
                                          GROUP BY THREAD#)) APPL
WHERE ARCH.THREAD# = APPL.THREAD#
ORDER BY 1;


   Thread Last Sequence Received Last Sequence Applied Difference
---------- ---------------------- --------------------- ----------
         1                 128950                128402        548
         1                 128950                128402        548
         2                 136799                136225        574
         2                 136799                136225        574

128403 -- next sequence number in production
128846 -- search and found the archive log is present, but between all 
		are missing and required to restore from backup, so we have to take -1 sequence and restore it back
		from archive backup

-- on production DB
. oranev 
MERWHP1

rman target / 

connect catalog exarman/b6a9dRwR@rcat2p

restore archivelog from logseq=128403 until logseq=128845 thread=1

restore archivelog from logseq=80159 until logseq=80165 thread=2 



-- check to see the high and low gap
SELECT high.thread#, "LowGap#", "HighGap#"
FROM
  (
  SELECT thread#, MIN(sequence#)-1 "HighGap#"
  FROM
  (
	  SELECT a.thread#, a.sequence#
	  FROM
	  (
		  SELECT *
		  FROM v$archived_log
	  ) a,
	  (
		  SELECT thread#, MAX(next_change#)gap1
		  FROM v$log_history
		  GROUP BY thread#
	  ) b
	  WHERE a.thread# = b.thread#
	  AND a.next_change# > gap1
  )
  GROUP BY thread#
) high,
(
  SELECT thread#, MIN(sequence#) "LowGap#"
  FROM
  (
	  SELECT thread#, sequence#
	  FROM v$log_history, v$datafile
	  WHERE checkpoint_change# <= next_change#
	  AND checkpoint_change# >= first_change#
  )
  GROUP BY thread#
) low
WHERE low.thread# = high.thread#





--- merwhps1 mrlndrtdbadm01

backup archivelog all not backed up 1 times;

<end node> 5P9i0s8y19Z
dt=Text
<node>
merdmp - stdby sync
2
1)
--- merdmp1/2 (mrlnprddbadm03/4)

stdBy database

--- merdmps1/2 (Mrlndrtdbadm03/4)

SELECT ARCH.THREAD# "Thread", ARCH.SEQUENCE# "Last Sequence Received",
    APPL.SEQUENCE# "Last Sequence Applied", (ARCH.SEQUENCE# - APPL.SEQUENCE#) "Difference"
FROM (SELECT THREAD# ,SEQUENCE#
      FROM V$ARCHIVED_LOG
      WHERE (THREAD#,FIRST_TIME ) IN (SELECT THREAD#,MAX(FIRST_TIME)
                                        FROM V$ARCHIVED_LOG
                                        GROUP BY THREAD#)) ARCH,
      (SELECT THREAD# ,SEQUENCE#
       FROM V$LOG_HISTORY
       WHERE (THREAD#,FIRST_TIME ) IN (SELECT THREAD#,MAX(FIRST_TIME)
                                          FROM V$LOG_HISTORY
                                          GROUP BY THREAD#)) APPL
WHERE ARCH.THREAD# = APPL.THREAD#
ORDER BY 1;


select max(sequence#) from v$archived_log

<end node> 5P9i0s8y19Z
dt=Text
<node>
merwhp - merwhpete
2
run
{
allocate channel ch04 device type disk;
allocate channel ch05 device type disk;
allocate channel ch06 device type disk;
allocate channel ch07 device type disk;
allocate channel ch08 device type disk;
allocate channel ch09 device type disk;
allocate channel ch10 device type disk;
allocate channel ch11 device type disk;
allocate channel ch12 device type disk;
allocate channel ch13 device type disk;
allocate channel ch14 device type disk;
allocate channel ch15 device type disk;
allocate channel ch16 device type disk;
allocate channel ch17 device type disk;
allocate channel ch18 device type disk;
allocate channel ch19 device type disk;
allocate channel ch20 device type disk;
allocate channel ch21 device type disk;
allocate channel ch22 device type disk;
allocate channel ch23 device type disk;
allocate channel ch24 device type disk;
set until time "to_date( '28-02-2018 12:47', 'DD-MM-RRRR HH24:MI')";
set newname for datafile  1 to '+DATA_ETE/MERWHTMP/DATAFILE/system.1328.895434719';
set newname for datafile  2 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.342.895434721';
set newname for datafile  3 to '+DATA_ETE/MERWHTMP/DATAFILE/undotbs1.343.895434721';
set newname for datafile  4 to '+DATA_ETE/MERWHTMP/DATAFILE/undotbs2.345.895434725';
set newname for datafile  15 to '+DATA_ETE/MERWHTMP/DATAFILE/ac_staging_t_v01.692.895607373';
set newname for datafile  285 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1531.909483313';
set newname for datafile  293 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1682.912995023';
set newname for datafile  350 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1534.942007219';
set newname for datafile  358 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1667.953335663';
set newname for datafile  359 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1666.953523335';
set newname for datafile  360 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1665.953528269';
set newname for datafile  361 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1664.953953107';
set newname for datafile  362 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1663.954236825';
set newname for datafile  363 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1662.954295177';
set newname for datafile  364 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1661.954653853';
set newname for datafile  365 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1660.954655513';
set newname for datafile  366 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1659.955172743';
set newname for datafile  367 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1658.955172809';
set newname for datafile  368 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1657.955252471';
set newname for datafile  369 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1656.955252501';
set newname for datafile  370 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1655.955252503';
set newname for datafile  371 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1654.955252505';
set newname for datafile  372 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1653.955936027';
set newname for datafile  373 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1652.956063873';
set newname for datafile  374 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1651.956426347';
set newname for datafile  375 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1650.956550691';
set newname for datafile  376 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1296.960338187';
set newname for datafile  377 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.589.960341983';
set newname for datafile  378 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1291.960638581';
set newname for datafile  380 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1294.960779569';
set newname for datafile  381 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1293.960790973';
set newname for datafile  382 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1292.960790975';
set newname for datafile  383 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.590.960790977';
set newname for datafile  384 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.591.960859723';
set newname for datafile  385 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.592.961207031';
set newname for datafile  386 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.599.961223753';
set newname for datafile  387 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.600.961554689';
set newname for datafile  388 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1527.961944649';
set newname for datafile  389 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1526.961944651';
set newname for datafile  390 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1525.962584267';
set newname for datafile  391 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1524.962598021';
set newname for datafile  392 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1523.962925421';
set newname for datafile  393 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1522.963294383';
set newname for datafile  394 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1521.963332665';
set newname for datafile  395 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1520.963332667';
set newname for datafile  396 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1519.963790717';
set newname for datafile  397 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1302.963790723';
set newname for datafile  398 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1301.963889733';
set newname for datafile  399 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1300.963962697';
set newname for datafile  400 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1299.964412509';
set newname for datafile  401 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1289.964671435';
set newname for datafile  402 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1297.965055257';
set newname for datafile  403 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1290.965055261';
set newname for datafile  404 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1287.965055263';
set newname for datafile  405 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1298.965055263';
set newname for datafile  406 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1288.966028723';
set newname for datafile  407 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1649.966028725';
set newname for datafile  408 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1648.966028727';
set newname for datafile  409 to '+DATA_ETE/MERWHTMP/DATAFILE/sysaux.1647.966844229';
restore tablespace  SYSTEM,UNDOTBS1,SYSAUX,UNDOTBS2,CIRSODS_TABLES,CIRSODS_INDEXES,USERS;
switch datafile all;
sql "alter database datafile 1,2,3,4,15,285,293,350,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409 online";
recover database skip forever tablespace TEMP,USERS,THIRTYTWOK,CAPMAN_DATA,AB_ADMIN,AB_INDEX,AB_OP,ACA,ACA_HSTRY_T_V01,ACTDMS,ACTFINODS,AGGREGATE,AGGREGATE_IX,AIM_DATA,AIPS_MISTERM_AUGUST_T_V01,AIPS_MISTERM_AUGUST_X_V01,APER_BO_LOSS_RATIO_BKP_T_V01,APER_BO_LOSS_RATIO_T_V01,APER_BO_LOSS_RATIO_WIP_T_V01,APER_BO_LOSS_RATIO_WIP_X_V01,APER_BO_LOSS_RATIO_X_V01,APER_BO_PREM_DETAIL_BKP_T_V01,APER_BO_PREM_DETAIL_T_V01,APER_BO_PREM_DETAIL_WIP_T_V01,APER_BO_PREM_DETAIL_WIP_X_V01,APER_BO_PREM_DETAIL_X_V01,APER_EP_QTR_SS_T_V01,APER_EP_QTR_SS_X_V01,ARCHIVE_T_V01,ARCH_RATING_FACTOR_CR_T_V01,ARCH_RATING_FACTOR_CR_X_V01,ARCH_RATING_FACTOR_RQ_T_V01,ARCH_RATING_FACTOR_RQ_X_V01,BASE_FACT_FINAL_BKP_T_V01,BASE_FACT_FINAL_T_V01,BASE_FACT_FINAL_WIP_T_V01,BASE_FACT_FINAL_X_V01,BASE_FACT_PRIOR_WK2A_T_V01,BASE_FACT_WK2A_T_V01,BASE_FACT_WK_T_V01,CANADA_T_V01,CC_INDEX,CC_OP,CLAIMDMS_INDEX,CLAIMDMS_TABLE,CLAIMODS_INDEX,CLAIMODS_LIST_CHAINED_T_V01,CLAIMODS_TABLE,CLAIM_ADDITIONAL_T_V01,CLAIM_ADDITIONAL_WEEKLY_T_V01,CLAIM_ADDITIONAL_WEEKLY_X_V01,CLAIM_ADDITIONAL_X_V01,CLAIM_TRANS_T_V01,CLAIM_TRANS_X_V01,CLAIM_T_V04,CLAIM_WEEKLY_T_V01,CLAIM_WEEKLY_X_V01,CLAIM_X_V04,CNA13_0692_V01,CNACOM_STAGING_T_V01,CNA_ATABLES,COMBINED_CLAIM_ADDL_T_V01,COMBINED_CLAIM_ADDL_X_V01,COMBINED_CLAIM_T_V01,COMBINED_CLAIM_X_V01,COMBINED_PAY_HIST_T_V01,COMBINED_PAY_HIST_X_V01,COMBINED_SUFFIX_SNAPS_T_V01,COMBINED_SUFFIX_SNAPS_X_V01,COMBINED_SUFFIX_T_V01,COMBINED_SUFFIX_X_V01,COSTCON_T_V01,COVERAGE_CR_T_V01,COVERAGE_CR_X_V01,COVERAGE_RQ_T_V01,COVERAGE_RQ_X_V01,CR_RQ_T_V01,CR_RQ_X_V01,CVS_T_V01,CVS_X_V01,CVTRY_HIST_T_V01,DASH_T_V01,DBA_CMDS_INDEXES,DBA_CMDS_TABLES,DED_AMT_CR_T_V01,DED_AMT_CR_X_V01,DED_AMT_RQ_T_V01,DED_AMT_RQ_X_V01,DIMENSIONS,DIMENSIONS_IX,DIRECT_TRANS_T_V06,DIRECT_TRANS_X_V06,DMSRPT_STAGE_INDEX,DMSRPT_STAGE_TABLE,DMS_INT_INDEX,DMS_INT_TABLE,ESIGHT_ADMIN_T_V01,EXPLORE,EXPLORE_WORK,FAS_CLAIMODS,FEEDS_IN_T_V01,FEEDS_OUT,GRIPCLOSE_T_V01,HAL_TABLES,HISTORICAL9DAY_T_V01,HISTORICAL_T_V01,IBMCDC_TABLES,INDEXES01,INFO,LIMIT_AMOUNT_CR_T_V01,LIMIT_AMOUNT_CR_X_V01,LIMIT_AMOUNT_RQ_T_V01,LIMIT_AMOUNT_RQ_X_V01,LITE_DATA,MEDBILL_MITCHELL_T_01,MEDBILL_T_V01,MISTERM_ENHANCED_20140102_T,MISTERM_ENHANCED_DAILY_T_V01,MISTERM_ENHANCED_DAILY_X_V01,MISTERM_ENHANCED_PRIOR_T_V01,MISTERM_ENHANCED_T_V01,MISTERM_ENHANCED_X_V01,MISTERM_LTD_BKP_T_V01,MISTERM_LTD_T_V01,MISTERM_LTD_WIP_T_V01,MISTERM_T_V01,MISTERM_X_V01,MIS_DM_RPT_ARCHIVE_T_V01,MIS_DM_RPT_ARCHIVE_X_V01,MIS_DM_RPT_T_V01,MIS_DM_RPT_X_V01,MIS_DM_RPT_YE_T_V01,MIS_EARN_OUT_EXP_T_V01,MIS_EARN_OUT_EXP_X_V01,MIS_EARN_OUT_LTD_T_V01,MIS_EARN_OUT_LTD_X_V01,MIS_EARN_OUT_RECAST_T_V01,MIS_EARN_OUT_RECAST_X_V01,MIS_EARN_OUT_T_V04,MIS_EARN_OUT_X_V04,MIS_LIST_CHAINED_T_V01,MIS_RPT_DEV_V01,MIS_WORK,ODSHIST_INDEX,ODSHIST_TABLE,ODSRPT_INDEX,ODSRPT_TABLE,ODS_INT_INDEX,ODS_INT_TABLE,PAFTRANS,PAFTRANS_IX,PAFTRANS_SUMMARY_T_V01,PAFTRANS_SUMMARY_X_V01,PAFTRAN_GL_ACCT_2009_T_V01,PAFTRAN_GL_ACCT_2010_T_V01,PAFTRAN_GL_ACCT_2011_T_V01,PAFTRAN_GL_ACCT_2012_T_V01,PAFTRAN_GL_ACCT_2013_T_V01,PAFTRAN_GL_ACCT_2014_T_V01,PAFTRAN_GL_ACCT_2015_T_V01,PAFTRAN_GL_ACCT_PRE2009_T_V01,PAY_HIST_T_V02,PAY_HIST_X_V02,PCA_CLAIM_T_V01,PCA_CLAIM_X_V01,PL_CALENDAR_YR_DATA_T_V01,PL_CALENDAR_YR_DATA_X_V01,PL_IBNR_FACTORS_PRIOR_T_V01,PL_IBNR_FACTORS_PRIOR_X_V01,PL_SUM_PRIOR_WIP_T_V01,PL_SUM_PRIOR_WIP_X_V01,PRELOAD,PRODUCTS_BKP_T_V01,PRODUCTS_CLMCLS_T_V01,PRODUCTS_CLMCLS_X_V01,PRODUCTS_QTR_T_V01,PRODUCTS_QTR_WIP_T_V01,PRODUCTS_T_V01,PRODUCTS_WIP_T_V01,PRODUCTS_WIP_X_V01,PRODUCTS_X_V01,PROFIT_LOSS_GROSS_PRV_T_V01,PROFIT_LOSS_GROSS_PRV_X_V01,PROFIT_LOSS_SUMMARY_BKP_T_V01,PROFIT_LOSS_SUMMARY_T_V01,PROFIT_LOSS_SUMMARY_WIP_T_V01,PROFIT_LOSS_SUMMARY_WIP_X_V01,PROFIT_LOSS_SUMMARY_X_V01,PROFIT_LOSS_SUMM_PRIOR_T_V01,PROFIT_LOSS_SUMM_PRIOR_X_V01,PRO_HIST_T_V01,PS_Z_ERNOUT_EXP_T_V01,RATE_FACT_BKP_T_V01,RATE_FACT_T_V01,RATE_FACT_WIP_T_V01,RATE_FACT_WIP_X_V01,RATE_FACT_X_V01,RATG_FTR_ADD_CR_T_V01,RATG_FTR_ADD_CR_X_V01,RATG_FTR_ADD_RQ_T_V01,RATG_FTR_ADD_RQ_X_V01,RATING_FACTOR_CR_T_V02,RATING_FACTOR_CR_X_V02,RATING_FACTOR_RQ_T_V02,RATING_FACTOR_RQ_X_V02,REINS_DIRECT_SNAPS_T_V02,REINS_DIRECT_SNAPS_X_V02,REINS_DIRECT_TRANS_T_V02,REINS_DIRECT_TRANS_X_V02,REINS_SPECIAL_TRANS_T_V02,REINS_SPECIAL_TRANS_X_V02,RETENTION_FACT_BKP_T_V01,RETENTION_FACT_T_V01,RETENTION_FACT_WIP_T_V01,RETENTION_FACT_WIP_X_V01,RETENTION_FACT_X_V01,RST_PPO_T_V01,STAGING,SUFFIX_ADDITIONAL_WEEKLY_T_V01,SUFFIX_ADDITIONAL_WEEKLY_X_V01,SUFFIX_SNAPS_T_V07,SUFFIX_SNAPS_WEEKLY_T_V04,SUFFIX_SNAPS_WEEKLY_X_V04,SUFFIX_SNAPS_X_V07,SUFFIX_T_V08,SUFFIX_WEEKLY_T_V05,SUFFIX_WEEKLY_X_V05,SUFFIX_X_V08,SURETY_ARCHIVE_T_V01,SURETY_ARCHIVE_X_V01,SURETY_STAGING_T_V01,SURETY_STAGING_X_V01,SUR_BOND_TERM_CVRG_T_V01,SUR_BOND_TERM_CVRG_X_V01,SUR_BOND_T_V01,SUR_BOND_X_V01,SUR_MISTERM_PRIOR_T_V01,SUR_MISTERM_T_V01,SUR_MISTERM_X_V01,SYMANTEC_I3_ORCL,TABLES01,TERADATA_T_V02,TOOLS,VIATICUS_T_V01,VIATICUS_X_V01,WCEDI,WCEDIDMS,WCFC01,WCFC_CLAIM_DETAIL_T_V01,WCFC_CLAIM_DETAIL_X_V01,WCFC_LOSS_DETAIL_T_V01,WCFC_LOSS_DETAIL_X_V01,WCFC_QTR_CLAIM_DETAIL_T_V01,WCFC_QTR_CLAIM_DETAIL_X_V01,BOXI_RPT_TMP,BO_TEMP,ESIGHT_TEMP,LAWYERS_INS_TEMP,MIS_DM_RPT_TEMP,MIS_RPT_DEV_TEMP,SYMANTEC_I3_ORCL_TMP,USER_TEMP,MAXCP_DATA01,MAXCP_INDEXES01,CIDBP_DATA01,CIDBP_INDEXES01,PERFBP_DATA01,PERFBP_INDEXES01,PAFTRAN_GL_ACCT_2016_T_V01,CEDELITE_STAGING_T_V01,ARCHIVE_TABLES,ARCHIVE_INDEX,ARCHIVE_LOB,INDEXES,DATA,CNACMRPT_LARGE_OBJECTS,CCN_PREMHIST_T_V01,CCN_PREMHIST_X_V01,CLAIMAPD_T01,SOSARCH_TABLES,SOS_TABLES,SOSARCH_INDEXES,SOS_INDEXES,MR_LANDING_TABLES,MR_LANDING_LOB,MR_LANDING_INDEXES,MR_PRELOAD_TABLES,MR_PRELOAD_LOB,MR_PRELOAD_INDEXES,AD1099_TAXPRO_T_V01,AD1099_TAXPRO_X_V01,CIMSODS_INDEXES,CIMSODS_TABLES,CIRSODS_INDEXES,CIRSODS_TABLES,EUSRPTODS_INDEXES,EUSRPTODS_TABLES,MAIN_INDEXES,CMMRCL_PLDG_ARCHIVE01,SURCDC_STAGE_T_V01,ODS_CONTROL_INDEXES,ODS_CONTROL_TABLES,PASEINPODS_INDEXES,PASEINPODS_TABLES,PASEREFODS_INDEXES,PASEREFODS_LARGEOBJ,PASEREFODS_TABLES,RATER_EXP_INDEXES,RATER_EXP_TABLES,RCTODS_INDEXES,RCTODS_LARGE_OBJ,RCTODS_TABLES,RSTSTAGE_INDEXES,RSTSTAGE_LARGE_OBJ,RSTSTAGE_TABLES,SSO_RATERS_STAGE_INDEXES,SSO_RATERS_STAGE_TABLES,STAGE_INDEXES,STAGE_TABLES,MAIN_TABLES,TAP_INDEXES,TAP_TABLES,ULSODS_INDEXES,ULSODS_TABLES,UWSODS_INDEXES,UWSODS_TABLES,WCODS_INDEXES,WCODS_STG_INDEXES,WCODS_STG_TABLES,WCODS_TABLES,WCPAYGO_INDEXES,WCPAYGO_TABLES,AR_LKU_T_V01,AR_LKU_X_V01,AR_STAGING_T_V01,AR_STAGING_X_V01,AR_T_V01,AR_X_V01,BLTK_T_V01,BLTK_X_V01,SURCDC_STAGE_I_V01,PAFTRAN_GL_ACCT_2017_T_V01,DVD_TEMP,STF_HOLD,AISS_TABLES,DEVLDBA_INDEXES,DEVLDBA_TABLES,UPS_TABLES,UPS_INDEXES,AISSMRPT_LARGE_OBJECTS,AISSMRPT_ARCHIVE_TABLES,AISSMRPT_ARCHIVE_INDEXES,PAFTRAN_GL_ACCT_2018_T_V01;  
release channel ch04;
release channel ch05;
release channel ch06;
release channel ch07;
release channel ch08;
release channel ch09;
release channel ch10;
release channel ch11;
release channel ch12;
release channel ch13;
release channel ch14;
release channel ch15;
release channel ch16;
release channel ch17;
release channel ch18;
release channel ch19;
release channel ch20;
release channel ch21;
release channel ch22;
release channel ch23;
release channel ch24;
}

------------------------------------------

# SCN
RECOVER TABLE TEST.T1
  UNTIL SCN 1853267
  AUXILIARY DESTINATION '/u01/aux'  
  REMAP TABLE 'TEST'.'T1':'T1_PREV';

# TIME
RECOVER TABLE TEST.T1
  UNTIL TIME "TO_DATE('01-JAN-2013 15:00', 'DD-MON-YYYY HH24:MI')"
  AUXILIARY DESTINATION '/u01/aux'  
  REMAP TABLE 'TEST'.'T1':'T1_PREV'; 

<end node> 5P9i0s8y19Z
dt=Text
<node>
merwhps
2
 sys/DbasRul3@MERWHPS 


-- backup script merwhp. and location of full backup
-- date waise folder is been created under location "/zfssa/mrln-prod-rman/backup01/MERWHP/"
-- like /zfssa/mrln-prod-rman/backup01/MERWHP/20190611 --(backup of 11th-Jun-2019)

[oracle@mrlnprddbadm01 log]$ cat backup_merwhp_24c_l0_monthly_20190611.rman
# backup_merwhp_24c_l0_monthly_20190611.rman
#       Note: This script was automatically generated on 11-JUN-19 09:00:02
#
#       Who             Date            Description
#       -----------     ------------    ----------------------------------
#       Dcox            30-May-2015     Initial build - Adapted from ESBU example
#       dcox            21-Jul-2015     modified to run for merdmp
#       dcox            19-Aug-2015     Modified to use mount for cf options
#       dcox            23-Sep-2015     Cleaned up and added catalog
#       dcox            17-Oct-2015     Added - Auto Generation of scripts
#       dcox            27-Oct-2015     Added spfile to text and copy of controlfile to backup location
#       dcox            10-Nov-2015     Added LF after "consistency"
#
#       Channel backup across 2 head bananced pools
#
# Use this script to allocate RMAN channels and run level 0 backup.
#

set echo on;


run
{
alter system set "_backup_disk_bufcnt"=64 scope=memory sid='*';
alter system set "_backup_disk_bufsz"=1048576 scope=memory sid='*';
alter system set "_backup_file_bufcnt"=64 scope=memory sid='*';
alter system set "_backup_file_bufsz"=1048576 scope=memory sid='*';

# for consistancy
alter system switch logfile;
alter system switch logfile;
alter system switch logfile;

allocate channel ch01 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup01' format '/zfssa/mrln-prod-rman/backup01/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch02 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup02' format '/zfssb/mrln-prod-rman/backup02/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch03 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup03' format '/zfssa/mrln-prod-rman/backup03/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch04 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup04' format '/zfssb/mrln-prod-rman/backup04/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch05 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup05' format '/zfssa/mrln-prod-rman/backup05/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch06 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup06' format '/zfssb/mrln-prod-rman/backup06/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch07 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup07' format '/zfssa/mrln-prod-rman/backup07/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch08 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup08' format '/zfssb/mrln-prod-rman/backup08/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch09 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup09' format '/zfssa/mrln-prod-rman/backup09/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch10 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup10' format '/zfssb/mrln-prod-rman/backup10/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch11 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup11' format '/zfssa/mrln-prod-rman/backup11/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch12 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup12' format '/zfssb/mrln-prod-rman/backup12/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch13 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup13' format '/zfssa/mrln-prod-rman/backup13/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch14 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup14' format '/zfssb/mrln-prod-rman/backup14/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch15 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup15' format '/zfssa/mrln-prod-rman/backup15/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch16 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup16' format '/zfssb/mrln-prod-rman/backup16/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch17 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup17' format '/zfssa/mrln-prod-rman/backup17/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch18 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup18' format '/zfssb/mrln-prod-rman/backup18/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch19 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup19' format '/zfssa/mrln-prod-rman/backup19/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch20 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup20' format '/zfssb/mrln-prod-rman/backup20/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch21 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup21' format '/zfssa/mrln-prod-rman/backup21/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch22 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup22' format '/zfssb/mrln-prod-rman/backup22/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch23 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup23' format '/zfssa/mrln-prod-rman/backup23/MERWHP/20190611/bkp_%d_%T_%U';
allocate channel ch24 device type disk connect 'SYS/DbasRul3@mrlnwhprd-scan/merwhp_bkup24' format '/zfssb/mrln-prod-rman/backup24/MERWHP/20190611/bkp_%d_%T_%U';



backup as  compressed  backupset incremental level 0 filesperset 1 section size 32g database tag 'MERWHP_24C_MONTHLY_L0' plus archivelog tag 'MERWHP_24C_MONTHLY_L0' keep until time 'sysdate + 93' ;

delete noprompt archivelog all backed up 2 times to disk;

backup current controlfile;

alter DATABASE BACKUP CONTROLFILE TO '/zfssa/mrln-prod-rman/backup01cf/MERWHP/20190611/control_MERWHP.bkp' reuse;

backup spfile format        '/zfssa/mrln-prod-rman/backup01cf/MERWHP/spfile_%I_%d_%T_%u' tag 'spfile';

alter database backup controlfile to trace;

alter database backup controlfile to trace as '/zfssa/mrln-prod-rman/backup01cf/MERWHP/backup_controlfile_merwhp_trace.trc' reuse;

}
exit;


[oracle@mrlnprddbadm01 log]$

<end node> 5P9i0s8y19Z
dt=Text
<node>
whp - wh2c - whr
2
-- prod
/u01/oracle/zfs-dr/datapump_new/RITM0058511/expdp_merwhp_wh2c_whr.dmp

--- drt/cut
/u01/oracle/zfs-dr/datapump/RITM0058511/expdp_merwhp_wh2c_whr.dmp

-- directory name
DDUMP : /u01/oracle/zfs-dr/datapump_new/RITM0058511

-- merwhp export command and directory name
nohup expdp "'/as sysdba'" directory=DDUMP dumpfile=expdp_merwhp_wh2c_whr.dmp logfile=expdp_logs.log tables=RCTODS.RCT_AC96,RCTODS.RCT_RX89,RCTODS.RCT_RECSTAT,RCTODS.RCT_ACCOUNT compression=all &

-- merwh2c imp command
nohup impdp "'/as sysdba'" directory=whp2wh2c dumpfile=expdp_merwhp_wh2c_whr.dmp logfile=impdp_expdp_merwhp_wh2c_whr.log table_exists_action=replace &

-- merwhr imp command 
impdp "'/as sysdba'" directory=whp2whr dumpfile=expdp_merwhp_wh2c_whr.dmp logfile=impdp_expdp_merwhp_wh2c_whr_whp2whr.log table_exists_action=replace



nohup expdp "'/as sysdba'" directory=DDUMP dumpfile=expdp_merwhp_wh2c_whr_26Apr2019_2.dmp logfile=expdp_logs_26Apr2019_2.log tables=RCTODS.RCT_SBU  compression=all &

nohup impdp "'/as sysdba'" directory=whp2wh2c dumpfile=expdp_merwhp_wh2c_whr_26Apr2019_2.dmp logfile=imp_expdp_logs_26Apr2019_wh2c_3.log table_exists_action=replace &

<end node> 5P9i0s8y19Z
dt=Text
<node>
PT exadata whp
2

login to mrlnprddbadm01 and do
cd /u01/db_utility/mrlnwhprd/enk/tools/sqld360-master

-- its a sqld360 tool for performance tunning queries

@sqld360.sql b2fdcph4h55xp T

<end node> 5P9i0s8y19Z
dt=Text
<node>
Exadata cellcli
2

-- exadata root user
dbmadmin,dbmmonitor,dbmsvc

<end node> 5P9i0s8y19Z
dt=Text
<node>
merwhp to merwhtbl
2


rman target sys/DbasRul3@MERWHPS 

---------
-- Date 08/May/2021

1) Trasfer the required dated backups
2) Take the pint-in-time date/time for recoervy from backup
3) restore the spfile/pfile
4) modify the init.ora file as per requirement, like remove the not required parameters from init.ora file
5) startup nomount pfile='';
6) connect to rman and restore the controlfile from that dated backups
rman target /
restore spfile -- you can restore the spfile from here

restore control file -- you can directly restore the controlfile like this and below

restore controlfile from '/u01/oracle/zfs-dr/datapump/merwhp_cirsods/bkp_MERWHP_20200708_p0v4p3bk_1_1';

--- check this on backup DB, what is current incarnation pointing to 
select INCARNATION#, RESETLOGS_TIME from v$database_incarnation order by RESETLOGS_TIME desc;

RMAN> list incarnation; -- take incarnation of the backup DB and reset the same incarnation value on recovery side DB

-- execute on recovery side DB, before running the or recieving the error like below (for any disk)
-- ORA-01180: can not create datafile 1
-- ORA-01110: data file 1: '+DATA_ETE'
rman targ /
reset database to incarnation 1;







----------------------------------------------------------------

-- URL for restore a single table
https://support.oracle.com/epmos/faces/DocumentDisplay?_afrLoop=393733706877781&id=223543.1&_afrWindowMode=0&_adf.ctrl-state=18i8krohyl_4 

-- How to Recover From a DROP / TRUNCATE / DELETE TABLE with RMAN (Doc ID 223543.1)
 
-- copy of PFILE merwhtbl which is saved in ORACLE_HOME/dbs locations

vi initMERWHTBL.ora
MERWHTBL.__data_transfer_cache_size=0
MERWHTBL.__db_cache_size=6442450944
MERWHTBL.__java_pool_size=234881024
MERWHTBL.__large_pool_size=134217728
MERWHTBL.__oracle_base='/u01/app/oracle'#ORACLE_BASE set from environment
MERWHTBL.__pga_aggregate_target=64424509440
MERWHTBL.__sga_target=17179869184
MERWHTBL.__shared_io_pool_size=0
MERWHTBL.__shared_pool_size=8589934592
MERWHTBL.__streams_pool_size=1073741824
*._client_enable_auto_unregister=TRUE
*._clusterwide_global_transactions=FALSE
*._enable_numa_support=FALSE
*._file_size_increase_increment=2143289344
*._optimizer_dsdir_usage_control=0
*._smm_auto_max_io_size=1024
*._smu_debug_mode=134217728
*._sql_plan_directive_mgmt_control=0
*.archive_lag_target=1800
*.audit_sys_operations=TRUE
*.audit_trail='db'
*.cluster_database=FALSE
*.compatible='12.1.0.2.0'
*.control_files='/u01/oracle/zfs-dr/datapump/merwhtbl/MERWHTBL/controlfile/MERWHTBL.ctl','+DATA_ETE/MERWHTBL/MERWHTBL.ctl'
*.cpu_count=36
*.db_32k_cache_size=500m
*.db_block_checking='low'
*.db_block_checksum='typical'
*.db_block_size=8192
*.db_create_file_dest='+DATA_ETE'
*.db_create_online_log_dest_1='+DATA_ETE'
*.db_create_online_log_dest_2='+RECO_ETE'
*.db_domain=''
*.db_files=1024
*.db_lost_write_protect='typical'
*.db_name='MERWHP'
*.db_recovery_file_dest='+RECO_ETE'
*.db_recovery_file_dest_size=21407727616000#90% of Total Space in FRA Disk Group
*.db_unique_name='MERWHTBL'
*.dg_broker_config_file1='+DATA_ETE/MERWHTBL/dr1MERWHP_TEMP.dat'
*.dg_broker_config_file2='+DATA_ETE/MERWHTBL/dr2MERWHP_TEMP.dat'
*.dg_broker_start=TRUE
*.diagnostic_dest='/u01/oracle'
*.fal_client='MERWHTBL'
*.fal_server='merwhp'
*.fast_start_mttr_target=300
*.filesystemio_options='setall'
*.global_names=FALSE
*.job_queue_processes=0
*.log_archive_config='dg_config=(MERWHTBL,MERWHP)'
*.log_archive_dest_1='location=USE_DB_RECOVERY_FILE_DEST valid_for=(ALL_LOGFILES,ALL_ROLES) db_unique_name=MERWHTBL'
*.log_archive_dest_2='location="+RECO_ETE",  valid_for=(STANDBY_LOGFILE,STANDBY_ROLE)'
*.log_archive_dest_3=''
*.log_archive_dest_state_2='ENABLE'
*.log_archive_dest_state_3='ENABLE'
*.log_archive_max_processes=4
*.log_archive_min_succeed_dest=1
*.log_buffer=134217728
*.open_cursors=1000
*.os_authent_prefix=''
*.parallel_adaptive_multi_user=FALSE
*.parallel_degree_limit='16'
*.parallel_degree_policy='MANUAL'
*.parallel_execution_message_size=16384
*.parallel_force_local=TRUE
*.parallel_max_servers=36
*.parallel_min_servers=36
*.parallel_servers_target=128
*.parallel_threads_per_cpu=1
*.pga_aggregate_target=61440m
*.processes=2048
*.recyclebin='on'
*.remote_login_passwordfile='exclusive'
*.sga_max_size=17179869184
*.sga_target=17179869184
*.shared_pool_size=8589934592
*.sql92_security=TRUE
*.standby_file_management='AUTO'
*.streams_pool_size=1073741824
*.undo_retention=36000
*.undo_tablespace='UNDOTBS1'
*.use_large_pages='ONLY'

Oracle:Mrlnetedbadm03>. oraenv
MERWHTBL


Oracle:Mrlnetedbadm03> export ORACLE_HOME=/u01/app/oracle/product/12.1.0.2/dbhome_1/


Oracle:Mrlnetedbadm03>sqlplus "/as sysdba"

sql>startup nomount pfile='/u01/app/oracle/product/12.1.0.2/dbhome_1/dbs/initMERWHTBL.ora'
SQL> exit


rman target /

restore controlfile from '/u01/oracle/zfs-dr/datapump/11Jun2019/backup01/control_MERWHP.bkp';


RMAN> alter database mount clone database;

-- disk backup location where the backup has been copied
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup01';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup03';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup05';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup07';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup09';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup11';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup13';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup15';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup17';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup19';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup21';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup23';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup02';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup04';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup06';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup08';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup10';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup12';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup14';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup16';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup18';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup20';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup22';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup24';


-- if you want to include the subfolders also then just do
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019'

RMAN>crosscheck backup;

-- save the below script into cmd file
vi rman_script.cmd

run
{
allocate channel ch04 device type disk;
allocate channel ch05 device type disk;
allocate channel ch06 device type disk;
allocate channel ch07 device type disk;
allocate channel ch08 device type disk;
allocate channel ch09 device type disk;
allocate channel ch10 device type disk;
allocate channel ch11 device type disk;
allocate channel ch12 device type disk;
allocate channel ch13 device type disk;
allocate channel ch14 device type disk;
allocate channel ch15 device type disk;
allocate channel ch16 device type disk;
allocate channel ch17 device type disk;
allocate channel ch18 device type disk;
allocate channel ch19 device type disk;
allocate channel ch20 device type disk;
allocate channel ch21 device type disk;
allocate channel ch22 device type disk;
allocate channel ch23 device type disk;
allocate channel ch24 device type disk;
set until time "to_date('12-06-2019 04:21:47','DD-MM-RRRR HH24:MI:SS')";
set newname for datafile  1 to '+DATA_ETE/MERWHTBL/DATAFILE/system.1328.895434719';
set newname for datafile  2 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.342.895434721';
set newname for datafile  3 to '+DATA_ETE/MERWHTBL/DATAFILE/undotbs1.343.895434721';
set newname for datafile  4 to '+DATA_ETE/MERWHTBL/DATAFILE/undotbs2.345.895434725';
set newname for datafile  53 to '+DATA_ETE/MERWHTBL/DATAFILE/claim_additional_t_v01.1604.895607465';
set newname for datafile  56 to '+DATA_ETE/MERWHTBL/DATAFILE/claim_additional_x_v01.668.895607467';
set newname for datafile  59 to '+DATA_ETE/MERWHTBL/DATAFILE/claim_t_v04.665.895607469';
set newname for datafile  62 to '+DATA_ETE/MERWHTBL/DATAFILE/claim_x_v04.662.895607471';
set newname for datafile  112 to '+DATA_ETE/MERWHTBL/DATAFILE/indexes01.820.895607543';
set newname for datafile  210 to '+DATA_ETE/MERWHTBL/DATAFILE/reins_direct_snaps_t_v02.722.895607743';
set newname for datafile  211 to '+DATA_ETE/MERWHTBL/DATAFILE/reins_direct_snaps_x_v02.721.895607743';
set newname for datafile  225 to '+DATA_ETE/MERWHTBL/DATAFILE/suffix_snaps_t_v07.707.895607757';
set newname for datafile  228 to '+DATA_ETE/MERWHTBL/DATAFILE/suffix_snaps_x_v07.704.895607765';
set newname for datafile  229 to '+DATA_ETE/MERWHTBL/DATAFILE/suffix_t_v08.703.895607767';
set newname for datafile  232 to '+DATA_ETE/MERWHTBL/DATAFILE/suffix_x_v08.700.895607773';
set newname for datafile  245 to '+DATA_ETE/MERWHTBL/DATAFILE/tables01.902.895607785';
set newname for datafile  285 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1531.909483313';
set newname for datafile  293 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1682.912995023';
set newname for datafile  350 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1534.942007219';
set newname for datafile  358 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1667.953335663';
set newname for datafile  359 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1666.953523335';
set newname for datafile  360 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1665.953528269';
set newname for datafile  361 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1664.953953107';
set newname for datafile  362 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1663.954236825';
set newname for datafile  363 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1662.954295177';
set newname for datafile  364 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1661.954653853';
set newname for datafile  365 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1660.954655513';
set newname for datafile  366 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1659.955172743';
set newname for datafile  367 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1658.955172809';
set newname for datafile  368 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1657.955252471';
set newname for datafile  369 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1656.955252501';
set newname for datafile  370 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1655.955252503';
set newname for datafile  371 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1654.955252505';
set newname for datafile  372 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1653.955936027';
set newname for datafile  373 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1652.956063873';
set newname for datafile  374 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1651.956426347';
set newname for datafile  375 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1650.956550691';
set newname for datafile  376 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1296.960338187';
set newname for datafile  377 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.589.960341983';
set newname for datafile  378 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1291.960638581';
set newname for datafile  380 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1294.960779569';
set newname for datafile  381 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1293.960790973';
set newname for datafile  382 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1292.960790975';
set newname for datafile  383 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.590.960790977';
set newname for datafile  384 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.591.960859723';
set newname for datafile  385 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.592.961207031';
set newname for datafile  386 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.599.961223753';
set newname for datafile  387 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.600.961554689';
set newname for datafile  388 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1527.961944649';
set newname for datafile  389 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1526.961944651';
set newname for datafile  390 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1525.962584267';
set newname for datafile  391 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1524.962598021';
set newname for datafile  392 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1523.962925421';
set newname for datafile  393 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1522.963294383';
set newname for datafile  394 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1521.963332665';
set newname for datafile  395 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1520.963332667';
set newname for datafile  396 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1519.963790717';
set newname for datafile  397 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1302.963790723';
set newname for datafile  398 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1301.963889733';
set newname for datafile  399 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1300.963962697';
set newname for datafile  400 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1299.964412509';
set newname for datafile  401 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1289.964671435';
set newname for datafile  402 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1297.965055257';
set newname for datafile  403 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1290.965055261';
set newname for datafile  404 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1287.965055263';
set newname for datafile  405 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1298.965055263';
set newname for datafile  406 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1288.966028723';
set newname for datafile  407 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1649.966028725';
set newname for datafile  408 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1648.966028727';
set newname for datafile  409 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1647.966844229';
restore tablespace SYSAUX,SYSTEM,UNDOTBS1,UNDOTBS2,CLAIM_T_V04,CLAIM_ADDITIONAL_T_V01,REINS_DIRECT_SNAPS_T_V02,TABLES01,SUFFIX_T_V08,SUFFIX_SNAPS_T_V07,CLAIM_X_V04,CLAIM_ADDITIONAL_X_V01,REINS_DIRECT_SNAPS_X_V02,INDEXES01,SUFFIX_X_V08,SUFFIX_SNAPS_X_V07;
switch datafile all;
sql "alter database datafile 1,2,3,4,53,56,59,62,112,210,211,225,228,229,232,245,285,293,350,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409 online";
recover database skip forever tablespace TEMP,USERS,AB_ADMIN,AB_INDEX,AB_OP,ACA,ACA_HSTRY_T_V01,ACTDMS,ACTFINODS,AC_STAGING_T_V01,AGGREGATE,AGGREGATE_IX,AIM_DATA,AIPS_MISTERM_AUGUST_T_V01,AIPS_MISTERM_AUGUST_X_V01,APER_BO_LOSS_RATIO_BKP_T_V01,APER_BO_LOSS_RATIO_T_V01,APER_BO_LOSS_RATIO_WIP_T_V01,
APER_BO_LOSS_RATIO_WIP_X_V01,APER_BO_LOSS_RATIO_X_V01,APER_BO_PREM_DETAIL_BKP_T_V01,APER_BO_PREM_DETAIL_T_V01,APER_BO_PREM_DETAIL_WIP_T_V01,APER_BO_PREM_DETAIL_WIP_X_V01,APER_BO_PREM_DETAIL_X_V01,APER_EP_QTR_SS_T_V01,APER_EP_QTR_SS_X_V01,ARCHIVE_T_V01,ARCH_RATING_FACTOR_CR_T_V01,ARCH_RATING_FACTOR_CR_X_V01,
ARCH_RATING_FACTOR_RQ_T_V01,ARCH_RATING_FACTOR_RQ_X_V01,BASE_FACT_FINAL_BKP_T_V01,BASE_FACT_FINAL_T_V01,BASE_FACT_FINAL_WIP_T_V01,BASE_FACT_FINAL_X_V01,BASE_FACT_PRIOR_WK2A_T_V01,BASE_FACT_WK2A_T_V01,BASE_FACT_WK_T_V01,CANADA_T_V01,CC_INDEX,CC_OP,CLAIMDMS_INDEX,CLAIMDMS_TABLE,CLAIMODS2_INDEX,CLAIMODS2_TABLE,
CLAIMODS_INDEX,CLAIMODS_LIST_CHAINED_T_V01,CLAIMODS_TABLE,CLAIM_ADDITIONAL_WEEKLY_T_V01,CLAIM_ADDITIONAL_WEEKLY_X_V01,CLAIM_TRANS_T_V01,CLAIM_TRANS_X_V01,CLAIM_WEEKLY_T_V01,CLAIM_WEEKLY_X_V01,CNACOM_STAGING_T_V01,CNA_ATABLES,COMBINED_CLAIM_ADDL_T_V01,COMBINED_CLAIM_ADDL_X_V01,COMBINED_CLAIM_T_V01,COMBINED_CLAIM_X_V01,
COMBINED_PAY_HIST_T_V01,COMBINED_PAY_HIST_X_V01,COMBINED_SUFFIX_SNAPS_T_V01,COMBINED_SUFFIX_SNAPS_X_V01,COMBINED_SUFFIX_T_V01,COMBINED_SUFFIX_X_V01,COSTCON_T_V01,COVERAGE_CR_T_V01,COVERAGE_CR_X_V01,COVERAGE_RQ_T_V01,COVERAGE_RQ_X_V01,CR_RQ_T_V01,CR_RQ_X_V01,CVS_T_V01,CVS_X_V01,DASH_T_V01,DBA_CMDS_INDEXES,DBA_CMDS_TABLES,
DED_AMT_CR_T_V01,DED_AMT_CR_X_V01,DED_AMT_RQ_T_V01,DED_AMT_RQ_X_V01,DIMENSIONS,DIMENSIONS_IX,DIRECT_TRANS_T_V06,DIRECT_TRANS_X_V06,DMSRPT_STAGE_INDEX,DMSRPT_STAGE_TABLE,DMS_INT_INDEX,DMS_INT_TABLE,ESIGHT_ADMIN_T_V01,EXPLORE,EXPLORE_WORK,FEEDS_IN_T_V01,FEEDS_OUT,HAL_TABLES,HISTORICAL9DAY_T_V01,HISTORICAL_T_V01,IBMCDC_TABLES,INFO,
LIMIT_AMOUNT_CR_T_V01,LIMIT_AMOUNT_CR_X_V01,LIMIT_AMOUNT_RQ_T_V01,LIMIT_AMOUNT_RQ_X_V01,MEDBILL_T_V01,MISTERM_ENHANCED_DAILY_T_V01,MISTERM_ENHANCED_DAILY_X_V01,MISTERM_ENHANCED_PRIOR_T_V01,MISTERM_ENHANCED_T_V01,MISTERM_ENHANCED_X_V01,MISTERM_LTD_BKP_T_V01,MISTERM_LTD_T_V01,MISTERM_LTD_WIP_T_V01,MISTERM_T_V01,MISTERM_X_V01,
MIS_DM_RPT_ARCHIVE_T_V01,MIS_DM_RPT_ARCHIVE_X_V01,MIS_DM_RPT_T_V01,MIS_DM_RPT_X_V01,MIS_EARN_OUT_EXP_T_V01,MIS_EARN_OUT_EXP_X_V01,MIS_EARN_OUT_LTD_T_V01,MIS_EARN_OUT_LTD_X_V01,MIS_EARN_OUT_RECAST_T_V01,MIS_EARN_OUT_RECAST_X_V01,MIS_EARN_OUT_T_V04,MIS_EARN_OUT_X_V04,MIS_LIST_CHAINED_T_V01,MIS_RPT_DEV_V01,MIS_WORK,ODSHIST_INDEX,
ODSHIST_TABLE,ODSRPT_INDEX,ODSRPT_TABLE,ODS_INT_INDEX,ODS_INT_TABLE,PAFTRANS,PAFTRANS_IX,PAFTRANS_SUMMARY_T_V01,PAFTRANS_SUMMARY_X_V01,PAFTRAN_GL_ACCT_2009_T_V01,PAFTRAN_GL_ACCT_2010_T_V01,PAFTRAN_GL_ACCT_2011_T_V01,PAFTRAN_GL_ACCT_2012_T_V01,PAFTRAN_GL_ACCT_2013_T_V01,PAFTRAN_GL_ACCT_2014_T_V01,PAFTRAN_GL_ACCT_2015_T_V01,
PAFTRAN_GL_ACCT_PRE2009_T_V01,PAY_HIST_T_V02,PAY_HIST_X_V02,PCA_CLAIM_T_V01,PCA_CLAIM_X_V01,PL_CALENDAR_YR_DATA_T_V01,PL_CALENDAR_YR_DATA_X_V01,PL_IBNR_FACTORS_PRIOR_T_V01,PL_IBNR_FACTORS_PRIOR_X_V01,PL_SUM_PRIOR_WIP_T_V01,PL_SUM_PRIOR_WIP_X_V01,PRELOAD,PRODUCTS_BKP_T_V01,PRODUCTS_CLMCLS_T_V01,PRODUCTS_CLMCLS_X_V01,PRODUCTS_QTR_T_V01,
PRODUCTS_QTR_WIP_T_V01,PRODUCTS_T_V01,PRODUCTS_WIP_T_V01,PRODUCTS_WIP_X_V01,PRODUCTS_X_V01,PROFIT_LOSS_GROSS_PRV_T_V01,PROFIT_LOSS_GROSS_PRV_X_V01,PROFIT_LOSS_SUMMARY_BKP_T_V01,PROFIT_LOSS_SUMMARY_T_V01,PROFIT_LOSS_SUMMARY_WIP_T_V01,PROFIT_LOSS_SUMMARY_WIP_X_V01,PROFIT_LOSS_SUMMARY_X_V01,PROFIT_LOSS_SUMM_PRIOR_T_V01,PROFIT_LOSS_SUMM_PRIOR_X_V01,
PRO_HIST_T_V01,PS_Z_ERNOUT_EXP_T_V01,RATE_FACT_BKP_T_V01,RATE_FACT_T_V01,RATE_FACT_WIP_T_V01,RATE_FACT_WIP_X_V01,RATE_FACT_X_V01,RATG_FTR_ADD_CR_T_V01,RATG_FTR_ADD_CR_X_V01,RATG_FTR_ADD_RQ_T_V01,RATG_FTR_ADD_RQ_X_V01,RATING_FACTOR_CR_T_V02,RATING_FACTOR_CR_X_V02,RATING_FACTOR_RQ_T_V02,RATING_FACTOR_RQ_X_V02,REINS_DIRECT_TRANS_T_V02,REINS_DIRECT_TRANS_X_V02,
REINS_SPECIAL_TRANS_T_V02,REINS_SPECIAL_TRANS_X_V02,REPLATFORM_BACKUP_T_V01,RETENTION_FACT_BKP_T_V01,RETENTION_FACT_T_V01,RETENTION_FACT_WIP_T_V01,RETENTION_FACT_WIP_X_V01,RETENTION_FACT_X_V01,RST_PPO_T_V01,STAGING,SUFFIX_ADDITIONAL_WEEKLY_T_V01,SUFFIX_ADDITIONAL_WEEKLY_X_V01,SUFFIX_SNAPS_REBUILD_T_V01,SUFFIX_SNAPS_WEEKLY_T_V04,SUFFIX_SNAPS_WEEKLY_X_V04,
SUFFIX_WEEKLY_T_V05,SUFFIX_WEEKLY_X_V05,SURETY_ARCHIVE_T_V01,SURETY_ARCHIVE_X_V01,SURETY_STAGING_T_V01,SURETY_STAGING_X_V01,SUR_BOND_TERM_CVRG_T_V01,SUR_BOND_TERM_CVRG_X_V01,SUR_BOND_T_V01,SUR_BOND_X_V01,SUR_MISTERM_PRIOR_T_V01,SUR_MISTERM_T_V01,SUR_MISTERM_X_V01,SYMANTEC_I3_ORCL,TOOLS,VIATICUS_T_V01,VIATICUS_X_V01,WCEDI,WCEDIDMS,WCFC01,WCFC_CLAIM_DETAIL_T_V01,
WCFC_CLAIM_DETAIL_X_V01,WCFC_LOSS_DETAIL_T_V01,WCFC_LOSS_DETAIL_X_V01,WCFC_QTR_CLAIM_DETAIL_T_V01,WCFC_QTR_CLAIM_DETAIL_X_V01,BOXI_RPT_TMP,BO_TEMP,ESIGHT_TEMP,LAWYERS_INS_TEMP,MIS_DM_RPT_TEMP,
MIS_RPT_DEV_TEMP,SYMANTEC_I3_ORCL_TMP,USER_TEMP,THIRTYTWOK,MEDBILL_MITCHELL_T_01,CEDELITE_STAGING_T_V01,CAPMAN_DATA,MISTERM_ENHANCED_20140102_T,CNA13_0692_V01,PAFTRAN_GL_ACCT_2016_T_V01,CCN_PREMHIST_T_V01,CCN_PREMHIST_X_V01,DATA,INDEXES,MR_LANDING_TABLES,MR_LANDING_LOB,MR_LANDING_INDEXES,MR_PRELOAD_TABLES,MR_PRELOAD_LOB,
MR_PRELOAD_INDEXES,STF_LARGE_OBJECTS,AISS_INDEXES,AISS_TABLES,AD1099_TAXPRO_T_V01,CLAIMAPD_T01,ARCHIVE_LOB,ARCHIVE_INDEX,ARCHIVE_TABLES,AD1099_TAXPRO_X_V01,AR_LKU_T_V01,AR_LKU_X_V01,AR_STAGING_T_V01,AR_STAGING_X_V01,AR_T_V01,AR_X_V01,BLTK_T_V01,BLTK_X_V01,CIMSODS_INDEXES,CIMSODS_TABLES,CIRSODS_INDEXES,CIRSODS_TABLES,EUSRPTODS_INDEXES,EUSRPTODS_TABLES,
MAIN_INDEXES,MVRODS_INDEXES,MVRODS_TABLES,ODS_CONTROL_INDEXES,ODS_CONTROL_TABLES,PASEINPODS_INDEXES,PASEINPODS_TABLES,PASEREFODS_INDEXES,PASEREFODS_LARGEOBJ,PASEREFODS_TABLES,
RATER_EXP_INDEXES,RATER_EXP_TABLES,RCTODS_INDEXES,UWSODS_INDEXES,RCTODS_LARGE_OBJ,RCTODS_TABLES,RSTSTAGE_INDEXES,RSTSTAGE_LARGE_OBJ,RSTSTAGE_TABLES,SSO_RATERS_STAGE_INDEXES,SSO_RATERS_STAGE_TABLES,STAGE_INDEXES,STAGE_TABLES,SURCDC_STAGE_T_V01,TABLES,TAP_INDEXES,TAP_TABLES,ULSODS_INDEXES,ULSODS_TABLES,UWSODS_TABLES,WCODS_INDEXES,WCODS_STG_INDEXES,WCODS_STG_TABLES,
WCODS_TABLES,WCPAYGO_INDEXES,WCPAYGO_TABLES,CNP_RE_REF_LARGE_OBJECTS,SURCDC_STAGE_ADMIN,SURCDC_STAGE_INDEX,SURCDC_STAGE_LOB,SURCDC_STAGE_OP,SURCDC_STAGE_STAGING,SURCDC_STAGE_TYPELIST,SURCDC_STAGE_I_V01,PAFTRAN_GL_ACCT_2017_T_V01,DVD_TEMP,CNACMRPT_LARGE_OBJECTS,AISS_LARGE_OBJ,DEVLDBA_INDEXES,DEVLDBA_TABLES,UPS_TABLES,UPS_INDEXES,AISSMRPT_LARGE_OBJECTS,
AISSMRPT_ARCHIVE_TABLES,AISSMRPT_ARCHIVE_INDEXES,PAFTRAN_GL_ACCT_2018_T_V01,ATLAS_LGL_HOLD_ARCHIVE_T1,EUR_CLAIM_DATA_TO_US_T01,
TEAMTHINK_T01,BLACKLINE_T1,CNP_RE_REF_OBJECTS,PAFTRAN_GL_ACCT_2019_T_V01,MEDBILL_CONDUENT_T01,COMPASS_01;
}


-- run the script (& is for background job)
rman target / cmdfile=rman_script.cmd |tee log=/u01/oracle/diag/rdbms/merwhtbl/log/merwhtbl_7tbls_restore_11jun2019.log &

<end node> 5P9i0s8y19Z
dt=Text
<node>
cell single block physical read
2

-- "cell single block physical read" 
I invetigate the issue and found that - your job statement was taking more time, because their was a wait event on exadata MERWHP database "cell single block physical read" was generating, while searching on it I found that - this wait event is more related to DMLs executed at the time of index creation. 

The reasons why the statement would have produced so many "cell single block physical read" waits (found from the Oracle documentation)
A. There are huge numbers of migrated rows in the table on which the index is being built.
B. There is an uncommitted transaction that has modified one block of the table on which the index is being built, in each cell.
C. There is a transaction that has modified one block of the table on which the index is being built in each cell, which committed after the create index began.
D. There are huge numbers of chained rows in the table on which the index is being built.
E. There is a ROWID column in the table on which the index is being built.  

Please let us know what is the process while executing the jobs like indexes are dropped and re-created for the better performance and then running the DMLs ? 

<end node> 5P9i0s8y19Z
dt=Text
<node>
ACL tables backup for Merlin refresh
2
-- Below is the script to take the ACL backup, Below script will generate the output and that output will be the backup
-- we have to execute the script in bot the DBs before import (refresh)

All Merlin (MERWHR and MERDMR) Activities should be carried on Node 2 where connectiones on weekend will be lesser
-- you might have to investigate for the busy node, by login into DB and taking the connection count on both the nodes and take the decision

1) MERWHR
2) MERDMR

-- copy the below script into on .sql and login to sqlplus "'/as sysdba'" and execute it 

vi acl_backup_script.sql

set serveroutput on

declare
v_param_list varchar2(2000);

cursor rec_c ( i_ACLID dba_network_acl_privileges.ACLID%type, i_ACL dba_network_acl_privileges.ACL%type ) is
select rownum POSITION , 
ACL,
PRINCIPAL,
decode(privilege,'use-cli','use-client-certificates','use-pas','use-passwords',privilege) PRIVILEGE,
IS_GRANT,INVERT,
decode(START_DATE,null,'null','to_timestamp_tz('''||to_char(START_DATE,'YYYYMMDDHH24MISSXFFTZR')||''',''YYYYMMDDHH24MISSXFF TZR'')') START_DATE,
decode(END_DATE,null,'null','to_timestamp_tz('''||to_char(END_DATE,'YYYYMMDDHH24MISSXFFTZR'||''',''YYYYMMDDHH24MISSXFF TZR'')')) END_DATE
from dba_network_acl_privileges a 
where a.ACLID = i_ACLID and a.ACL = i_ACL ;

rec rec_c%rowtype ;

begin
   for i in ( select distinct ACLID,ACL from dba_network_acl_privileges ) loop
     open rec_c ( i.ACLID , i.acl ) ;
     fetch rec_c into rec;
      v_param_list:='acl=>'''||substr(rec.acl,instr(rec.acl,'/',-1)+1)||'''';
      v_param_list:=v_param_list||',description=>'''||substr(rec.acl,11,length(rec.acl))||'''';
      v_param_list:=v_param_list||',principal=>'''||rec.principal||'''';
      v_param_list:=v_param_list||',privilege=>'''||rec.privilege||'''';
      v_param_list:=v_param_list||',is_grant=>'||rec.is_grant;
      v_param_list:=v_param_list||',start_date=>'||rec.END_DATE;
      v_param_list:=v_param_list||',end_date=>'||rec.END_DATE||');';
      dbms_output.put_line('exec dbms_network_acl_admin.create_acl('||v_param_list);
      -- fetch rec_c into rec ; NOT FETCHING HERE TO AVOID DUPLICATES 
         while rec_c%FOUND loop
             v_param_list:='acl=>'''||substr(rec.acl,instr(rec.acl,'/',-1)+1)||'''';
             v_param_list:=v_param_list||',principal=>'''||rec.principal||'''';
             v_param_list:=v_param_list||',is_grant=>'||rec.is_grant;
             v_param_list:=v_param_list||',privilege=>'''||rec.privilege||'''';
             v_param_list:=v_param_list||',position=>'||rec.POSITION;
             v_param_list:=v_param_list||',start_date=>'||rec.END_DATE;
             v_param_list:=v_param_list||',end_date=>'||rec.END_DATE||');';
             dbms_output.put_line('exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE('||v_param_list);
             fetch rec_c into rec ;
         end loop;
       close rec_c ;

    for rec2 in (select HOST,decode(LOWER_PORT,null,'null',to_char(LOWER_PORT))LOWER_PORT,decode(UPPER_PORT,null,'null',to_char(UPPER_PORT))UPPER_PORT,ACL,ACLID
                 from dba_network_acls 
                 where acl = i.acl and ACLID= i.aclid) loop
                    v_param_list:='acl=>'''||substr(rec2.acl,instr(rec2.acl,'/',-1)+1)||''',host=>'''||rec2.host||''',lower_port=>'||rec2.lower_port||',upper_port=>'||rec2.upper_port||');';
                    dbms_output.put_line('exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL('||v_param_list);
    end loop;

  end loop;
end;
/

SQL> @acl_backup_script.sql

<end node> 5P9i0s8y19Z
dt=Text
<node>
merwhr rman
2
+ LOGFILE=/home/oracle/dba/log/MERWHR1_rman_arch_del.log
+ /u01/oracle/product/12.1.0.2/bin/rman target / nocatalog
+ 0<< \EOF
@ 
exit
EOF


rm /zfss*/*/backup*/*/bkp_*_20190911* 

rm -f /zfss*/mrln*/backup*/MER*/bkp_*_201909*




 allocate channel ch01 device type disk connect * format '/zfssa/mrln-prod-rman/backup01/MERWHP/bkp_%d_%T_%U';
36> allocate channel ch02 device type disk connect * format '/zfssb/mrln-prod-rman/backup02/MERWHP/bkp_%d_%T_%U';
37> allocate channel ch03 device type disk connect * format '/zfssa/mrln-prod-rman/backup03/MERWHP/bkp_%d_%T_%U';
38> allocate channel ch04 device type disk connect * format '/zfssb/mrln-prod-rman/backup04/MERWHP/bkp_%d_%T_%U';
39> allocate channel ch05 device type disk connect * format '/zfssa/mrln-prod-rman/backup05/MERWHP/bkp_%d_%T_%U';
40> allocate channel ch06 device type disk connect * format '/zfssb/mrln-prod-rman/backup06/MERWHP/bkp_%d_%T_%U';
41> allocate channel ch07 device type disk connect * format '/zfssa/mrln-prod-rman/backup07/MERWHP/bkp_%d_%T_%U';
42> allocate channel ch08 device type disk connect * format '/zfssb/mrln-prod-rman/backup08/MERWHP/bkp_%d_%T_%U';
43> allocate channel ch09 device type disk connect * format '/zfssa/mrln-prod-rman/backup09/MERWHP/bkp_%d_%T_%U';
44> allocate channel ch10 device type disk connect * format '/zfssb/mrln-prod-rman/backup10/MERWHP/bkp_%d_%T_%U';
45> allocate channel ch11 device type disk connect * format '/zfssa/mrln-prod-rman/backup11/MERWHP/bkp_%d_%T_%U';
46> allocate channel ch12 device type disk connect * format '/zfssb/mrln-prod-rman/backup12/MERWHP/bkp_%d_%T_%U';
47> allocate channel ch13 device type disk connect * format '/zfssa/mrln-prod-rman/backup13/MERWHP/bkp_%d_%T_%U';
48> allocate channel ch14 device type disk connect * format '/zfssb/mrln-prod-rman/backup14/MERWHP/bkp_%d_%T_%U';
49> allocate channel ch15 device type disk connect * format '/zfssa/mrln-prod-rman/backup15/MERWHP/bkp_%d_%T_%U';
50> allocate channel ch16 device type disk connect * format '/zfssb/mrln-prod-rman/backup16/MERWHP/bkp_%d_%T_%U';
51> allocate channel ch17 device type disk connect * format '/zfssa/mrln-prod-rman/backup17/MERWHP/bkp_%d_%T_%U';
52> allocate channel ch18 device type disk connect * format '/zfssb/mrln-prod-rman/backup18/MERWHP/bkp_%d_%T_%U';
53> allocate channel ch19 device type disk connect * format '/zfssa/mrln-prod-rman/backup19/MERWHP/bkp_%d_%T_%U';
54> allocate channel ch20 device type disk connect * format '/zfssb/mrln-prod-rman/backup20/MERWHP/bkp_%d_%T_%U';
55> allocate channel ch21 device type disk connect * format '/zfssa/mrln-prod-rman/backup21/MERWHP/bkp_%d_%T_%U';
56> allocate channel ch22 device type disk connect * format '/zfssb/mrln-prod-rman/backup22/MERWHP/bkp_%d_%T_%U';
57> allocate channel ch23 device type disk connect * format '/zfssa/mrln-prod-rman/backup23/MERWHP/bkp_%d_%T_%U';
58> allocate channel ch24 device type disk connect * format '/zfssb/mrln-prod-rman/backup24/MERWHP/bkp_%d_%T_%U';


CONFIGURE ARCHIVELOG DELETION POLICY CLEAR;

delete noprompt archivelog all;

CONFIGURE ARCHIVELOG DELETION POLICY TO BACKED UP 2 TIMES TO DISK;

<end node> 5P9i0s8y19Z
dt=Text
<node>
restore merwhp
2
rman target / catalog exarman/b6a9dRwR@rcat2p 

-- connect catalog exarman/b6a9dRwR@rcat2p 

restore spfile

restore control file
restore controlfile from '/u01/oracle/zfs-dr/datapump/merwhp_cirsods/bkp_MERWHP_20200708_p0v4p3bk_1_1';

start the database in nomount stag
connect to rman target /

run
{
allocate channel ch04 device type disk;
allocate channel ch05 device type disk;
allocate channel ch06 device type disk;
allocate channel ch07 device type disk;
allocate channel ch08 device type disk;
allocate channel ch09 device type disk;
allocate channel ch10 device type disk;
allocate channel ch11 device type disk;
allocate channel ch12 device type disk;
allocate channel ch13 device type disk;
allocate channel ch14 device type disk;
allocate channel ch15 device type disk;
allocate channel ch16 device type disk;
allocate channel ch17 device type disk;
allocate channel ch18 device type disk;
allocate channel ch19 device type disk;
allocate channel ch20 device type disk;
allocate channel ch21 device type disk;
allocate channel ch22 device type disk;
allocate channel ch23 device type disk;
allocate channel ch24 device type disk;
set until time "to_date( '08-07-2020 06:33', 'DD-MM-RRRR HH24:MI')";
set newname for datafile 1 to '+DATA_WH/MERWHP/DATAFILE/system.1328.895434719';
set newname for datafile 2 to '+DATA_WH/MERWHP/DATAFILE/sysaux.342.895434721';
set newname for datafile 3 to '+DATA_WH/MERWHP/DATAFILE/undotbs1.343.895434721';
set newname for datafile 4 to '+DATA_WH/MERWHP/DATAFILE/undotbs2.345.895434725';
set newname for datafile 5 to '+DATA_WH/MERWHP/DATAFILE/users.346.895434727';
set newname for datafile 259 to '+DATA_WH/MERWHP/DATAFILE/users.596.896088205';
set newname for datafile 260 to '+DATA_WH/MERWHP/DATAFILE/users.595.896088207';
set newname for datafile 261 to '+DATA_WH/MERWHP/DATAFILE/users.594.896088321';
set newname for datafile 262 to '+DATA_WH/MERWHP/DATAFILE/users.593.896088325';
set newname for datafile 263 to '+DATA_WH/MERWHP/DATAFILE/users.1530.897151671';
set newname for datafile 285 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1531.909483313';
set newname for datafile 292 to '+DATA_WH/MERWHP/DATAFILE/users.1681.912168531';
set newname for datafile 293 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1682.912995023';
set newname for datafile 294 to '+DATA_WH/MERWHP/DATAFILE/users.1686.913330315';
set newname for datafile 299 to '+DATA_WH/MERWHP/DATAFILE/cirsods_indexes.586.914018353';
set newname for datafile 300 to '+DATA_WH/MERWHP/DATAFILE/cirsods_tables.585.914018361';
set newname for datafile 350 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1534.942007219';
set newname for datafile 358 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1667.953335663';
set newname for datafile 359 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1666.953523335';
set newname for datafile 360 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1665.953528269';
set newname for datafile 361 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1664.953953107';
set newname for datafile 362 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1663.954236825';
set newname for datafile 363 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1662.954295177';
set newname for datafile 364 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1661.954653853';
set newname for datafile 365 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1660.954655513';
set newname for datafile 366 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1659.955172743';
set newname for datafile 367 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1658.955172809';
set newname for datafile 368 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1657.955252471';
set newname for datafile 369 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1656.955252501';
set newname for datafile 370 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1655.955252503';
set newname for datafile 371 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1654.955252505';
set newname for datafile 372 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1653.955936027';
set newname for datafile 373 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1652.956063873';
set newname for datafile 374 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1651.956426347';
set newname for datafile 375 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1650.956550691';
set newname for datafile 376 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1296.960338187';
set newname for datafile 377 to '+DATA_WH/MERWHP/DATAFILE/sysaux.589.960341983';
set newname for datafile 378 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1291.960638581';
set newname for datafile 380 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1294.960779569';
set newname for datafile 381 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1293.960790973';
set newname for datafile 382 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1292.960790975';
set newname for datafile 383 to '+DATA_WH/MERWHP/DATAFILE/sysaux.590.960790977';
set newname for datafile 384 to '+DATA_WH/MERWHP/DATAFILE/sysaux.591.960859723';
set newname for datafile 385 to '+DATA_WH/MERWHP/DATAFILE/sysaux.592.961207031';
set newname for datafile 386 to '+DATA_WH/MERWHP/DATAFILE/sysaux.599.961223753';
set newname for datafile 387 to '+DATA_WH/MERWHP/DATAFILE/sysaux.600.961554689';
set newname for datafile 388 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1527.961944649';
set newname for datafile 389 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1526.961944651';
set newname for datafile 390 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1525.962584267';
set newname for datafile 391 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1524.962598021';
set newname for datafile 392 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1523.962925421';
set newname for datafile 393 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1522.963294383';
set newname for datafile 394 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1521.963332665';
set newname for datafile 395 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1520.963332667';
set newname for datafile 396 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1519.963790717';
set newname for datafile 397 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1302.963790723';
set newname for datafile 398 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1301.963889733';
set newname for datafile 399 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1300.963962697';
set newname for datafile 400 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1299.964412509';
set newname for datafile 401 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1289.964671435';
set newname for datafile 402 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1297.965055257';
set newname for datafile 403 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1290.965055261';
set newname for datafile 404 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1287.965055263';
set newname for datafile 405 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1298.965055263';
set newname for datafile 406 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1288.966028723';
set newname for datafile 407 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1649.966028725';
set newname for datafile 408 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1648.966028727';
set newname for datafile 409 to '+DATA_WH/MERWHP/DATAFILE/sysaux.1647.966844229';
set newname for datafile 416 to '+DATA_WH/MERWHP/DATAFILE/users.1640.995380629';
set newname for datafile 422 to '+DATA_WH/MERWHP/DATAFILE/users.1634.1017576895';
set newname for datafile 423 to '+DATA_WH/MERWHP/DATAFILE/users.1633.1017576913';
set newname for datafile 424 to '+DATA_WH/MERWHP/DATAFILE/users.1632.1017667089';
set newname for datafile 425 to '+DATA_WH/MERWHP/DATAFILE/users.1631.1017667095';
set newname for datafile 426 to '+DATA_WH/MERWHP/DATAFILE/users.1630.1017667101';
set newname for datafile 427 to '+DATA_WH/MERWHP/DATAFILE/users.1629.1018093941';
set newname for datafile 434 to '+DATA_WH/MERWHP/DATAFILE/users.1621.1034067221';
set newname for datafile 435 to '+DATA_WH/MERWHP/DATAFILE/users.1620.1036151965';
set newname for datafile 436 to '+DATA_WH/MERWHP/DATAFILE/users.1619.1036151975';
set newname for datafile 437 to '+DATA_WH/MERWHP/DATAFILE/users.1618.1036151979';
set newname for datafile 438 to '+DATA_WH/MERWHP/DATAFILE/users.1617.1036151985';
set newname for datafile 440 to '+DATA_WH/MERWHP/DATAFILE/users.1615.1038936659';
set newname for datafile 441 to '+DATA_WH/MERWHP/DATAFILE/users.1614.1038936669';
set newname for datafile 442 to '+DATA_WH/MERWHP/DATAFILE/users.1613.1038936687';
set newname for datafile 443 to '+DATA_WH/MERWHP/DATAFILE/users.1612.1038936691';
set newname for datafile 444 to '+DATA_WH/MERWHP/DATAFILE/users.1611.1038943179';
set newname for datafile 445 to '+DATA_WH/MERWHP/DATAFILE/users.1610.1038943187';
set newname for datafile 446 to '+DATA_WH/MERWHP/DATAFILE/users.1609.1038943193';
set newname for datafile 447 to '+DATA_WH/MERWHP/DATAFILE/users.1608.1038943197';
restore tablespace SYSTEM,UNDOTBS1,SYSAUX,UNDOTBS2,CIRSODS_TABLES,CIRSODS_INDEXES;
switch datafile all;
sql "alter database datafile 1,2,3,4,15,285,293,350,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409 online";
recover database skip forever tablespace TEMP,USERS,AB_ADMIN,AB_INDEX,AB_OP,ACA,ACA_HSTRY_T_V01,ACTDMS,ACTFINODS,AC_STAGING_T_V01,AD1099_TAXPRO_T_V01,AD1099_TAXPRO_X_V01,AGGREGATE,AGGREGATE_IX,AIM_DATA,AIPS_MISTERM_AUGUST_T_V01,AIPS_MISTERM_AUGUST_X_V01,AISSMRPT_ARCHIVE_INDEXES,AISSMRPT_ARCHIVE_TABLES,AISSMRPT_LARGE_OBJECTS,AISS_TABLES,APER_BO_LOSS_RATIO_BKP_T_V01,APER_BO_LOSS_RATIO_T_V01,APER_BO_LOSS_RATIO_WIP_T_V01,APER_BO_LOSS_RATIO_WIP_X_V01,APER_BO_LOSS_RATIO_X_V01,APER_BO_PREM_DETAIL_BKP_T_V01,APER_BO_PREM_DETAIL_T_V01,APER_BO_PREM_DETAIL_WIP_T_V01,APER_BO_PREM_DETAIL_WIP_X_V01,APER_BO_PREM_DETAIL_X_V01,APER_EP_QTR_SS_T_V01,APER_EP_QTR_SS_X_V01,ARCHIVE_INDEX,ARCHIVE_LOB,ARCHIVE_TABLES,ARCHIVE_T_V01,ARCH_RATING_FACTOR_CR_T_V01,ARCH_RATING_FACTOR_CR_X_V01,ARCH_RATING_FACTOR_RQ_T_V01,ARCH_RATING_FACTOR_RQ_X_V01,AR_LKU_T_V01,AR_LKU_X_V01,AR_STAGING_T_V01,AR_STAGING_X_V01,AR_T_V01,AR_X_V01,ATLAS_LGL_HOLD_ARCHIVE_T1,BASE_FACT_FINAL_BKP_T_V01,BASE_FACT_FINAL_T_V01,BASE_FACT_FINAL_WIP_T_V01,BASE_FACT_FINAL_X_V01,BASE_FACT_PRIOR_WK2A_T_V01,BASE_FACT_WK2A_T_V01,BASE_FACT_WK_T_V01,BLACKLINE_T1,BLTK_T_V01,BLTK_X_V01,BOXI_RPT_TMP,BO_TEMP,CANADA_T_V01,CAPMAN_DATA,CARPE_T01,CCN_PREMHIST_T_V01,CCN_PREMHIST_X_V01,CC_INDEX,CC_OP,CDC_CHECK_TBL,CEDELITE_STAGING_T_V01,CIDBP_DATA01,CIDBP_INDEXES01,CIMSODS_INDEXES,CIMSODS_TABLES,CLAIMAPD_T01,CLAIMDMS_INDEX,CLAIMDMS_TABLE,CLAIMODS_INDEX,CLAIMODS_LIST_CHAINED_T_V01,CLAIMODS_TABLE,CLAIM_ADDITIONAL_T_V01,CLAIM_ADDITIONAL_WEEKLY_T_V01,CLAIM_ADDITIONAL_WEEKLY_X_V01,CLAIM_ADDITIONAL_X_V01,CLAIM_TRANS_T_V01,CLAIM_TRANS_X_V01,CLAIM_T_V04,CLAIM_WEEKLY_T_V01,CLAIM_WEEKLY_X_V01,CLAIM_X_V04,CMMRCL_PLDG_ARCHIVE01,CNA13_0692_V01,CNACMRPT_LARGE_OBJECTS,CNACOM_STAGING_T_V01,CNA_ATABLES,CNP_RE_REF_OBJECTS,COMBINED_CLAIM_ADDL_T_V01,COMBINED_CLAIM_ADDL_X_V01,COMBINED_CLAIM_T_V01,COMBINED_CLAIM_X_V01,COMBINED_PAY_HIST_T_V01,COMBINED_PAY_HIST_X_V01,COMBINED_SUFFIX_SNAPS_T_V01,COMBINED_SUFFIX_SNAPS_X_V01,COMBINED_SUFFIX_T_V01,COMBINED_SUFFIX_X_V01,COMPASS_01,COSTCON_T_V01,COVERAGE_CR_T_V01,COVERAGE_CR_X_V01,COVERAGE_RQ_T_V01,COVERAGE_RQ_X_V01,CR_RQ_T_V01,CR_RQ_X_V01,CVS_T_V01,CVS_X_V01,CVTRY_HIST_T_V01,DASH_T_V01,DATA,DBA_CMDS_INDEXES,DBA_CMDS_TABLES,DED_AMT_CR_T_V01,DED_AMT_CR_X_V01,DED_AMT_RQ_T_V01,DED_AMT_RQ_X_V01,DEVLDBA_INDEXES,DEVLDBA_TABLES,DIMENSIONS,DIMENSIONS_IX,DIRECT_TRANS_T_V06,DIRECT_TRANS_X_V06,DMSRPT_STAGE_INDEX,DMSRPT_STAGE_TABLE,DMS_INT_INDEX,DMS_INT_TABLE,DVD_TEMP,ESIGHT_ADMIN_T_V01,ESIGHT_TEMP,EUR_CLAIM_DATA_TO_US_T01,EUSRPTODS_INDEXES,EUSRPTODS_TABLES,EXPLORE,EXPLORE_WORK,FAS_CLAIMODS,FEEDS_IN_T_V01,FEEDS_OUT,FV_ARCHIVE_V01,GRIPCLOSE_T_V01,HAL_TABLES,HISTORICAL9DAY_T_V01,HISTORICAL_T_V01,IBMCDC_TABLES,INDEXES,INDEXES01,INFO,LAWYERS_INS_TEMP,LIMIT_AMOUNT_CR_T_V01,LIMIT_AMOUNT_CR_X_V01,LIMIT_AMOUNT_RQ_T_V01,LIMIT_AMOUNT_RQ_X_V01,LITE_DATA,MAIN_INDEXES,MAIN_TABLES,MAXCP_DATA01,MAXCP_INDEXES01,MEDBILL_CONDUENT_T01,MEDBILL_MITCHELL_T_01,MEDBILL_T_V01,METADATA_REP_TABLES,MISTERM_ENHANCED_20140102_T,MISTERM_ENHANCED_DAILY_T_V01,MISTERM_ENHANCED_DAILY_X_V01,MISTERM_ENHANCED_PRIOR_T_V01,MISTERM_ENHANCED_T_V01,MISTERM_ENHANCED_X_V01,MISTERM_LTD_BKP_T_V01,MISTERM_LTD_T_V01,MISTERM_LTD_WIP_T_V01,MISTERM_T_V01,MISTERM_X_V01,MIS_DM_RPT_ARCHIVE_T_V01,MIS_DM_RPT_ARCHIVE_X_V01,MIS_DM_RPT_TEMP,MIS_DM_RPT_T_V01,MIS_DM_RPT_X_V01,MIS_DM_RPT_YE_T_V01,MIS_EARN_OUT_EXP_T_V01,MIS_EARN_OUT_EXP_X_V01,MIS_EARN_OUT_LTD_T_V01,MIS_EARN_OUT_LTD_X_V01,MIS_EARN_OUT_RECAST_T_V01,MIS_EARN_OUT_RECAST_X_V01,MIS_EARN_OUT_T_V04,MIS_EARN_OUT_X_V04,MIS_LIST_CHAINED_T_V01,MIS_RPT_DEV_TEMP,MIS_RPT_DEV_V01,MIS_WORK,MR_LANDING_INDEXES,MR_LANDING_LOB,MR_LANDING_TABLES,MR_PRELOAD_INDEXES,MR_PRELOAD_LOB,MR_PRELOAD_TABLES,ODSHIST_INDEX,ODSHIST_TABLE,ODSRPT_INDEX,ODSRPT_TABLE,ODS_CONTROL_INDEXES,ODS_CONTROL_TABLES,ODS_INT_INDEX,ODS_INT_TABLE,PAFTRANS,PAFTRANS_IX,PAFTRANS_SUMMARY_T_V01,PAFTRANS_SUMMARY_X_V01,PAFTRAN_GL_ACCT_2009_T_V01,PAFTRAN_GL_ACCT_2010_T_V01,PAFTRAN_GL_ACCT_2011_T_V01,PAFTRAN_GL_ACCT_2012_T_V01,PAFTRAN_GL_ACCT_2013_T_V01,PAFTRAN_GL_ACCT_2014_T_V01,PAFTRAN_GL_ACCT_2015_T_V01,PAFTRAN_GL_ACCT_2016_T_V01,PAFTRAN_GL_ACCT_2017_T_V01,PAFTRAN_GL_ACCT_2018_T_V01,PAFTRAN_GL_ACCT_2019_T_V01,PAFTRAN_GL_ACCT_PRE2009_T_V01,PASEINPODS_INDEXES,PASEINPODS_TABLES,PASEREFODS_INDEXES,PASEREFODS_LARGEOBJ,PASEREFODS_TABLES,PAY_HIST_T_V02,PAY_HIST_X_V02,PCA_CLAIM_T_V01,PCA_CLAIM_X_V01,PERFBP_DATA01,PERFBP_INDEXES01,PL_CALENDAR_YR_DATA_T_V01,PL_CALENDAR_YR_DATA_X_V01,PL_IBNR_FACTORS_PRIOR_T_V01,PL_IBNR_FACTORS_PRIOR_X_V01,PL_SUM_PRIOR_WIP_T_V01,PL_SUM_PRIOR_WIP_X_V01,PRELOAD,PRODUCTS_BKP_T_V01,PRODUCTS_CLMCLS_T_V01,PRODUCTS_CLMCLS_X_V01,PRODUCTS_QTR_T_V01,PRODUCTS_QTR_WIP_T_V01,PRODUCTS_T_V01,PRODUCTS_WIP_T_V01,PRODUCTS_WIP_X_V01,PRODUCTS_X_V01,PROFIT_LOSS_GROSS_PRV_T_V01,PROFIT_LOSS_GROSS_PRV_X_V01,PROFIT_LOSS_SUMMARY_BKP_T_V01,PROFIT_LOSS_SUMMARY_T_V01,PROFIT_LOSS_SUMMARY_WIP_T_V01,PROFIT_LOSS_SUMMARY_WIP_X_V01,PROFIT_LOSS_SUMMARY_X_V01,PROFIT_LOSS_SUMM_PRIOR_T_V01,PROFIT_LOSS_SUMM_PRIOR_X_V01,PRO_HIST_T_V01,PS_Z_ERNOUT_EXP_T_V01,RATER_EXP_INDEXES,RATER_EXP_TABLES,RATE_FACT_BKP_T_V01,RATE_FACT_T_V01,RATE_FACT_WIP_T_V01,RATE_FACT_WIP_X_V01,RATE_FACT_X_V01,RATG_FTR_ADD_CR_T_V01,RATG_FTR_ADD_CR_X_V01,RATG_FTR_ADD_RQ_T_V01,RATG_FTR_ADD_RQ_X_V01,RATING_FACTOR_CR_T_V02,RATING_FACTOR_CR_X_V02,RATING_FACTOR_RQ_T_V02,RATING_FACTOR_RQ_X_V02,RCA_ODS_INDEXES,RCA_ODS_TABLES,RCTODS_INDEXES,RCTODS_LARGE_OBJ,RCTODS_TABLES,REINS_DIRECT_SNAPS_T_V02,REINS_DIRECT_SNAPS_X_V02,REINS_DIRECT_TRANS_T_V02,REINS_DIRECT_TRANS_X_V02,REINS_SPECIAL_TRANS_T_V02,REINS_SPECIAL_TRANS_X_V02,RETENTION_FACT_BKP_T_V01,RETENTION_FACT_T_V01,RETENTION_FACT_WIP_T_V01,RETENTION_FACT_WIP_X_V01,RETENTION_FACT_X_V01,RSTSTAGE_INDEXES,RSTSTAGE_LARGE_OBJ,RSTSTAGE_TABLES,RST_PPO_T_V01,SENUS_01,SHIFT_01,SOSARCH_INDEXES,SOSARCH_TABLES,SOS_INDEXES,SOS_TABLES,SSO_RATERS_STAGE_INDEXES,SSO_RATERS_STAGE_TABLES,STAGE_INDEXES,STAGE_TABLES,STAGING,STF_HOLD,SUFFIX_ADDITIONAL_WEEKLY_T_V01,SUFFIX_ADDITIONAL_WEEKLY_X_V01,SUFFIX_SNAPS_T_V07,SUFFIX_SNAPS_WEEKLY_T_V04,SUFFIX_SNAPS_WEEKLY_X_V04,SUFFIX_SNAPS_X_V07,SUFFIX_T_V08,SUFFIX_WEEKLY_T_V05,SUFFIX_WEEKLY_X_V05,SUFFIX_X_V08,SURCDC_STAGE_I_V01,SURCDC_STAGE_T_V01,SURETY_ARCHIVE_T_V01,SURETY_ARCHIVE_X_V01,SURETY_STAGING_T_V01,SURETY_STAGING_X_V01,SUR_BOND_TERM_CVRG_T_V01,SUR_BOND_TERM_CVRG_X_V01,SUR_BOND_T_V01,SUR_BOND_X_V01,SUR_MISTERM_PRIOR_T_V01,SUR_MISTERM_T_V01,SUR_MISTERM_X_V01,SYMANTEC_I3_ORCL,SYMANTEC_I3_ORCL_TMP,TABLES01,TAP_INDEXES,TAP_TABLES,TEAMTHINK_T01,TEMP,TERADATA_T_V02,TFN_ARCHIVE_V01,THIRTYTWOK,TOOLS,TRECS_ARCHIVE_01,ULSODS_INDEXES,ULSODS_TABLES,UPS_INDEXES,UPS_TABLES,USER_TEMP,UWSODS_INDEXES,UWSODS_TABLES,VIATICUS_T_V01,VIATICUS_X_V01,WCEDI,WCEDIDMS,WCFC01,WCFC_CLAIM_DETAIL_T_V01,WCFC_CLAIM_DETAIL_X_V01,WCFC_LOSS_DETAIL_T_V01,WCFC_LOSS_DETAIL_X_V01,WCFC_QTR_CLAIM_DETAIL_T_V01,WCFC_QTR_CLAIM_DETAIL_X_V01,WCODS_INDEXES,WCODS_STG_INDEXES,WCODS_STG_TABLES,WCODS_TABLES,WCPAYGO_INDEXES,WCPAYGO_TABLES;
release channel ch04;
release channel ch05;
release channel ch06;
release channel ch07;
release channel ch08;
release channel ch09;
release channel ch10;
release channel ch11;
release channel ch12;
release channel ch13;
release channel ch14;
release channel ch15;
release channel ch16;
release channel ch17;
release channel ch18;
release channel ch19;
release channel ch20;
release channel ch21;
release channel ch22;
release channel ch23;
release channel ch24;
}

------------------------------------------

# SCN
RECOVER TABLE TEST.T1
  UNTIL SCN 1853267
  AUXILIARY DESTINATION '/u01/aux'  
  REMAP TABLE 'TEST'.'T1':'T1_PREV';

# TIME
RECOVER TABLE TEST.T1
  UNTIL TIME "TO_DATE('01-JAN-2013 15:00', 'DD-MON-YYYY HH24:MI')"
  AUXILIARY DESTINATION '/u01/aux'  
  REMAP TABLE 'TEST'.'T1':'T1_PREV'; 

------------------------------------------------------
nohup rman target / cmdfile=location_of_script_restoration.sql log=location_of_restoration_logs.log &

catalog with '/u01/oracle/zfs-dr/datapump/merwhp_cirsods';
run
{
allocate channel ch04 device type disk;
allocate channel ch05 device type disk;
allocate channel ch06 device type disk;
allocate channel ch07 device type disk;
allocate channel ch08 device type disk;
allocate channel ch09 device type disk;
allocate channel ch10 device type disk;
allocate channel ch11 device type disk;
allocate channel ch12 device type disk;
allocate channel ch13 device type disk;
allocate channel ch14 device type disk;
allocate channel ch15 device type disk;
allocate channel ch16 device type disk;
allocate channel ch17 device type disk;
allocate channel ch18 device type disk;
allocate channel ch19 device type disk;
allocate channel ch20 device type disk;
allocate channel ch21 device type disk;
allocate channel ch22 device type disk;
allocate channel ch23 device type disk;
allocate channel ch24 device type disk;
set until time "to_date( '08-07-2020 06:33', 'DD-MM-RRRR HH24:MI')";
set newname for tablespace SYSTEM to '+DATA_ETE';
set newname for tablespace UNDOTBS1 to '+DATA_ETE';
set newname for tablespace SYSAUX to '+DATA_ETE';
set newname for tablespace UNDOTBS2 to '+DATA_ETE';
set newname for tablespace CIRSODS_TABLES to '+DATA_ETE';
set newname for tablespace CIRSODS_INDEXES to '+DATA_ETE';
restore tablespace SYSTEM,UNDOTBS1,SYSAUX,UNDOTBS2,CIRSODS_TABLES,CIRSODS_INDEXES;
switch datafile all;
recover database skip forever tablespace TEMP,USERS,AB_ADMIN,AB_INDEX,AB_OP,ACA,ACA_HSTRY_T_V01,ACTDMS,ACTFINODS,AC_STAGING_T_V01,AD1099_TAXPRO_T_V01,AD1099_TAXPRO_X_V01,AGGREGATE,AGGREGATE_IX,AIM_DATA,AIPS_MISTERM_AUGUST_T_V01,AIPS_MISTERM_AUGUST_X_V01,AISSMRPT_ARCHIVE_INDEXES,AISSMRPT_ARCHIVE_TABLES,AISSMRPT_LARGE_OBJECTS,AISS_TABLES,APER_BO_LOSS_RATIO_BKP_T_V01,APER_BO_LOSS_RATIO_T_V01,APER_BO_LOSS_RATIO_WIP_T_V01,APER_BO_LOSS_RATIO_WIP_X_V01,APER_BO_LOSS_RATIO_X_V01,APER_BO_PREM_DETAIL_BKP_T_V01,APER_BO_PREM_DETAIL_T_V01,APER_BO_PREM_DETAIL_WIP_T_V01,APER_BO_PREM_DETAIL_WIP_X_V01,APER_BO_PREM_DETAIL_X_V01,APER_EP_QTR_SS_T_V01,APER_EP_QTR_SS_X_V01,ARCHIVE_INDEX,ARCHIVE_LOB,ARCHIVE_TABLES,ARCHIVE_T_V01,ARCH_RATING_FACTOR_CR_T_V01,ARCH_RATING_FACTOR_CR_X_V01,ARCH_RATING_FACTOR_RQ_T_V01,ARCH_RATING_FACTOR_RQ_X_V01,AR_LKU_T_V01,AR_LKU_X_V01,AR_STAGING_T_V01,AR_STAGING_X_V01,AR_T_V01,AR_X_V01,ATLAS_LGL_HOLD_ARCHIVE_T1,BASE_FACT_FINAL_BKP_T_V01,BASE_FACT_FINAL_T_V01,BASE_FACT_FINAL_WIP_T_V01,BASE_FACT_FINAL_X_V01,BASE_FACT_PRIOR_WK2A_T_V01,BASE_FACT_WK2A_T_V01,BASE_FACT_WK_T_V01,BLACKLINE_T1,BLTK_T_V01,BLTK_X_V01,BOXI_RPT_TMP,BO_TEMP,CANADA_T_V01,CAPMAN_DATA,CARPE_T01,CCN_PREMHIST_T_V01,CCN_PREMHIST_X_V01,CC_INDEX,CC_OP,CDC_CHECK_TBL,CEDELITE_STAGING_T_V01,CIDBP_DATA01,CIDBP_INDEXES01,CIMSODS_INDEXES,CIMSODS_TABLES,CLAIMAPD_T01,CLAIMDMS_INDEX,CLAIMDMS_TABLE,CLAIMODS_INDEX,CLAIMODS_LIST_CHAINED_T_V01,CLAIMODS_TABLE,CLAIM_ADDITIONAL_T_V01,CLAIM_ADDITIONAL_WEEKLY_T_V01,CLAIM_ADDITIONAL_WEEKLY_X_V01,CLAIM_ADDITIONAL_X_V01,CLAIM_TRANS_T_V01,CLAIM_TRANS_X_V01,CLAIM_T_V04,CLAIM_WEEKLY_T_V01,CLAIM_WEEKLY_X_V01,CLAIM_X_V04,CMMRCL_PLDG_ARCHIVE01,CNA13_0692_V01,CNACMRPT_LARGE_OBJECTS,CNACOM_STAGING_T_V01,CNA_ATABLES,CNP_RE_REF_OBJECTS,COMBINED_CLAIM_ADDL_T_V01,COMBINED_CLAIM_ADDL_X_V01,COMBINED_CLAIM_T_V01,COMBINED_CLAIM_X_V01,COMBINED_PAY_HIST_T_V01,COMBINED_PAY_HIST_X_V01,COMBINED_SUFFIX_SNAPS_T_V01,COMBINED_SUFFIX_SNAPS_X_V01,COMBINED_SUFFIX_T_V01,COMBINED_SUFFIX_X_V01,COMPASS_01,COSTCON_T_V01,COVERAGE_CR_T_V01,COVERAGE_CR_X_V01,COVERAGE_RQ_T_V01,COVERAGE_RQ_X_V01,CR_RQ_T_V01,CR_RQ_X_V01,CVS_T_V01,CVS_X_V01,CVTRY_HIST_T_V01,DASH_T_V01,DATA,DBA_CMDS_INDEXES,DBA_CMDS_TABLES,DED_AMT_CR_T_V01,DED_AMT_CR_X_V01,DED_AMT_RQ_T_V01,DED_AMT_RQ_X_V01,DEVLDBA_INDEXES,DEVLDBA_TABLES,DIMENSIONS,DIMENSIONS_IX,DIRECT_TRANS_T_V06,DIRECT_TRANS_X_V06,DMSRPT_STAGE_INDEX,DMSRPT_STAGE_TABLE,DMS_INT_INDEX,DMS_INT_TABLE,DVD_TEMP,ESIGHT_ADMIN_T_V01,ESIGHT_TEMP,EUR_CLAIM_DATA_TO_US_T01,EUSRPTODS_INDEXES,EUSRPTODS_TABLES,EXPLORE,EXPLORE_WORK,FAS_CLAIMODS,FEEDS_IN_T_V01,FEEDS_OUT,FV_ARCHIVE_V01,GRIPCLOSE_T_V01,HAL_TABLES,HISTORICAL9DAY_T_V01,HISTORICAL_T_V01,IBMCDC_TABLES,INDEXES,INDEXES01,INFO,LAWYERS_INS_TEMP,LIMIT_AMOUNT_CR_T_V01,LIMIT_AMOUNT_CR_X_V01,LIMIT_AMOUNT_RQ_T_V01,LIMIT_AMOUNT_RQ_X_V01,LITE_DATA,MAIN_INDEXES,MAIN_TABLES,MAXCP_DATA01,MAXCP_INDEXES01,MEDBILL_CONDUENT_T01,MEDBILL_MITCHELL_T_01,MEDBILL_T_V01,METADATA_REP_TABLES,MISTERM_ENHANCED_20140102_T,MISTERM_ENHANCED_DAILY_T_V01,MISTERM_ENHANCED_DAILY_X_V01,MISTERM_ENHANCED_PRIOR_T_V01,MISTERM_ENHANCED_T_V01,MISTERM_ENHANCED_X_V01,MISTERM_LTD_BKP_T_V01,MISTERM_LTD_T_V01,MISTERM_LTD_WIP_T_V01,MISTERM_T_V01,MISTERM_X_V01,MIS_DM_RPT_ARCHIVE_T_V01,MIS_DM_RPT_ARCHIVE_X_V01,MIS_DM_RPT_TEMP,MIS_DM_RPT_T_V01,MIS_DM_RPT_X_V01,MIS_DM_RPT_YE_T_V01,MIS_EARN_OUT_EXP_T_V01,MIS_EARN_OUT_EXP_X_V01,MIS_EARN_OUT_LTD_T_V01,MIS_EARN_OUT_LTD_X_V01,MIS_EARN_OUT_RECAST_T_V01,MIS_EARN_OUT_RECAST_X_V01,MIS_EARN_OUT_T_V04,MIS_EARN_OUT_X_V04,MIS_LIST_CHAINED_T_V01,MIS_RPT_DEV_TEMP,MIS_RPT_DEV_V01,MIS_WORK,MR_LANDING_INDEXES,MR_LANDING_LOB,MR_LANDING_TABLES,MR_PRELOAD_INDEXES,MR_PRELOAD_LOB,MR_PRELOAD_TABLES,ODSHIST_INDEX,ODSHIST_TABLE,ODSRPT_INDEX,ODSRPT_TABLE,ODS_CONTROL_INDEXES,ODS_CONTROL_TABLES,ODS_INT_INDEX,ODS_INT_TABLE,PAFTRANS,PAFTRANS_IX,PAFTRANS_SUMMARY_T_V01,PAFTRANS_SUMMARY_X_V01,PAFTRAN_GL_ACCT_2009_T_V01,PAFTRAN_GL_ACCT_2010_T_V01,PAFTRAN_GL_ACCT_2011_T_V01,PAFTRAN_GL_ACCT_2012_T_V01,PAFTRAN_GL_ACCT_2013_T_V01,PAFTRAN_GL_ACCT_2014_T_V01,PAFTRAN_GL_ACCT_2015_T_V01,PAFTRAN_GL_ACCT_2016_T_V01,PAFTRAN_GL_ACCT_2017_T_V01,PAFTRAN_GL_ACCT_2018_T_V01,PAFTRAN_GL_ACCT_2019_T_V01,PAFTRAN_GL_ACCT_PRE2009_T_V01,PASEINPODS_INDEXES,PASEINPODS_TABLES,PASEREFODS_INDEXES,PASEREFODS_LARGEOBJ,PASEREFODS_TABLES,PAY_HIST_T_V02,PAY_HIST_X_V02,PCA_CLAIM_T_V01,PCA_CLAIM_X_V01,PERFBP_DATA01,PERFBP_INDEXES01,PL_CALENDAR_YR_DATA_T_V01,PL_CALENDAR_YR_DATA_X_V01,PL_IBNR_FACTORS_PRIOR_T_V01,PL_IBNR_FACTORS_PRIOR_X_V01,PL_SUM_PRIOR_WIP_T_V01,PL_SUM_PRIOR_WIP_X_V01,PRELOAD,PRODUCTS_BKP_T_V01,PRODUCTS_CLMCLS_T_V01,PRODUCTS_CLMCLS_X_V01,PRODUCTS_QTR_T_V01,PRODUCTS_QTR_WIP_T_V01,PRODUCTS_T_V01,PRODUCTS_WIP_T_V01,PRODUCTS_WIP_X_V01,PRODUCTS_X_V01,PROFIT_LOSS_GROSS_PRV_T_V01,PROFIT_LOSS_GROSS_PRV_X_V01,PROFIT_LOSS_SUMMARY_BKP_T_V01,PROFIT_LOSS_SUMMARY_T_V01,PROFIT_LOSS_SUMMARY_WIP_T_V01,PROFIT_LOSS_SUMMARY_WIP_X_V01,PROFIT_LOSS_SUMMARY_X_V01,PROFIT_LOSS_SUMM_PRIOR_T_V01,PROFIT_LOSS_SUMM_PRIOR_X_V01,PRO_HIST_T_V01,PS_Z_ERNOUT_EXP_T_V01,RATER_EXP_INDEXES,RATER_EXP_TABLES,RATE_FACT_BKP_T_V01,RATE_FACT_T_V01,RATE_FACT_WIP_T_V01,RATE_FACT_WIP_X_V01,RATE_FACT_X_V01,RATG_FTR_ADD_CR_T_V01,RATG_FTR_ADD_CR_X_V01,RATG_FTR_ADD_RQ_T_V01,RATG_FTR_ADD_RQ_X_V01,RATING_FACTOR_CR_T_V02,RATING_FACTOR_CR_X_V02,RATING_FACTOR_RQ_T_V02,RATING_FACTOR_RQ_X_V02,RCA_ODS_INDEXES,RCA_ODS_TABLES,RCTODS_INDEXES,RCTODS_LARGE_OBJ,RCTODS_TABLES,REINS_DIRECT_SNAPS_T_V02,REINS_DIRECT_SNAPS_X_V02,REINS_DIRECT_TRANS_T_V02,REINS_DIRECT_TRANS_X_V02,REINS_SPECIAL_TRANS_T_V02,REINS_SPECIAL_TRANS_X_V02,RETENTION_FACT_BKP_T_V01,RETENTION_FACT_T_V01,RETENTION_FACT_WIP_T_V01,RETENTION_FACT_WIP_X_V01,RETENTION_FACT_X_V01,RSTSTAGE_INDEXES,RSTSTAGE_LARGE_OBJ,RSTSTAGE_TABLES,RST_PPO_T_V01,SENUS_01,SHIFT_01,SOSARCH_INDEXES,SOSARCH_TABLES,SOS_INDEXES,SOS_TABLES,SSO_RATERS_STAGE_INDEXES,SSO_RATERS_STAGE_TABLES,STAGE_INDEXES,STAGE_TABLES,STAGING,STF_HOLD,SUFFIX_ADDITIONAL_WEEKLY_T_V01,SUFFIX_ADDITIONAL_WEEKLY_X_V01,SUFFIX_SNAPS_T_V07,SUFFIX_SNAPS_WEEKLY_T_V04,SUFFIX_SNAPS_WEEKLY_X_V04,SUFFIX_SNAPS_X_V07,SUFFIX_T_V08,SUFFIX_WEEKLY_T_V05,SUFFIX_WEEKLY_X_V05,SUFFIX_X_V08,SURCDC_STAGE_I_V01,SURCDC_STAGE_T_V01,SURETY_ARCHIVE_T_V01,SURETY_ARCHIVE_X_V01,SURETY_STAGING_T_V01,SURETY_STAGING_X_V01,SUR_BOND_TERM_CVRG_T_V01,SUR_BOND_TERM_CVRG_X_V01,SUR_BOND_T_V01,SUR_BOND_X_V01,SUR_MISTERM_PRIOR_T_V01,SUR_MISTERM_T_V01,SUR_MISTERM_X_V01,SYMANTEC_I3_ORCL,SYMANTEC_I3_ORCL_TMP,TABLES01,TAP_INDEXES,TAP_TABLES,TEAMTHINK_T01,TEMP,TERADATA_T_V02,TFN_ARCHIVE_V01,THIRTYTWOK,TOOLS,TRECS_ARCHIVE_01,ULSODS_INDEXES,ULSODS_TABLES,UPS_INDEXES,UPS_TABLES,USER_TEMP,UWSODS_INDEXES,UWSODS_TABLES,VIATICUS_T_V01,VIATICUS_X_V01,WCEDI,WCEDIDMS,WCFC01,WCFC_CLAIM_DETAIL_T_V01,WCFC_CLAIM_DETAIL_X_V01,WCFC_LOSS_DETAIL_T_V01,WCFC_LOSS_DETAIL_X_V01,WCFC_QTR_CLAIM_DETAIL_T_V01,WCFC_QTR_CLAIM_DETAIL_X_V01,WCODS_INDEXES,WCODS_STG_INDEXES,WCODS_STG_TABLES,WCODS_TABLES,WCPAYGO_INDEXES,WCPAYGO_TABLES;
release channel ch04;
release channel ch05;
release channel ch06;
release channel ch07;
release channel ch08;
release channel ch09;
release channel ch10;
release channel ch11;
release channel ch12;
release channel ch13;
release channel ch14;
release channel ch15;
release channel ch16;
release channel ch17;
release channel ch18;
release channel ch19;
release channel ch20;
release channel ch21;
release channel ch22;
release channel ch23;
release channel ch24;
}

------------------------------------------

# SCN
RECOVER TABLE TEST.T1
  UNTIL SCN 1853267
  AUXILIARY DESTINATION '/u01/aux'  
  REMAP TABLE 'TEST'.'T1':'T1_PREV';

# TIME
RECOVER TABLE TEST.T1
  UNTIL TIME "TO_DATE('01-JAN-2013 15:00', 'DD-MON-YYYY HH24:MI')"
  AUXILIARY DESTINATION '/u01/aux'  
  REMAP TABLE 'TEST'.'T1':'T1_PREV'; 

<end node> 5P9i0s8y19Z
dt=Text
<node>
restore rman 01
2
MERWHTBL.__data_transfer_cache_size=0
MERWHTBL.__db_cache_size=6442450944
MERWHTBL.__java_pool_size=234881024
MERWHTBL.__large_pool_size=134217728
MERWHTBL.__oracle_base='/u01/app/oracle'#ORACLE_BASE set from environment
MERWHTBL.__pga_aggregate_target=64424509440
MERWHTBL.__sga_target=17179869184
MERWHTBL.__shared_io_pool_size=0
MERWHTBL.__shared_pool_size=8589934592
MERWHTBL.__streams_pool_size=1073741824
*._client_enable_auto_unregister=TRUE
*._clusterwide_global_transactions=FALSE
*._enable_numa_support=FALSE
*._file_size_increase_increment=2143289344
*._optimizer_dsdir_usage_control=0
*._smm_auto_max_io_size=1024
*._smu_debug_mode=134217728
*._sql_plan_directive_mgmt_control=0
*.archive_lag_target=1800
*.audit_sys_operations=TRUE
*.audit_trail='db'
*.cluster_database=FALSE
*.compatible='12.1.0.2.0'
*.control_files='/u01/oracle/zfs-dr/datapump/merwhtbl/MERWHTBL/controlfile/MERWHTBL.ctl','+DATA_ETE/MERWHTBL/MERWHTBL.ctl'
*.cpu_count=36
*.db_32k_cache_size=500m
*.db_block_checking='low'
*.db_block_checksum='typical'
*.db_block_size=8192
*.db_create_file_dest='+DATA_ETE'
*.db_create_online_log_dest_1='+DATA_ETE'
*.db_create_online_log_dest_2='+RECO_ETE'
*.db_domain=''
*.db_files=1024
*.db_lost_write_protect='typical'
*.db_name='MERWHP'
*.db_recovery_file_dest='+RECO_ETE'
*.db_recovery_file_dest_size=21407727616000#90% of Total Space in FRA Disk Group
*.db_unique_name='MERWHTBL'
*.dg_broker_config_file1='+DATA_ETE/MERWHTBL/dr1MERWHP_TEMP.dat'
*.dg_broker_config_file2='+DATA_ETE/MERWHTBL/dr2MERWHP_TEMP.dat'
*.dg_broker_start=TRUE
*.diagnostic_dest='/u01/oracle'
*.fal_client='MERWHTBL'
*.fal_server='merwhp'
*.fast_start_mttr_target=300
*.filesystemio_options='setall'
*.global_names=FALSE
*.job_queue_processes=0
*.log_archive_config='dg_config=(MERWHTBL,MERWHP)'
*.log_archive_dest_1='location=USE_DB_RECOVERY_FILE_DEST valid_for=(ALL_LOGFILES,ALL_ROLES) db_unique_name=MERWHTBL'
*.log_archive_dest_2='location="+RECO_ETE",  valid_for=(STANDBY_LOGFILE,STANDBY_ROLE)'
*.log_archive_dest_3=''
*.log_archive_dest_state_2='ENABLE'
*.log_archive_dest_state_3='ENABLE'
*.log_archive_max_processes=4
*.log_archive_min_succeed_dest=1
*.log_buffer=134217728
*.open_cursors=1000
*.os_authent_prefix=''
*.parallel_adaptive_multi_user=FALSE
*.parallel_degree_limit='16'
*.parallel_degree_policy='MANUAL'
*.parallel_execution_message_size=16384
*.parallel_force_local=TRUE
*.parallel_max_servers=36
*.parallel_min_servers=36
*.parallel_servers_target=128
*.parallel_threads_per_cpu=1
*.pga_aggregate_target=61440m
*.processes=2048
*.recyclebin='on'
*.remote_login_passwordfile='exclusive'
*.sga_max_size=17179869184
*.sga_target=17179869184
*.shared_pool_size=8589934592
*.sql92_security=TRUE
*.standby_file_management='AUTO'
*.streams_pool_size=1073741824
*.undo_retention=36000
*.undo_tablespace='UNDOTBS1'
*.use_large_pages='ONLY'

. oraenv
MERWHTBL


export ORACLE_HOME=/u01/app/oracle/product/12.1.0.2/dbhome_1/


sqlplus "/as sysdba"

sql>startup nomount pfile='/u01/app/oracle/product/12.1.0.2/dbhome_1/dbs/initMERWHTBL.ora'
SQL> exit


rman target /

restore controlfile from '/u01/oracle/zfs-dr/datapump/11Jun2019/backup01/control_MERWHP.bkp';


RMAN> alter database mount clone database;

-- disk backup location where the backup has been copied
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup01';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup03';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup05';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup07';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup09';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup11';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup13';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup15';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup17';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup19';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup21';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup23';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup02';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup04';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup06';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup08';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup10';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup12';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup14';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup16';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup18';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup20';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup22';
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup24';


-- if you want to include the subfolders also then just do
RMAN> catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019'

RMAN>crosscheck backup;

-- save the below script into cmd file
vi rman_script.cmd

run
{
allocate channel ch04 device type disk;
allocate channel ch05 device type disk;
allocate channel ch06 device type disk;
allocate channel ch07 device type disk;
allocate channel ch08 device type disk;
allocate channel ch09 device type disk;
allocate channel ch10 device type disk;
allocate channel ch11 device type disk;
allocate channel ch12 device type disk;
allocate channel ch13 device type disk;
allocate channel ch14 device type disk;
allocate channel ch15 device type disk;
allocate channel ch16 device type disk;
allocate channel ch17 device type disk;
allocate channel ch18 device type disk;
allocate channel ch19 device type disk;
allocate channel ch20 device type disk;
allocate channel ch21 device type disk;
allocate channel ch22 device type disk;
allocate channel ch23 device type disk;
allocate channel ch24 device type disk;
set until time "to_date('12-06-2019 04:21:47','DD-MM-RRRR HH24:MI:SS')";
set newname for datafile  1 to '+DATA_ETE/MERWHTBL/DATAFILE/system.1328.895434719';
set newname for datafile  2 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.342.895434721';
set newname for datafile  3 to '+DATA_ETE/MERWHTBL/DATAFILE/undotbs1.343.895434721';
set newname for datafile  4 to '+DATA_ETE/MERWHTBL/DATAFILE/undotbs2.345.895434725';
set newname for datafile  53 to '+DATA_ETE/MERWHTBL/DATAFILE/claim_additional_t_v01.1604.895607465';
set newname for datafile  56 to '+DATA_ETE/MERWHTBL/DATAFILE/claim_additional_x_v01.668.895607467';
set newname for datafile  59 to '+DATA_ETE/MERWHTBL/DATAFILE/claim_t_v04.665.895607469';
set newname for datafile  62 to '+DATA_ETE/MERWHTBL/DATAFILE/claim_x_v04.662.895607471';
set newname for datafile  112 to '+DATA_ETE/MERWHTBL/DATAFILE/indexes01.820.895607543';
set newname for datafile  210 to '+DATA_ETE/MERWHTBL/DATAFILE/reins_direct_snaps_t_v02.722.895607743';
set newname for datafile  211 to '+DATA_ETE/MERWHTBL/DATAFILE/reins_direct_snaps_x_v02.721.895607743';
set newname for datafile  225 to '+DATA_ETE/MERWHTBL/DATAFILE/suffix_snaps_t_v07.707.895607757';
set newname for datafile  228 to '+DATA_ETE/MERWHTBL/DATAFILE/suffix_snaps_x_v07.704.895607765';
set newname for datafile  229 to '+DATA_ETE/MERWHTBL/DATAFILE/suffix_t_v08.703.895607767';
set newname for datafile  232 to '+DATA_ETE/MERWHTBL/DATAFILE/suffix_x_v08.700.895607773';
set newname for datafile  245 to '+DATA_ETE/MERWHTBL/DATAFILE/tables01.902.895607785';
set newname for datafile  285 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1531.909483313';
set newname for datafile  293 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1682.912995023';
set newname for datafile  350 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1534.942007219';
set newname for datafile  358 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1667.953335663';
set newname for datafile  359 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1666.953523335';
set newname for datafile  360 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1665.953528269';
set newname for datafile  361 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1664.953953107';
set newname for datafile  362 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1663.954236825';
set newname for datafile  363 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1662.954295177';
set newname for datafile  364 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1661.954653853';
set newname for datafile  365 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1660.954655513';
set newname for datafile  366 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1659.955172743';
set newname for datafile  367 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1658.955172809';
set newname for datafile  368 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1657.955252471';
set newname for datafile  369 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1656.955252501';
set newname for datafile  370 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1655.955252503';
set newname for datafile  371 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1654.955252505';
set newname for datafile  372 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1653.955936027';
set newname for datafile  373 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1652.956063873';
set newname for datafile  374 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1651.956426347';
set newname for datafile  375 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1650.956550691';
set newname for datafile  376 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1296.960338187';
set newname for datafile  377 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.589.960341983';
set newname for datafile  378 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1291.960638581';
set newname for datafile  380 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1294.960779569';
set newname for datafile  381 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1293.960790973';
set newname for datafile  382 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1292.960790975';
set newname for datafile  383 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.590.960790977';
set newname for datafile  384 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.591.960859723';
set newname for datafile  385 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.592.961207031';
set newname for datafile  386 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.599.961223753';
set newname for datafile  387 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.600.961554689';
set newname for datafile  388 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1527.961944649';
set newname for datafile  389 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1526.961944651';
set newname for datafile  390 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1525.962584267';
set newname for datafile  391 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1524.962598021';
set newname for datafile  392 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1523.962925421';
set newname for datafile  393 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1522.963294383';
set newname for datafile  394 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1521.963332665';
set newname for datafile  395 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1520.963332667';
set newname for datafile  396 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1519.963790717';
set newname for datafile  397 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1302.963790723';
set newname for datafile  398 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1301.963889733';
set newname for datafile  399 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1300.963962697';
set newname for datafile  400 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1299.964412509';
set newname for datafile  401 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1289.964671435';
set newname for datafile  402 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1297.965055257';
set newname for datafile  403 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1290.965055261';
set newname for datafile  404 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1287.965055263';
set newname for datafile  405 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1298.965055263';
set newname for datafile  406 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1288.966028723';
set newname for datafile  407 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1649.966028725';
set newname for datafile  408 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1648.966028727';
set newname for datafile  409 to '+DATA_ETE/MERWHTBL/DATAFILE/sysaux.1647.966844229';
restore tablespace SYSAUX,SYSTEM,UNDOTBS1,UNDOTBS2,CLAIM_T_V04,CLAIM_ADDITIONAL_T_V01,REINS_DIRECT_SNAPS_T_V02,TABLES01,SUFFIX_T_V08,SUFFIX_SNAPS_T_V07,CLAIM_X_V04,CLAIM_ADDITIONAL_X_V01,REINS_DIRECT_SNAPS_X_V02,INDEXES01,SUFFIX_X_V08,SUFFIX_SNAPS_X_V07;
switch datafile all;
sql "alter database datafile 1,2,3,4,53,56,59,62,112,210,211,225,228,229,232,245,285,293,350,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409 online";
recover database skip forever tablespace TEMP,USERS,AB_ADMIN,AB_INDEX,AB_OP,ACA,ACA_HSTRY_T_V01,ACTDMS,ACTFINODS,AC_STAGING_T_V01,AGGREGATE,AGGREGATE_IX,AIM_DATA,AIPS_MISTERM_AUGUST_T_V01,AIPS_MISTERM_AUGUST_X_V01,APER_BO_LOSS_RATIO_BKP_T_V01,APER_BO_LOSS_RATIO_T_V01,APER_BO_LOSS_RATIO_WIP_T_V01,
APER_BO_LOSS_RATIO_WIP_X_V01,APER_BO_LOSS_RATIO_X_V01,APER_BO_PREM_DETAIL_BKP_T_V01,APER_BO_PREM_DETAIL_T_V01,APER_BO_PREM_DETAIL_WIP_T_V01,APER_BO_PREM_DETAIL_WIP_X_V01,APER_BO_PREM_DETAIL_X_V01,APER_EP_QTR_SS_T_V01,APER_EP_QTR_SS_X_V01,ARCHIVE_T_V01,ARCH_RATING_FACTOR_CR_T_V01,ARCH_RATING_FACTOR_CR_X_V01,
ARCH_RATING_FACTOR_RQ_T_V01,ARCH_RATING_FACTOR_RQ_X_V01,BASE_FACT_FINAL_BKP_T_V01,BASE_FACT_FINAL_T_V01,BASE_FACT_FINAL_WIP_T_V01,BASE_FACT_FINAL_X_V01,BASE_FACT_PRIOR_WK2A_T_V01,BASE_FACT_WK2A_T_V01,BASE_FACT_WK_T_V01,CANADA_T_V01,CC_INDEX,CC_OP,CLAIMDMS_INDEX,CLAIMDMS_TABLE,CLAIMODS2_INDEX,CLAIMODS2_TABLE,
CLAIMODS_INDEX,CLAIMODS_LIST_CHAINED_T_V01,CLAIMODS_TABLE,CLAIM_ADDITIONAL_WEEKLY_T_V01,CLAIM_ADDITIONAL_WEEKLY_X_V01,CLAIM_TRANS_T_V01,CLAIM_TRANS_X_V01,CLAIM_WEEKLY_T_V01,CLAIM_WEEKLY_X_V01,CNACOM_STAGING_T_V01,CNA_ATABLES,COMBINED_CLAIM_ADDL_T_V01,COMBINED_CLAIM_ADDL_X_V01,COMBINED_CLAIM_T_V01,COMBINED_CLAIM_X_V01,
COMBINED_PAY_HIST_T_V01,COMBINED_PAY_HIST_X_V01,COMBINED_SUFFIX_SNAPS_T_V01,COMBINED_SUFFIX_SNAPS_X_V01,COMBINED_SUFFIX_T_V01,COMBINED_SUFFIX_X_V01,COSTCON_T_V01,COVERAGE_CR_T_V01,COVERAGE_CR_X_V01,COVERAGE_RQ_T_V01,COVERAGE_RQ_X_V01,CR_RQ_T_V01,CR_RQ_X_V01,CVS_T_V01,CVS_X_V01,DASH_T_V01,DBA_CMDS_INDEXES,DBA_CMDS_TABLES,
DED_AMT_CR_T_V01,DED_AMT_CR_X_V01,DED_AMT_RQ_T_V01,DED_AMT_RQ_X_V01,DIMENSIONS,DIMENSIONS_IX,DIRECT_TRANS_T_V06,DIRECT_TRANS_X_V06,DMSRPT_STAGE_INDEX,DMSRPT_STAGE_TABLE,DMS_INT_INDEX,DMS_INT_TABLE,ESIGHT_ADMIN_T_V01,EXPLORE,EXPLORE_WORK,FEEDS_IN_T_V01,FEEDS_OUT,HAL_TABLES,HISTORICAL9DAY_T_V01,HISTORICAL_T_V01,IBMCDC_TABLES,INFO,
LIMIT_AMOUNT_CR_T_V01,LIMIT_AMOUNT_CR_X_V01,LIMIT_AMOUNT_RQ_T_V01,LIMIT_AMOUNT_RQ_X_V01,MEDBILL_T_V01,MISTERM_ENHANCED_DAILY_T_V01,MISTERM_ENHANCED_DAILY_X_V01,MISTERM_ENHANCED_PRIOR_T_V01,MISTERM_ENHANCED_T_V01,MISTERM_ENHANCED_X_V01,MISTERM_LTD_BKP_T_V01,MISTERM_LTD_T_V01,MISTERM_LTD_WIP_T_V01,MISTERM_T_V01,MISTERM_X_V01,
MIS_DM_RPT_ARCHIVE_T_V01,MIS_DM_RPT_ARCHIVE_X_V01,MIS_DM_RPT_T_V01,MIS_DM_RPT_X_V01,MIS_EARN_OUT_EXP_T_V01,MIS_EARN_OUT_EXP_X_V01,MIS_EARN_OUT_LTD_T_V01,MIS_EARN_OUT_LTD_X_V01,MIS_EARN_OUT_RECAST_T_V01,MIS_EARN_OUT_RECAST_X_V01,MIS_EARN_OUT_T_V04,MIS_EARN_OUT_X_V04,MIS_LIST_CHAINED_T_V01,MIS_RPT_DEV_V01,MIS_WORK,ODSHIST_INDEX,
ODSHIST_TABLE,ODSRPT_INDEX,ODSRPT_TABLE,ODS_INT_INDEX,ODS_INT_TABLE,PAFTRANS,PAFTRANS_IX,PAFTRANS_SUMMARY_T_V01,PAFTRANS_SUMMARY_X_V01,PAFTRAN_GL_ACCT_2009_T_V01,PAFTRAN_GL_ACCT_2010_T_V01,PAFTRAN_GL_ACCT_2011_T_V01,PAFTRAN_GL_ACCT_2012_T_V01,PAFTRAN_GL_ACCT_2013_T_V01,PAFTRAN_GL_ACCT_2014_T_V01,PAFTRAN_GL_ACCT_2015_T_V01,
PAFTRAN_GL_ACCT_PRE2009_T_V01,PAY_HIST_T_V02,PAY_HIST_X_V02,PCA_CLAIM_T_V01,PCA_CLAIM_X_V01,PL_CALENDAR_YR_DATA_T_V01,PL_CALENDAR_YR_DATA_X_V01,PL_IBNR_FACTORS_PRIOR_T_V01,PL_IBNR_FACTORS_PRIOR_X_V01,PL_SUM_PRIOR_WIP_T_V01,PL_SUM_PRIOR_WIP_X_V01,PRELOAD,PRODUCTS_BKP_T_V01,PRODUCTS_CLMCLS_T_V01,PRODUCTS_CLMCLS_X_V01,PRODUCTS_QTR_T_V01,
PRODUCTS_QTR_WIP_T_V01,PRODUCTS_T_V01,PRODUCTS_WIP_T_V01,PRODUCTS_WIP_X_V01,PRODUCTS_X_V01,PROFIT_LOSS_GROSS_PRV_T_V01,PROFIT_LOSS_GROSS_PRV_X_V01,PROFIT_LOSS_SUMMARY_BKP_T_V01,PROFIT_LOSS_SUMMARY_T_V01,PROFIT_LOSS_SUMMARY_WIP_T_V01,PROFIT_LOSS_SUMMARY_WIP_X_V01,PROFIT_LOSS_SUMMARY_X_V01,PROFIT_LOSS_SUMM_PRIOR_T_V01,PROFIT_LOSS_SUMM_PRIOR_X_V01,
PRO_HIST_T_V01,PS_Z_ERNOUT_EXP_T_V01,RATE_FACT_BKP_T_V01,RATE_FACT_T_V01,RATE_FACT_WIP_T_V01,RATE_FACT_WIP_X_V01,RATE_FACT_X_V01,RATG_FTR_ADD_CR_T_V01,RATG_FTR_ADD_CR_X_V01,RATG_FTR_ADD_RQ_T_V01,RATG_FTR_ADD_RQ_X_V01,RATING_FACTOR_CR_T_V02,RATING_FACTOR_CR_X_V02,RATING_FACTOR_RQ_T_V02,RATING_FACTOR_RQ_X_V02,REINS_DIRECT_TRANS_T_V02,REINS_DIRECT_TRANS_X_V02,
REINS_SPECIAL_TRANS_T_V02,REINS_SPECIAL_TRANS_X_V02,REPLATFORM_BACKUP_T_V01,RETENTION_FACT_BKP_T_V01,RETENTION_FACT_T_V01,RETENTION_FACT_WIP_T_V01,RETENTION_FACT_WIP_X_V01,RETENTION_FACT_X_V01,RST_PPO_T_V01,STAGING,SUFFIX_ADDITIONAL_WEEKLY_T_V01,SUFFIX_ADDITIONAL_WEEKLY_X_V01,SUFFIX_SNAPS_REBUILD_T_V01,SUFFIX_SNAPS_WEEKLY_T_V04,SUFFIX_SNAPS_WEEKLY_X_V04,
SUFFIX_WEEKLY_T_V05,SUFFIX_WEEKLY_X_V05,SURETY_ARCHIVE_T_V01,SURETY_ARCHIVE_X_V01,SURETY_STAGING_T_V01,SURETY_STAGING_X_V01,SUR_BOND_TERM_CVRG_T_V01,SUR_BOND_TERM_CVRG_X_V01,SUR_BOND_T_V01,SUR_BOND_X_V01,SUR_MISTERM_PRIOR_T_V01,SUR_MISTERM_T_V01,SUR_MISTERM_X_V01,SYMANTEC_I3_ORCL,TOOLS,VIATICUS_T_V01,VIATICUS_X_V01,WCEDI,WCEDIDMS,WCFC01,WCFC_CLAIM_DETAIL_T_V01,
WCFC_CLAIM_DETAIL_X_V01,WCFC_LOSS_DETAIL_T_V01,WCFC_LOSS_DETAIL_X_V01,WCFC_QTR_CLAIM_DETAIL_T_V01,WCFC_QTR_CLAIM_DETAIL_X_V01,BOXI_RPT_TMP,BO_TEMP,ESIGHT_TEMP,LAWYERS_INS_TEMP,MIS_DM_RPT_TEMP,
MIS_RPT_DEV_TEMP,SYMANTEC_I3_ORCL_TMP,USER_TEMP,THIRTYTWOK,MEDBILL_MITCHELL_T_01,CEDELITE_STAGING_T_V01,CAPMAN_DATA,MISTERM_ENHANCED_20140102_T,CNA13_0692_V01,PAFTRAN_GL_ACCT_2016_T_V01,CCN_PREMHIST_T_V01,CCN_PREMHIST_X_V01,DATA,INDEXES,MR_LANDING_TABLES,MR_LANDING_LOB,MR_LANDING_INDEXES,MR_PRELOAD_TABLES,MR_PRELOAD_LOB,
MR_PRELOAD_INDEXES,STF_LARGE_OBJECTS,AISS_INDEXES,AISS_TABLES,AD1099_TAXPRO_T_V01,CLAIMAPD_T01,ARCHIVE_LOB,ARCHIVE_INDEX,ARCHIVE_TABLES,AD1099_TAXPRO_X_V01,AR_LKU_T_V01,AR_LKU_X_V01,AR_STAGING_T_V01,AR_STAGING_X_V01,AR_T_V01,AR_X_V01,BLTK_T_V01,BLTK_X_V01,CIMSODS_INDEXES,CIMSODS_TABLES,CIRSODS_INDEXES,CIRSODS_TABLES,EUSRPTODS_INDEXES,EUSRPTODS_TABLES,
MAIN_INDEXES,MVRODS_INDEXES,MVRODS_TABLES,ODS_CONTROL_INDEXES,ODS_CONTROL_TABLES,PASEINPODS_INDEXES,PASEINPODS_TABLES,PASEREFODS_INDEXES,PASEREFODS_LARGEOBJ,PASEREFODS_TABLES,
RATER_EXP_INDEXES,RATER_EXP_TABLES,RCTODS_INDEXES,UWSODS_INDEXES,RCTODS_LARGE_OBJ,RCTODS_TABLES,RSTSTAGE_INDEXES,RSTSTAGE_LARGE_OBJ,RSTSTAGE_TABLES,SSO_RATERS_STAGE_INDEXES,SSO_RATERS_STAGE_TABLES,STAGE_INDEXES,STAGE_TABLES,SURCDC_STAGE_T_V01,TABLES,TAP_INDEXES,TAP_TABLES,ULSODS_INDEXES,ULSODS_TABLES,UWSODS_TABLES,WCODS_INDEXES,WCODS_STG_INDEXES,WCODS_STG_TABLES,
WCODS_TABLES,WCPAYGO_INDEXES,WCPAYGO_TABLES,CNP_RE_REF_LARGE_OBJECTS,SURCDC_STAGE_ADMIN,SURCDC_STAGE_INDEX,SURCDC_STAGE_LOB,SURCDC_STAGE_OP,SURCDC_STAGE_STAGING,SURCDC_STAGE_TYPELIST,SURCDC_STAGE_I_V01,PAFTRAN_GL_ACCT_2017_T_V01,DVD_TEMP,CNACMRPT_LARGE_OBJECTS,AISS_LARGE_OBJ,DEVLDBA_INDEXES,DEVLDBA_TABLES,UPS_TABLES,UPS_INDEXES,AISSMRPT_LARGE_OBJECTS,
AISSMRPT_ARCHIVE_TABLES,AISSMRPT_ARCHIVE_INDEXES,PAFTRAN_GL_ACCT_2018_T_V01,ATLAS_LGL_HOLD_ARCHIVE_T1,EUR_CLAIM_DATA_TO_US_T01,
TEAMTHINK_T01,BLACKLINE_T1,CNP_RE_REF_OBJECTS,PAFTRAN_GL_ACCT_2019_T_V01,MEDBILL_CONDUENT_T01,COMPASS_01;
}


-- run the script (& is for background job)
rman target / cmdfile=rman_script.cmd |tee log=/u01/oracle/diag/rdbms/merwhtbl/log/merwhtbl_7tbls_restore_11jun2019.log &


-- once the recovery is completed while restoring it might be asking for more archive pieces

-- you have to do catalog start with or catalog backuppiece
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup01';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup03';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup05';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup07';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup09';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup11';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup13';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup15';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup17';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup19';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup21';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup23';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup02';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup04';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup06';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup08';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup10';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup12';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup14';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup16';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup18';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup20';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup22';
catalog start with '/u01/oracle/zfs-dr/datapump/11Jun2019/backup24';


or

catalog backuppiece '/u01/oracle/zfs-dr/datapump/11Jun2019/level01/backup23/bkp_MERWHP_20190614_esu43ega_1_1'
catalog backuppiece '/u01/oracle/zfs-dr/datapump/11Jun2019/level01/backup23/bkp_MERWHP_20190614_b1u43ca6_1_1'
catalog backuppiece '/u01/oracle/zfs-dr/datapump/11Jun2019/level01/backup23/bkp_MERWHP_20190614_dou43drk_1_1'
catalog backuppiece '/u01/oracle/zfs-dr/datapump/11Jun2019/level01/backup23/bkp_MERWHP_20190614_equ43efg_1_1'
catalog backuppiece '/u01/oracle/zfs-dr/datapump/11Jun2019/level01/backup23/bkp_MERWHP_20190614_ivu43gs8_1_1'
catalog backuppiece '/u01/oracle/zfs-dr/datapump/11Jun2019/level01/backup23/bkp_MERWHP_20190614_6qu43a1e_1_1'
catalog backuppiece '/u01/oracle/zfs-dr/datapump/11Jun2019/level01/backup23/bkp_MERWHP_20190614_fsu43f29_1_1'
catalog backuppiece '/u01/oracle/zfs-dr/datapump/11Jun2019/level01/backup23/bkp_MERWHP_20190614_gru43fke_1_1'


-- for checking the sequence and timestamp
select thread#, sequence#, next_change#, to_char(next_time,'dd-mon-yyyy hh24:mi:ss') 
from gv$archived_log 
where sequence# between 154040 and 154049


select thread#, sequence#, next_change#, to_char(next_time,'dd-mon-yyyy hh24:mi:ss') 
from gv$archived_log 
where sequence# between 154040 and 154049
order by to_char(next_time,'dd-mon-yyyy hh24:mi:ss')  desc

-- while doing the open restelogs it will ask for the media recovery so give the missing 
-- archivelog file name with full path including file 
SQL> recover database using backup controlfile until cancel;
ORA-00279: change 8053603224669 generated at 06/12/2019 04:19:57 needed for
thread 2
ORA-00289: suggestion : +RECO_ETE
ORA-00280: change 8053603224669 for thread 2 is in sequence #154041


Specify log: {<RET>=suggested | filename | AUTO | CANCEL}
/u01/oracle/zfs-dr/datapump/11Jun2019/archive/thread_2_seq_154041.9814.1012670813
ORA-00279: change 8053603224669 generated at 06/12/2019 04:19:55 needed for
thread 1
ORA-00289: suggestion : +RECO_ETE
ORA-00280: change 8053603224669 for thread 1 is in sequence #146113


Specify log: {<RET>=suggested | filename | AUTO | CANCEL}
/u01/oracle/zfs-dr/datapump/11Jun2019/archive/thread_1_seq_146113.10978.1012670929
ORA-00279: change 8053603508133 generated at 06/12/2019 04:25:10 needed for
thread 1
ORA-00289: suggestion : +RECO_ETE
ORA-00280: change 8053603508133 for thread 1 is in sequence #146114
ORA-00278: log file
'/u01/oracle/zfs-dr/datapump/11Jun2019/archive/thread_1_seq_146113.10978.1012670
929' no longer needed for this recovery


Specify log: {<RET>=suggested | filename | AUTO | CANCEL}
cancel
Media recovery cancelled.
SQL> alter database open resetlogs;
alter database open resetlogs
*
ERROR at line 1:
ORA-00395: online logs for the clone database must be renamed
ORA-00312: online log 1 thread 1:
'+DATA_WH/MERWHP/ONLINELOG/group_1.273.910023613'


SQL> select member from gv$logfile;


-- you might be asked to rename the redolog file location

alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_9.7074.910024221' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_9.843.910024219' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_9.7074.910024221' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_10.842.910024255' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_10.7073.910024259' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_10.842.910024255' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_10.7073.910024259' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_11.841.910024273' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_11.7068.910024277' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_11.841.910024273' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_11.7068.910024277' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_12.840.910024293' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_12.7067.910024297' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_12.840.910024293' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_12.7067.910024297' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_13.839.910024311' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_13.7062.910024315' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_13.839.910024311' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_13.7062.910024315' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_14.838.910024329' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_14.7061.910024333' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_14.838.910024329' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_14.7061.910024333' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_15.837.910024353' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_15.7056.910024357' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_15.837.910024353' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_15.7056.910024357' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_16.836.910024371' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_16.7055.910024377' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_16.836.910024371' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_16.7055.910024377' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_17.835.910024391' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_17.7050.910024395' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_17.835.910024391' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_17.7050.910024395' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_18.834.910024411' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_18.7049.910024415' to '+RECO_ETE';
alter database rename file '+DATA_WH/MERWHP/ONLINELOG/group_18.834.910024411' to '+RECO_ETE';
alter database rename file '+RECO_WH/MERWHP/ONLINELOG/group_18.7049.910024415' to '+RECO_ETE';


alter database open resetlogs;

<end node> 5P9i0s8y19Z
dt=Text
<node>
merwhp - rman incre backup
2
run
{
alter system set "_backup_disk_bufcnt"=64 scope=memory sid='*';
alter system set "_backup_disk_bufsz"=1048576 scope=memory sid='*';
alter system set "_backup_file_bufcnt"=64 scope=memory sid='*';
alter system set "_backup_file_bufsz"=1048576 scope=memory sid='*';

# for consistancy
alter system switch logfile;
alter system switch logfile;
alter system switch logfile;

allocate channel ch01 device type disk connect * format '/zfssa/mrln-prod-rman/backup01/MERWHP/bkp_%d_%T_%U';
allocate channel ch02 device type disk connect * format '/zfssb/mrln-prod-rman/backup02/MERWHP/bkp_%d_%T_%U';
allocate channel ch03 device type disk connect * format '/zfssa/mrln-prod-rman/backup03/MERWHP/bkp_%d_%T_%U';
allocate channel ch04 device type disk connect * format '/zfssb/mrln-prod-rman/backup04/MERWHP/bkp_%d_%T_%U';
allocate channel ch05 device type disk connect * format '/zfssa/mrln-prod-rman/backup05/MERWHP/bkp_%d_%T_%U';
allocate channel ch06 device type disk connect * format '/zfssb/mrln-prod-rman/backup06/MERWHP/bkp_%d_%T_%U';
allocate channel ch07 device type disk connect * format '/zfssa/mrln-prod-rman/backup07/MERWHP/bkp_%d_%T_%U';
allocate channel ch08 device type disk connect * format '/zfssb/mrln-prod-rman/backup08/MERWHP/bkp_%d_%T_%U';
allocate channel ch09 device type disk connect * format '/zfssa/mrln-prod-rman/backup09/MERWHP/bkp_%d_%T_%U';
allocate channel ch10 device type disk connect * format '/zfssb/mrln-prod-rman/backup10/MERWHP/bkp_%d_%T_%U';
allocate channel ch11 device type disk connect * format '/zfssa/mrln-prod-rman/backup11/MERWHP/bkp_%d_%T_%U';
allocate channel ch12 device type disk connect * format '/zfssb/mrln-prod-rman/backup12/MERWHP/bkp_%d_%T_%U';
allocate channel ch13 device type disk connect * format '/zfssa/mrln-prod-rman/backup13/MERWHP/bkp_%d_%T_%U';
allocate channel ch14 device type disk connect * format '/zfssb/mrln-prod-rman/backup14/MERWHP/bkp_%d_%T_%U';
allocate channel ch15 device type disk connect * format '/zfssa/mrln-prod-rman/backup15/MERWHP/bkp_%d_%T_%U';
allocate channel ch16 device type disk connect * format '/zfssb/mrln-prod-rman/backup16/MERWHP/bkp_%d_%T_%U';
allocate channel ch17 device type disk connect * format '/zfssa/mrln-prod-rman/backup17/MERWHP/bkp_%d_%T_%U';
allocate channel ch18 device type disk connect * format '/zfssb/mrln-prod-rman/backup18/MERWHP/bkp_%d_%T_%U';
allocate channel ch19 device type disk connect * format '/zfssa/mrln-prod-rman/backup19/MERWHP/bkp_%d_%T_%U';
allocate channel ch20 device type disk connect * format '/zfssb/mrln-prod-rman/backup20/MERWHP/bkp_%d_%T_%U';
allocate channel ch21 device type disk connect * format '/zfssa/mrln-prod-rman/backup21/MERWHP/bkp_%d_%T_%U';
allocate channel ch22 device type disk connect * format '/zfssb/mrln-prod-rman/backup22/MERWHP/bkp_%d_%T_%U';
allocate channel ch23 device type disk connect * format '/zfssa/mrln-prod-rman/backup23/MERWHP/bkp_%d_%T_%U';
allocate channel ch24 device type disk connect * format '/zfssb/mrln-prod-rman/backup24/MERWHP/bkp_%d_%T_%U';

# added include current controlfile to backup controlfile with the backupset
backup as  compressed  backupset incremental level 1 
filesperset 1 section size 32g 
database include current controlfile tag 'MERWHP_24C_INCR_L1' 
plus archivelog tag 'MERWHP_24C_INCR_L1';

delete noprompt archivelog all backed up 2 times to disk;

backup current controlfile;
ALTER DATABASE BACKUP CONTROLFILE TO '/zfssa/mrln-prod-rman/backup01cf/MERWHP/control_MERWHP.bkp' REUSE;

backup spfile format '/zfssa/mrln-prod-rman/backup01cf/MERWHP/spfile_%I_%d_%T_%u' tag 'spfile';

alter database backup controlfile to trace;
alter database backup controlfile to trace as '/zfssa/mrln-prod-rman/backup01cf/MERWHP/backup_controlfile_merwhp_trace.trc' reuse;
}

<end node> 5P9i0s8y19Z
dt=Text
<node>
cellinfo exadata
2
[oracle@mrlnetedbadm01 ~]$ cat cell_group
mrlneteceladm01
mrlneteceladm02
mrlneteceladm03
mrlneteceladm04
mrlneteceladm05
mrlneteceladm06
mrlneteceladm07
mrlneteceladm08
mrlneteceladm09
mrlneteceladm10
mrlneteceladm11
[oracle@mrlnetedbadm01 ~]$ ssh mrlneteceladm01
[cae0748@mrlnetedbadm01 ~]$ sudo su -
Last login: Wed Jul 22 00:26:43 CDT 2020 on pts/0
[root@mrlnetedbadm01 ~]# ssh mrlneteceladm02
Last login: Sat May 16 19:33:08 CDT 2020 from mrlnetedbadm01.cna.com on ssh
Last login: Wed Jul 22 11:24:58 2020 from mrlnetedbadm01.cna.com
[root@mrlneteceladm02 ~]# cellcli
CellCLI: Release 19.2.11.0.0 - Production on Wed Jul 22 11:25:08 CDT 2020

Copyright (c) 2007, 2016, Oracle and/or its affiliates. All rights reserved.

CellCLI> help

<end node> 5P9i0s8y19Z
dt=Text
<node>
DRT Patching RDBMS
2
opatch rollback -id 32119956

-- * Prechecks for the Opatche *
--1) check lsinventory
export ORACLE_HOME=/u01/oracle/product/12.1.0.2
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
/u01/oracle/product/12.1.0.2/OPatch/opatch lsinventory -detail -oh /u01/oracle/product/12.1.0.2

--- select oraenv as +ASM 
export ORACLE_HOME=/u01/grid/product/12.1.0.2/grid
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
/u01/grid/product/12.1.0.2/grid/OPatch/opatch lsinventory -detail -oh /u01/grid/product/12.1.0.2/grid


--2) check all the subfolders of the patches for prerequirements
export ORACLE_HOME=/u01/oracle/product/12.1.0.2
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
/u01/oracle/product/12.1.0.2/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/27547374
/u01/oracle/product/12.1.0.2/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/26983807
/u01/oracle/product/12.1.0.2/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/28537740
/u01/oracle/product/12.1.0.2/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/23312691

--- select oraenv as +ASM 
export ORACLE_HOME=/u01/grid/product/12.1.0.2/grid
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
/u01/grid/product/12.1.0.2/grid/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/27547374
/u01/grid/product/12.1.0.2/grid/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/26983807
/u01/grid/product/12.1.0.2/grid/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/28537740
/u01/grid/product/12.1.0.2/grid/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/23312691


--3) check the space for patche applying for both homes using root account
/u01/oracle/product/12.1.0.2/OPatch/opatch prereq CheckSystemSpace -phBaseFile /u01/oracle/zfs-dr/datapump/patches_2020/logs/checksystemspace_basfile.txt 
/u01/grid/product/12.1.0.2/grid/OPatch/opatch prereq CheckSystemSpace -phBaseFile /u01/oracle/zfs-dr/datapump/patches_2020/logs/checksystemspace_basfile.txt 

--4) Analyze the applying patch using root account for both homes
export ORACLE_HOME=/u01/oracle/product/12.1.0.2
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
$ORACLE_HOME/OPatch/opatchauto apply /u01/oracle/zfs-dr/datapump/patches_2020/28553949 -oh /u01/oracle/product/12.1.0.2 -analyze 

--- select oraenv as +ASM 
export ORACLE_HOME=/u01/grid/product/12.1.0.2/grid
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
$ORACLE_HOME/OPatch/opatchauto apply /u01/oracle/zfs-dr/datapump/patches_2020/28553949 -oh /u01/grid/product/12.1.0.2/grid -analyze 


asmcmd -p

asmcmd>lsdg
asmcmd>volinfo --all

-- before starting to apply grid patche using root account
export ORACLE_HOME=/u01/grid/product/12.1.0.2/grid
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
srvctl stop scan_listener -scannumber 2 --- you can stop scan_listener 2 3 4 1
lsnrctl stop listener
/u01/grid/product/12.1.0.2/grid/bin/./crsctl stop crs
/u01/grid/product/12.1.0.2/grid/bin/./crsctl start crs

-- relocate on mgmtdb first node
srvctl relocate mgmtdb -node mrlndrtdbadm01

fuser -uc /u01/oracle/product/12.1.0.2

fuser -uc /u01/grid/product/12.1.0.2/grid

--*start*--
-- unzip the patches using oracle account
-- chmod -R 777 patches_2020/

-- keep the database up and running before applying the patches so it will apply the sql patches also into DBs

-- from root account we have apply the patche on grid home
export ORACLE_HOME=/u01/grid/product/12.1.0.2/grid
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
/u01/grid/product/12.1.0.2/grid/OPatch/opatchauto apply /u01/oracle/patches_2020/28553949 -oh /u01/grid/product/12.1.0.2/grid

export ORACLE_HOME=/u01/oracle/product/12.1.0.2
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
/u01/oracle/product/12.1.0.2/OPatch/opatchauto apply /u01/oracle/patches_2020/28553949 -oh /u01/oracle/product/12.1.0.2

-- if there is any error while applying and want to resume the session of patching after fixing it 
--- do not exists from the node session
/u01/oracle/product/12.1.0.2/OPatch/opatchauto resume -session CT69

or

/u01/oracle/product/12.1.0.2/OPatch/opatchauto resume 



---- apply all the steps from --*start*--
alter system set cluster_database=false scope=spfile sid='*';
srvctl stop database -d merwhr -stopoption immediate
--- upgrade mode is only supported in sqlplus not in srvctl 
sqlplus "/as sysdba"
startup upgrade;
--echo "apply the OJVM patch with datapatch verbose option"
/u01/oracle/product/12.1.0.2/OPatch/datapatch -verbose

echo "shutdown databases after upgradation is completed"
shutdown immediate;

echo "Startup normal DBs"
sqlplus "/as sysdba"
startup
alter system set cluster_database=true scope=spfile sid='*';
shutdown immediate

srvctl start database -d merwhr

show parameters cluster_database ---- should be true




export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
. oraenv
MERWHR1
/u01/oracle/product/12.1.0.2/OPatch/datapatch -verbose

<end node> 5P9i0s8y19Z
dt=Text
<node>
recovery 27Apr2021
2

restore controlfile from '/u01/oracle/zfs-dr/datapump/merwhp_tbls/bkp_MERWHP_20210428_1bvtd82h_1_1'
restore controlfile from '/zfssb/mrln-dr-rman/backup02/ETE0428_01/bkp_MERWHP_20210428_8nvtdbm6_1_1';
--- backup pieces copied on ETE node3 server
-- to adjust the space we have copied backups on multiple location
/u01/oracle/zfs-dr/datapump/merwhp_tbls
/zfssb/mrln-dr-rman/backup08/ETE0427_01,
/zfssb/mrln-dr-rman/backup08/ETE0427_02,
/zfssb/mrln-dr-rman/backup02/ETE0428_01

-- removed as duplicat copied
/u01/oracle/zfs-dr/datapump/merwhp_tbls/bkp_MERWHP_20210428_1tvtd88p_1_1

--------------------

. oraenv
MERDMTMP

sqlplus "/as sysdba"
alter database mount;
alter database disable block change tracking;


rman target /
> catalog start with '/u01/oracle/zfs-dr/datapump/merwhp_tbls';
-- after completing the catalog of above location 
> catalog start with '/zfssb/mrln-dr-rman/backup02/ETE0428_01';
-- then
> catalog start with '/zfssb/mrln-dr-rman/backup04/ETE0427_01'
-- then
> catalog start with '/zfssb/mrln-dr-rman/backup08/ETE0427_02'
-- some sequence missed so cataloged them back after copiying
> catalog start with '/zfssb/mrln-dr-rman/backup02/ETE0428_02_missing'

RMAN>crosscheck backup


--- check this on backup DB, what is current incarnation pointing to 
select INCARNATION#, RESETLOGS_TIME from v$database_incarnation order by RESETLOGS_TIME desc;

RMAN> list incarnation; -- take incarnation of the backup DB and reset the same incarnation value on recovery side DB

-- execute on recovery side DB, before running the or recieving the error like below (for any disk)
-- ORA-01180: can not create datafile 1
-- ORA-01110: data file 1: '+DATA_ETE'
rman targ /
reset database to incarnation 1;


run
{
allocate channel ch04 device type disk;
allocate channel ch05 device type disk;
allocate channel ch06 device type disk;
allocate channel ch07 device type disk;
allocate channel ch08 device type disk;
allocate channel ch09 device type disk;
allocate channel ch10 device type disk;
allocate channel ch11 device type disk;
allocate channel ch12 device type disk;
allocate channel ch13 device type disk;
allocate channel ch14 device type disk;
allocate channel ch15 device type disk;
allocate channel ch16 device type disk;
allocate channel ch17 device type disk;
allocate channel ch18 device type disk;
allocate channel ch19 device type disk;
allocate channel ch20 device type disk;
allocate channel ch21 device type disk;
allocate channel ch22 device type disk;
allocate channel ch23 device type disk;
allocate channel ch24 device type disk;
set until time "to_date( '28-04-2021 05:28', 'DD-MM-RRRR HH24:MI')";
set newname for database to '+RECO_ETE';
restore tablespace SYSTEM,UNDOTBS1,SYSAUX,UNDOTBS2,PRODUCTS_T_V01,PAFTRANS_SUMMARY_T_V01,TABLES01,DIMENSIONS,AGGREGATE,MISTERM_ENHANCED_T_V01,PAFTRANS_SUMMARY_X_V01,DIMENSIONS_IX;
switch datafile all;
}

list backup of archivelog sequence between 248474 and 248487 thread 2;
list backup of archivelog sequence 248474 to sequence 248487 thread 2;

list backup of archivelog sequence 248488 thread 2;
restore archivelog sequence 248488 thread 2;

released channel: ch200
released channel: ch201
released channel: ch202
released channel: ch203
released channel: ch204
RMAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-03002: failure of recover command at 05/09/2021 08:36:58
RMAN-06054: media recovery requesting unknown archived log for thread 2 with sequence 248488 and starting SCN of 8201576605500


-- copy the sequence log from produ backups 
-- then catalog it 
RMAN> catalog start with '/zfssb/mrln-dr-rman/backup02/ETE0428_02_missing/bkp_MERWHP_20210429_69vth0dl_1_1';

-- check if that is present in current backup list
RMAN> list backup of archivelog sequence 248488 thread 2;

-- you can restore it ... without running all above block
RMAN> restore archivelog sequence 248488 thread 2;


list backup of archivelog sequence 240640 thread 1;

---------------->>>>>
-- if any thing goes wrong with restore then you will have restart all from begining, 
-- dopr recoery DB
-- drop DB
shutdown immediate

startup mount exclusive restrict;
Drop database;
---------------->>>>>

run{
allocate channel ch1320 device type disk;
allocate channel ch321 device type disk;
allocate channel ch342 device type disk;
allocate channel ch153 device type disk;
allocate channel ch164 device type disk;
allocate channel ch175 device type disk;
allocate channel ch186 device type disk;
allocate channel ch197 device type disk;
allocate channel ch928 device type disk;
allocate channel ch829 device type disk;
allocate channel ch720 device type disk;
allocate channel ch621 device type disk;
allocate channel ch522 device type disk;
allocate channel ch423 device type disk;
allocate channel ch324 device type disk;
set until time "to_date( '28-04-2021 05:28', 'DD-MM-RRRR HH24:MI')";
set newname for database to '+RECO_ETE';
recover database skip forever tablespace TEMP,USERS,THIRTYTWOK,CAPMAN_DATA,AB_ADMIN,AB_INDEX,AB_OP,ACA,ACA_HSTRY_T_V01,ACTDMS,ACTFINODS,AC_STAGING_T_V01,AGGREGATE_IX,AIM_DATA,AIPS_MISTERM_AUGUST_T_V01,
AIPS_MISTERM_AUGUST_X_V01,APER_BO_LOSS_RATIO_BKP_T_V01,APER_BO_LOSS_RATIO_T_V01,APER_BO_LOSS_RATIO_WIP_T_V01,APER_BO_LOSS_RATIO_WIP_X_V01,APER_BO_LOSS_RATIO_X_V01,
APER_BO_PREM_DETAIL_BKP_T_V01,APER_BO_PREM_DETAIL_T_V01,APER_BO_PREM_DETAIL_WIP_T_V01,APER_BO_PREM_DETAIL_WIP_X_V01,APER_BO_PREM_DETAIL_X_V01,APER_EP_QTR_SS_T_V01,
APER_EP_QTR_SS_X_V01,ARCHIVE_T_V01,ARCH_RATING_FACTOR_CR_T_V01,ARCH_RATING_FACTOR_CR_X_V01,ARCH_RATING_FACTOR_RQ_T_V01,ARCH_RATING_FACTOR_RQ_X_V01,
BASE_FACT_FINAL_BKP_T_V01,BASE_FACT_FINAL_T_V01,BASE_FACT_FINAL_WIP_T_V01,BASE_FACT_FINAL_X_V01,BASE_FACT_PRIOR_WK2A_T_V01,BASE_FACT_WK2A_T_V01,
BASE_FACT_WK_T_V01,CANADA_T_V01,CC_INDEX,CC_OP,CLAIMDMS_INDEX,CLAIMDMS_TABLE,CLAIMODS_INDEX,CLAIMODS_LIST_CHAINED_T_V01,CLAIMODS_TABLE,CLAIM_ADDITIONAL_T_V01,
CLAIM_ADDITIONAL_WEEKLY_T_V01,CLAIM_ADDITIONAL_WEEKLY_X_V01,CLAIM_ADDITIONAL_X_V01,CLAIM_TRANS_T_V01,CLAIM_TRANS_X_V01,CLAIM_T_V04,CLAIM_WEEKLY_T_V01,
CLAIM_WEEKLY_X_V01,CLAIM_X_V04,CNA13_0692_V01,CNACOM_STAGING_T_V01,CNA_ATABLES,COMBINED_CLAIM_ADDL_T_V01,COMBINED_CLAIM_ADDL_X_V01,COMBINED_CLAIM_T_V01,
COMBINED_CLAIM_X_V01,COMBINED_PAY_HIST_T_V01,COMBINED_PAY_HIST_X_V01,COMBINED_SUFFIX_SNAPS_T_V01,COMBINED_SUFFIX_SNAPS_X_V01,COMBINED_SUFFIX_T_V01,
COMBINED_SUFFIX_X_V01,COSTCON_T_V01,COVERAGE_CR_T_V01,COVERAGE_CR_X_V01,COVERAGE_RQ_T_V01,COVERAGE_RQ_X_V01,CR_RQ_T_V01,CR_RQ_X_V01,CVS_T_V01,CVS_X_V01,
CVTRY_HIST_T_V01,DASH_T_V01,DBA_CMDS_INDEXES,DBA_CMDS_TABLES,DED_AMT_CR_T_V01,DED_AMT_CR_X_V01,DED_AMT_RQ_T_V01,DED_AMT_RQ_X_V01,
DIRECT_TRANS_T_V06,DIRECT_TRANS_X_V06,DMSRPT_STAGE_INDEX,DMSRPT_STAGE_TABLE,DMS_INT_INDEX,DMS_INT_TABLE,ESIGHT_ADMIN_T_V01,EXPLORE,EXPLORE_WORK,
FAS_CLAIMODS,FEEDS_IN_T_V01,FEEDS_OUT,GRIPCLOSE_T_V01,HAL_TABLES,HISTORICAL9DAY_T_V01,HISTORICAL_T_V01,IBMCDC_TABLES,INDEXES01,INFO,LIMIT_AMOUNT_CR_T_V01,
LIMIT_AMOUNT_CR_X_V01,LIMIT_AMOUNT_RQ_T_V01,LIMIT_AMOUNT_RQ_X_V01,LITE_DATA,MEDBILL_MITCHELL_T_01,MEDBILL_T_V01,MISTERM_ENHANCED_20140102_T,
MISTERM_ENHANCED_DAILY_T_V01,MISTERM_ENHANCED_DAILY_X_V01,MISTERM_ENHANCED_PRIOR_T_V01,MISTERM_ENHANCED_X_V01,MISTERM_LTD_BKP_T_V01,MISTERM_LTD_T_V01,
MISTERM_LTD_WIP_T_V01,MISTERM_T_V01,MISTERM_X_V01,MIS_DM_RPT_ARCHIVE_T_V01,MIS_DM_RPT_ARCHIVE_X_V01,MIS_DM_RPT_T_V01,MIS_DM_RPT_X_V01,MIS_DM_RPT_YE_T_V01,
MIS_EARN_OUT_EXP_T_V01,MIS_EARN_OUT_EXP_X_V01,MIS_EARN_OUT_LTD_T_V01,MIS_EARN_OUT_LTD_X_V01,MIS_EARN_OUT_RECAST_T_V01,MIS_EARN_OUT_RECAST_X_V01,
MIS_EARN_OUT_T_V04,MIS_EARN_OUT_X_V04,MIS_LIST_CHAINED_T_V01,MIS_RPT_DEV_V01,MIS_WORK,ODSHIST_INDEX,ODSHIST_TABLE,ODSRPT_INDEX,ODSRPT_TABLE,ODS_INT_INDEX,
ODS_INT_TABLE,PAFTRANS,PAFTRANS_IX,PAFTRAN_GL_ACCT_2009_T_V01,PAFTRAN_GL_ACCT_2010_T_V01,PAFTRAN_GL_ACCT_2011_T_V01,PAFTRAN_GL_ACCT_2012_T_V01,
PAFTRAN_GL_ACCT_2013_T_V01,PAFTRAN_GL_ACCT_2014_T_V01,PAFTRAN_GL_ACCT_2015_T_V01,PAFTRAN_GL_ACCT_PRE2009_T_V01,PAY_HIST_T_V02,PAY_HIST_X_V02,PCA_CLAIM_T_V01,
PCA_CLAIM_X_V01,PL_CALENDAR_YR_DATA_T_V01,PL_CALENDAR_YR_DATA_X_V01,PL_IBNR_FACTORS_PRIOR_T_V01,PL_IBNR_FACTORS_PRIOR_X_V01,PL_SUM_PRIOR_WIP_T_V01,
PL_SUM_PRIOR_WIP_X_V01,PRELOAD,PRODUCTS_BKP_T_V01,PRODUCTS_CLMCLS_T_V01,PRODUCTS_CLMCLS_X_V01,PRODUCTS_QTR_T_V01,PRODUCTS_QTR_WIP_T_V01,PRODUCTS_WIP_T_V01,
PRODUCTS_WIP_X_V01,PRODUCTS_X_V01,PROFIT_LOSS_GROSS_PRV_T_V01,PROFIT_LOSS_GROSS_PRV_X_V01,PROFIT_LOSS_SUMMARY_BKP_T_V01,PROFIT_LOSS_SUMMARY_T_V01,
PROFIT_LOSS_SUMMARY_WIP_T_V01,PROFIT_LOSS_SUMMARY_WIP_X_V01,PROFIT_LOSS_SUMMARY_X_V01,PROFIT_LOSS_SUMM_PRIOR_T_V01,PROFIT_LOSS_SUMM_PRIOR_X_V01,
PRO_HIST_T_V01,PS_Z_ERNOUT_EXP_T_V01,RATE_FACT_BKP_T_V01,RATE_FACT_T_V01,RATE_FACT_WIP_T_V01,RATE_FACT_WIP_X_V01,RATE_FACT_X_V01,RATG_FTR_ADD_CR_T_V01,
RATG_FTR_ADD_CR_X_V01,RATG_FTR_ADD_RQ_T_V01,RATG_FTR_ADD_RQ_X_V01,RATING_FACTOR_CR_T_V02,RATING_FACTOR_CR_X_V02,RATING_FACTOR_RQ_T_V02,RATING_FACTOR_RQ_X_V02,
REINS_DIRECT_SNAPS_T_V02,REINS_DIRECT_SNAPS_X_V02,REINS_DIRECT_TRANS_T_V02,REINS_DIRECT_TRANS_X_V02,REINS_SPECIAL_TRANS_T_V02,REINS_SPECIAL_TRANS_X_V02,
RETENTION_FACT_BKP_T_V01,RETENTION_FACT_T_V01,RETENTION_FACT_WIP_T_V01,RETENTION_FACT_WIP_X_V01,RETENTION_FACT_X_V01,RST_PPO_T_V01,
STAGING,SUFFIX_ADDITIONAL_WEEKLY_T_V01,SUFFIX_ADDITIONAL_WEEKLY_X_V01,SUFFIX_SNAPS_T_V07,SUFFIX_SNAPS_WEEKLY_T_V04,SUFFIX_SNAPS_WEEKLY_X_V04,
SUFFIX_SNAPS_X_V07,SUFFIX_T_V08,SUFFIX_WEEKLY_T_V05,SUFFIX_WEEKLY_X_V05,SUFFIX_X_V08,SURETY_ARCHIVE_T_V01,SURETY_ARCHIVE_X_V01,SURETY_STAGING_T_V01,
SURETY_STAGING_X_V01,SUR_BOND_TERM_CVRG_T_V01,SUR_BOND_TERM_CVRG_X_V01,SUR_BOND_T_V01,SUR_BOND_X_V01,SUR_MISTERM_PRIOR_T_V01,SUR_MISTERM_T_V01,
SUR_MISTERM_X_V01,SYMANTEC_I3_ORCL,TERADATA_T_V02,TOOLS,VIATICUS_T_V01,VIATICUS_X_V01,WCEDI,WCEDIDMS,WCFC01,WCFC_CLAIM_DETAIL_T_V01,WCFC_CLAIM_DETAIL_X_V01,
WCFC_LOSS_DETAIL_T_V01,WCFC_LOSS_DETAIL_X_V01,WCFC_QTR_CLAIM_DETAIL_T_V01,WCFC_QTR_CLAIM_DETAIL_X_V01,BOXI_RPT_TMP,BO_TEMP,ESIGHT_TEMP,LAWYERS_INS_TEMP,
MIS_DM_RPT_TEMP,MIS_RPT_DEV_TEMP,SYMANTEC_I3_ORCL_TMP,USER_TEMP,INDEXES,MAXCP_DATA01,MAXCP_INDEXES01,CIDBP_DATA01,CIDBP_INDEXES01,PERFBP_DATA01,PERFBP_INDEXES01,
PAFTRAN_GL_ACCT_2016_T_V01,CEDELITE_STAGING_T_V01,ARCHIVE_TABLES,ARCHIVE_INDEX,ARCHIVE_LOB,DATA,CNACMRPT_LARGE_OBJECTS,CCN_PREMHIST_T_V01,CCN_PREMHIST_X_V01,
CLAIMAPD_T01,SOSARCH_TABLES,SOS_TABLES,SOSARCH_INDEXES,SOS_INDEXES,MR_LANDING_TABLES,MR_LANDING_LOB,MR_LANDING_INDEXES,MR_PRELOAD_TABLES,MR_PRELOAD_LOB,
MR_PRELOAD_INDEXES,AD1099_TAXPRO_T_V01,AD1099_TAXPRO_X_V01,CIMSODS_INDEXES,CIMSODS_TABLES,CIRSODS_INDEXES,CIRSODS_TABLES,EUSRPTODS_INDEXES,EUSRPTODS_TABLES,
MAIN_INDEXES,ODS_CONTROL_INDEXES,ODS_CONTROL_TABLES,PASEINPODS_INDEXES,PASEINPODS_TABLES,PASEREFODS_INDEXES,PASEREFODS_LARGEOBJ,PASEREFODS_TABLES,RATER_EXP_INDEXES,
RATER_EXP_TABLES,RCTODS_INDEXES,RCTODS_LARGE_OBJ,RCTODS_TABLES,RSTSTAGE_INDEXES,RSTSTAGE_LARGE_OBJ,RSTSTAGE_TABLES,SSO_RATERS_STAGE_INDEXES,SSO_RATERS_STAGE_TABLES,
STAGE_INDEXES,STAGE_TABLES,MAIN_TABLES,TAP_INDEXES,TAP_TABLES,ULSODS_INDEXES,ULSODS_TABLES,UWSODS_INDEXES,UWSODS_TABLES,WCODS_INDEXES,WCODS_STG_INDEXES,
WCODS_STG_TABLES,WCODS_TABLES,WCPAYGO_INDEXES,WCPAYGO_TABLES,AR_LKU_T_V01,AR_LKU_X_V01,AR_STAGING_T_V01,AR_STAGING_X_V01,AR_T_V01,AR_X_V01,BLTK_T_V01,
BLTK_X_V01,CMMRCL_PLDG_ARCHIVE01,SURCDC_STAGE_T_V01,SURCDC_STAGE_I_V01,PAFTRAN_GL_ACCT_2017_T_V01,DVD_TEMP,STF_HOLD,AISS_TABLES,DEVLDBA_INDEXES,
DEVLDBA_TABLES,UPS_TABLES,UPS_INDEXES,AISSMRPT_LARGE_OBJECTS,AISSMRPT_ARCHIVE_TABLES,AISSMRPT_ARCHIVE_INDEXES,PAFTRAN_GL_ACCT_2018_T_V01,
ATLAS_LGL_HOLD_ARCHIVE_T1,EUR_CLAIM_DATA_TO_US_T01,TEAMTHINK_T01,BLACKLINE_T1,CNP_RE_REF_OBJECTS,PAFTRAN_GL_ACCT_2019_T_V01,MEDBILL_CONDUENT_T01,CDC_CHECK_TBL,COMPASS_01,
METADATA_REP_TABLES,SENUS_01,SHIFT_01,CARPE_T01,TRECS_ARCHIVE_01,FV_ARCHIVE_V01,TFN_ARCHIVE_V01,RCA_ODS_TABLES,RCA_ODS_INDEXES,INFOBURST_NEW_DATA,STRIIM_USER_TABLES;
}


alter database open resetlogs;


 nohup expdp "'/as sysdba'" directory=expdp1 dumpfile=expdp_RITM0572485_bkup_merwhp_tbls_Ap272021_%U.dmp logfile=expdp_RITM0572485_bkup_merwhp_tbls_Ap27_logs.log tables=MIS.CODE_LIB_DEDUCT_LIMIT_LIAB,MIS.CODE_LIB_DEDUCT_LIMIT_WC,MIS.PROGRAM_SUBPROGRAM_LKU,MIS.PRODUCTS,MIS.PAFTRANS_SUMMARY,MIS.SUBPROGRAM_COVERAGE_ROLLUP_WIP,MIS.PRODUCER,MIS.ACCOUNT,MIS.MISTERM_ENHANCED exclude=statistics,index,constraint,ref_constraints &
 
 
--- keep the limit on single line for tablespace name 
-- take them in new line by enter key and at last put ; semi-collon



 rman log=/u01/oracle/zfs-dr/datapump/aux_merwhp_tbls/rman_logs_RITM0572485_08May2021_logs.log
RMAN> connect target /
-- paste the command 




select owner, tablespace_name,count(*)
from dba_Segments
where segment_name in
('CODE_LIB_DEDUCT_LIMIT_LIAB','CODE_LIB_DEDUCT_LIMIT_WC','PROGRAM_SUBPROGRAM_LKU','PRODUCTS',
'PAFTRANS_SUMMARY','SUBPROGRAM_COVERAGE_ROLLUP_WIP','PRODUCER','ACCOUNT','MISTERM_ENHANCED')
and owner='MIS'
group by owner,tablespace_name
;


select owner, table_name,count(*)
from dba_tables
where table_name in ('CODE_LIB_DEDUCT_LIMIT_LIAB','CODE_LIB_DEDUCT_LIMIT_WC','PROGRAM_SUBPROGRAM_LKU','PRODUCTS',
'PAFTRANS_SUMMARY','SUBPROGRAM_COVERAGE_ROLLUP_WIP','PRODUCER','ACCOUNT','MISTERM_ENHANCED')
 and owner='MIS'
group by owner, table_name
order by owner, table_name;

select tablespace_name, sum(bytes/1024/1024) mbsize
from dba_Segments
where tablespace_name in ('PRODUCTS_T_V01','PAFTRANS_SUMMARY_T_V01','TABLES01','DIMENSIONS','AGGREGATE','MISTERM_ENHANCED_T_V01')
group by tablespace_name;

select tablespace_name
from dba_tablespaces
where tablespace_name not in ('SYSTEM','UNDOTBS1','SYSAUX','UNDOTBS2','PRODUCTS_T_V01','PAFTRANS_SUMMARY_T_V01','TABLES01','DIMENSIONS','AGGREGATE','MISTERM_ENHANCED_T_V01');




list copy of database completed between '27-APRIL-2021' and '28-APRIL-2021';

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

-- MERDMP backup completed and to be recover until time
set until time "to_date( '27-04-2021 15:18', 'DD-MM-RRRR HH24:MI')";

-- copy pfile from merdmp DB

SQLPLUS> startup nomount pfile='initmerdmp.ora';

-- restore controlfile from
RMAN> restore controlfile from '/zfssa/mrln-dr-rman/backup05/ETE_DMP_RESTORE/bkp_MERDMP_20210427_jfvtbpsf_1_1'

SQLPLUS> alter database mount;

-- catalog the backuppieces from 
RMAN> catalog start with '/zfssa/mrln-dr-rman/backup05/ETE_DMP_RESTORE';
RMAN> crosscheck backup;


run{
allocate channel ch04 device type disk;
allocate channel ch05 device type disk;
allocate channel ch06 device type disk;
allocate channel ch07 device type disk;
allocate channel ch08 device type disk;
allocate channel ch09 device type disk;
allocate channel ch10 device type disk;
allocate channel ch11 device type disk;
allocate channel ch12 device type disk;
allocate channel ch13 device type disk;
allocate channel ch14 device type disk;
allocate channel ch15 device type disk;
allocate channel ch16 device type disk;
allocate channel ch17 device type disk;
allocate channel ch18 device type disk;
allocate channel ch19 device type disk;
allocate channel ch20 device type disk;
allocate channel ch21 device type disk;
allocate channel ch22 device type disk;
allocate channel ch23 device type disk;
allocate channel ch24 device type disk;
set until time "to_date( '27-04-2021 15:18', 'DD-MM-RRRR HH24:MI')";
set newname for database to '+RECO_ETE';
restore tablespace SYSTEM,SYSAUX,UNDOTBS1,UNDOTBS2,D_CLAIM_T_V01,D_COMBINED_SUFFIX_SNAPS_T_V03,F_COMBINED_SUFFIX_SNAPS_T_V02,MIS_DM_T_V01;
switch datafile all;
}


run{
allocate channel ch04 device type disk;
allocate channel ch05 device type disk;
allocate channel ch06 device type disk;
allocate channel ch07 device type disk;
allocate channel ch08 device type disk;
allocate channel ch09 device type disk;
allocate channel ch10 device type disk;
allocate channel ch11 device type disk;
allocate channel ch12 device type disk;
allocate channel ch13 device type disk;
allocate channel ch14 device type disk;
allocate channel ch15 device type disk;
allocate channel ch16 device type disk;
allocate channel ch17 device type disk;
allocate channel ch18 device type disk;
allocate channel ch19 device type disk;
allocate channel ch20 device type disk;
allocate channel ch21 device type disk;
allocate channel ch22 device type disk;
allocate channel ch23 device type disk;
allocate channel ch24 device type disk;
set until time "to_date( '27-04-2021 15:18', 'DD-MM-RRRR HH24:MI')";
set newname for database to '+RECO_ETE';
recover database skip forever tablespace ACTRL_RESV_READ_T01,ADB_T_V01,BO_TEMP,CNA_ATABLES,DART_ADM_T_V01,DART_TEMP,DASH_ADM_T_V01,DASH_ADM_WIP_T_V01,
DASH_ADM_WIP_X_V01,DASH_ADM_X_V01,DASH_TEMP,DVD_TEMP,D_CLAIM8_T_V01,D_CLAIM8_X_V01,D_CLAIM_ADDITIONAL_T_V01,
D_CLAIM_ADDITIONAL_X_V01,D_CLAIM_X_V01,D_COMBINED_SUFFIX_SNAPS_X_V03,D_COMB_CLM8_SNAPS_T_V01,
D_COMB_CLM8_SNAPS_WIP_T_V01,D_COMB_CLM8_SNAPS_WIP_X_V01,D_COMB_CLM8_SNAPS_X_V01,D_COMB_SUFFIX_SNAPS_WIP_T_V02,
D_COMB_SUFFIX_SNAPS_WIP_X_V01,D_MISTERM_ENHANCED_T_V01,D_MISTERM_ENHANCED_X_V01,D_MISTERM_LTD_T_V01,
D_MISTERM_LTD_WIP_T_V01,D_MISTERM_LTD_WIP_X_V01,D_MISTERM_LTD_X_V01,D_SUFFIX_T_V02,D_SUFFIX_WIP_T_V01,
D_SUFFIX_WIP_X_V01,D_SUFFIX_X_V02,D_SUR_MISTERM_T_V01,D_SUR_MISTERM_X_V01,ERM_CAT_MGMT_T_V01,EXPLORE_WORK,
FDM_TOOLS_T_01,FEEDS_IN_T_V01,FV_DM_GAAP_T_V01,FV_DM_GAAP_X_V01,FV_DM_JRNL_LN_SNAP_T_V01,FV_DM_JRNL_SUMMARY_T_V01,
FV_DM_JRNL_SUMMARY_X_V01,FV_DM_PF_ACT_T_V01,FV_DM_PF_ACT_X_V01,FV_DM_PLAN_FORECAST_AR_T_V01,FV_DM_PLAN_FORECAST_T_V01,
FV_DM_PLAN_FORECAST_X_V01,FV_DM_STAT_T_V01,FV_DM_STAT_X_V01,FV_DM_TEMP,FV_DM_T_V01,FV_DM_X_V01,
F_COMBINED_SUFFIX_SNAPS_X_V02,F_COMB_CLAIM_CNT_SNAPS_T_V01,F_COMB_CLAIM_CNT_SNAPS_X_V01,F_COMB_CLM8_SNAPS_T_V01,
F_COMB_CLM8_SNAPS_WIP_T_V01,F_COMB_CLM8_SNAPS_WIP_X_V01,F_COMB_CLM8_SNAPS_X_V01,F_COMB_SUFFIX_SNAPS_WIP_T_V01,
F_COMB_SUFFIX_SNAPS_WIP_X_V01,F_PROFIT_LOSS_SUMMARY_T_V01,F_PROFIT_LOSS_SUMMARY_X_V01,F_PROFIT_LOSS_SUMM_WIP_T_V01,
F_PROFIT_LOSS_SUMM_WIP_X_V01,F_RATE_FACT_T_V01,F_RATE_FACT_WIP_T_V01,F_RATE_FACT_WIP_X_V01,F_RATE_FACT_X_V01,
F_RETENTION_FACT_T_V01,F_RETENTION_FACT_WIP_T_V01,F_RETENTION_FACT_WIP_X_V01,F_RETENTION_FACT_X_V01,F_TRIANGLE_SUMMARY_T_V01,
F_TRIANGLE_SUMMARY_X_V01,F_TRIANGLE_SUM_ALLMONTHS_T_V01,F_TRIANGLE_SUM_ALLMONTHS_X_V01,IDM_DM_T_V01,IDM_DM_X_V01,
IDM_FEEDS_OUT_T_V01,IDM_STAGING_T_V01,IDM_STAGING_X_V01,IDM_TEMP,MERLINDASH_TEMP,MIS_DM_RPT_ARCHIVE_T_V01,
MIS_DM_RPT_ARCHIVE_X_V01,MIS_DM_RPT_TEMP,MIS_DM_RPT_T_V01,MIS_DM_RPT_X_V01,MIS_DM_RPT_YE_T_V01,MIS_DM_X_V01,
MIS_RPT_DEV_TEMP,MIS_RPT_DEV_V01,SD_COMBINED_SUFFIX_SNPS_T_V01,SD_COMBINED_SUFFIX_SNPS_X_V01,SD_DIRECT_TRANS_T_V01,
SD_DIRECT_TRANS_X_V01,SF_COMBINED_SUFFIX_SNPS_T_V01,SF_COMBINED_SUFFIX_SNPS_X_V01,SPC_COMPANY_T_V01,SPC_STAGING_T_V01,
STAGING_T_V01,STAGING_X_V01,STRIIM_USER_TABLES,SYMANTEC_I3_ORCL,SYMANTEC_I3_ORCL_TMP,TEMP,THIRTYTWOK,TOOLS,USERS,USER_TEMP;
}

-- check if that is present in current backup list
RMAN> list backup of archivelog sequence 130330 thread 2;

-- you can restore it ... without running all above block
RMAN> restore archivelog sequence 130330 thread 2;


list backup of archivelog sequence 130330 thread 1;


RMAN> alter database open resetlogs;

--- if this is giving error then try for 
-- shutdown immediate and start it the DB in mount stag
RMAN>alter database open;

-- fi required for the media recovery
recover database using backup controlfile until cancel;




select table_owner, table_name, tablespace_name
from dba_tab_partitions
where table_owner='MIS_DM'
 and table_name in ('F_COMBINED_SUFFIX_SNAPS','D_CLAIM','D_STATE_XREF','D_PROGRAM_SUBPROGRAM_LKU','D_COMBINED_SUFFIX_SNAPS','D_IMPAIRED_POLICY_TERM','D_SUFFIX_DATES')
;

select index_owner,tablespace_name,
from dba_ind_partitions
;

select owner,table_name
from dba_tables
where segment_name in ('F_COMBINED_SUFFIX_SNAPS','D_CLAIM','D_STATE_XREF','D_PROGRAM_SUBPROGRAM_LKU','D_COMBINED_SUFFIX_SNAPS','D_IMPAIRED_POLICY_TERM','D_SUFFIX_DATES')
  and owner='MIS_DM';

select table_name,tablespace_name,count(*)
from dba_indexes
where table_name in  ('F_COMBINED_SUFFIX_SNAPS','D_CLAIM','D_STATE_XREF','D_PROGRAM_SUBPROGRAM_LKU','D_COMBINED_SUFFIX_SNAPS','D_IMPAIRED_POLICY_TERM','D_SUFFIX_DATES')
and owner='MIS_DM'
group by table_name,tablespace_name;


select owner,index_name,table_name,status, 
    'alter index '||owner||'.'||index_name||' unusable;'
from dba_indexes
where table_name in ('F_COMBINED_SUFFIX_SNAPS','D_CLAIM','D_STATE_XREF','D_PROGRAM_SUBPROGRAM_LKU','D_COMBINED_SUFFIX_SNAPS','D_IMPAIRED_POLICY_TERM','D_SUFFIX_DATES')
and owner='MIS_DM'
;


select table_name,tablespace_name,count(*)
from dba_tables
where table_name in ('F_COMBINED_SUFFIX_SNAPS','D_CLAIM','D_STATE_XREF','D_PROGRAM_SUBPROGRAM_LKU','D_COMBINED_SUFFIX_SNAPS','D_IMPAIRED_POLICY_TERM','D_SUFFIX_DATES')
 and owner='MIS_DM'
 group by table_name,tablespace_name
order by table_name,tablespace_name asc
;


select * from dba_objects where object_name='V_D_CLAIM';

select * from dba_views where view_name='V_D_CLAIM';




select tablespace_name||','
from dba_tablespaces 
where tablespace_name not in ('SYSTEM','UNDOTBS1','SYSAUX','UNDOTBS2','D_CLAIM_T_V01','D_COMBINED_SUFFIX_SNAPS_T_V03','F_COMBINED_SUFFIX_SNAPS_T_V02','MIS_DM_T_V01')
order by 1 asc
;


select tablespace_name,dbms_xplan.format_size(bytes)
from dba_data_files
where tablespace_name in ('SYSTEM','UNDOTBS1','SYSAUX','UNDOTBS2','D_CLAIM_T_V01','D_COMBINED_SUFFIX_SNAPS_T_V03','F_COMBINED_SUFFIX_SNAPS_T_V02','MIS_DM_T_V01')
;

--- after restoration and recovery. now you have to take export backup of mentioned tables
--- and if you got any file not able to read error for any missing indexes tablespace which was not taken in restoration
--- then simply put the indexes in unsable state and start export again by excluding them
alter index MIS_DM.J6_D_COMBINED_SUFFIX_SNAPS unusable;
alter index MIS_DM.J7_D_COMBINED_SUFFIX_SNAPS unusable;
alter index MIS_DM.J8_D_COMBINED_SUFFIX_SNAPS unusable;
alter index MIS_DM.PK_D_CLAIM unusable;
alter index MIS_DM.SF_01_D_CLAIM unusable;

nohup expdp "'/as sysdba'" directory=expdp dumpfile=expdp_MERDMP_BKP_RMANRestore_May2021_v2_%U.dmp logfile=expdp_MERDMP_BKP_RMANRestore_logs.log tables=MIS_DM.F_COMBINED_SUFFIX_SNAPS,MIS_DM.D_CLAIM,MIS_DM.D_STATE_XREF,MIS_DM.D_PROGRAM_SUBPROGRAM_LKU,MIS_DM.D_COMBINED_SUFFIX_SNAPS,MIS_DM.D_IMPAIRED_POLICY_TERM,MIS_DM.D_SUFFIX_DATES exclude=index,constraint,ref_constraint,statistics,FGA_POLICY,grant parallel=7 &

MIS_DM.F_COMBINED_SUFFIX_SNAPS,MIS_DM.D_CLAIM,MIS_DM.D_STATE_XREF,MIS_DM.D_PROGRAM_SUBPROGRAM_LKU,MIS_DM.D_COMBINED_SUFFIX_SNAPS,MIS_DM.D_IMPAIRED_POLICY_TERM,MIS_DM.D_SUFFIX_DATES

nohup expdp "'/as sysdba'" directory=expdp dumpfile=expdp_MERDMP_BKP_RMANRestore_May2021_v2_%U.dmp logfile=expdp_MERDMP_BKP_RMANRestore_logs100_v2.log tables=MIS_DM.F_COMBINED_SUFFIX_SNAPS,MIS_DM.D_CLAIM,MIS_DM.D_STATE_XREF,MIS_DM.D_PROGRAM_SUBPROGRAM_LKU,MIS_DM.D_COMBINED_SUFFIX_SNAPS,MIS_DM.D_IMPAIRED_POLICY_TERM,MIS_DM.D_SUFFIX_DATES exclude=index,constraint,ref_constraint,statistics,FGA_POLICY,grant parallel=7 reuse_dumpfiles=y




nohup impdp "'/as sysdba'" directory=DUMP01 dumpfile=expdp_MERDMP_BKP_RMANRestore_May2021_v2_%U.dmp logfile=impdp_expdp_MERDMP_BKP_RMANRestore_May2021_logs100.log tables=MIS_DM.F_COMBINED_SUFFIX_SNAPS,MIS_DM.D_CLAIM,MIS_DM.D_STATE_XREF,MIS_DM.D_PROGRAM_SUBPROGRAM_LKU,MIS_DM.D_COMBINED_SUFFIX_SNAPS,MIS_DM.D_IMPAIRED_POLICY_TERM,MIS_DM.D_SUFFIX_DATES table_exists_action=replace parallel=7 transform=storage:N:table &

<end node> 5P9i0s8y19Z
dt=Text
<node>
Merlin Refresh
2
<end node> 5P9i0s8y19Z
dt=Text
<node>
Merlin Refresh and code Merge - Warehouse and Datamarts
3
RE: Merlin Refresh and code Merge - Warehouse and Datamarts - DRT - October Release 
 
starting @ Wed 28-08-2019 22:31 

merwhp --- merwhr
merdmp --- merdmr


drop only objects not users
exclude=db_link

2 kind of export metadata and data

take the safe export also from merwhr

where there is objects and no data -- means import will be done only for metadata there will be no data in those schemas in merwhr

ACL table backup -- Chandrakant has send an email how to take the backup of ACL 	

Work on node 2 of merwhp, merwhr, merdmp and merdmr (Do Not work on Node 1 Instance)

parfile is .out file

change the parfile and edit it as per the document given.. Enter the schemas given only and remove those are not found in document

ask Gopi b4 starting the activity .... Gopi will confirmed to start activity or not ?

Hi Gopi,

Please let us know if we can start the activity of refresh merwhp >> merwhr and merdmp >> merdmr at 08:00 PM as mentioned by your we are just checking with you 

Regards,


login into Node 2 instance for refresh activity


--------------------------------------------------------------------------------------------------------------
---- Below are the location of the usefull scripts for Warehouse and Datamarts - DRT Merlin refresh
Once you started the activity send activity status every 4 hrs
 
MERWHP >> MERWHR   parfile and dump path
=======================

mrlnprddbadm01:/u01/oracle/zfs-dr/datapump_new/MIS
--- Imp parfile MERWHR

mrlnprddbadm01:/u01/oracle/zfs-dr/datapump_new/MIS/sql
---- drop object sql MERWHR 

mrlnprddbadm01:/zfs_aur_dp5/MIS
---- expdp parfile and dumpfile for MERWHR refresh

mrlndrtdbadm01:/u01/oracle/zfs-dr/datapump/temp_expdp
---- safe export merwhr 
 
 
MERDMP >> MERDMR   parfile and dump path
=======================

mrlnprddbadm01:/zfs_aur_dp1/MERDMP 
---- expdp parfile and dumpfile for MERDMR refresh

mrlndrtdbadm03:/u01/oracle/zfs-dr/datapump/temp_expdp
---- safe export merdmr

mrlndrtdbadm03:/u01/oracle/zfs-dr/datapump/temp_expdp/sql
---- drop object sql  for MERDMR

mrlndrtdbadm03:/u01/oracle/zfs-dr/datapump/temp_expdp
--- Impdp parfile  for MERDMR 

copy dumpfile from prod zfs to drt zfs 
=========================================
mrlnprddbadm01:/zfs_aur_dp5/MIS     cp.ksh 
mrlnprddbadm03:/zfs_aur_dp1/MERDMP  cp.ksh  

<end node> 5P9i0s8y19Z
dt=Text
<node>
chck tablespaces
3

-- check merdmr FEEDS_IN and MIS_DM tablespace
SELECT Tablespace_Name, "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM
 (
    SELECT  a.tablespace_name Tablespace_Name,
           round(a.bytes_alloc / 1024 / 1024) "Allocated (MB)",
           round(nvl(b.bytes_free, 0) / 1024 / 1024) "Free (MB)",
           round((a.bytes_alloc - nvl(b.bytes_free, 0)) / 1024 / 1024) "Used (MB)",
           round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
           100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Used",
           round(maxbytes/1024 / 1024) "Max. Bytes (MB)"
      FROM  
		( 
          SELECT f.tablespace_name, sum(f.bytes) bytes_alloc,
                 sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
            FROM dba_data_files f
           WHERE f.tablespace_name in (SELECT unique tablespace_name FROM dba_segments WHERE owner in ('FEEDS_IN','MIS_DM'))
          GROUP BY tablespace_name
		) a,
        (
		  SELECT f.tablespace_name, sum(f.bytes)  bytes_free
            FROM dba_free_space f
           WHERE f.tablespace_name in (SELECT unique tablespace_name FROM dba_segments WHERE owner in ('FEEDS_IN','MIS_DM'))
           GROUP BY tablespace_name
	    ) b
     WHERE a.tablespace_name = b.tablespace_name (+)
--   GROUP BY h.tablespace_name
 )  --WHERE Tablespace_name in ('MIS_WORK')
order by 6 desc; 


-- check merwhr ESIGHT_ADMIN, FEEDS_IN and FEEDS_OUT tablespace
SELECT Tablespace_Name, "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM
 (
    SELECT  a.tablespace_name Tablespace_Name,
           round(a.bytes_alloc / 1024 / 1024) "Allocated (MB)",
           round(nvl(b.bytes_free, 0) / 1024 / 1024) "Free (MB)",
           round((a.bytes_alloc - nvl(b.bytes_free, 0)) / 1024 / 1024) "Used (MB)",
           round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
           100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Used",
           round(maxbytes/1024 / 1024) "Max. Bytes (MB)"
      FROM  
		( 
          SELECT f.tablespace_name, sum(f.bytes) bytes_alloc,
                 sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
            FROM dba_data_files f
           WHERE f.tablespace_name in (SELECT unique tablespace_name FROM dba_segments WHERE owner in ('ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT'))
          GROUP BY tablespace_name
		) a,
        (
		  SELECT f.tablespace_name, sum(f.bytes)  bytes_free
            FROM dba_free_space f
           WHERE f.tablespace_name in (SELECT unique tablespace_name FROM dba_segments WHERE owner in ('ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT'))
           GROUP BY tablespace_name
	    ) b
     WHERE a.tablespace_name = b.tablespace_name (+)
--   GROUP BY h.tablespace_name
 )  --WHERE Tablespace_name in ('MIS_WORK')
order by 6 desc;  






SELECT Tablespace_Name, "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM(
select  a.tablespace_name Tablespace_Name,
       round(a.bytes_alloc / 1024 / 1024) "Allocated (MB)",
       round(nvl(b.bytes_free, 0) / 1024 / 1024) "Free (MB)",
       round((a.bytes_alloc - nvl(b.bytes_free, 0)) / 1024 / 1024) "Used (MB)",
       round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
       100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Used",
       round(maxbytes/1024 / 1024) "Max. Bytes (MB)"
from  ( select  f.tablespace_name,
               sum(f.bytes) bytes_alloc,
               sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
        from dba_data_files f
        where f.tablespace_name in (select unique tablespace_name from dba_segments where owner='MIS')
        group by tablespace_name) a,
      ( select  f.tablespace_name,
               sum(f.bytes)  bytes_free
        from dba_free_space f
        where f.tablespace_name in (select unique tablespace_name from dba_segments where owner='MIS')
        group by tablespace_name) b
where a.tablespace_name = b.tablespace_name (+)
union all
select h.tablespace_name,
       round(sum(h.bytes_free + h.bytes_used) / 1048576) megs_alloc,
       round(sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / 1048576) megs_free,
       round(sum(nvl(p.bytes_used, 0))/ 1048576) megs_used,
       round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) Pct_Free,
       100 - round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) pct_used,
       round(sum(f.maxbytes) / 1048576) max
from   sys.v_$TEMP_SPACE_HEADER h, sys.v_$Temp_extent_pool p, dba_temp_files f
where  p.file_id(+) = h.file_id
and    p.tablespace_name(+) = h.tablespace_name
and    f.file_id = h.file_id
and    f.tablespace_name = h.tablespace_name
group by h.tablespace_name
)  --where Tablespace_name in ('MIS_WORK')
order by 6 desc;


SELECT Tablespace_Name, "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM
 (
    SELECT  a.tablespace_name Tablespace_Name,
           round(a.bytes_alloc / 1024 / 1024) "Allocated (MB)",
           round(nvl(b.bytes_free, 0) / 1024 / 1024) "Free (MB)",
           round((a.bytes_alloc - nvl(b.bytes_free, 0)) / 1024 / 1024) "Used (MB)",
           round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
           100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Used",
           round(maxbytes/1024 / 1024) "Max. Bytes (MB)"
      FROM  
		( 
          SELECT f.tablespace_name, sum(f.bytes) bytes_alloc,
                 sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
            FROM dba_data_files f
           WHERE f.tablespace_name in (SELECT unique tablespace_name FROM dba_segments WHERE owner in ('ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT'))
          GROUP BY tablespace_name
		) a,
        (
		  SELECT f.tablespace_name, sum(f.bytes)  bytes_free
            FROM dba_free_space f
           WHERE f.tablespace_name in (SELECT unique tablespace_name FROM dba_segments WHERE owner in ('ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT'))
           GROUP BY tablespace_name
	    ) b
     WHERE a.tablespace_name = b.tablespace_name (+)
--   GROUP BY h.tablespace_name
 )  --WHERE Tablespace_name in ('MIS_WORK')
order by 6 desc;  

select * from gv$session where regexp_like(module,'*data*','i')


col username format a10
col OPNAME format a30
col SOFAR format 999999999
col 'WorkDone%' format 999.99
col Start_time format a20
col "End_At" for a20
select sl.inst_id, sl.sid, sl.serial#, sl.username, sl.opname,s.module,TOTALWORK, 
       ROUND(sl.sofar/sl.totalwork * 100, 2) "WorkDone%",    
       sl.target_desc, to_char(sl.start_time,'mm/dd/yyyy hh24:mi:ss')start_time,
       to_char(sl.last_update_time,'mm/dd/yyyy hh24:mi:ss')last_update_time,
       to_char(sysdate + TIME_REMAINING/3600/24,'DD-MON-YY hh24:mi:ss') "End_At",
       sl.message
from gv$session_longops sl, gv$session s
where sl.sid = s.sid
  and sl.serial# = s.serial#
  and sl.opname='MRLNRF_MERWHP_02092020'
--and s.module like 'Data%';



SELECT owner, object_type,status, count(*)
from dba_objects
where owner in ('MIS','ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT','MIS_DM_RPT','AC_STAGING','ARCHIVE','DASH','DASHBOARD','HAL',
 'INFO','MERLINAUI','MIS_DM_RPT','MISWEB','MISWEBWIP','MLBOACT','MLBOMAJOR','MLBOWIP','CNACOM_STAGING',
 'MEDBILL','MEDBILL_MITCHELL','RST','CANADA','SURETY_ARCHIVE','SURETY_STAGING','WCFC','VIATICUS',
 'PRELOAD','STAGING')
group by  owner, object_type,status
order by owner, object_type asc



--307068846

select owner, segment_name, sum(bytes/1024/1024/1024)
from dba_segments 
where owner='MIS_DM_RPT' and segment_name='MV_B_DAILY_TRANS'
group by owner, segment_name



select count(1) from MIS_DM_RPT.MV_B_DAILY_TRANS


select * from dba_objects where object_name='MV_B_DAILY_TRANS'

SYS_EXPORT_SCHEMA_02




SELECT Oracle_Username Username, owner Object_Owner, Object_Name, Object_Type, s.osuser, s.SID SID,p.spid,
    s.SERIAL# SERIAL,s.inst_id,S.MACHINE,s.module,
    DECODE(l.BLOCK, 0, 'Not Blocking', 1, 'Blocking', 2, 'Global') STATUS,
    DECODE(v.locked_mode, 0, 'None', 1, 'Null', 2, 'Row-S (SS)', 3, 'Row-X (SX)', 4, 'Share', 5, 'S/Row-X (SSX)', 6, 'Exclusive', TO_CHAR(lmode) ) MODE_HELD,
    'alter system kill session ' || ''''|| s.sid || ',' || s.serial# || ',@'||s.inst_id ||''' immediate;'  "Kill_Command"
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s, gv$process p
WHERE v.object_id = d.object_id
  AND (v.object_id = l.id1)
  AND v.session_id = s.SID
  and s.paddr = p.addr
 and (d.owner <>'SYS' or s.type <> 'BACKGROUND')
--  and d.owner='MIS_DM_RPT'
--  and Object_Name='MV_B_DAILY_TRANS'
ORDER BY oracle_username, session_id;



SELECT Oracle_Username Username, owner Object_Owner, Object_Name, Object_Type, s.osuser, s.SID SID,p.spid,
    s.SERIAL# SERIAL,s.inst_id,S.MACHINE,s.module,
    DECODE(l.BLOCK, 0, 'Not Blocking', 1, 'Blocking', 2, 'Global') STATUS,
    DECODE(v.locked_mode, 0, 'None', 1, 'Null', 2, 'Row-S (SS)', 3, 'Row-X (SX)', 4, 'Share', 5, 'S/Row-X (SSX)', 6, 'Exclusive', TO_CHAR(lmode) ) MODE_HELD,
    'alter system kill session ' || ''''|| s.sid || ',' || s.serial# || ',@'||s.inst_id ||''' immediate;'  "Kill_Command"
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s, gv$process p
WHERE v.object_id = d.object_id
  AND (v.object_id = l.id1)
  AND v.session_id = s.SID
  and s.paddr = p.addr
  and (d.owner <>'SYS' or s.type <> 'BACKGROUND')
--  and d.owner='OLTP'
--  and Object_Name='EPC_WC7COST'
ORDER BY oracle_username, session_id;


select inst_id,sid,serial#,username,schemaname,osuser,status,machine,program,module
from gv$session
where schemaname not in ('SYS','DBSNMP','CAE0748','C031793','CAE4320','CAE2771')


select * 
from 
(
	select df.tablespace_name Tablespace,
			df.totalspace Total_MB,
			totalusedspace used_MB,
			(df.totalspace - tu.totalusedspace) free_MB,			
			round(100 * ( (df.totalspace - tu.totalusedspace)/ df.totalspace)) Percentage_Free
	from
		(
          select tablespace_name, round(sum(bytes/1048576)) TotalSpace
          from dba_data_files ddf
          where exists (select 1 
                        from dba_segments ds
                        where ds.owner='MIS'
                          and ds.tablespace_name = ddf.tablespace_name)
          group by tablespace_name
		 ) df,
		(select tablespace_name, round(sum(bytes)/(1024*1024)) totalusedspace
		   from dba_segments ds
          where ds.owner='MIS'
          group by tablespace_name
		 ) tu
	where df.tablespace_name = tu.tablespace_name 
 ) 
 -- where Tablespace in (select unique tablespace_name from dba_segments where owner='MIS' order by 1 asc)
order by USED_MB,Percentage_Free desc;




(select unique tablespace_name from dba_segments where owner='MIS')

SELECT tablespace_name, "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM(
select  a.tablespace_name tablespace_name,
       round(a.bytes_alloc / 1024 / 1024) "Allocated (MB)",
       round(nvl(b.bytes_free, 0) / 1024 / 1024) "Free (MB)",
       round((a.bytes_alloc - nvl(b.bytes_free, 0)) / 1024 / 1024) "Used (MB)",
       round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
       100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Used",
       round(maxbytes/1024 / 1024) "Max. Bytes (MB)"
from  ( select  f.tablespace_name,
               sum(f.bytes) bytes_alloc,
               sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
        from dba_data_files f
        group by tablespace_name) a,
      ( select  f.tablespace_name,
               sum(f.bytes)  bytes_free
        from dba_free_space f
        group by tablespace_name) b
where a.tablespace_name = b.tablespace_name (+)
union all
select h.tablespace_name,
       round(sum(h.bytes_free + h.bytes_used) / 1048576) megs_alloc,
       round(sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / 1048576) megs_free,
       round(sum(nvl(p.bytes_used, 0))/ 1048576) megs_used,
       round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) Pct_Free,
       100 - round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) pct_used,
       round(sum(f.maxbytes) / 1048576) max
from   sys.v_$TEMP_SPACE_HEADER h, sys.v_$Temp_extent_pool p, dba_temp_files f
where  p.file_id(+) = h.file_id
and    p.tablespace_name(+) = h.tablespace_name
and    f.file_id = h.file_id
and    f.tablespace_name = h.tablespace_name
group by h.tablespace_name
ORDER BY 2
)
--where tablespace_name='TEMP'




SELECT tablespace_name, "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM(
select  a.tablespace_name tablespace_name,
       round(a.bytes_alloc / 1024 / 1024) "Allocated (MB)",
       round(nvl(b.bytes_free, 0) / 1024 / 1024) "Free (MB)",
       round((a.bytes_alloc - nvl(b.bytes_free, 0)) / 1024 / 1024) "Used (MB)",
       round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
       100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Used",
       round(maxbytes/1024 / 1024) "Max. Bytes (MB)"
from  ( select  f.tablespace_name,
               sum(f.bytes) bytes_alloc,
               sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
        from dba_data_files f 
        group by tablespace_name) a,
      ( select  f.tablespace_name,
               sum(f.bytes)  bytes_free
        from dba_free_space f
        group by tablespace_name) b
where a.tablespace_name = b.tablespace_name (+)
) where tablespace_name='ARCHIVE_T_V01'
ORDER BY 6 asc


--- Tablespace usage check query for 4Schema 
SELECT tablespace_name, "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM(
select  a.tablespace_name Tablespace_Name,
       round(a.bytes_alloc / 1024 / 1024) "Allocated (MB)",
       round(nvl(b.bytes_free, 0) / 1024 / 1024) "Free (MB)",
       round((a.bytes_alloc - nvl(b.bytes_free, 0)) / 1024 / 1024) "Used (MB)",
       round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
       100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Used",
       round(maxbytes/1024 / 1024) "Max. Bytes (MB)"
from  ( select  f.tablespace_name,
               sum(f.bytes) bytes_alloc,
               sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
        from dba_data_files f where tablespace_name in (select unique tablespace_name from dba_segments where owner in ('ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT','MIS_DM_RPT'))
        group by tablespace_name) a,
      ( select  f.tablespace_name,
               sum(f.bytes)  bytes_free
        from dba_free_space f where tablespace_name in (select unique tablespace_name from dba_segments where owner in ('ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT','MIS_DM_RPT'))
        group by tablespace_name) b
where a.tablespace_name = b.tablespace_name (+)
) 
ORDER BY 6 asc



select a.*, 'alter database  datafile '''||file_name||''' resize '||total_mb||'m;'
from 
(
	select df.tablespace_name Tablespace,
			df.totalspace Total_MB,
			totalusedspace Used_MB,
			(df.totalspace - tu.totalusedspace) Free_MB,
			round(100 * ( (df.totalspace - tu.totalusedspace)/ df.totalspace)) precent_free,
			file_name
	from
		(select file_name, tablespace_name, round(sum(bytes) / 1048576) TotalSpace
		 from dba_data_files 
		 group by tablespace_name, file_name) df,
		(select round(sum(bytes)/(1024*1024)) totalusedspace, tablespace_name
		 from dba_segments 
		 group by tablespace_name) tu
	where df.tablespace_name = tu.tablespace_name 
 ) a
 where Tablespace in ('ARCHIVE_T_V01')
 order by tablespace asc
 
 
MIS_RPT_DEV.
'FPA_PROGRAM_LKU','FPA_SECONDARY_PRDCR_LKU'

MIS_DM_RPT
'MV_B_ARR_MAC_MONTHLY','MV_R_CLMDAILY_POA'

 
 
 alter database  datafile '+DATA_WH/MERWHR/DATAFILE/mis_rpt_dev_v01.756.888000573' resize 2762400m;
 
 alter database  datafile '+DATA_WH/MERWHR/DATAFILE/mis_dm_rpt_t_v01.745.888000483' resize 3679664m;
 
 alter database  datafile '+DATA_WH/MERWHR/DATAFILE/claim_weekly_t_v01.678.888000359' resize 60080m;

alter database  datafile '+DATA_WH/MERWHR/DATAFILE/combined_claim_t_v01.685.888000365' resize 60209m;
alter database  datafile '+DATA_WH/MERWHR/DATAFILE/pay_hist_t_v02.1038.888000835' resize 60519m;
alter database  datafile '+DATA_WH/MERWHR/DATAFILE/profit_loss_gross_prv_t_v01.1058.888000963' resize 120448m;
alter database  datafile '+DATA_WH/MERWHR/DATAFILE/rate_fact_wip_t_v01.1071.888000999' resize 19428m;
alter database  datafile '+DATA_WH/MERWHR/DATAFILE/reins_direct_snaps_t_v02.1082.888001899' resize 48752m;
alter database  datafile '+DATA_WH/MERWHR/DATAFILE/retention_fact_wip_t_v01.1091.888001903' resize 41852m;
alter database  datafile '+DATA_WH/MERWHR/DATAFILE/sur_bond_term_cvrg_t_v01.1110.888001929' resize 58351m;
alter database  datafile '+DATA_WH/MERWHR/DATAFILE/sur_misterm_t_v01.1115.888001933' resize 43692m;
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/misterm_t_v01.741.888000481' resize 33000m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/ratg_ftr_add_cr_t_v01.1074.888001019' resize 97140m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/ded_amt_cr_t_v01.705.888000429' resize 110000m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/limit_amount_rq_t_v01.730.888000471' resize 69219m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/suffix_weekly_t_v05.1103.888001925' resize 200000m
  
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/ded_amt_rq_t_v01.707.888000435' resize 59216m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/combined_suffix_t_v01.691.888000379' resize 133059m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/reins_direct_trans_t_v02.1084.888001901' resize 59984m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/mis_earn_out_exp_t_v01.747.888000495' resize 2442560m
  
  
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/suffix_t_v08.1102.888001923' resize 80008m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/ratg_ftr_add_rq_t_v01.1076.888001059' resize 78732m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/arch_rating_factor_rq_t_v01.652.888000297' resize 250000m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/coverage_cr_t_v01.694.888000395' resize 217384m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/suffix_snaps_t_v07.1098.888001911' resize 266240m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/rating_factor_cr_t_v02.1078.888001097' resize 542000m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/combined_suffix_snaps_t_v01.689.888000369' resize 384629m
 
 alter database datafile '+DATA_WH/MERWHR/DATAFILE/suffix_snaps_weekly_t_v04.1099.888001915' resize 378080m
 
select SID,username,OPNAME,SOFAR,TOTALWORK,round(SOFAR/TOTALWORK*100) "Work Done %",
	to_char(START_TIME,'DD-MON-YY hh24:mi:ss') "Start_time",
	to_char(sysdate + TIME_REMAINING/3600/24,'DD-MON-YY hh24:mi:ss') "End_at"
  from v$session_longops
 where sofar!=TOTALWORK
   and totalwork!=0 ;

MIS_RPT_DEV.
'FPA_PROGRAM_LKU','FPA_SECONDARY_PRDCR_LKU'

select *
from dba_tables 
where table_name in ('MV_B_ARR_MAC_MONTHLY','MV_R_CLMDAILY_POA')
  and owner='MIS_DM_RPT'
   
select * from sys.IMPDP_MIS_MERWHR   


select *
from dba_tables 
where table_name in ('FPA_PROGRAM_LKU','FPA_SECONDARY_PRDCR_LKU')
  and owner='MIS_RPT_DEV'

select *
from dba_tables 
where table_name in ('FPA_PROGRAM_LKU','FPA_SECONDARY_PRDCR_LKU')
  and owner='MIS_RPT_DEV'

select * from dba_directories where directory_name='MIS_EXP'


select unique tablespace_name from dba_segments where owner='MIS' order by 1 asc


MIS_EARN_OUT_EXP_T_V01


select owner, round(sum(bytes/1024/1024/1024))size_gb
from dba_segments
where owner in ('ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT','MIS_DM_RPT','MIS')
group by owner


SELECT ROUND(sofar/totalwork*100,2)  percent_completed, 
     v$session_longops.* 
FROM v$session_longops 
WHERE sofar <> totalwork 
ORDER BY target, SID;


select * from sys.JOB$


SELECT "Tablespace Name", "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM(
select  a.tablespace_name "Tablespace Name",
       round(a.bytes_alloc / 1024 / 1024) "Allocated (MB)",
       round(nvl(b.bytes_free, 0) / 1024 / 1024) "Free (MB)",
       round((a.bytes_alloc - nvl(b.bytes_free, 0)) / 1024 / 1024) "Used (MB)",
       round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
       100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Used",
       round(maxbytes/1024 / 1024) "Max. Bytes (MB)"
from  ( select  f.tablespace_name,
               sum(f.bytes) bytes_alloc,
               sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
        from dba_data_files f where tablespace_name not in (select unique tablespace_name from dba_segments where owner='MIS')
        group by tablespace_name) a,
      ( select  f.tablespace_name,
               sum(f.bytes)  bytes_free
        from dba_free_space f where tablespace_name not in (select unique tablespace_name from dba_segments where owner='MIS')
        group by tablespace_name) b
where a.tablespace_name = b.tablespace_name (+)
)
order by 2,6 desc

SELECT File_ID, Tablespace_name, file_name, High_Water_Mark, current_size_in_GB,
    'ALTER DATABASE DATAFILE '''||file_name||''' resize '|| High_Water_Mark|| 'M;' script_reclaim
FROM 
(
    WITH v_file_info
         AS (SELECT FILE_NAME, FILE_ID, BLOCK_SIZE
               FROM dba_tablespaces tbs, dba_data_files df
              WHERE tbs.tablespace_name = df.tablespace_name)
    SELECT A.FILE_ID,
           A.FILE_NAME,
           A.TABLESPACE_NAME,
           CEIL ( (NVL (hwm, 1) * v_file_info.block_size) / 1024 / 1024) High_Water_Mark,
           CEIL (BLOCKS * v_file_info.block_size / 1024 / 1024 /2014) current_size_in_GB
      FROM dba_data_files A,
           v_file_info,
           (  SELECT file_id, MAX (block_id + BLOCKS - 1) hwm
                FROM dba_extents
            GROUP BY file_id) b
     WHERE A.file_id = b.file_id(+) 
       AND A.file_id = v_file_info.file_id
       AND tablespace_name='CLAIMDMS_INDEX' -- << change the tablespace name to reclaim the datafile size
)     
WHERE  High_Water_Mark <> current_size_in_GB


nohup dmts64 -I merwhrsur &


select * from dba_users where account_status like 'MER%'








  CREATE TABLE "MIS_DM_RPT"."MV_B_ARR_MAC_MONTHLY" 
   (	"AR_DIMENSION_SK" NUMBER(38,0) NOT NULL ENABLE, 
	"AR_OPEN_FACT_SK" NUMBER(38,0) NOT NULL ENABLE, 
	"BRANCH_CD" VARCHAR2(3 CHAR), 
	"COMMISSION_AMT" NUMBER(14,2), 
	"DAYS_PAST_DUE" NUMBER, 
	"GROSS_AMT" NUMBER(14,2), 
	"POLICY_NUMBER" VARCHAR2(16 CHAR), 
	"LEGAL_ID" VARCHAR2(3 CHAR), 
	"LEGAL_STATUS_ID" VARCHAR2(5 CHAR), 
	"LEGAL_TRANSFER_DT" DATE, 
	"INSTALLMENT_DT" DATE, 
	"EFFECTIVE_DATE" DATE, 
	"EXPIRATION_DATE" DATE, 
	"PROCESS_BRANCH_CD" VARCHAR2(3 CHAR), 
	"PROCESS_PRODUCER_CD" VARCHAR2(6 CHAR), 
	"SEQUENCE_DATE" DATE, 
	"SEQUENCE_NUMBER" VARCHAR2(9 CHAR), 
	"NET_AMT" NUMBER(14,2), 
	"PROCESS_CYCLE_DT" DATE NOT NULL ENABLE, 
	"PRODUCER_CD" VARCHAR2(6 CHAR), 
	"PRODUCER_SK" NUMBER(38,0) NOT NULL ENABLE, 
	"RECEIVABLE_DUE_DT" DATE, 
	"SEN_US_BRANCH_PRODUCER_IND" CHAR(1 CHAR), 
	"SOURCE_SYS_CD" NUMBER(2,0) NOT NULL ENABLE, 
	"BRANCH_PRODUCER_POLICY" VARCHAR2(21 CHAR), 
	"POLICY_7NBR" VARCHAR2(10 CHAR), 
	"LEGAL_STATUS" VARCHAR2(9 CHAR), 
	"DEBIT_VS_CREDIT" VARCHAR2(1 CHAR), 
	"INSURED_NAME" VARCHAR2(20 CHAR), 
	"POLICY_PREFIX" VARCHAR2(4 CHAR), 
	"CTM_CD" CHAR(1 CHAR), 
	"RECORD_ID" VARCHAR2(2 CHAR), 
	"MAC_REF_CD" CHAR(1 CHAR), 
	"MAC_REF_NBR" VARCHAR2(6 CHAR), 
	"MAC_FUNDING_PLAN_CD" CHAR(1 CHAR), 
	"MAC_FUNDING_PLAN_NBR" CHAR(1 CHAR), 
	"MAC_TRANS_CD" CHAR(1 CHAR), 
	"MAC_HF_BKR_CODE" NUMBER(4,0), 
	"FOREIGN_CURR_AMT" NUMBER(14,2), 
	"FOREIGN_CURR_TYP" VARCHAR2(3 CHAR), 
	"MAC_SPD_REF" VARCHAR2(12 CHAR), 
	"SENATOR_BROKER_CODE" VARCHAR2(7 CHAR), 
	"AIPS_DIST_BRANCH_NAM" VARCHAR2(255 CHAR), 
	"AIPS_DIST_REGION_NAM" VARCHAR2(255 CHAR), 
	"XREF_CODE" VARCHAR2(255 CHAR), 
	"PRODUCER_NAME" VARCHAR2(40 CHAR), 
	"XREF_PRDCR_NAM" VARCHAR2(40 CHAR), 
	"XREF_PRDCR_NBR" NUMBER, 
	"DISTRBN_BR_NAM" VARCHAR2(30 CHAR), 
	"PROGRAM_CD" VARCHAR2(6 CHAR), 
	"PROGRAM_DESCRIPTION" VARCHAR2(30 CHAR), 
	"SEGMENT" VARCHAR2(30 CHAR), 
	"SBU_ROLLUP" VARCHAR2(30 CHAR), 
	"SBU" VARCHAR2(30 CHAR), 
	"PROGRAM_SUMMARY" VARCHAR2(30 CHAR), 
	"TRANS_DESC" VARCHAR2(75 CHAR) NOT NULL ENABLE, 
	"USER_ID" VARCHAR2(10 CHAR), 
	"COLLQ_ITEM_STATUS" VARCHAR2(50 CHAR), 
	"NATIONAL_BROKER_NAME" VARCHAR2(40 CHAR), 
	"NATIONAL_BROKER_CODE" VARCHAR2(5 CHAR), 
	"IF_NOT_PAID_BY_DATE" DATE, 
	"MANAGER_LVL_1" VARCHAR2(50 CHAR), 
	"MANAGER_LVL_2" VARCHAR2(50 CHAR), 
	"MANAGER_LVL_3" VARCHAR2(50 CHAR), 
	"MANAGER_LVL_4" VARCHAR2(50 CHAR), 
	"FULL_NAME" VARCHAR2(50 CHAR), 
	"LOCATION" VARCHAR2(11 CHAR), 
	"CIS_DT" DATE, 
	"REFERENCE_NUMBER" VARCHAR2(14 CHAR), 
	"TRAN_CATEGORY" VARCHAR2(7 CHAR), 
	"PREMIUM_DIARY_CD" VARCHAR2(3 CHAR), 
	"RECV_VS_CASH" VARCHAR2(5 CHAR), 
	"PROCESS_CYCLE_DT_YYYYMM" VARCHAR2(6 CHAR), 
	"EFFECTIVE_DATE_YYYYMMDD" VARCHAR2(8 CHAR), 
	"EXPIRATION_DATE_YYYYMMDD" VARCHAR2(8 CHAR), 
	"RECEIVABLE_DUE_DT_YYYYMMDD" VARCHAR2(8 CHAR), 
	"IF_NOT_PAID_BY_DATE_YYYYMMDD" VARCHAR2(8 CHAR), 
	"POTENTIAL_AGE_DAYS" NUMBER, 
	"AGE_CATEGORY" VARCHAR2(15 CHAR), 
	"ACTUAL_AGE_GROUP" VARCHAR2(8 CHAR), 
	"MBR_AGE_CATEGORY" VARCHAR2(21 CHAR), 
	"RECV_SELECTION" CHAR(8 CHAR), 
	"MEASURE_TYPE_DESCRIPTION" VARCHAR2(13 CHAR), 
	"COLLECTIONS_SEGMENT" VARCHAR2(22 CHAR), 
	"POTENTIAL_EOM_AGE_GROUP" VARCHAR2(8 CHAR), 
	"POTENTIAL_EOM_AGE_CATEGORY" VARCHAR2(17 CHAR), 
	"BUSINESS_SEGMENT" VARCHAR2(25 CHAR)
   ) 
 COMPRESS BASIC NOLOGGING
    TABLESPACE "MIS_DM_RPT_T_V01" ;




select owner, object_type, status, count(*)
  from dba_objects
 where owner in 
('FEEDS_IN','MIS_DM','DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','MIS_DM_RPT',
'MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE','MIS_RPT_DEV','MLBOACTWIP','STAGING')
group by owner, object_type, status
order by owner, object_type asc


SELECT grantee, owner, table_name, grantor, 
        DECODE(grantable, 'YES', 'grant '||(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||' WITH GRANT OPTION;',
                                 'grant '||(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||';') privs_grant
from dba_tab_privs
where grantee in ('FEEDS_IN','MIS_DM','DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','MIS_DM_RPT',
'MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE','MIS_RPT_DEV','MLBOACTWIP','STAGING')


select 'create or replace synonym '||owner||'.'||synonym_name||' for '||table_owner||'.'||table_name||';'
from dba_synonyms
where owner in
('FEEDS_IN','MIS_DM','DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','MIS_DM_RPT',
'MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE','MIS_RPT_DEV','MLBOACTWIP','STAGING')


select 'exec dbms_utility.compile_schema(schema=>'''||username||''');'
  from dba_users
 where username in 
('FEEDS_IN','MIS_DM','DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','MIS_DM_RPT',
'MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE','MIS_RPT_DEV','MLBOACTWIP','STAGING')
order by username asc



select 'exec dbms_stats.gather_schema_stats('''||username||''');'
  from dba_users
 where username in 
('FEEDS_IN','MIS_DM','DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','MIS_DM_RPT',
'MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE','MIS_RPT_DEV','MLBOACTWIP','STAGING')
order by username asc


select owner, object_type, status, count(*)
  from dba_objects
 where owner in 
('FEEDS_IN','MIS_DM','DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','MIS_DM_RPT',
'MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE','MIS_RPT_DEV','MLBOACTWIP','STAGING')
group by owner, object_type, status
order by owner, object_type asc


('FEEDS_IN','MIS_DM','DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','MIS_DM_RPT',
'MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE','MIS_RPT_DEV','MLBOACTWIP','STAGING')


'ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT','MIS_DM_RPT'


'MIS_EARN_OUT_T_V04','RATING_FACTOR_CR_X_V02','AIPS_MISTERM_AUGUST_X_V01','PAFTRANS',
'CR_RQ_T_V01','DIRECT_TRANS_T_V06','DIMENSIONS','PAFTRANS_SUMMARY_T_V01','ARCH_RATING_FACTOR_RQ_X_V01',
'PROFIT_LOSS_SUMM_PRIOR_T_V01'



('ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT','MIS_DM_RPT')


select *
from dba_tab_privs
where grantee in ('FEEDS_IN','MIS_DM','DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','MIS_DM_RPT',
'MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE','MIS_RPT_DEV','MLBOACTWIP','STAGING')


exec dbms_stats.gather_schema_stats(ownname=>'TRANSNOX_IOX', degree=>8, estimate_percent=>50, cascade=>TRUE,granularity=>'ALL');




set serveroutput on
set lines 100 pages 10000
show parameters db_name
declare
	v_SqlSTMT  varchar2(32000);
begin
FOR i IN ( select owner, object_type, object_name
			 from dba_objects 
			where owner in ('AC_STAGING','ARCHIVE','DASH','DASHBOARD','HAL','INFO','MERLINAUI','MISWEB','MISWEBWIP','MLBOACT',
 							'MLBOMAJOR','MLBOWIP','CNACOM_STAGING','MEDBILL','MEDBILL_MITCHELL','RST','CANADA','SURETY_ARCHIVE',
 							'SURETY_STAGING','WCFC','VIATICUS','PRELOAD','STAGING')
			  and OBJECT_TYPE in ('SEQUENCE','PROCEDURE','VIEW','FUNCTION')
			order by OWNER, OBJECT_TYPE ASC)
loop
	begin 
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME;
		execute immediate v_SqlSTMT;
	exception
	  when others then
	  	null;
	end;
	dbms_output.put_line(v_SqlSTMT);
end loop;
end;
/



select owner, object_type, 
  from dba_objects
 where owner in ('ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT','MIS_DM_RPT')
 order by OWNER, OBJECT_TYPE ASC




select owner, object_type, status, count(*)
from dba_objects
where owner in 
('AC_STAGING','ARCHIVE','DASH','DASHBOARD','HAL','INFO','MERLINAUI','MISWEB','MISWEBWIP','MLBOACT',
 'MLBOMAJOR','MLBOWIP','CNACOM_STAGING','MEDBILL','MEDBILL_MITCHELL','RST','CANADA','SURETY_ARCHIVE',
 'SURETY_STAGING','WCFC','VIATICUS','PRELOAD','STAGING')
group by owner, object_type,status




SEQUENCE,PROCEDURE,VIEW,FUNCTION






set serveroutput on
set echo on
set pages 100
exec dbms_utility.compile_schema(schema=>'AC_STAGING');
exec dbms_utility.compile_schema(schema=>'ARCHIVE');
exec dbms_utility.compile_schema(schema=>'CANADA');
exec dbms_utility.compile_schema(schema=>'CNACOM_STAGING');
exec dbms_utility.compile_schema(schema=>'DASH');
exec dbms_utility.compile_schema(schema=>'DASHBOARD');
exec dbms_utility.compile_schema(schema=>'ESIGHT_ADMIN');
exec dbms_utility.compile_schema(schema=>'FEEDS_IN');
exec dbms_utility.compile_schema(schema=>'FEEDS_OUT');
exec dbms_utility.compile_schema(schema=>'HAL');
exec dbms_utility.compile_schema(schema=>'INFO');
exec dbms_utility.compile_schema(schema=>'MEDBILL');
exec dbms_utility.compile_schema(schema=>'MEDBILL_MITCHELL');
exec dbms_utility.compile_schema(schema=>'MERLINAUI');
exec dbms_utility.compile_schema(schema=>'MIS');
exec dbms_utility.compile_schema(schema=>'MISWEB');
exec dbms_utility.compile_schema(schema=>'MISWEBWIP');
exec dbms_utility.compile_schema(schema=>'MIS_DM_RPT');
exec dbms_utility.compile_schema(schema=>'MLBOACT');
exec dbms_utility.compile_schema(schema=>'MLBOMAJOR');
exec dbms_utility.compile_schema(schema=>'MLBOWIP');
exec dbms_utility.compile_schema(schema=>'PRELOAD');
exec dbms_utility.compile_schema(schema=>'RST');
exec dbms_utility.compile_schema(schema=>'STAGING');
exec dbms_utility.compile_schema(schema=>'SURETY_ARCHIVE');
exec dbms_utility.compile_schema(schema=>'SURETY_STAGING');
exec dbms_utility.compile_schema(schema=>'VIATICUS');
exec dbms_utility.compile_schema(schema=>'WCFC');

exec dbms_stats.gather_schema_stats('AC_STAGING');
exec dbms_stats.gather_schema_stats('ARCHIVE');
exec dbms_stats.gather_schema_stats('CANADA');
exec dbms_stats.gather_schema_stats('CNACOM_STAGING');
exec dbms_stats.gather_schema_stats('DASH');
exec dbms_stats.gather_schema_stats('DASHBOARD');
exec dbms_stats.gather_schema_stats('ESIGHT_ADMIN');
exec dbms_stats.gather_schema_stats('FEEDS_IN');
exec dbms_stats.gather_schema_stats('FEEDS_OUT');
exec dbms_stats.gather_schema_stats('HAL');
exec dbms_stats.gather_schema_stats('INFO');
exec dbms_stats.gather_schema_stats('MEDBILL');
exec dbms_stats.gather_schema_stats('MEDBILL_MITCHELL');
exec dbms_stats.gather_schema_stats('MERLINAUI');
exec dbms_stats.gather_schema_stats('MIS');
exec dbms_stats.gather_schema_stats('MISWEB');
exec dbms_stats.gather_schema_stats('MISWEBWIP');
exec dbms_stats.gather_schema_stats('MIS_DM_RPT');
exec dbms_stats.gather_schema_stats('MLBOACT');
exec dbms_stats.gather_schema_stats('MLBOMAJOR');
exec dbms_stats.gather_schema_stats('MLBOWIP');
exec dbms_stats.gather_schema_stats('PRELOAD');
exec dbms_stats.gather_schema_stats('RST');
exec dbms_stats.gather_schema_stats('STAGING');
exec dbms_stats.gather_schema_stats('SURETY_ARCHIVE');
exec dbms_stats.gather_schema_stats('SURETY_STAGING');
exec dbms_stats.gather_schema_stats('VIATICUS');
exec dbms_stats.gather_schema_stats('WCFC');

<end node> 5P9i0s8y19Z
dt=Text
<node>
ACL Networks
3
-- Below is the script to take the ACL backup, Below script will generate the output and that output will be the backup
-- we have to execute the script in bot the DBs before import (refresh)

All the Merline (MERWHR and MERDMR) Activities should be carried on Node 2 where connectiones on weekend will be lesser
-- you might have to investigate for the busy node, by check the connection count on both the nodes and take the decision

1) MERWHR
2) MERDMR

-- copy the below script into on .sql and login to sqlplus "'/as sysdba'" and execute it 

vi acl_bkup_MerlinRef_script.sql

set serveroutput on
declare
v_param_list varchar2(2000);
cursor rec_c ( i_ACLID dba_network_acl_privileges.ACLID%type, i_ACL dba_network_acl_privileges.ACL%type ) is
select rownum POSITION , 
ACL,
PRINCIPAL,
decode(privilege,'use-cli','use-client-certificates','use-pas','use-passwords',privilege) PRIVILEGE,
IS_GRANT,INVERT,
decode(START_DATE,null,'null','to_timestamp_tz('''||to_char(START_DATE,'YYYYMMDDHH24MISSXFFTZR')||''',''YYYYMMDDHH24MISSXFF TZR'')') START_DATE,
decode(END_DATE,null,'null','to_timestamp_tz('''||to_char(END_DATE,'YYYYMMDDHH24MISSXFFTZR'||''',''YYYYMMDDHH24MISSXFF TZR'')')) END_DATE
from dba_network_acl_privileges a 
where a.ACLID = i_ACLID and a.ACL = i_ACL ;

rec rec_c%rowtype ;

begin

DBMS_OUTPUT.PUT_LINE(' ');
DBMS_OUTPUT.PUT_LINE('--- MerlineRef DR WareHouse MERWHR ACL Networks Backup  ');
DBMS_OUTPUT.PUT_LINE('ACL Network Backups for Date : ' || to_char(sysdate,'mm/dd/yyyy hh24:mi:ss'));
DBMS_OUTPUT.PUT_LINE(' ');
DBMS_OUTPUT.PUT_LINE(' ');

   for i in ( select distinct ACLID,ACL from dba_network_acl_privileges ) loop
     open rec_c ( i.ACLID , i.acl ) ;
     fetch rec_c into rec;
      v_param_list:='acl=>'''||substr(rec.acl,instr(rec.acl,'/',-1)+1)||'''';
      v_param_list:=v_param_list||',description=>'''||substr(rec.acl,11,length(rec.acl))||'''';
      v_param_list:=v_param_list||',principal=>'''||rec.principal||'''';
      v_param_list:=v_param_list||',privilege=>'''||rec.privilege||'''';
      v_param_list:=v_param_list||',is_grant=>'||rec.is_grant;
      v_param_list:=v_param_list||',start_date=>'||rec.END_DATE;
      v_param_list:=v_param_list||',end_date=>'||rec.END_DATE||');';
      dbms_output.put_line('exec dbms_network_acl_admin.create_acl('||v_param_list);
      -- fetch rec_c into rec ; NOT FETCHING HERE TO AVOID DUPLICATES 
         while rec_c%FOUND loop
             v_param_list:='acl=>'''||substr(rec.acl,instr(rec.acl,'/',-1)+1)||'''';
             v_param_list:=v_param_list||',principal=>'''||rec.principal||'''';
             v_param_list:=v_param_list||',is_grant=>'||rec.is_grant;
             v_param_list:=v_param_list||',privilege=>'''||rec.privilege||'''';
             v_param_list:=v_param_list||',position=>'||rec.POSITION;
             v_param_list:=v_param_list||',start_date=>'||rec.END_DATE;
             v_param_list:=v_param_list||',end_date=>'||rec.END_DATE||');';
             dbms_output.put_line('exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE('||v_param_list);
             fetch rec_c into rec ;
         end loop;
       close rec_c ;

    for rec2 in (select HOST,decode(LOWER_PORT,null,'null',to_char(LOWER_PORT))LOWER_PORT,decode(UPPER_PORT,null,'null',to_char(UPPER_PORT))UPPER_PORT,ACL,ACLID
                 from dba_network_acls 
                 where acl = i.acl and ACLID= i.aclid) loop
                    v_param_list:='acl=>'''||substr(rec2.acl,instr(rec2.acl,'/',-1)+1)||''',host=>'''||rec2.host||''',lower_port=>'||rec2.lower_port||',upper_port=>'||rec2.upper_port||');';
                    dbms_output.put_line('exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL('||v_param_list);
    end loop;

  end loop;
end;
/

SQL> @acl_backup_script.sql

<end node> 5P9i0s8y19Z
dt=Text
<node>
MERDMR Refresh
3

-- MERDMR


-- IMP Note: This has to be executed on Merwhp DB so it will be calculating the stats before starting the MerlinRef Activity
EXEC DBMS_STATS.GATHER_DICTIONARY_STATS;
EXEC DBMS_STATS.GATHER_SYSTEM_STATS;
EXEC DBMS_STATS.GATHER_FIXED_OBJECTS_STATS (null); 

safe export backup of merDMR
DB server: mrlndrtdbadm04
location : /u01/oracle/zfs-dr/datapump/temp_expdp/Merlin_DataMart_merDMR_SafeBkup.par

[oracle@mrlndrtdbadm04 temp_expdp]$ ps -ef |grep pmon

[oracle@mrlndrtdbadm04 temp_expdp]$ . oraenv
ORACLE_SID = [MERDMR2] ? MERDMR2
The Oracle base remains unchanged with value /u01/oracle
[oracle@mrlndrtdbadm04 temp_expdp]$

[oracle@mrlndrtdbadm04 temp_expdp]$cd /u01/oracle/zfs-dr/datapump/temp_expdp/safebkp
7 -rw-r--r--+ 1 oracle oinstall 350 Sep  1 15:17 Merlin_DataMart_merDMR_SafeBkup.par

--- modify the parfile as per the documented schemas, document will be send by customer
--- put clusert=n 
--- Mostly at weekend on Instance 2 (Node 2) there are less connectivity from Application end
--- So Node 2 is not busy and so we can perform the Merlin refresh on Node 2

1) Step :
--- merDMR
-- modify the export dumpfile name as per expdp_MerlinRef_merDMR_SafeBkup_<<ddMONyyyy>>.dmp
[oracle@mrlndrtdbadm04 temp_expdp]$ cat Merlin_DataMart_merDMR_SafeBkup.par
dumpfile=expdp_MerlineRef_DataMart_merDMR_SafeBkup_02Mar2021_%U.dmp
logfile=expdp_MerlineRef_DataMart_merDMR_SafeBkup_02Mar2021_logs.log
directory=MERLINE_REF_SAFEBKUP
schemas=MIS_DM,FEEDS_IN,DART_ADMIN,EXEC_DASHBOARD_ADMIN,EXEC_DASHBOARD_ADMIN_WIP,MIS_DM_RPT,MERLINDASH,MERLINDASHWIP,MIS_DM_READ,MIS_DM_USER,MIS_DM_WRITE,MIS_RPT_DEV,MLBOACT,MLBOACTWIP,STAGING
exclude=statistics
parallel=8
CLUSTER=N
compression=ALL

2) Step :
-- Check if the directory exists, if not create the same on the location as MERLINE_REF_SAFEBKUP
[oracle@mrlndrtdbadm04 datapump]$ sqlplus "/as sysdba"

SQL> set lines 32000 pages 1000
SQL> col directory_name for a30
SQL> col directory_path for a70
SQL> select directory_name, directory_path from dba_directories where directory_name like 'MERLINE_REF_SAFEBKUP';

DIRECTORY_NAME                 DIRECTORY_PATH
------------------------------ ----------------------------------------------------------------------
MERLINE_REF_SAFEBKUP            /u01/oracle/zfs-dr/datapump/temp_expdp

cd /u01/oracle/zfs-dr/datapump/temp_expdp

3) Step :
-- check the free space if it's limited then remove the older *.dmp files
df -h /u01/oracle/zfs-dr/datapump/temp_expdp

4) Step :
-- modify the job_name as ddMONyy and run the safe export for merDMR
nohup expdp "'/as sysdba'" parfile=/u01/oracle/zfs-dr/datapump/temp_expdp/Merlin_DataMart_merDMR_SafeBkup.par job_name=MerlineRef_merDMR_02Mar2021 & 

5) Step : 
-- Take the ACL Networks backup using below script, Once the output is generated copy it and save into some file on the same location 
[oracle@mrlndrtdbadm04 temp_expdp]$ cd /u01/oracle/zfs-dr/datapump/temp_expdp
[oracle@mrlndrtdbadm04 temp_expdp]$
[oracle@mrlndrtdbadm04 temp_expdp]$ vi acl_bkup_MerlinRef_merDMR_script.sql
[oracle@mrlndrtdbadm04 temp_expdp]$
[oracle@mrlndrtdbadm04 temp_expdp]$ pwd
/u01/oracle/zfs-dr/datapump/temp_expdp
[oracle@mrlndrtdbadm04 temp_expdp]$
[oracle@mrlndrtdbadm04 temp_expdp]$ sqlplus "/as sysdba"

SQL*Plus: Release 12.1.0.2.0 Production on Sun Sep 1 16:38:23 2019

Copyright (c) 1982, 2014, Oracle.  All rights reserved.


Connected to:
Oracle Database 12c Enterprise Edition Release 12.1.0.2.0 - 64bit Production
With the Partitioning, Real Application Clusters, Automatic Storage Management, OLAP,
Advanced Analytics and Real Application Testing options

SQL> @acl_bkup_MerlinRef_merDMR_script.sql;
NAME                                               TYPE        VALUE                                                                                                
-------------------------------------------------- ----------- -----------------------
db_name                                            string      MERDMR                                                                                               
 
--- MerlineRef DR WareHouse MERWHR ACL Networks Backup  
ACL Network Backups for Date : 07/26/2020 08:40:51
 
 
exec dbms_network_acl_admin.create_acl(acl=>'ops$fnmpaudit.xml',description=>'ops$fnmpaudit.xml',principal=>'OPS$FNMPAUDIT',privilege=>'resolve',is_grant=>true,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ops$fnmpaudit.xml',principal=>'OPS$FNMPAUDIT',is_grant=>true,privilege=>'resolve',position=>1,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ops$fnmpaudit.xml',host=>'10.20.39.*',lower_port=>null,upper_port=>null);
exec dbms_network_acl_admin.create_acl(acl=>'ldap_calls.xml',description=>'ldap_calls.xml',principal=>'ENKITEC',privilege=>'connect',is_grant=>true,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'ENKITEC',is_grant=>true,privilege=>'connect',position=>1,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'ENKITEC',is_grant=>true,privilege=>'resolve',position=>2,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS_RPT_DEV',is_grant=>true,privilege=>'connect',position=>3,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS_RPT_DEV',is_grant=>true,privilege=>'resolve',position=>4,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS_DM_RPT',is_grant=>true,privilege=>'connect',position=>5,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS_DM_RPT',is_grant=>true,privilege=>'resolve',position=>6,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS_DM',is_grant=>true,privilege=>'connect',position=>7,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS_DM',is_grant=>true,privilege=>'resolve',position=>8,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'drt-ldap-tam60.cna.com',lower_port=>null,upper_port=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'prd-ldap-tam60.cna.com',lower_port=>null,upper_port=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'ete.ldap.cna.com',lower_port=>390,upper_port=>390);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'cut.ldap.cna.com',lower_port=>389,upper_port=>389);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'ldap.cna.com',lower_port=>null,upper_port=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'cna.com',lower_port=>389,upper_port=>389);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'dr.ldap.cna.com',lower_port=>null,upper_port=>null);
exec dbms_network_acl_admin.create_acl(acl=>'NETWORK_ACL_1D87C7D6A961E256E0537A27140AD2DD',description=>'L_1D87C7D6A961E256E0537A27140AD2DD',principal=>'GSMADMIN_INTERNAL',privilege=>'resolve',is_grant=>true,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_1D87C7D6A961E256E0537A27140AD2DD',principal=>'GSMADMIN_INTERNAL',is_grant=>true,privilege=>'resolve',position=>1,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'NETWORK_ACL_1D87C7D6A961E256E0537A27140AD2DD',host=>'*',lower_port=>null,upper_port=>null);
exec dbms_network_acl_admin.create_acl(acl=>'fnmpaudit.xml',description=>'fnmpaudit.xml',principal=>'OPS$FNMPAUDIT',privilege=>'resolve',is_grant=>true,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'fnmpaudit.xml',principal=>'OPS$FNMPAUDIT',is_grant=>true,privilege=>'resolve',position=>1,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'fnmpaudit.xml',principal=>'FNMPAUDIT',is_grant=>true,privilege=>'resolve',position=>2,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'fnmpaudit.xml',host=>'localhost',lower_port=>null,upper_port=>null);


SQL> exit

-- Copy the above content into one file acl_network_merDMR_bkup.log (This might be different for MERWHR DB)

[oracle@mrlndrtdbadm04 temp_expdp]$vi acl_bkup_MerlinRef_merDMR_output.log

-----------------------------------------------------------------------------------------------------

6) Step :
-- Send out a email for updates and take a email confirmation to start the activity
-- There might be possiblity that application team might not be facing any issues jobs delayed so we can start the refresh activity 
-- at mentioned timings

7) Step :
-- Start the export as per mentioned in the document
-- start with 5schema_dataOnly export as that's the huge export

-- execute the export one-by-one 

-- MAKE SURE TO CHANGE EXPORT/IMPORT JOB_NAME paramers else will get error sys.**** job table already exsists
-- if so you got the error login as sys as sysdba and drop the table
-- drop table sys.****; and restart the export/import

[oracle@mrlnprddbadm04 MERDMP]$ pwd
/zfs_aur_dp1/MERDMP

[oracle@mrlnprddbadm04 MERDMP]$ cat MerlinRef_MERDMP_FeedsIn_MisDm.par
dumpfile=expdp_MerlineRef_MERDMP_DataOnly_02Mar2021_%U.dmp
logfile=expdp_MerlineRef_MERDMP_DataOnly_02Mar2021_logs.log
directory=MER_EXP
schemas=FEEDS_IN,MIS_DM
parallel=8
CLUSTER=N
compression=all
EXCLUDE=DB_LINK,STATISTICS

OR
--- /u01/oracle/zfs-prod/datapump/temp_expdp, if /zfs_aur_dp1/MERDMP is busy and not responding 
dumpfile=expdp_MrlNRf_MERDMP_FeedsIn_MISDM_02Mar2021_%U.dmp
logfile=expdp_MrlNRf_MERDMP_FeedsIn_MISDM_02Mar2021_logs.log
directory=TEMP_EXPDP1
schemas=FEEDS_IN,MIS_DM
parallel=8
CLUSTER=N
EXCLUDE=DB_LINK,STATISTICS
compression=all


nohup expdp "'/as sysdba'" parfile=MerlinRef_MERDMP_FeedsIn_MisDm.par job_name=MerRfsh_MDMP_02Mar2021 & 
OR
nohup expdp "'/as sysdba'" parfile=/u01/oracle/zfs-prod/datapump/temp_expdp/MerlinRef_MERDMP_FeedsIn_MisDm.par job_name=MerRfsh_MDMP_02Mar2021v3 & 

[oracle@mrlnprddbadm04 MERDMP]$ ls -larts *.par
1 -rw-r--r-- 1 oracle oinstall 333 Apr 24 22:20 MerlinRef_MERDMP_Metadata.par
1 -rw-r--r-- 1 oracle oinstall 174 Sep  2 03:10 MerlinRef_MERDMP_FeedsIn_MisDm.par
[oracle@mrlnprddbadm04 MERDMP]$ cat MerlinRef_MERDMP_Metadata.par
dumpfile=expdp_MerlineRef_MerDMP_Metadata_02Mar2021_%U.dmp
logfile=expdp_MerlineRef_MerDMP_Metadata_02Mar2021_logs.log
directory=MER_EXP
schemas=(DART_ADMIN,EXEC_DASHBOARD_ADMIN,EXEC_DASHBOARD_ADMIN_WIP,MIS_DM_RPT,MERLINDASH,MERLINDASHWIP,MIS_DM_READ,MIS_DM_USER,MIS_DM_WRITE,MIS_RPT_DEV,MLBOACT,MLBOACTWIP,STAGING) 
parallel=8
CLUSTER=N
EXCLUDE=DB_LINK
content=METADATA_ONLY
compression=METADATA_ONLY

nohup expdp "'/as sysdba'" parfile=/zfs_aur_dp1/MERDMP/MerlinRef_MERDMP_Metadata.par job_name=MerRfsh_MERDMP_MD1 &
OR
nohup expdp "'/as sysdba'" parfile=/u01/oracle/zfs-prod/datapump/temp_expdp/MerlinRef_MERDMP_Metadata.par job_name=MerRfsh_MERDMP_MD1 &

8) Step :
-- copy all export dumpfiles (Data and Metadata) from prod zfs to drt zfs mount points.

-- You can always modify the copy script as per the export dumpfiles naming conventions
-- location : /u01/oracle/zfs-dr/datapump/temp_expdp is the location on merDMR DB servers
[oracle@mrlnprddbadm04 MERDMP]$ pwd
/zfs_aur_dp1/MERDMP
[oracle@mrlnprddbadm04 MERDMP]$
[oracle@mrlnprddbadm04 MERDMP]$ cat cp_expdp_MerlinRef_MERDMP_2_MERDMR.ksh
#!/bin/ksh
date
cp MERDMP_EXPDP_01.dmp /u01/oracle/zfs-dr/datapump_new/temp_expdp
date
cp MERDMP_EXPDP_02.dmp /u01/oracle/zfs-dr/datapump_new/temp_expdp
date
cp MERDMP_EXPDP_03.dmp /u01/oracle/zfs-dr/datapump_new/temp_expdp
date
cp MERDMP_EXPDP_04.dmp /u01/oracle/zfs-dr/datapump_new/temp_expdp
date
cp MERDMP_EXPDP_05.dmp /u01/oracle/zfs-dr/datapump_new/temp_expdp
date
cp MERDMP_EXPDP_06.dmp /u01/oracle/zfs-dr/datapump_new/temp_expdp
date
cp MERDMP_EXPDP_07.dmp /u01/oracle/zfs-dr/datapump_new/temp_expdp
date
cp MERDMP_EXPDP_08.dmp /u01/oracle/zfs-dr/datapump_new/temp_expdp
date
cp expdp_MerlinRef_MerDMP_Metadata_02Mar2021_01.dmp /u01/oracle/zfs-dr/datapump_new/temp_expdp
date

9) Step :
-- give the execute permissions for the cp file
[oracle@mrlnprddbadm04 MERDMP]$ chmod +x cp_expdp_MerlinRef_MERDMP_2_MERDMR.ksh

10) Step :
-- start copying the export dumpfiles 
[oracle@mrlnprddbadm04 MERDMP]$ ./cp_expdp_MerlinRef_MERDMP_2_MERDMR.ksh 
[oracle@mrlnprddbadm04 MERDMP]$ ps -ef |grep cp_expdp*
oracle   226675  99852  0 14:08 pts/0    00:00:00 /bin/ksh ./cp_expdp_MerlinRef_MERDMP_2_MERDMR.ksh
oracle   236587  99852  0 14:10 pts/0    00:00:00 grep cp_expdp_MerlinRef_MERDMP_2_MERDMR.ksh

-- check which export dumpfile is been copied
[oracle@mrlnprddbadm04 MERDMP]$ ps -ef |grep -e " cp MERDMP_EXPDP_0*"
oracle   226678 226675  8 14:08 pts/0    00:00:16 cp MERDMP_EXPDP_01.dmp /u01/oracle/zfs-dr/datapump_new/temp_expdp
oracle   241314  99852  0 14:11 pts/0    00:00:00 grep -e  cp MERDMP_EXPDP_0*
[oracle@mrlnprddbadm04 MERDMP]$

11) Step :
-- Take the object counts and status on MERDMP database using the below query and store it on below location

[oracle@mrlnprddbadm04 MERDMP]$ pwd
/zfs_aur_dp1/MERDMP

sqlplus "/as sysdba"

SELECT owner, object_type,status, count(*)
from dba_objects
where owner in ('FEEDS_IN','MIS_DM','DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','MIS_DM_RPT','MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE','MIS_RPT_DEV','MLBOACT','MLBOACTWIP','STAGING')
group by  owner, object_type,status
order by owner, object_type asc;

MERDMP

                      OWNER           OBJECT_TYPE     STATUS    COUNT(*)
___________________________ _____________________ __________ ___________
DART_ADMIN                  INDEX                 VALID               32
DART_ADMIN                  PROCEDURE             VALID                8
DART_ADMIN                  TABLE                 VALID               32
DART_ADMIN                  VIEW                  VALID                2
EXEC_DASHBOARD_ADMIN        INDEX                 VALID               30
EXEC_DASHBOARD_ADMIN        LOB                   VALID                1
EXEC_DASHBOARD_ADMIN        PACKAGE               VALID                1
EXEC_DASHBOARD_ADMIN        PACKAGE BODY          VALID                1
EXEC_DASHBOARD_ADMIN        SEQUENCE              VALID                7
EXEC_DASHBOARD_ADMIN        SYNONYM               INVALID              1
EXEC_DASHBOARD_ADMIN        SYNONYM               VALID                1
EXEC_DASHBOARD_ADMIN        TABLE                 VALID               66
EXEC_DASHBOARD_ADMIN        VIEW                  VALID                3
EXEC_DASHBOARD_ADMIN_WIP    INDEX                 VALID               24
EXEC_DASHBOARD_ADMIN_WIP    LOB                   VALID                1
EXEC_DASHBOARD_ADMIN_WIP    PACKAGE               VALID                1
EXEC_DASHBOARD_ADMIN_WIP    PACKAGE BODY          VALID                1
EXEC_DASHBOARD_ADMIN_WIP    SEQUENCE              VALID                7
EXEC_DASHBOARD_ADMIN_WIP    SYNONYM               INVALID              1
EXEC_DASHBOARD_ADMIN_WIP    SYNONYM               VALID                2
EXEC_DASHBOARD_ADMIN_WIP    TABLE                 VALID               39
EXEC_DASHBOARD_ADMIN_WIP    VIEW                  VALID                3
FEEDS_IN                    TABLE                 VALID               33
MERLINDASH                  SYNONYM               INVALID            136
MERLINDASH                  SYNONYM               VALID              180
MERLINDASHWIP               SYNONYM               INVALID            125
MERLINDASHWIP               SYNONYM               VALID              203
MIS_DM                      DATABASE LINK         VALID                4
MIS_DM                      FUNCTION              VALID               30
MIS_DM                      INDEX                 VALID             2830
MIS_DM                      INDEX PARTITION       VALID             1407
MIS_DM                      LOB                   VALID                5
MIS_DM                      PACKAGE               VALID               17
MIS_DM                      PACKAGE BODY          INVALID              1
MIS_DM                      PACKAGE BODY          VALID               16
MIS_DM                      PROCEDURE             INVALID              8
MIS_DM                      PROCEDURE             VALID               72
MIS_DM                      SEQUENCE              VALID               19
MIS_DM                      SYNONYM               VALID               20
MIS_DM                      TABLE                 VALID             1446
MIS_DM                      TABLE PARTITION       VALID              103
MIS_DM                      VIEW                  INVALID            266
MIS_DM                      VIEW                  VALID               64
MIS_DM_READ                 SYNONYM               INVALID             50
MIS_DM_READ                 SYNONYM               VALID              317
MIS_DM_RPT                  DATABASE LINK         VALID                5
MIS_DM_RPT                  FUNCTION              VALID                3
MIS_DM_RPT                  INDEX                 VALID             5099
MIS_DM_RPT                  INDEX PARTITION       VALID            24803
MIS_DM_RPT                  INDEX SUBPARTITION    VALID            10256
MIS_DM_RPT                  LOB                   VALID              105
MIS_DM_RPT                  PACKAGE               VALID               41
MIS_DM_RPT                  PACKAGE BODY          INVALID              9
MIS_DM_RPT                  PACKAGE BODY          VALID               31
MIS_DM_RPT                  PROCEDURE             INVALID             40
MIS_DM_RPT                  PROCEDURE             VALID              473
MIS_DM_RPT                  SEQUENCE              VALID                2
MIS_DM_RPT                  SYNONYM               VALID                4
MIS_DM_RPT                  TABLE                 VALID             2805
MIS_DM_RPT                  TABLE PARTITION       VALID             2393
MIS_DM_RPT                  TABLE SUBPARTITION    VALID              792
MIS_DM_RPT                  TYPE                  VALID               13
MIS_DM_RPT                  TYPE BODY             VALID                1
MIS_DM_RPT                  VIEW                  INVALID             18
MIS_DM_RPT                  VIEW                  VALID               28
MIS_DM_USER                 DATABASE LINK         VALID                5
MIS_DM_WRITE                SYNONYM               INVALID             46
MIS_DM_WRITE                SYNONYM               VALID              335
MIS_RPT_DEV                 DATABASE LINK         VALID               54
MIS_RPT_DEV                 FUNCTION              INVALID              3
MIS_RPT_DEV                 FUNCTION              VALID               17
MIS_RPT_DEV                 INDEX                 VALID              550
MIS_RPT_DEV                 INDEX PARTITION       VALID             6040
MIS_RPT_DEV                 LOB                   VALID              143
MIS_RPT_DEV                 MATERIALIZED VIEW     INVALID              1
MIS_RPT_DEV                 MATERIALIZED VIEW     VALID                2
MIS_RPT_DEV                 PACKAGE               INVALID              1
MIS_RPT_DEV                 PACKAGE               VALID               68
MIS_RPT_DEV                 PACKAGE BODY          INVALID             32
MIS_RPT_DEV                 PACKAGE BODY          VALID               36
MIS_RPT_DEV                 PROCEDURE             INVALID            183
MIS_RPT_DEV                 PROCEDURE             VALID              989
MIS_RPT_DEV                 SEQUENCE              VALID                8
MIS_RPT_DEV                 SYNONYM               INVALID             16
MIS_RPT_DEV                 SYNONYM               VALID               50
MIS_RPT_DEV                 TABLE                 VALID             4444
MIS_RPT_DEV                 TABLE PARTITION       VALID              410
MIS_RPT_DEV                 TABLE SUBPARTITION    VALID              288
MIS_RPT_DEV                 TRIGGER               VALID               75
MIS_RPT_DEV                 TYPE                  INVALID              2
MIS_RPT_DEV                 TYPE                  VALID               87
MIS_RPT_DEV                 TYPE BODY             INVALID              1
MIS_RPT_DEV                 TYPE BODY             VALID                4
MIS_RPT_DEV                 VIEW                  INVALID             32
MIS_RPT_DEV                 VIEW                  VALID               59
MLBOACT                     SYNONYM               INVALID            252
MLBOACT                     SYNONYM               VALID              935
MLBOACTWIP                  SYNONYM               INVALID             51
MLBOACTWIP                  SYNONYM               VALID              180
STAGING                     FUNCTION              VALID                1
STAGING                     INDEX                 VALID              469
STAGING                     LOB                   VALID               12
STAGING                     PROCEDURE             INVALID              6
STAGING                     PROCEDURE             VALID               13
STAGING                     SYNONYM               VALID                1
STAGING                     TABLE                 VALID             1400
STAGING                     TABLE PARTITION       VALID               23
STAGING                     TRIGGER               VALID                5

108 rows selected.

-- copy the above output and store the same in the belo log file
[oracle@mrlnprddbadm04 MERDMP]$ vi merRfsh_MERDMP_and_MERDMR_objs_count.logs
[oracle@mrlndrtdbadm04 temp_expdp]$ vi merRfsh_MERDMP_and_MERDMR_objs_count.logs
[oracle@mrlndrtdbadm04 temp_expdp]$ pwd
/u01/oracle/zfs-dr/datapump/temp_expdp
[oracle@mrlndrtdbadm04 temp_expdp]$


11) Step : --- MERDMR
-- Now go to merDMR database and start dropping the objects Please use the below script for dropping purpose
-- you can always change/modify the script as per schemans and object mentioned in the provided document
--'FEEDS_IN','MIS_DM'
[oracle@mrlndrtdbadm04 ~]$ sqlplus "/as sysdba"
SQL>
set serveroutput on
set lines 32000 pages 10000
show parameters db_name
declare
	v_SqlSTMT  varchar2(32000);
begin
FOR i IN ( select owner, object_type, object_name
			 from dba_objects 
			where owner in ('DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP',	'MIS_DM_RPT','MERLINDASH','MERLINDASHWIP',
							'MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE','MIS_RPT_DEV','MLBOACT','MLBOACTWIP','STAGING')
			  and OBJECT_TYPE in ('VIEW','PROCEDURE','SEQUENCE','FUNCTION','SYNONYM','MATERIALIZED VIEW','PACKAGE','PACKAGE BODY','TYPE','TRIGGER')
			order by OWNER, OBJECT_TYPE ASC)
loop
	begin 
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME;
		execute immediate v_SqlSTMT;
	exception
	  when others then
	  	null;
	end;
	dbms_output.put_line(v_SqlSTMT);
end loop;
end;
/

-- After dropping the objects from listed schemas, Check the objects if any not dropped.

12) Step :
-- before starting the import on MERDMR Convert the database from Archive to NO Archivelog 
---  Disable Archive Log Mode
[oracle@mrlndrtdbadm04 temp_expdp]$ sqlplus "/as sysdba"

--- convert archivelog mode to no archivelog mode into RAC systems
--login to instance
sqlplus "/as sysdba"

SQL> alter system set CLUSTER_DATABASE=FALSE scope=spfile sid='*'; 

srvctl stop database -d merdmr -stopoption immediate

. oraenv
MERDMR2

sqlplus "/as sysdba"

SQL> startup mount
SQL> alter database noarchivelog;
SQL> alter system set CLUSTER_DATABASE=TRUE scope=spfile sid='*';
SQL> shutdown immediate;

srvctl start database -d merdmr

SQL> set lines 500 pages 500
SQL> col HOST_NAME for a25
select inst_id, instance_name, host_name,
         to_char(startup_time, 'mm/dd/yyyy hh24:mi:ss') "Startup time"
from gv$instance;
SQL>   2    3
   INST_ID INSTANCE_NAME    HOST_NAME                 Startup time
---------- ---------------- ------------------------- -------------------
         2 MERDMR2          mrlndrtdbadm04.cna.com    09/03/2019 07:53:08
         1 MERDMR1          mrlndrtdbadm03.cna.com    09/03/2019 07:53:07

SQL> archive log list;
Database log mode              No Archive Mode
Automatic archival             Disabled
Archive destination            USE_DB_RECOVERY_FILE_DEST
Oldest online log sequence     72376
Current log sequence           72379
SQL>

set serveroutput on
declare 
	v_SqlSTMT  varchar2(32000);
begin
FOR i IN (select owner, object_type, object_name
			from dba_objects 
			where owner in ('FEEDS_IN','MIS_DM')
			  and object_type in ('TABLE','VIEW','TRIGGER','PROCEDURE','FUNCTION','PACKAGE','PACKAGE BODY','SEQUENCE','MATERIALIZED VIEW')
			ORDER BY OWNER, OBJECT_TYPE ASC)
loop
	begin 
	  if i.object_type='TABLE' then
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME||' cascade constraint';
	  else
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME;
	  end if;
		execute immediate v_SqlSTMT;
	exception
	  when others then
	  	null;
	end;
	dbms_output.put_line(v_SqlSTMT);
end loop;
end;
/

13) Step :
-- Start the bigger import of data only
-- Make very sure you have not take the export of DB_LINK if at-total you have taken add exclude=db_link in the import parfile
[oracle@mrlndrtdbadm04 temp_expdp]$ cat par_MerlinRef_merDMR_DataOnly_impdp.par
dumpfile=expdp_MrlNRf_MERDMP_FeedsIn_MISDM_02Mar2021_%U.dmp
logfile=impdp_MrlNRf_MERDMP_FeedsIn_MISDM_02Mar2021_logs.log
directory=MER_EXP
schemas=FEEDS_IN,MIS_DM
table_exists_action=replace
parallel=16
CLUSTER=N

nohup impdp "'/as sysdba'" parfile=/u01/oracle/zfs-dr/datapump/temp_expdp/par_MerlinRef_merDMR_DataOnly_impdp.par job_name=impdp_DO_mDMR02Mar2021 &



-- before executing step 14) execute the below first on merdmr DB
select owner, object_type,status, count(*)
from dba_objects
where owner in ('DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','MIS_DM_RPT','MERLINDASH',
'MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE','MIS_RPT_DEV','MLBOACTWIP','STAGING')
group by owner, object_type,status
order by owner, object_type asc;

set serveroutput on
declare
	v_SqlSTMT  varchar2(32000);
begin
FOR i IN ( select owner, object_type, object_name
			 from dba_objects 
			where owner in ('DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','MIS_DM_RPT','MERLINDASH',
							'MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE','MIS_RPT_DEV','MLBOACTWIP','STAGING')
			  and OBJECT_TYPE in ('VIEW','PROCEDURE','SEQUENCE','FUNCTION','SYNONYM','MATERIALIZED VIEW','PACKAGE','PACKAGE BODY','TYPE','TRIGGER')
			order by OWNER, OBJECT_TYPE ASC)
loop
	begin 
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME;
		execute immediate v_SqlSTMT;
	exception
	  when others then
	  	null;
	end;
	dbms_output.put_line(v_SqlSTMT);
end loop;
end;
/

14) Step :
-- start prepairing for importing the metadata
[oracle@mrlndrtdbadm04 temp_expdp]$ vi par_MerlinRef_merDMR_Metadata_import.par
dumpfile=expdp_MerlineRef_MERDMP_DataOnly_02Mar2021_%U.dmp
logfile=impdp_MerlinRef_merDMR_MetadataOnly_02Mar2021_logs.log
directory=MER_EXP
schemas=(DART_ADMIN,EXEC_DASHBOARD_ADMIN,EXEC_DASHBOARD_ADMIN_WIP,MIS_DM_RPT,MERLINDASH,MERLINDASHWIP,MIS_DM_READ,MIS_DM_USER,MIS_DM_WRITE,MIS_RPT_DEV,MLBOACTWIP,STAGING)
parallel=8
CLUSTER=N
include=SEQUENCE,PROCEDURE,PACKAGE,PACKAGE_BODY,TYPE_BODY,SYNONYM,VIEW,FUNCTION,TYPE

nohup impdp "'/as sysdba'" parfile=/u01/oracle/zfs-dr/datapump/temp_expdp/par_MerlinRef_merDMR_Metadata_import.par job_name=impdp_MDO_mDMR02Mar2021 &



-- take the count of MERDMP and MERDMR and compare them
select owner, object_type, status, count(*)
  from dba_objects
 where owner in 
			('DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','FEEDS_IN','MIS_DM',
			'MIS_DM_RPT','MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE',
			'MIS_RPT_DEV','MLBOACT','MLBOACTWIP','STAGING')
group by owner, object_type, status
order by owner, object_type asc

- generate the grant privilleges script from merwhp and execute it on merwhr
SELECT -- grantee, owner, table_name, grantor, 
        DECODE(grantable, 'YES', 'grant '||(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||' WITH GRANT OPTION;',
                                 'grant '||(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||';') privs_grant
from dba_tab_privs
where grantee in
			('DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','FEEDS_IN','MIS_DM',
			'MIS_DM_RPT','MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE',
			'MIS_RPT_DEV','MLBOACT','MLBOACTWIP','STAGING')
  and not regexp_like(table_name,'BIN\$','i')
union all
-- generate the synonym script merwhp and execute the same on merwhr
select 'create or replace synonym '||owner||'.'||synonym_name||' for '||table_owner||'.'||table_name||';'
from dba_synonyms
where owner in
			('DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','FEEDS_IN','MIS_DM',
			'MIS_DM_RPT','MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE',
			'MIS_RPT_DEV','MLBOACT','MLBOACTWIP','STAGING')
  and not regexp_like(table_name,'BIN\$','i')
 union all
select 'create or replace public synonym '||synonym_name||' for '||table_owner||'.'||table_name||';'
from dba_synonyms
where table_owner in
			('DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','FEEDS_IN','MIS_DM',
			'MIS_DM_RPT','MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE',
			'MIS_RPT_DEV','MLBOACT','MLBOACTWIP','STAGING')
  and not regexp_like(table_name,'BIN\$','i')
;

-- Once the aboce script of Grant s and Synonyms are executed on MERDMR
-- Compile all the required schemas
select 'exec dbms_utility.compile_schema(schema=>'''||username||''');'
  from dba_users
 where username in 
			('DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','FEEDS_IN','MIS_DM',
			'MIS_DM_RPT','MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE',
			'MIS_RPT_DEV','MLBOACT','MLBOACTWIP','STAGING')
order by username asc;

-- generate the schema gather stats script of MERDMR
-- and execute it on Node 2 server with SYSDBA
select 'exec dbms_stats.gather_schema_stats('''||username||''');'
  from dba_users
 where username in 
			('DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','FEEDS_IN','MIS_DM',
			'MIS_DM_RPT','MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE',
			'MIS_RPT_DEV','MLBOACT','MLBOACTWIP','STAGING')
order by username asc

-- again check and compare the MERDMP and MERDMR for objects count
select owner, object_type, status, count(*)
  from dba_objects
 where owner in 
			('DART_ADMIN','EXEC_DASHBOARD_ADMIN','EXEC_DASHBOARD_ADMIN_WIP','FEEDS_IN','MIS_DM',
			'MIS_DM_RPT','MERLINDASH','MERLINDASHWIP','MIS_DM_READ','MIS_DM_USER','MIS_DM_WRITE',
			'MIS_RPT_DEV','MLBOACT','MLBOACTWIP','STAGING')
group by owner, object_type, status
order by owner, object_type asc



--- convert archivelog mode to no archivelog mode into RAC systems
--login to instance
sqlplus "/as sysdba"

SQL> alter system set CLUSTER_DATABASE=FALSE scope=spfile sid='*'; 

srvctl stop database -d merdmr -stopoption immediate

. oraenv
MERDMR2

sqlplus "/as sysdba"

SQL> startup mount
SQL>
SQL> alter database archivelog;
SQL>
SQL> archive log list;
SQL>
SQL> alter system set CLUSTER_DATABASE=TRUE scope=spfile sid='*'; 
SQL> shutdown immediate;

srvctl start database -d merdmr

SQL> set lines 500 pages 500
SQL> col HOST_NAME for a25
select inst_id, instance_name, host_name,
         to_char(startup_time, 'mm/dd/yyyy hh24:mi:ss') "Startup time"
from gv$instance;
SQL>   2    3
   INST_ID INSTANCE_NAME    HOST_NAME                 Startup time
---------- ---------------- ------------------------- -------------------
         2 MERDMR2          mrlndrtdbadm04.cna.com    09/03/2019 07:53:08
         1 MERDMR1          mrlndrtdbadm03.cna.com    09/03/2019 07:53:07

SQL> archive log list;
Database log mode              No Archive Mode
Automatic archival             Disabled
Archive destination            USE_DB_RECOVERY_FILE_DEST
Oldest online log sequence     72376
Current log sequence           72379
SQL>

-----------------------------------------------------------------------------------
-- Final Steps

-- copying the sqlfile and parameters files on mentioned vslr* servers


-- sqlfiles 
vslrau1p015.cna.com

sudo su - exadba

cd /apps/exadba/dba_cmds/merdmp

tar -cvf dart_admin_MAR2021.tar dart_admin 
tar -cvf exec_dashboard_admin_MAR2021.tar exec_dashboard_admin 
tar -cvf exec_dashboard_admin_wip_MAR2021.tar exec_dashboard_admin_wip 
tar -cvf feeds_in_MAR2021.tar feeds_in 
tar -cvf mis_dm_MAR2021.tar mis_dm 
tar -cvf mis_dm_rpt_MAR2021.tar mis_dm_rpt 
tar -cvf staging_MAR2021.tar staging 
tar -cvf idm_dm_MAR2021.tar idm_dm 
tar -cvf idm_feeds_out_MAR2021.tar idm_feeds_out 
tar -cvf idm_staging_MAR2021.tar idm_staging 

gzip *MAR2021.tar  

scp *MAR2021.tar.gz vslrch1d028.cna.com:/apps/exadba/dba_cmds/merdmr

=======================================================================
-- login to of the cluster vslrch1d028 or vslrch1d029

-- vslrch1d028

cd /apps/exadba/dba_cmds/merdmr

mv  dart_admin dart_admin_MAR2021
mv  exec_dashboard_admin exec_dashboard_admin_MAR2021
mv  exec_dashboard_admin_wip exec_dashboard_admin_wip_MAR2021
mv  feeds_in feeds_in_MAR2021
mv  mis_dm mis_dm_MAR2021
mv  mis_dm_rpt mis_dm_rpt_MAR2021
mv  staging staging_MAR2021
mv  idm_dm idm_dm_MAR2021
mv  idm_feeds_out idm_feeds_out_MAR2021
mv  idm_staging idm_staging_MAR2021

gzip -d *MAR2021.tar.gz 


tar -xvf dart_admin_MAR2021.tar 
tar -xvf exec_dashboard_admin_MAR2021.tar 
tar -xvf exec_dashboard_admin_wip_MAR2021.tar 
tar -xvf feeds_in_MAR2021.tar 
tar -xvf mis_dm_MAR2021.tar 
tar -xvf mis_dm_rpt_MAR2021.tar 
tar -xvf staging_MAR2021.tar 
tar -xvf idm_dm_MAR2021.tar 
tar -xvf idm_feeds_out_MAR2021.tar 
tar -xvf idm_staging_MAR2021.tar


chmod -R 755 dart_admin 
chmod -R 755 exec_dashboard_admin 
chmod -R 755 exec_dashboard_admin_wip 
chmod -R 755 feeds_in 
chmod -R 755 mis_dm 
chmod -R 755 mis_dm_rpt 
chmod -R 755 staging 
chmod -R 755 idm_dm 
chmod -R 755 idm_feeds_out 
chmod -R 755 idm_staging 


-----------------------------------------------------------------------------------------

-- parameter files

vslrau1p015.cna.com

cd /apps/exadba/dba_cmds/

mkdir MERDMR_control_MAR2021

cp dba_cmds.control.merdmp.dart_admin  MERDMR_control_MAR2021/dba_cmds.control.merdmr.dart_admin
cp dba_cmds.control.merdmp.exec_dashboard_admin   MERDMR_control_MAR2021/dba_cmds.control.merdmr.exec_dashboard_admin
cp dba_cmds.control.merdmp.exec_dashboard_admin_wip MERDMR_control_MAR2021/dba_cmds.control.merdmr.exec_dashboard_admin_wip
cp dba_cmds.control.merdmp.feeds_in  MERDMR_control_MAR2021/dba_cmds.control.merdmr.feeds_in
cp dba_cmds.control.merdmp.mis_dm   MERDMR_control_MAR2021/dba_cmds.control.merdmr.mis_dm
cp dba_cmds.control.merdmp.mis_dm_rpt  MERDMR_control_MAR2021/dba_cmds.control.merdmr.mis_dm_rpt
cp dba_cmds.control.merdmp.staging   MERDMR_control_MAR2021/dba_cmds.control.merdmr.staging
cp dba_cmds.control.merdmp.idm_dm   MERDMR_control_MAR2021/dba_cmds.control.merdmr.idm_dm
cp dba_cmds.control.merdmp.idm_feeds_out  MERDMR_control_MAR2021/dba_cmds.control.merdmr.idm_feeds_out
cp dba_cmds.control.merdmp.idm_staging   MERDMR_control_MAR2021/dba_cmds.control.merdmr.idm_staging

$ pwd
/apps/exadba/dba_cmds
$ ls -larts  MERDMR_control_MAR2021

=======================================================================
-- login to of the cluster vslrch1d028 or vslrch1d029

-- vslrch1d028

cd /apps/exadba/dba_cmds/

mkdir bkp_merdmr_control_MAR2021

mv dba_cmds.control.merdmr.dart_admin                bkp_merdmr_control_MAR2021
mv dba_cmds.control.merdmr.exec_dashboard_admin      bkp_merdmr_control_MAR2021
mv dba_cmds.control.merdmr.exec_dashboard_admin_wip  bkp_merdmr_control_MAR2021
mv dba_cmds.control.merdmr.feeds_in                  bkp_merdmr_control_MAR2021
mv dba_cmds.control.merdmr.mis_dm                    bkp_merdmr_control_MAR2021
mv dba_cmds.control.merdmr.mis_dm_rpt                bkp_merdmr_control_MAR2021
mv dba_cmds.control.merdmr.staging                   bkp_merdmr_control_MAR2021
mv dba_cmds.control.merdmr.idm_dm                    bkp_merdmr_control_MAR2021
mv dba_cmds.control.merdmr.idm_feeds_out             bkp_merdmr_control_MAR2021
mv dba_cmds.control.merdmr.idm_staging               bkp_merdmr_control_MAR2021

$ pwd
/apps/exadba/dba_cmds
$ ls -larts bkp_merdmr_control_MAR2021


-- login to vslrau1p015 production server
cd /apps/exadba/dba_cmds/MERDMR_control_MAR2021

scp /apps/exadba/dba_cmds/MERDMR_control_MAR2021/*.* vslrch1d028.cna.com:/apps/exadba/dba_cmds

---*/ login to vslrch1d028
cd /apps/exadba/dba_cmds/

chmod 644 dba_cmds.control.merdmr.dart_admin
chmod 644 dba_cmds.control.merdmr.exec_dashboard_admin
chmod 644 dba_cmds.control.merdmr.exec_dashboard_admin_wip
chmod 644 dba_cmds.control.merdmr.feeds_in
chmod 644 dba_cmds.control.merdmr.idm_dm
chmod 644 dba_cmds.control.merdmr.idm_feeds_out
chmod 644 dba_cmds.control.merdmr.idm_staging
chmod 644 dba_cmds.control.merdmr.mis_dm
chmod 644 dba_cmds.control.merdmr.mis_dm_rpt
chmod 644 dba_cmds.control.merdmr.staging

<end node> 5P9i0s8y19Z
dt=Text
<node>
MERWHR Refresh
3

-- MERWHR

-- IMP Note: This has to be executed on Merwhp DB so it will be calculating the stats before starting the MerlinRef Activity
EXEC DBMS_STATS.GATHER_DICTIONARY_STATS;
EXEC DBMS_STATS.GATHER_SYSTEM_STATS;
EXEC DBMS_STATS.GATHER_FIXED_OBJECTS_STATS (null); 


safe export backup of MERWHR
DB server: mrlndrtdbadm02
location : /u01/oracle/zfs-dr/datapump/temp_expdp/Merlin_DRWareHouse_MERWHR_SafeBkup.par

[oracle@mrlndrtdbadm02 temp_expdp]$ ps -ef |grep pmon

[oracle@mrlndrtdbadm02 temp_expdp]$ . oraenv
ORACLE_SID = [MERWHR2] ? MERWHR2
The Oracle base remains unchanged with value /u01/oracle
[oracle@mrlndrtdbadm02 temp_expdp]$

[oracle@mrlndrtdbadm02 temp_expdp]$cd /u01/oracle/zfs-dr/datapump/temp_expdp/
7 -rw-r--r--+ 1 oracle oinstall 455 Sep  1 15:09 Merlin_DRWareHouse_MERWHR_SafeBkup.par

--- modify the parfile as per the documented schemas, document will be send by customer
--- put clusert=n 
--- Mostly at weekend on Instance 2 (Node 2) there are less connectivity from Application end
--- So Node 2 is not busy and so we can perform the Merlin refresh on Node 2

1) Step :
--- MERWHR
-- modify the export dumpfile name as per expdp_MerlinRef_MERWHR_SafeBkup_<<ddMONyyyy>>.dmp
[oracle@mrlndrtdbadm02 datapump]$ cat Merlin_DRWareHouse_MERWHR_SafeBkup.par
dumpfile=expdp_MerlinRef_MERWHR_SafeBkup_03022021_%U.dmp
logfile=expdp_MerlinRef_MERWHR_SafeBkup_03022021_logs.log
directory=MERLINE_REF_SAFEBKUP
schemas=AC_STAGING,ARCHIVE,DASH,DASHBOARD,ESIGHT_ADMIN,FEEDS_IN,FEEDS_OUT,MIS,HAL,MIS_DM_RPT,MISWEB,MISWEBWIP,CNACOM_STAGING,MEDBILL,MEDBILL_MITCHELL,RST,CANADA,SURETY_ARCHIVE,SURETY_STAGING,PRELOAD,STAGING
exclude=statistics
parallel=10
CLUSTER=N
compression=ALL


2) Step :
-- Check if the directory exists, if not create the same on the location as MERLINE_REF_SAFEBKUP
[oracle@mrlndrtdbadm02 datapump]$ sqlplus "/as sysdba"

SQL> set lines 32000 pages 1000
SQL> col directory_name for a30
SQL> col directory_path for a70
SQL> select directory_name, directory_path from dba_directories where directory_name like 'MERLINE_REF_SAFEBKUP';

DIRECTORY_NAME                 DIRECTORY_PATH
------------------------------ ----------------------------------------------------------------------
MERLINE_REF_SAFEBKUP                         /u01/oracle/zfs-dr/datapump/temp_expdp

cd /u01/oracle/zfs-dr/datapump/temp_expdp

3) Step :
-- check the free space if it's limited then remove the older *.dmp files
df -h /u01/oracle/zfs-dr/datapump/temp_expdp

4) Step :
-- Start export and modify the job_name as ddMONyy and run the safe export for MERWHR
nohup expdp "'/as sysdba'" parfile=/u01/oracle/zfs-dr/datapump/temp_expdp/Merlin_DRWareHouse_MERWHR_SafeBkup.par job_name=MerRfsh_MWHR_03022021 &

5) Step : 
-- Take the ACL Networks backup using below script, Once the output is generated copy it and save into some file on the same location 
[oracle@mrlndrtdbadm02 temp_expdp]$ cd /u01/oracle/zfs-dr/datapump/temp_expdp
[oracle@mrlndrtdbadm02 temp_expdp]$
[oracle@mrlndrtdbadm02 temp_expdp]$ vi acl_bkup_MerlinRef_merWHR_script.sql
[oracle@mrlndrtdbadm02 temp_expdp]$
[oracle@mrlndrtdbadm02 temp_expdp]$ pwd
/u01/oracle/zfs-dr/datapump/temp_expdp
[oracle@mrlndrtdbadm02 temp_expdp]$
[oracle@mrlndrtdbadm02 temp_expdp]$ sqlplus "/as sysdba"

SQL*Plus: Release 12.1.0.2.0 Production on Sun Sep 1 16:38:23 2019

Copyright (c) 1982, 2014, Oracle.  All rights reserved.


Connected to:
Oracle Database 12c Enterprise Edition Release 12.1.0.2.0 - 64bit Production
With the Partitioning, Real Application Clusters, Automatic Storage Management, OLAP,
Advanced Analytics and Real Application Testing options

SQL> @acl_bkup_MerlinRef_merWHR_script.sql;
 
--- MerlineRef DR WareHouse MERWHR ACL Networks Backup  
ACL Network Backups for Date : 07/26/2020 08:39:20
 
 
exec dbms_network_acl_admin.create_acl(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',description=>'L_57C993E5FAB96FB0E0537827140A4BEC',principal=>'ENKITEC',privilege=>'connect',is_grant=>true,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',principal=>'ENKITEC',is_grant=>true,privilege=>'connect',position=>1,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',principal=>'ENKITEC',is_grant=>true,privilege=>'resolve',position=>2,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',principal=>'AIM',is_grant=>true,privilege=>'connect',position=>3,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',principal=>'AIM',is_grant=>true,privilege=>'resolve',position=>4,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',principal=>'MIS_RPT_DEV',is_grant=>true,privilege=>'connect',position=>5,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',principal=>'MIS_RPT_DEV',is_grant=>true,privilege=>'resolve',position=>6,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',principal=>'MIS_DM_RPT',is_grant=>true,privilege=>'connect',position=>7,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',principal=>'MIS_DM_RPT',is_grant=>true,privilege=>'resolve',position=>8,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',principal=>'MIS',is_grant=>true,privilege=>'connect',position=>9,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',principal=>'MIS',is_grant=>true,privilege=>'resolve',position=>10,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',principal=>'MIS_DM',is_grant=>true,privilege=>'connect',position=>11,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',principal=>'MIS_DM',is_grant=>true,privilege=>'resolve',position=>12,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'NETWORK_ACL_57C993E5FAB96FB0E0537827140A4BEC',host=>'mailhost.cna.com',lower_port=>25,upper_port=>25);
exec dbms_network_acl_admin.create_acl(acl=>'NETWORK_ACL_1D87C7D6A961E256E0537A27140AD2DD',description=>'L_1D87C7D6A961E256E0537A27140AD2DD',principal=>'GSMADMIN_INTERNAL',privilege=>'resolve',is_grant=>true,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'NETWORK_ACL_1D87C7D6A961E256E0537A27140AD2DD',principal=>'GSMADMIN_INTERNAL',is_grant=>true,privilege=>'resolve',position=>1,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'NETWORK_ACL_1D87C7D6A961E256E0537A27140AD2DD',host=>'*',lower_port=>null,upper_port=>null);
exec dbms_network_acl_admin.create_acl(acl=>'ldap_calls.xml',description=>'ldap_calls.xml',principal=>'MEDBILL_CONDUENT',privilege=>'connect',is_grant=>true,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MEDBILL_CONDUENT',is_grant=>true,privilege=>'connect',position=>1,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MEDBILL_CONDUENT',is_grant=>true,privilege=>'resolve',position=>2,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'ALTERYX_SERVICE',is_grant=>true,privilege=>'connect',position=>3,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'ALTERYX_SERVICE',is_grant=>true,privilege=>'resolve',position=>4,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'AIM',is_grant=>true,privilege=>'connect',position=>5,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'AIM',is_grant=>true,privilege=>'resolve',position=>6,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS',is_grant=>true,privilege=>'connect',position=>7,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS',is_grant=>true,privilege=>'resolve',position=>8,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS_DM',is_grant=>true,privilege=>'resolve',position=>9,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS_DM',is_grant=>true,privilege=>'connect',position=>10,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS_DM_RPT',is_grant=>true,privilege=>'resolve',position=>11,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS_DM_RPT',is_grant=>true,privilege=>'connect',position=>12,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS_RPT_DEV',is_grant=>true,privilege=>'resolve',position=>13,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'MIS_RPT_DEV',is_grant=>true,privilege=>'connect',position=>14,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'ENKITEC',is_grant=>true,privilege=>'resolve',position=>15,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ldap_calls.xml',principal=>'ENKITEC',is_grant=>true,privilege=>'connect',position=>16,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'drt-ldap-tam60.cna.com',lower_port=>null,upper_port=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'ete.ldap.cna.com',lower_port=>390,upper_port=>390);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'prd-ldap-tam60.cna.com',lower_port=>null,upper_port=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'ldap.cna.com',lower_port=>null,upper_port=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'cut.ldap.cna.com',lower_port=>389,upper_port=>389);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'dr.ldap.cna.com',lower_port=>null,upper_port=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ldap_calls.xml',host=>'cna.com',lower_port=>389,upper_port=>389);
exec dbms_network_acl_admin.create_acl(acl=>'fnmpaudit.xml',description=>'fnmpaudit.xml',principal=>'ORACLE_OCM',privilege=>'resolve',is_grant=>true,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'fnmpaudit.xml',principal=>'ORACLE_OCM',is_grant=>true,privilege=>'resolve',position=>1,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'fnmpaudit.xml',principal=>'FNMPAUDIT',is_grant=>true,privilege=>'resolve',position=>2,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'fnmpaudit.xml',principal=>'OPS$FNMPAUDIT',is_grant=>true,privilege=>'resolve',position=>3,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'fnmpaudit.xml',host=>'localhost',lower_port=>null,upper_port=>null);
exec dbms_network_acl_admin.create_acl(acl=>'ops$fnmpaudit.xml',description=>'ops$fnmpaudit.xml',principal=>'OPS$FNMPAUDIT',privilege=>'resolve',is_grant=>true,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE(acl=>'ops$fnmpaudit.xml',principal=>'OPS$FNMPAUDIT',is_grant=>true,privilege=>'resolve',position=>1,start_date=>null,end_date=>null);
exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL(acl=>'ops$fnmpaudit.xml',host=>'10.20.39.*',lower_port=>null,upper_port=>null);

SQL> exit

-- Copy the above content into one file acl_network_merDMR_bkup.log (This might be different for MERWHR DB)

[oracle@mrlndrtdbadm02 temp_expdp]$vi acl_bkup_MerlinRef_merWHR_output.log

-----------------------------------------------------------------
-- MERDMR database
--- Now start safe export backup for MERDMR database
-----------------------------------------------------------------

6) Step :
-- Send out a email for updates and take a email confirmation to start the activity
-- There might be possiblity that application team might not be facing any issues jobs delayed so we can start the refresh activity 
-- at mentioned timings


7) Step :
-- Start the export as per mentioned in the document
-- start with 5schema_dataOnly export as that's the huge export

-- execute the export one-by-one 

[oracle@mrlnprddbadm02 MIS]$
[oracle@mrlnprddbadm02 MIS]$ pwd
/zfs_aur_dp5/MIS
[oracle@mrlnprddbadm02 MIS]$ ls -larts *.par
1 -rwxr-xr-x 1 oracle oinstall  390 Apr 18 18:11 par_MerlinRef_MERWHP_MetadataOnly.par
1 -rw-r--r-- 1 oracle oinstall  239 Sep  4 05:57 par_MerlinRef_MERWHR_4Schemas.par
1 -rw-r--r-- 1 oracle oinstall  195 Sep  4 06:30 par_expdp_MerlinRef_merWHP_2_merWHR.par
1 -rwxr-xr-x 1 oracle oinstall  517 Sep  4 21:17 par_MerlinRef_MERWHP_Tables_DataOnly.par
[oracle@mrlnprddbadm02 MIS]$

8) Step : -- 4 schemas export
-- Below is the cat of the parfiles, we can always mofify the parfile based on provided document to add/remove the schemas and the information
[oracle@mrlnprddbadm02 MIS]$ cat par_merRfsh_MWHP_3Schema.par
dumpfile=expdp_MerlineRef_MERWHP_3schemas_03022021_%U.dmp
logfile=expdp_MerlineRef_MERWHP_3schemas_03022021_logs.log
directory=MIS_EXP
schemas=ESIGHT_ADMIN,FEEDS_IN,FEEDS_OUT
parallel=16
CLUSTER=N
EXCLUDE=DB_LINK,STATISTICS


nohup expdp "'/as sysdba'" parfile=/zfs_aur_dp5/MIS/par_merRfsh_MWHP_3Schema.par job_name=MerRfsh_MWHP_03022021 &

9) Step : -- MIS schema export
-- cd /zfs_aur_dp5/MIS -- MIS_EXP directory
oracle@mrlnprddbadm02 MIS]$ cat par_expdp_merlinRefresh_MERWHP_MIS.par
dumpfile=expdp_MerlineRef_MERWHP_MIS_schema_03022021_%U.dmp
logfile=expdp_MerlineRef_MERWHP_MIS_schema_03022021_logs.log
directory=MIS_EXP
schemas=MIS
parallel=16
CLUSTER=N
EXCLUDE=DB_LINK,STATISTICS
compression=all

nohup expdp "'/as sysdba'" parfile=/zfs_aur_dp5/MIS/par_expdp_merlinRefresh_MERWHP_MIS.par job_name=MrlnRf_MERWHP_03022021 &

9) Step : -- selected tables export for data only 
[oracle@mrlnprddbadm02 MIS]$ cat par_MerlinRef_MERWHP_Tables_DataOnly.par
dumpfile=expdp_MerlineRef_MERWHP_Selected_Tables_DataOnly_03022021_%U.dmp
logfile=expdp_MerlineRef_MERWHP_Selected_Tables_DataOnly_03022021_logs.log
directory=MIS_EXP
tables=STAGING.P2T_CONTROL_TOTALS_MAP,STAGING.CONTROL_TOTALS,PRELOAD.PL_POL_VRSN_CR,PRELOAD.PL_GL_EXPOS_UOM_TRANS_LKU,PRELOAD.PL_SOURCE_SYSTEM_LKU,PRELOAD.PL_TAP_GL_EXPOS_SBJ_TRANS_LKU,PRELOAD.PL_PLEDGE_WC_DED_LKU,PRELOAD.PL_PLEDGE_WC_EL_LIMITS_LKU,PRELOAD.PL_PLEDGE_WC_MARITM_EL_LMT_LKU
exclude=statistics
parallel=8
CLUSTER=N
compression=DATA_ONLY


nohup expdp "'/as sysdba'" parfile=/zfs_aur_dp5/MIS/par_MerlinRef_MERWHP_Tables_DataOnly.par job_name=MerRfsh_MWHP_seltd_Tbls_DO &

10) Step : 
[oracle@mrlnprddbadm02 MIS]$ cat par_MerlinRef_MERWHP_MetadataOnly.par
dumpfile=expdp_MerlineRef_MERWHP_MetadataOnly_03022021_%U.dmp
logfile=expdp_MerlineRef_MERWHP_MetadataOnly_03022021_logs.log
directory=MIS_EXP
schemas=(AC_STAGING,ARCHIVE,DASH,DASHBOARD,HAL,MIS_DM_RPT,MISWEB,MISWEBWIP,CNACOM_STAGING,MEDBILL,MEDBILL_MITCHELL,RST,CANADA,SURETY_ARCHIVE,SURETY_STAGING,PRELOAD,STAGING)
exclude=db_link,statistics
parallel=16
CLUSTER=N
content=METADATA_ONLY
compression=METADATA_ONLY

nohup expdp "'/as sysdba'" parfile=/zfs_aur_dp5/MIS/par_MerlinRef_MERWHP_MetadataOnly.par job_name=MerRfsh_MERwhp_MDO_03022021 &


--------------------

10) Step : 
-- Take the object counts and status on MERWHP database using the below query and store it on below location

[oracle@mrlnprddbadm02 MIS]$ pwd
/zfs_aur_dp5/MIS

sqlplus "/as sysdba"

SELECT owner, object_type,status, count(*)
from dba_objects
where owner in ('AC_STAGING','ARCHIVE','DASH','DASHBOARD','ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT',
				'MIS','HAL','MIS_DM_RPT','MISWEB','MISWEBWIP','CNACOM_STAGING','MEDBILL',
				'MEDBILL_MITCHELL','RST','CANADA','SURETY_ARCHIVE','SURETY_STAGING','PRELOAD',
				'STAGING')
group by  owner, object_type,status
order by owner, object_type asc;

-- save the above query result into below files
[oracle@mrlnprddbadm02 MIS]$ vi MerRfsh_Objs_N_Count_mWHP_and_mWHR.log


--- start transferring 4schemas export dumpfiles to target (MERWHR) DB server node 2
-- /u01/oracle/zfs-dr/datapump/MIS location on MERWHR
[oracle@mrlnprddbadm02 MIS]$ pwd
/zfs_aur_dp5/MIS

[oracle@mrlnprddbadm02 MIS]$ cat cp_MerlinRef_MerWHP_4schema_expdp_files.ksh
#!/bin/ksh
date
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_10.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_07.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_11.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_15.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_06.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_12.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_16.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_08.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_13.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_05.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_14.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_04.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_03.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_02.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_01.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlineRef_MERWHP_4schemas_27Apr2020_09.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
date

[oracle@mrlnprddbadm02 MIS]$ chmod +x cp_MerlinRef_MerWHP_4schema_expdp_files.ksh

[oracle@mrlnprddbadm02 MIS]$ ./cp_MerlinRef_MerWHP_4schema_expdp_files.ksh &

[oracle@mrlnprddbadm02 MIS]$ ps -ef |grep -e "expdp_MerlineRef_MERWHP_4schemas*"
oracle    14019  14016 33 12:23 pts/0    00:00:11 cp expdp_MerlineRef_MERWHP_4schemas_01.dmp /u01/oracle/zfs-dr/datapump_new/MIS
oracle    19540 201514  0 12:24 pts/0    00:00:00 grep -e expdp_MerlineRef_MERWHP_4schemas*
[oracle@mrlnprddbadm02 MIS]$



[oracle@mrlnprddbadm02 MIS]$ chmod +x cp_MerlinRef_MERWHP_MIS_Schema_files.ksh

[oracle@mrlnprddbadm02 MIS]$ cat cp_MerlinRef_MERWHP_MIS_Schema_files.ksh

nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_01.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_02.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_03.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_04.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_05.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_06.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_07.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_08.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_09.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_10.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_11.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_12.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_13.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_14.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_15.dmp /u01/oracle/zfs-dr/datapump_new/MIS &
nohup cp /zfssa/zfs-prod-db/db01/MIS/expdp_MerlineRef_MERWHP_5schemas_05Mar2021_v4_16.dmp /u01/oracle/zfs-dr/datapump_new/MIS &

jobs

[oracle@mrlnprddbadm02 MIS]$ ./cp_MerlinRef_MERWHP_MIS_Schema_files.ksh &


[oracle@mrlnprddbadm02 MIS]$ chmod +x cp_MerlinRef_MERWHP_Selected_Tables_DataOnly.ksh
[oracle@mrlnprddbadm02 MIS]$ cat cp_MerlinRef_MERWHP_Selected_Tables_DataOnly.ksh
#!/bin/ksh
date
date
cp expdp_MerlinRef_MERWHP_Selected_Tables_DataOnly_27Apr2020_07.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlinRef_MERWHP_Selected_Tables_DataOnly_27Apr2020_06.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlinRef_MERWHP_Selected_Tables_DataOnly_27Apr2020_05.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlinRef_MERWHP_Selected_Tables_DataOnly_27Apr2020_02.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlinRef_MERWHP_Selected_Tables_DataOnly_27Apr2020_01.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlinRef_MERWHP_Selected_Tables_DataOnly_27Apr2020_03.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
cp expdp_MerlinRef_MERWHP_Selected_Tables_DataOnly_27Apr2020_04.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date
date

[oracle@mrlnprddbadm02 MIS]$ ./cp_MerlinRef_MERWHP_Selected_Tables_DataOnly.ksh &

[oracle@mrlnprddbadm02 MIS]$ chmod +x cp_MerlinRef_MERWHP_Metadata_Only.ksh
[oracle@mrlnprddbadm02 MIS]$ vi cp_MerlinRef_MERWHP_Metadata_Only.ksh
[oracle@mrlnprddbadm02 MIS]$ cat cp_MerlinRef_MERWHP_Metadata_Only.ksh
#!/bin/ksh
date
cp expdp_000_MerlinRef_MerWHP_Metadata_01.dmp /u01/oracle/zfs-dr/datapump_new/MIS
date

[oracle@mrlnprddbadm02 MIS]$ ./cp_MerlinRef_MERWHP_Metadata_Only.ksh &


-- Conver the MERWHR database into NO archivelog MODE--- convert archivelog mode to no archivelog mode into RAC systems
--login to instance
sqlplus "/as sysdba"

SQL> alter system set CLUSTER_DATABASE=FALSE scope=spfile sid='*'; 

srvctl stop database -d merwhr -stopoption immediate

. oraenv
MERWHR2

sqlplus "/as sysdba"

SQL> startup mount
SQL> alter database noarchivelog;
SQL> alter system set CLUSTER_DATABASE=TRUE scope=spfile sid='*'; 
SQL> shutdown immediate;

srvctl start database -d merwhr

set lines 500 pages 500
col HOST_NAME for a25
select inst_id, instance_name, host_name,
         to_char(startup_time, 'mm/dd/yyyy hh24:mi:ss') "Startup time"
from gv$instance;
SQL>  

   INST_ID INSTANCE_NAME    HOST_NAME                 Startup time
---------- ---------------- ------------------------- -------------------
         1 MERWHR1          mrlndrtdbadm01.cna.com    03/04/2021 20:09:59
         2 MERWHR2          mrlndrtdbadm02.cna.com    03/04/2021 20:10:0

SQL> archive log list;
Database log mode              No Archive Mode
Automatic archival             Disabled
Archive destination            USE_DB_RECOVERY_FILE_DEST
Oldest online log sequence     72376
Current log sequence           72379
SQL>


[oracle@mrlndrtdbadm02 sql]$ sqlplus "/as sysdba"

SQL*Plus: Release 12.1.0.2.0 Production on Thu Sep 5 11:44:47 2019

Copyright (c) 1982, 2014, Oracle.  All rights reserved.


Connected to:
Oracle Database 12c Enterprise Edition Release 12.1.0.2.0 - 64bit Production
With the Partitioning, Real Application Clusters, Automatic Storage Management, OLAP,
Advanced Analytics and Real Application Testing options

SQL> show parameters db_name

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
db_name                              string      MERWHR
SQL> col owner for a10
SQL> select owner,object_type, status,count(*) 
	from dba_objects 
	where owner='MIS' 
	group by owner, object_type, status 
	order by 4 desc;

MERWHR

OWNER      OBJECT_TYPE             STATUS    COUNT(*)
---------- ----------------------- ------- ----------
MIS        TABLE                   VALID         3957
MIS        INDEX                   VALID         3097
MIS        INDEX PARTITION         VALID         2033
MIS        TABLE PARTITION         VALID          367
MIS        SEQUENCE                VALID           77
MIS        VIEW                    INVALID         30
MIS        LOB                     VALID           20
MIS        VIEW                    VALID           15
MIS        PACKAGE                 VALID            9
MIS        PACKAGE BODY            VALID            9
MIS        FUNCTION                VALID            2
MIS        DATABASE LINK           VALID            2
MIS        PROCEDURE               VALID            1

13 rows selected.


-----------------------

MERWHP

   OWNER        OBJECT_TYPE     STATUS    COUNT(*)
________ __________________ __________ ___________
MIS      TABLE              VALID             3958
MIS      INDEX              VALID             3097
MIS      INDEX PARTITION    VALID             2033
MIS      TABLE PARTITION    VALID              367
MIS      SEQUENCE           VALID               77
MIS      VIEW               VALID               35
MIS      LOB                VALID               28
MIS      VIEW               INVALID             10
MIS      PACKAGE            VALID                9
MIS      PACKAGE BODY       VALID                9
MIS      FUNCTION           VALID                2
MIS      DATABASE LINK      VALID                2
MIS      PROCEDURE          VALID                1

13 rows selected.


-----------------------------------------------------------

SQL> set serveroutput on
SQL> set lines 100 pages 10000
SQL> show parameters db_name

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
db_name                              string      MERWHR
SQL>
set serveroutput on
declare 
	v_SqlSTMT  varchar2(32000);
begin
FOR i IN (select owner, object_type, object_name
			from dba_objects 
			where owner in ('MIS')
			  and object_type in ('TABLE','TABLE PARTITION','VIEW','TRIGGER','PROCEDURE','FUNCTION','PACKAGE','PACKAGE BODY','SEQUENCE','MATERIALIZED VIEW')
			ORDER BY OWNER, OBJECT_TYPE ASC)
loop
	begin 
	  if i.object_type='TABLE' then
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME||' cascade constraint';
	  else
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME;
	  end if;
		execute immediate v_SqlSTMT;
	exception
	  when others then
	  	null;
	end;
	dbms_output.put_line(v_SqlSTMT);
end loop;
end;
/


SQL>  select owner,object_type, status,count(*) from dba_objects where owner='MIS' group by owner, object_type, status order by 4 desc;

OWNER      OBJECT_TYPE             STATUS    COUNT(*)
---------- ----------------------- ------- ----------
MIS        TABLE                   VALID         3877
MIS        INDEX                   VALID         3093
MIS        INDEX PARTITION         VALID         1859
MIS        TABLE PARTITION         VALID          331
MIS        LOB                     VALID           15
MIS        DATABASE LINK           VALID            3

6 rows selected.

cd /u01/oracle/zfs-dr/datapump/MIS/

-- start import of MIS schema on MERWHR database
[oracle@mrlndrtdbadm02 MIS]$ vi par_MerlinRef_MERWHR_MIS_import.par
[oracle@mrlndrtdbadm02 MIS]$ cat par_MerlinRef_MERWHR_MIS_import.par
dumpfile=expdp_MerlineRef_MERWHP_MIS_schema_03022021_%U.dmp
logfile=impdp_mis_MerlineRef_MERWHP_MIS_03022021_logs.log
directory=MIS_EXP
schemas=MIS
parallel=10
CLUSTER=N
table_exists_action=replace

nohup impdp "'/as sysdba'" parfile=par_MerlinRef_MERWHR_MIS_import.par job_name=impdp_MIS_mWHR03022021 &


SQL> dbstatus

     NAME     OPEN_MODE
_________ _____________
MERWHP    READ WRITE

select owner, object_type,status, count(*)
from dba_objects
where owner in ('ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT')
group by owner, object_type,status;

          OWNER      OBJECT_TYPE     STATUS    COUNT(*)
_______________ ________________ __________ ___________


			
			
SQL>
-- including Tables
set serveroutput on
declare 
	v_SqlSTMT  varchar2(32000);
begin
FOR i IN (select owner, object_type, object_name
			from dba_objects 
			where owner in ('CLAIMODS','STAGING')
			  and object_type in ('TABLE','TABLE PARTITION','VIEW','TRIGGER','PROCEDURE','FUNCTION','PACKAGE','PACKAGE BODY','SEQUENCE','MATERIALIZED VIEW')
			ORDER BY OWNER, OBJECT_TYPE ASC)
loop
	begin 
	  if i.object_type='TABLE' then
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME||' cascade constraint';
	  else
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME;
	  end if;
		execute immediate v_SqlSTMT;
	exception
	  when others then
	  	null;
	end;
	dbms_output.put_line(v_SqlSTMT);
end loop;
end;
/

[oracle@mrlndrtdbadm02 MIS]$ mkdir 4schema
[oracle@mrlndrtdbadm02 MIS]$ pwd
/u01/oracle/zfs-dr/datapump/MIS
[oracle@mrlndrtdbadm02 MIS]$ cd 4schema/
[oracle@mrlndrtdbadm02 4schema]$ pwd
/u01/oracle/zfs-dr/datapump/MIS/4schema
[oracle@mrlndrtdbadm02 4schema]$


[oracle@mrlndrtdbadm02 4schema]$ cat par_MerlinRef_MERWHR_4Schemas_import.par
dumpfile=expdp_MerlineRef_MERWHP_3schemas_03022021_%U.dmp
logfile=impdp_MerlineRef_MERWHR_3schemas_03022021_logs.log
directory=mrlnrf
schemas=ESIGHT_ADMIN,FEEDS_IN,FEEDS_OUT
parallel=16
CLUSTER=N


nohup impdp "'/as sysdba'" parfile=/u01/oracle/zfs-dr/datapump/MIS/par_MerlinRef_MERWHR_4Schemas_import.par job_name=impdp_3shma_mWHR &

nohup impdp "'/as sysdba'" parfile=/zfssa/mrln-prod-rman/backup01/mrlNRf_MAR2021/par_MerlinRef_MERWHR_4Schemas_import.par job_name=impdp_3shma_mWHR &
-- start import of Selected tables on MERWHR database

-- Data only import for selected tables
[oracle@mrlndrtdbadm02 select_tables]$ pwd
/u01/oracle/zfs-dr/datapump/MIS/select_tables


[oracle@mrlndrtdbadm02 select_tables]$ vi par_MerlinRef_MerWHR_Sltd_tbls_import.par
dumpfile=expdp_MerlineRef_MERWHP_Selected_Tables_DataOnly_03022021_%U.dmp
logfile=impdp_MerlineRef_WHR_Sltd_Tables_DataOnly_03022021_logs.log
directory=mrlnrf
tables=STAGING.P2T_CONTROL_TOTALS_MAP,STAGING.CONTROL_TOTALS,PRELOAD.PL_POL_VRSN_CR,PRELOAD.PL_GL_EXPOS_UOM_TRANS_LKU,PRELOAD.PL_SOURCE_SYSTEM_LKU,PRELOAD.PL_TAP_GL_EXPOS_SBJ_TRANS_LKU,PRELOAD.PL_PLEDGE_WC_DED_LKU,PRELOAD.PL_PLEDGE_WC_EL_LIMITS_LKU,PRELOAD.PL_PLEDGE_WC_MARITM_EL_LMT_LKU
parallel=10
CLUSTER=N
table_exists_action=replace

[oracle@mrlndrtdbadm02 select_tables]$

nohup impdp "'/as sysdba'" parfile=/u01/oracle/zfs-dr/datapump/MIS/par_MerlinRef_MerWHR_Sltd_tbls_import.par job_name=impdp_Sltd_tbls_mWHR03022021 &

nohup impdp "'/as sysdba'" parfile=/zfssa/mrln-prod-rman/backup01/mrlNRf_MAR2021/par_MerlinRef_MerWHR_Sltd_tbls_import.par job_name=impdp_Sltd_tbls_mWHR03022021 &

select owner, object_type,status, count(*)
from dba_objects
where owner in ('AC_STAGING','ARCHIVE','DASH','DASHBOARD','HAL','MIS_DM_RPT','MISWEB','MISWEBWIP',
'CNACOM_STAGING','MEDBILL','MEDBILL_MITCHELL','RST','CANADA','SURETY_ARCHIVE',
'SURETY_STAGING','PRELOAD')
group by owner, object_type,status;

set serveroutput on
declare
	v_SqlSTMT  varchar2(32000);
begin
FOR i IN ( select owner, object_type, object_name
			 from dba_objects 
			where owner in ('AC_STAGING','ARCHIVE','DASH','DASHBOARD','HAL','MIS_DM_RPT','MISWEB','MISWEBWIP',
							'CNACOM_STAGING','MEDBILL','MEDBILL_MITCHELL','RST','CANADA','SURETY_ARCHIVE',
							'SURETY_STAGING','PRELOAD')
			  and OBJECT_TYPE in ('VIEW','PROCEDURE','SEQUENCE','FUNCTION','SYNONYM','MATERIALIZED VIEW','PACKAGE','PACKAGE BODY','TYPE','TRIGGER')
			order by OWNER, OBJECT_TYPE ASC)
loop
	begin 
		v_SqlSTMT:= 'DROP '||i.OBJECT_TYPE||' '||i.OWNER||'.'||i.OBJECT_NAME;
		execute immediate v_SqlSTMT;
	exception
	  when others then
	  	null;
	end;
	dbms_output.put_line(v_SqlSTMT);
end loop;
end;
/


[oracle@mrlndrtdbadm02 metadata_only]$ vi par_MerlinRef_MERWHR_Metadata_only_impdp.par

[oracle@mrlndrtdbadm02 metadata_only]$ pwd
/u01/oracle/zfs-dr/datapump/MIS/

[oracle@mrlndrtdbadm02 metadata_only]$ cat par_MerlinRef_MERWHR_Metadata_only_impdp.par
dumpfile=expdp_MerlineRef_MERWHP_MetadataOnly_03022021_%U.dmp
logfile=impdp_MerlineRef_WHR_Metadt_03022021_logs.log
directory=MIS_EXP
schemas=(AC_STAGING,ARCHIVE,DASH,DASHBOARD,HAL,MIS_DM_RPT,MISWEB,MISWEBWIP,CNACOM_STAGING,MEDBILL,MEDBILL_MITCHELL,RST,CANADA,SURETY_ARCHIVE,SURETY_STAGING,PRELOAD,STAGING)
parallel=16
CLUSTER=N
include=SEQUENCE,PROCEDURE,PACKAGE,PACKAGE_BODY,TYPE_BODY,SYNONYM,VIEW,FUNCTION,TYPE

nohup impdp "'/as sysdba'" parfile=/u01/oracle/zfs-dr/datapump/MIS/par_MerlinRef_MERWHR_Metadata_only_impdp.par job_name=impdp_MetatdaO_mwh03022021 &
nohup impdp "'/as sysdba'" parfile=/zfssa/mrln-prod-rman/backup01/mrlNRf_MAR2021/par_MerlinRef_MERWHR_Metadata_only_impdp.par job_name=impdp_MetatdaO_mwh03022021 &

-- generate the grant privilleges script from merwhp and execute it on merwhr
SELECT -- grantee, owner, table_name, grantor, 
        DECODE(grantable, 'YES', 'grant '||(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||' WITH GRANT OPTION;',
                                 'grant '||(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||';') privs_grant
from dba_tab_privs
where grantee in
	('MIS','ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT','AC_STAGING','ARCHIVE','DASH','DASHBOARD','HAL','MIS_DM_RPT',
	 'MISWEB','MISWEBWIP','CNACOM_STAGING','MEDBILL','MEDBILL_MITCHELL','RST','CANADA','SURETY_ARCHIVE',
	 'SURETY_STAGING','PRELOAD','STAGING','CLAIMODS')
  and not regexp_like(table_name,'BIN\$','i')
union all
-- generate the synonym script merwhp and execute the same on merwhr
select 'create or replace synonym '||owner||'.'||synonym_name||' for '||table_owner||'.'||table_name||';'
from dba_synonyms
where owner in
	('MIS','ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT','AC_STAGING','ARCHIVE','DASH','DASHBOARD','HAL','MIS_DM_RPT',
	 'MISWEB','MISWEBWIP','CNACOM_STAGING','MEDBILL','MEDBILL_MITCHELL','RST','CANADA','SURETY_ARCHIVE',
	 'SURETY_STAGING','PRELOAD','STAGING','CLAIMODS')
  and not regexp_like(table_name,'BIN\$','i')
 union all
select 'create or replace public synonym '||synonym_name||' for '||table_owner||'.'||table_name||';'
from dba_synonyms
where table_owner in
	('MIS','ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT','AC_STAGING','ARCHIVE','DASH','DASHBOARD','HAL','MIS_DM_RPT',
	 'MISWEB','MISWEBWIP','CNACOM_STAGING','MEDBILL','MEDBILL_MITCHELL','RST','CANADA','SURETY_ARCHIVE',
	 'SURETY_STAGING','PRELOAD','STAGING','CLAIMODS')
  and not regexp_like(table_name,'BIN\$','i')
;

-- Once the aboce script of Grant s and Synonyms are executed on merwhr
-- Compile all the required schemas
select 'exec dbms_utility.compile_schema(schema=>'''||username||''');'
  from dba_users
 where username in 
	('MIS','ESIGHT_ADMIN','FEEDS_IN','FEEDS_OUT','AC_STAGING','ARCHIVE','DASH','DASHBOARD','HAL','MIS_DM_RPT',
	 'MISWEB','MISWEBWIP','CNACOM_STAGING','MEDBILL','MEDBILL_MITCHELL','RST','CANADA','SURETY_ARCHIVE',
	 'SURETY_STAGING','PRELOAD','STAGING','CLAIMODS')
order by username asc
;



-- Conver the MERWHR database into NO archivelog MODE--- convert archivelog mode to no archivelog mode into RAC systems
--login to instance
sqlplus "/as sysdba"

SQL> alter system set CLUSTER_DATABASE=FALSE scope=spfile sid='*'; 

srvctl stop database -d merwhr -stopoption immediate

srvctl start instance -d merwhr -i MERWHR1 -startoption mount

. oraenv
MERWHR2

sqlplus "/as sysdba"

SQL> startup mount
SQL>
SQL>
SQL> alter database archivelog;
SQL> archive log list;
SQL>
SQL>
SQL> alter system set CLUSTER_DATABASE=TRUE scope=spfile sid='*'; 
SQL> shutdown immediate;

srvctl start database -d merwhr

SQL> set lines 500 pages 500
SQL> col HOST_NAME for a25
select inst_id, instance_name, host_name,
         to_char(startup_time, 'mm/dd/yyyy hh24:mi:ss') "Startup time"
from gv$instance;
SQL>   2    3
   INST_ID INSTANCE_NAME    HOST_NAME                 Startup time
---------- ---------------- ------------------------- -------------------
         2 MERDMR2          mrlndrtdbadm04.cna.com    09/03/2019 07:53:08
         1 MERDMR1          mrlndrtdbadm03.cna.com    09/03/2019 07:53:07

SQL> archive log list;
Database log mode              No Archive Mode
Automatic archival             Disabled
Archive destination            USE_DB_RECOVERY_FILE_DEST
Oldest online log sequence     72376
Current log sequence           72379
SQL>


[oracle@mrlndrtdbadm02 sql]$ sqlplus "/as sysdba"

SQL*Plus: Release 12.1.0.2.0 Production on Thu Sep 5 11:44:47 2019

Copyright (c) 1982, 2014, Oracle.  All rights reserved.


Connected to:
Oracle Database 12c Enterprise Edition Release 12.1.0.2.0 - 64bit Production
With the Partitioning, Real Application Clusters, Automatic Storage Management, OLAP,
Advanced Analytics and Real Application Testing options

SQL> show parameters db_name

NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
db_name                              string      MERWHR
SQL> col owner for a10


----------------------------------------------------------------------------------------------------
-- Final Steps

-- copying the sqlfile and parameters files on mentioned vslr* servers


-- sqlfiles 
vslrau1p015.cna.com

sudo su - exadba

cd /apps/exadba/dba_cmds/merwhp

-- replace the month to current month
tar -cvf ac_staging_MAR2021.tar ac_staging
tar -cvf archive_MAR2021.tar archive
tar -cvf esight_admin_MAR2021.tar esight_admin
tar -cvf feeds_in__MAR2021.tar feeds_in
tar -cvf feeds_out_MAR2021.tar feeds_out
tar -cvf mis_MAR2021.tar mis
tar -cvf hal_MAR2021.tar hal
tar -cvf info_MAR2021.tar info
tar -cvf mis_dm_rpt_MAR2021.tar mis_dm_rpt
tar -cvf cnacom_staging_MAR2021.tar cnacom_staging
tar -cvf medbill_MAR2021.tar  medbill
tar -cvf medbill_mitchell_MAR2021.tar medbill_mitchell
tar -cvf canada_MAR2021.tar canada
tar -cvf surety_staging_MAR2021.tar surety_staging  
tar -cvf wcfc_MAR2021.tar wcfc
tar -cvf viaticus_MAR2021.tar viaticus
tar -cvf preload_MAR2021.tar preload
tar -cvf staging_MAR2021.tar staging

ls -larts *MAR2021.tar

gzip *MAR2021.tar

scp *MAR2021.tar.gz vslrch1d028.cna.com:/apps/exadba/dba_cmds/merwhr

=======================================================================
-- login to of the cluster vslrch1d028 or vslrch1d029

-- vslrch1d028

cd /apps/exadba/dba_cmds/merwhr/

mv ac_staging ac_staging_MAR2021
mv archive archive_MAR2021
mv esight_admin esight_admin_MAR2021
mv feeds_in feeds_in_MAR2021
mv feeds_out feeds_out_MAR2021
mv mis mis_MAR2021
mv hal hal_MAR2021
mv info info_MAR2021
mv mis_dm_rpt mis_dm_rpt_MAR2021
mv cnacom_staging cnacom_staging_MAR2021
mv medbill medbill_MAR2021
mv medbill_mitchell medbill_mitchell_MAR2021
mv canada canada_MAR2021
mv surety_staging surety_staging_MAR2021
mv wcfc wcfc_MAR2021
mv viaticus viaticus_MAR2021
mv preload preload_MAR2021
mv staging staging_MAR2021

gzip -d *MAR2021.tar.gz


tar -xvf ac_staging_MAR2021.tar
tar -xvf archive_MAR2021.tar
tar -xvf esight_admin_MAR2021.tar 
tar -xvf feeds_in__MAR2021.tar
tar -xvf feeds_out_MAR2021.tar 
tar -xvf mis_MAR2021.tar 
tar -xvf hal_MAR2021.tar
tar -xvf info_MAR2021.tar 
tar -xvf mis_dm_rpt_MAR2021.tar 
tar -xvf cnacom_staging_MAR2021.tar
tar -xvf medbill_MAR2021.tar 
tar -xvf medbill_mitchell_MAR2021.tar 
tar -xvf canada_MAR2021.tar 
tar -xvf surety_staging_MAR2021.tar  
tar -xvf wcfc_MAR2021.tar 
tar -xvf viaticus_MAR2021.tar 
tar -xvf preload_MAR2021.tar 
tar -xvf staging_MAR2021.tar

chmod -R 755 ac_staging 
chmod -R 755 archive 
chmod -R 755 esight_admin 
chmod -R 755 feeds_in 
chmod -R 755 feeds_out 
chmod -R 755 mis 
chmod -R 755 hal 
chmod -R 755 info 
chmod -R 755 mis_dm_rpt 
chmod -R 755 cnacom_staging 
chmod -R 755 medbill
chmod -R 755 medbill_mitchell 
chmod -R 755 canada 
chmod -R 755 surety_staging 
chmod -R 755 wcfc 
chmod -R 755 viaticus 
chmod -R 755 preload
chmod -R 755 staging 


-----------------------------------------------------------------------------------------

-- parameter files

vslrau1p015.cna.com

cd /apps/exadba/dba_cmds/

mkdir MERWHR_control_MAR2021

cp dba_cmds.control.merwhp.ac_staging MERWHR_control_MAR2021/dba_cmds.control.merwhr.ac_staging
cp dba_cmds.control.merwhp.archive MERWHR_control_MAR2021/dba_cmds.control.merwhr.archive
cp dba_cmds.control.merwhp.esight_admin MERWHR_control_MAR2021/dba_cmds.control.merwhr.esight_admin
cp dba_cmds.control.merwhp.feeds_in MERWHR_control_MAR2021/dba_cmds.control.merwhr.feeds_in
cp dba_cmds.control.merwhp.feeds_out MERWHR_control_MAR2021/dba_cmds.control.merwhr.feeds_out
cp dba_cmds.control.merwhp.mis MERWHR_control_MAR2021/dba_cmds.control.merwhr.mis
cp dba_cmds.control.merwhp.hal MERWHR_control_MAR2021/dba_cmds.control.merwhr.hal
cp dba_cmds.control.merwhp.info MERWHR_control_MAR2021/dba_cmds.control.merwhr.info
cp dba_cmds.control.merwhp.mis_dm_rpt MERWHR_control_MAR2021/dba_cmds.control.merwhr.mis_dm_rpt
cp dba_cmds.control.merwhp.cnacom_staging MERWHR_control_MAR2021/dba_cmds.control.merwhr.cnacom_staging
cp dba_cmds.control.merwhp.medbill MERWHR_control_MAR2021/dba_cmds.control.merwhr.medbill
cp dba_cmds.control.merwhp.medbill_mitchell MERWHR_control_MAR2021/dba_cmds.control.merwhr.medbill_mitchell
cp dba_cmds.control.merwhp.canada MERWHR_control_MAR2021/dba_cmds.control.merwhr.canada
cp dba_cmds.control.merwhp.surety_staging MERWHR_control_MAR2021/dba_cmds.control.merwhr.surety_staging
cp dba_cmds.control.merwhp.wcfc MERWHR_control_MAR2021/dba_cmds.control.merwhr.wcfc
cp dba_cmds.control.merwhp.viaticus MERWHR_control_MAR2021/dba_cmds.control.merwhr.viaticus
cp dba_cmds.control.merwhp.preload MERWHR_control_MAR2021/dba_cmds.control.merwhr.preload
cp dba_cmds.control.merwhp.staging MERWHR_control_MAR2021/dba_cmds.control.merwhr.staging

cd /apps/exadba/dba_cmds/MERWHR_control_MAR2021

ls -larts

=======================================================================
-- login to of the cluster vslrch1d028 or vslrch1d029

-- vslrch1d028

cd  /apps/exadba/dba_cmds/

mkdir bkp_MERWHR_control_MAR2021

mv dba_cmds.control.merwhr.ac_staging bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.archive bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.esight_admin bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.feeds_in bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.feeds_out bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.mis bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.hal bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.info bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.mis_dm_rpt bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.cnacom_staging bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.medbill bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.medbill_mitchell bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.canada bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.surety_staging bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.wcfc bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.viaticus bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.preload bkp_MERWHR_control_MAR2021
mv dba_cmds.control.merwhr.staging bkp_MERWHR_control_MAR2021

$ cd bkp_MERWHR_control_MAR2021
$ pwd
/apps/exadba/dba_cmds/bkp_MERWHR_control_MAR2021
$ ls -larts

-- login to vslrau1p015 production server
cd /apps/exadba/dba_cmds/MERWHR_control_MAR2021

scp /apps/exadba/dba_cmds/MERWHR_control_MAR2021/*.* vslrch1d028.cna.com:/apps/exadba/dba_cmds

---*/ login to vslrch1d028
cd /apps/exadba/dba_cmds/

chmod 644 dba_cmds.control.merwhr.ac_staging
chmod 644 dba_cmds.control.merwhr.archive
chmod 644 dba_cmds.control.merwhr.esight_admin
chmod 644 dba_cmds.control.merwhr.feeds_in
chmod 644 dba_cmds.control.merwhr.feeds_out
chmod 644 dba_cmds.control.merwhr.mis
chmod 644 dba_cmds.control.merwhr.hal
chmod 644 dba_cmds.control.merwhr.info
chmod 644 dba_cmds.control.merwhr.mis_dm_rpt
chmod 644 dba_cmds.control.merwhr.cnacom_staging
chmod 644 dba_cmds.control.merwhr.medbill
chmod 644 dba_cmds.control.merwhr.medbill_mitchell
chmod 644 dba_cmds.control.merwhr.canada
chmod 644 dba_cmds.control.merwhr.surety_staging
chmod 644 dba_cmds.control.merwhr.wcfc
chmod 644 dba_cmds.control.merwhr.viaticus
chmod 644 dba_cmds.control.merwhr.preload
chmod 644 dba_cmds.control.merwhr.staging


-- check all the below directories, which should be present already
ls -larts /apps/exadba/dba_cmds/merwhr/ac_staging
ls -larts /apps/exadba/dba_cmds/merwhr/archive
ls -larts /apps/exadba/dba_cmds/merwhr/feeds_in
ls -larts /apps/exadba/dba_cmds/merwhr/feeds_out
ls -larts /apps/exadba/dba_cmds/merwhr/hal 
ls -larts /apps/exadba/dba_cmds/merwhr/info
ls -larts /apps/exadba/dba_cmds/merwhr/mis
ls -larts /apps/exadba/dba_cmds/merwhr/wcfc
ls -larts /apps/exadba/dba_cmds/merwhr/mis_dm_rpt
ls -larts /apps/exadba/dba_cmds/merwhr/medbill_mitchell
ls -larts /apps/exadba/dba_cmds/merwhr/medbill
ls -larts /apps/exadba/dba_cmds/merwhr/canada
ls -larts /apps/exadba/dba_cmds/merwhr/cnacom_staging
ls -larts /apps/exadba/dba_cmds/merwhr/preload
ls -larts /apps/exadba/dba_cmds/merwhr/staging
ls -larts /apps/exadba/dba_cmds/merwhr/viaticus
ls -larts /apps/exadba/dba_cmds/merwhr/esight_admin
ls -larts /apps/exadba/dba_cmds/merwhr/mis_dm_rpt

<end node> 5P9i0s8y19Z
dt=Text
<node>
FGA Policy
2
-- Dropping the policy in exadata 
NAME      OPEN_MODE
--------- --------------------
MERWHR    READ WRITE

SQL> EXEC DBMS_FGA.DROP_POLICY(object_schema => 'MIS', object_name => 'PCA_DETAILS',policy_name => 'MPCA_DETAILS' );

PL/SQL procedure successfully completed.


mrlnprddbadm01

/u01/oracle/zfs-dr/datapump_new/OFFSHORE/utility/scripts/audit_policy_status_rpt/sql/wh

select policy_name from cnaoaud.refresh_audit_policy where object_name='PCA_DETAILS';

---------------------------------------------------------------------------------

<end node> 5P9i0s8y19Z
dt=Text
<node>
DBA Info
1
-- OCA and OCP 12c
SQL Fundamentals 1Z0-061 = 10000 / 8417
Installation and Administration 1Z0-062 = 12000 / 10100
Advanced Administration 1Z0-063 = 12000 / 10100 

Complete the course submission form

-- Oracle 12c RAC
RAC and Grid Infrastructure Administration 1Z0-068 = 10100
-- GoldenGate
12c GoldenGate Implementation Essentials 1Z0-447 = 10100

server name: apac.it-solutions.myatos.net


To determine whether the oraInst.loc file exists, enter the following command:

# more /etc/oraInst.loc


-- some of the columns have got following meaning of sys.user$ table:
NAME  	– name for user or role
TYPE# 	– 0 for role or 1 for user
CTIME 	– the date of creation
PTIME 	– the date the password was last changed
EXPTIME   – the date the password has last expired
LTIME  	– the date the resource was last locked
LCOUNT 	– number of failed logon

SELECT NAME, type#, ctime, ptime, exptime, ltime, lcount 
  FROM sys.user$
 WHERE NAME IN ('SYS', 'SYSTEM', 'PUBLIC', 'DBA', 'SCOTT')  
 ORDER BY NAME; 


-- Direct connection string
sqlplus rchaudhari@"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=wdl1mltidbs01.tsysacquiring.org)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=tnoxsnox)))"

sqlplus rchaudhari@"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.64.51)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=utxndb)))"
sqlplus rchaudhari@"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.64.61)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=urptdb)))"

sqlplus arcotuser@"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.132.13.231)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=devracdbtaf)))"
sqlplus rchaudhari@"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=10.132.12.172)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=qaracdbtaf)))"

<end node> 5P9i0s8y19Z
dt=Text
<node>
DB Obj Levels
2
<end node> 5P9i0s8y19Z
dt=Text
<node>
Table Partition
3

SQL> CREATE TABLE table2000
  2  ( x int,
  3    y int,
  4    z DATE
  5  )
  6  PARTITION BY RANGE (z)
  7  (
  8  PARTITION tab_1999_h1 VALUES LESS
  9  THAN(to_date('30-jun-1999','dd-mon-yyyy')),
 10  PARTITION tab_1999_h2 VALUES LESS
 11  THAN(to_date('31-dec-1999','dd-mon-yyyy')),
 12  PARTITION tab_2000_h1 VALUES LESS
 13  THAN(to_date('30-jun-2000','dd-mon-yyyy')),
 14  PARTITION tab_2000_h2 VALUES LESS
 15  THAN(to_date('31-dec-2000','dd-mon-yyyy'))
 16  )
 17  /

Table created.

insert into table2000  values ( 1, 1, '15-jun-1999' );
insert into table2000  values ( 2, 2, '15-dec-1999' );
insert into table2000  values ( 3, 3, '15-jun-2000' );
insert into table2000  values ( 4, 4, '15-dec-2000' );


SQL> CREATE TABLE new_table2000
	( x int,
	  y int,
	  z DATE
	)
	PARTITION BY RANGE (z)
	(
	PARTITION newtab_1999_h1 VALUES LESS
	THAN(to_date('30-jun-1999','dd-mon-yyyy')),
	PARTITION newtab_1999_h2 VALUES LESS
	THAN(to_date('31-dec-1999','dd-mon-yyyy'))
	)
/

Table created.

insert into NEW_table2000  values ( -1, -1, '15-jun-1999' );
insert into NEW_table2000  values ( -2, -2, '15-dec-1999' );


--So, how to make the NEW partitions replace the old?  we will make A new partition 
--become a table and swap that table for an OLD partition.  It'll look like this:

SQL> create table temp ( x int, y int, z date );
Table created.

SQL> alter table new_table2000 exchange partition newtab_1999_h1  with table temp;

Table altered.

SQL> 
SQL> alter table table2000  exchange partition tab_1999_h1  with table temp;

Table altered.

SQL> 
SQL> rename temp to table2000_tab_1999_h1;

Table renamed.

SQL> 


-- Renaming a table partition
SQL> ALTER TABLE range_list RENAME PARTITION sf TO sales_future;

-- good link for table partition syntax
http://psoug.org/reference/partitions.html



--- Processes of archiving parition table 

CREATE TABLE <Schema_Name>.<New_Arch_TableName> AS
SELECT * 
FROM <schema_name>.<Partition_Table_Name>
WHERE 1=2;

ALTER TABLE <schema_name>.<Partition_Table_Name> 
EXCHANGE PARTITION <Partition_Name>
WITH TABLE <Schema_Name>.<New_Arch_TableName>
EXCLUDING INDEXES
WITHOUT VALIDATION
UPDATE GLOBAL INDEXES;

ALTER TABLE <Schema_Name>.<New_Arch_TableName> DROP PARTITION <Partition_Name>;

-- for e.g >>> ALTER TABLE range_list DROP PARTITION s2k UPDATE GLOBAL INDEXES;


Analyze Parition tables and Indexes

Compile Schemas

-- for e.g....

SELECT * FROM list_part PARTITION (q1_northwest);


-- Local Indexes
CREATE INDEX year_idx
on all_fact (order_date)
LOCAL
(PARTITION name_idx1),
(PARTITION name_idx2),
(PARTITION name_idx3);



-- Global Indexes
CREATE INDEX item_idx
on all_fact (item_nbr)
GLOBAL
(PARTITION city_idx1 VALUES LESS THAN (100)),
(PARTITION city_idx1 VALUES LESS THAN (200)),
(PARTITION city_idx1 VALUES LESS THAN (300)),
(PARTITION city_idx1 VALUES LESS THAN (400)),
(PARTITION city_idx1 VALUES LESS THAN (500));

-- A global partitioned index is used for all other indexes except for the one that is used as the table partition key.

-- change the interval partition from year to month and month to day
--
ALTER TABLE SNOX4TRANSNOX.INFONOX_SERVICE_USAGE SET INTERVAL(NUMTOYMINTERVAL(1,'MONTH'));

--
ALTER TABLE SNOX4TRANSNOX.INFONOX_SERVICE_USAGE SET INTERVAL (NUMTODSINTERVAL(7,'day'));



-- Get the tablespace_name of the partition table
SELECT table_owner, table_name, partition_name, tablespace_name
  FROM dba_tab_partitions
 WHERE table_owner = 'AUDIT_STAGE'
   AND table_name='ADDRESS_CONTACT_ARC'; 


-- Get sub partition tablespace name
-- by owner and table name 
SELECT UNIQUE  tablespace_name FROM (
SELECT table_owner, table_name, partition_name, tablespace_name
  FROM DBA_TAB_SUBPARTITIONS 
 WHERE table_owner = 'AUDIT_STAGE'
   AND table_name='FIELD_EXPOSURE_INCIDENT_AUD'); 


-- Get the Tablespace name of Partition Indexes
-- for particular owner and table name
SELECT UNIQUE tablespace_name 
FROM (SELECT index_owner, index_name, partition_name, tablespace_name 
      FROM dba_ind_partitions 
      WHERE index_name IN (SELECT  index_name 
                             FROM dba_part_indexes 
                            WHERE owner='CISADM' AND table_name='D1_MSRMT')) 


-- Get the tablespace_name of subpartition indexes
-- for particular owner and table name
SELECT UNIQUE tablespace_name FROM (        
SELECT index_owner, index_name, partition_name, tablespace_name
FROM DBA_IND_SUBPARTITIONS
WHERE INDEX_name IN (SELECT index_name
                       FROM dba_part_indexes
                      WHERE owner='CISADM' AND table_name='D1_MSRMT')))

<end node> 5P9i0s8y19Z
dt=Text
<node>
Pl/SQL codes
3
-- FORALL

-- PLS-00436 Restriction in FORALL Statements Removed

The PLS-00436 restriction has been removed, which means you can now reference the individual elements of a collection within the SET and 
WHERE clauses of a DML statement in a FORALL construct. To see this in action, create and populates a test table using the following code.

CREATE TABLE forall_test (
  id          NUMBER,
  description VARCHAR2(50)
);

INSERT INTO forall_test VALUES (1, 'ONE');
INSERT INTO forall_test VALUES (2, 'TWO');
INSERT INTO forall_test VALUES (3, 'THREE');
INSERT INTO forall_test VALUES (4, 'FOUR');
INSERT INTO forall_test VALUES (5, 'FIVE');
COMMIT;

The PL/SQL block below populates a collection with the existing data, amends the data in the collection, then updates the table with the amended data. 
The final query displays the changed data in the table.

DECLARE
  TYPE t_forall_test_tab IS TABLE OF forall_test%ROWTYPE;
  l_tab t_forall_test_tab;
BEGIN
  -- Retrieve the existing data into a collection.
  SELECT *
  BULK COLLECT INTO l_tab
  FROM   forall_test;

  -- Alter the data in the collection.
  FOR i IN l_tab.first .. l_tab.last LOOP
    l_tab(i).description := 'Description for ' || i;
  END LOOP;

  -- Update the table using the collection.
  FORALL i IN l_tab.first .. l_tab.last
    UPDATE forall_test
    SET    description = l_tab(i).description
    WHERE  id          = l_tab(i).id;

  COMMIT;
END;
/

SELECT * FROM forall_test;

        ID DESCRIPTION
---------- ---------------------------
         1 Description for 1
         2 Description for 2
         3 Description for 3
         4 Description for 4
         5 Description for 5

5 rows selected.

SQL>


--Next example of ForAll statment using Bulk Collect
CREATE OR REPLACE PROCEDURE UPD_FOR_DEPT
(
    V_depart_id IN  employee.department_id%type,
	v_NewSalary IN  employee.salary%type
)
is  
  type employee_tt is table of employee.employee_id%type  
      index by binary_integer;
	  employees employee_tt;
	  
type salary_tt is table of employee.salary%type  
      index by binary_integer;
	  salaries salary_tt;

type hire_date_tt is table of employee.hire_date%type  
      index by binary_integer;
	  hire_dates hire_date_tt;

begin
   select employee_id, salary, hire_date
   bulk collect into employees, salaries, hire_dates
   from employee
   where department_id = V_depart_id
   for update;
   
   forall indx inemployees.first ..employees.last
   insert into employee_history(employee_id, salary, hire_date)
   vales(employees(indx), salaries(indx), hire_dates(indx));
   
   forall indx in employees.first ..employee.last
   update employee
   set salary = v_NewSalary,
       hire_date = hire_dates(indx),
   where employee_id = employees (indx);

end UPD_FOR_DEPT;
/
	  
===================================================================================


-- Query returns date as per different time zone in the database

SELECT date_created, TO_DATE(TO_CHAR(TO_TIMESTAMP_TZ(TO_CHAR(date_created,'mm/dd/yyyy hh24:mi:ss'), 'mm/dd/yyyy hh24:mi:ss tzr') AT TIME ZONE TIME_ZONE,'mm/dd/yyyy hh24:mi:ss'),'mm/dd/yyyy hh24:mi:ss') AS merchant_time_zone 
FROM snox4transnox.merchant;


--********************************************************************--
-- Query returns the date of last months starting and ending date

SELECT ADD_MONTHS(TRUNC(SYSDATE,'MM'),-1) Last_Months_1day,
  TO_DATE(TO_CHAR(TRUNC(SYSDATE,'MM')-1,'mm/dd/yyyy')||' 23:59:59','mm/dd/yyyy hh24:mi:ss') Last_Months_lastDay
FROM dual;

-- will return the first of next month 11:00:00 AM
select ADD_MONTHS(TRUNC(SYSDATE,'MM'),+1)+11/24 from dual;
--********************************************************************--
===================================================================================


--- insert 100000 records at a time
INSERT INTO transnox_cpass.TRANS_ATM  
(
SELECT transnox_cpass.seq_trans_atm.NEXTVAL,SUBSTR(dbms_random.value(1,10),25), SUBSTR(dbms_random.value(1,10),37)
FROM dual
connect BY LEVEL <= 100000
 );
 
SELECT MAX(LENGTH(ID)) FROM 
(
  SELECT SUBSTR(dbms_random.value(1,10),31) ID, SUBSTR(dbms_random.value(1,10),25), RPAD('*',16,'*' ) DATA
  FROM dual
  connect BY LEVEL <= 100000
)
===================================================================================

-- bulk deletion
BEGIN
	loop -- keep looping 
	  --do the delete 4999 in each iteration
	  Delete from transcapitalone.Transactions where  Transactions_ID and rownum < 5000;

	  -- exit the loop when there where no more 5000 reccods to delete. 
	  exit when SQL%rowcount < 4999;

	  -- commit to clear the rollback segments. 
	  commit;
	end loop;

	commit; -- commit the last delete
END;
/
===================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
DBA cmds
3
-- If you want to drop primary key and associated index;
ALTER TABLE MY_TABLE DROP PRIMARY KEY DROP INDEX;

-- OR

ALTER TABLE MY_TABLE  DROP PRIMARY KEY CASCADE;

-- If you want to drop primary key but keep index then following
ALTER TABLE MY_TABLE DROP PRIMARY KEY KEEP INDEX;


-- Create a stored procedure owned by a schema with the alter any user system privilege.
CREATE OR REPLACE PROCEDURE sp_alter_user (a_user_name VARCHAR2,
a_user_password VARCHAR2, a_admin VARCHAR2 := 'N') IS
 l_user VARCHAR2(255);
 l_user_grants VARCHAR2(255);
 l_user_default_role VARCHAR2(255);
BEGIN
  l_user := 'alter user ' || a_user_name ||
            ' identified by ' || a_user_password;

  -- If they need roles granted
  l_user_grants := 'GRANT connect,resource TO ' || a_user_name;

  l_user_default_role := 'alter user ' || a_user_name ||
  ' default role dba';

  dbms_utility.exec_ddl_statement(l_user);
  dbms_utility.exec_ddl_statement(l_user_grants);
  dbms_utility.exec_ddl_statement(l_user_default_role);
END sp_alter_user;
/


CREATE OR REPLACE PROCEDURE sp_create_user (a_user_name VARCHAR2,
a_user_password VARCHAR2, a_admin VARCHAR2 := 'N') IS
 l_user   VARCHAR2(255);
BEGIN
   l_user := 'create user ' || a_user_name ||
   ' identified by ' || a_user_password ||
   ' temporary tablespace temp';

   dbms_utility.exec_ddl_statement(l_user);

   sp_alter_user(a_user_name, a_user_password, a_admin);
END sp_create_user;
/



-- object dependency can be sreached like the below e.g..
exec dbms_utility.get_dependency('TABLE', 'UWCLASS', 'TESTTAB');

<end node> 5P9i0s8y19Z
dt=Text
<node>
Indexes
3
select * --'alter index '||owner||'.'||index_name||' rebuild;' 
from dba_indexes 
where status='UNUSABLE'

<end node> 5P9i0s8y19Z
dt=Text
<node>
Objs SQLs
3
-- compaire the index/constraint of 2 DB schemas
SELECT UNIQUE OWNER, CONSTRAINT_NAME, TABLE_NAME, COLUMN_NAME, position, DECODE(CONSTRAINT_TYPE,'V','Check View','R','Foreign Key','U','Unique Key','P','Primary Key','C','Check','O','Read Only View','Others')Constraint_Type, MISSING_CONS
FROM 
  (
    SELECT
        remo.owner, remo.constraint_name, remo.table_name, remo.column_name, remo.position, remo.constraint_type,
        NVL2((SELECT UNIQUE table_name FROM dba_cons_columns dcc1 WHERE dcc1.table_name=remo.table_name AND dcc1.owner=remo.owner),'Y','N')MISSING_CONS 
    FROM 
      (
        SELECT dcc.owner, dcc.constraint_name, dcc.table_name, dcc.column_name, dcc.position, dc.constraint_type
        FROM dba_cons_columns@cpdb dcc, dba_constraints@cpdb dc
        WHERE 
           dc.owner IN ('ETLUPDATE','KEYNOX_CPASS','WEBFORT_CPASS','TRANSNOX_CAT','TRANSNOX_IOX','SNOX4TRANSNOX','TRANSNOX_IOX_APP','SNOX4TRANSNOX_APP','TRANSTSYSPAYMENTGW','TRANSTSYSPAYMENTGWAPP','TNOXPASS_GWAY_012','SNOXPASS_GWAY_012','SNOXPASS_SMSNOX_307','TNOXPASS_SMSNOX_307','SNOXPASS_TFE_2016','TNOXPASS_TFE_2016','TNOXPASS_GWAY_011','SNOXPASS_GWAY_011','SNOXPASS_SMSNOX_306','TNOXPASS_SMSNOX_306','TNOXPASS_TFE_2015','SNOXPASS_TFE_2015','SNOXPASS_SMSNOX_20195','TNOXPASS_SMSNOX_20195','SNOXPASS_GWAY_00526','TNOXPASS_GWAY_00526','TNOXPASS_GWAY_013','SNOXPASS_TFE_2017','SNOXPASS_GWAY_013','TNOXPASS_TFE_2017' )
--           dc.owner IN ('QCP','CHECKCASH')
          AND DC.CONSTRAINT_NAME = DCC.CONSTRAINT_NAME 
          AND DC.OWNER=DCC.OWNER
        ORDER BY TABLE_NAME,POSITION ASC
      ) remo  
  ) i
WHERE i.MISSING_CONS='N'    
--  AND EXISTS (SELECT 1 FROM dba_tables dt WHERE dt.table_name=i.table_name AND i.owner=i.owner)
  AND NOT REGEXP_LIKE(i.table_name,'ORG|*[[:digit:]]','i')
ORDER BY table_name, position ASC



-- compare missing indexes using database link (DBLink) 
SELECT UNIQUE table_owner, table_name, column_name, index_name, mixs
FROM 
(
    SELECT i.table_owner, i.table_name, i.column_name, i.index_name,
      NVL2((SELECT UNIQUE dic.table_name FROM dba_ind_columns dic WHERE DIC.TABLE_NAME = i.table_name AND dic.table_owner = i.table_owner AND dic.column_name = i.column_name AND dic.table_owner IN ('SNOX4TRANSNOX', 'SNOX4TRANSNOX_GCA', 'TRANSNOX_GCA', 'TRANSNOX_GLORY', 'TRANSNOX_RECON', 'TRANSNOX_WM')),'Y','N') mixs 
    FROM     
    (
        SELECT index_owner, index_name, table_owner, table_name, column_name
        FROM DBA_ind_columns@tp22
        WHERE index_owner IN ('SNOX4TRANSNOX', 'SNOX4TRANSNOX_GCA', 'TRANSNOX_GCA', 'TRANSNOX_GLORY', 'TRANSNOX_RECON', 'TRANSNOX_WM')
          AND table_name NOT LIKE '%ORG'
        ORDER BY index_owner,table_owner,table_name ASC
    )i
)
WHERE mixs='N'
ORDER BY 1,2,3 ASC     



-- compare the missing objects using dblink
SELECT owner, object_name, object_type, mis_tables, mis_view, mis_proc, mis_func, mis_tri, mis_pac, mis_pac_body, mis_seq 
FROM 
(    
    SELECT UNIQUE doj.owner, doj.object_name, doj.object_type,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='TABLE' AND OBJECT_name NOT LIKE 'SN_TEMP%' AND OBJECT_name NOT LIKE 'SC_TEMP%' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_tables,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='VIEW' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_view,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='PROCEDURE' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_proc,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='FUNCTION' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_func,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='TRIGGER' AND OBJECT_name NOT LIKE '%REPL' AND oj.object_name NOT LIKE '%REPL' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_tri,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='PACKAGE' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_pac,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='PACKAGE BODY' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_pac_body,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='SEQUENCE' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_seq
    FROM 
    (
        SELECT owner, object_name, object_type  
        FROM dba_objects@col122
        WHERE owner IN ('TRANSNOX_GCA','SNOX4TRANSNOX_GCA','SNOX4TRANSNOX','TRANSNOX_GLORY','TRANSNOX_WM')
          AND object_name NOT LIKE '%ORG' AND object_name NOT LIKE 'BIN$%'
          AND object_name NOT LIKE '%REPL'
          AND object_type IN ('TABLE','PROCEDURE','FUNCTION','TRIGGER','PACKAGE','PACKAGE BODY','SEQUENCE','VIEW')
        ORDER BY owner, object_name, object_type ASC
    ) doj
)
WHERE mis_tables='N'
  AND mis_view='N'
  AND mis_proc='N'
  AND mis_func='N'
  AND mis_tri='N'
  AND mis_pac='N'
  AND mis_pac_body='N'
  AND mis_seq='N'
  AND NOT REGEXP_LIKE(object_name,'TEMPSRI*|[[:digit:]]','i')
ORDER BY 3,2 ASC

-- compare the table's columns using dblink
SELECT unique owner, table_name, column_name, data_type, data_length, mis_cols
FROM
(
    SELECT dtc.owner, dtc.table_name, dtc.column_name, dtc.data_type, dtc.data_length,
        NVL2((SELECT UNIQUE dc.table_name FROM dba_tab_columns dc WHERE dc.owner=dtc.owner AND dc.table_name = dtc.table_name AND dc.column_name = dtc.column_name AND DC.DATA_TYPE = dtc.data_type AND DC.DATA_LENGTH = dtc.data_length ),'Y','N') mis_cols
    FROM
    (
        SELECT owner, table_name, column_name, data_type, data_length
        FROM dba_tab_columns@tp62
        WHERE owner IN ('ACM','ACM6000','CHECKCASH','CHECKCASHAPP','EDITH','GCA_PARSER','GCAACH','IDNOX','KEYNOX','MERGECUSTCODE','QCAPP','QCMGR','QCP','QCPAPP','QCPMGR','QCPTESTAPP','QCREDIT','QFAPP','QFCS','QFUND','QKADVANCE','QKADVANCEAPP','QRACM','QRACM_TEST','QRACMQCP','QRQCP','QUIKMEDIA','REALTIMERPT','SNOX','SCORENOX','SCORENOXAPP','SNOXDEVICES','USAP_ADAPTER','VERIBIOMETRICS','WUMT','WUMTAPP')
          AND table_name NOT LIKE '%ORG' AND table_name NOT LIKE 'BIN$%'
          AND table_name NOT LIKE 'SN_TEMP%'
        ORDER BY owner, table_name, column_name ASC
    )dtc
)
WHERE mis_cols='Y'
  AND REGEXP_LIKE(table_name,'[^0-9]$','i')
ORDER BY 1,2,3,4 ASC



--matrix which will show the set of table names, and schema name in coulms, Under those will have Y for yes having PK on table
-- else N no pk is not present in table on column name as schema name
SELECT DISTINCT j.table_name,
  NVL2((SELECT table_name FROM dba_constraints i1 WHERE i1.table_name = j.table_name AND constraint_type='P' AND owner='TRANSNOX_EAN'),'Y','N') "EAN",
  NVL2((SELECT table_name FROM dba_constraints i2 WHERE i2.table_name = j.table_name AND constraint_type='P' AND owner='TRANSNOX_WU'),'Y','N') "WU",
  NVL2((SELECT table_name FROM dba_constraints i3 WHERE i3.table_name = j.table_name AND constraint_type='P' AND owner='TRANSNOX_SSA'),'Y','N') "SSA",
  NVL2((SELECT table_name FROM dba_constraints i4 WHERE i4.table_name = j.table_name AND constraint_type='P' AND owner='TRANSNOX_WUMT'),'Y','N') "WUMT",
  NVL2((SELECT table_name FROM dba_constraints i5 WHERE i5.table_name = j.table_name AND constraint_type='P' AND owner='TRANSNOX_PEL'),'Y','N') "PEL",
  NVL2((SELECT table_name FROM dba_constraints i6 WHERE i6.table_name = j.table_name AND constraint_type='P' AND owner='TRANSNOX_CNW'),'Y','N') "CNW",
  NVL2((SELECT table_name FROM dba_constraints i7 WHERE i7.table_name = j.table_name AND constraint_type='P' AND owner='TRANSNOX_CNE'),'Y','N') "CNE"
FROM 
     (SELECT DISTINCT table_name 
      FROM 
        (SELECT owner, table_name FROM dba_tables 
         WHERE owner IN ('TRANSNOX_PEL', 'TRANSNOX_EAN', 'TRANSNOX_SSA', 'TRANSNOX_WUMT', 'TRANSNOX_WU', 'TRANSNOX_CNW')
          MINUS
         SELECT owner, table_name 
         FROM dba_constraints 
         WHERE constraint_type='P'
           AND owner IN ('TRANSNOX_PEL', 'TRANSNOX_EAN', 'TRANSNOX_SSA', 'TRANSNOX_WUMT', 'TRANSNOX_WU', 'TRANSNOX_CNW','TRANSNOX_CNE')
         )
      WHERE table_name <> 'RELEASE_HISTORY'
         AND table_name NOT LIKE '%BKP%'
         AND table_name NOT LIKE '%TEMP%'
         AND table_name NOT LIKE 'TODROP'
         AND table_name NOT LIKE '%BK%'
         AND table_name NOT LIKE '%STAGDB%'
         AND table_name NOT LIKE '%TABLE%'
         AND table_name NOT LIKE '%TEST%'
         AND table_name NOT LIKE '%0%'
         AND table_name NOT LIKE '%PROD%'
      )j
         

--- gives the list of missing table_name from given owners.
SELECT table_name, EAN, WU, SSA, WUMT, PEL, CNW, CNE
FROM (
SELECT DISTINCT j.table_name,
  NVL2((SELECT table_name FROM dba_tables i1 WHERE i1.table_name = j.table_name AND owner='TRANSNOX_EAN'),'Y','N') EAN,
  NVL2((SELECT table_name FROM dba_tables i2 WHERE i2.table_name = j.table_name AND owner='TRANSNOX_WU'),'Y','N')  WU,
  NVL2((SELECT table_name FROM dba_tables i3 WHERE i3.table_name = j.table_name AND owner='TRANSNOX_SSA'),'Y','N') SSA,
  NVL2((SELECT table_name FROM dba_tables i4 WHERE i4.table_name = j.table_name AND owner='TRANSNOX_WUMT'),'Y','N') WUMT,
  NVL2((SELECT table_name FROM dba_tables i5 WHERE i5.table_name = j.table_name AND owner='TRANSNOX_PEL'),'Y','N') PEL,
  NVL2((SELECT table_name FROM dba_tables i6 WHERE i6.table_name = j.table_name AND owner='TRANSNOX_CNW'),'Y','N') CNW,
  NVL2((SELECT table_name FROM dba_tables i7 WHERE i7.table_name = j.table_name AND owner='TRANSNOX_CNE'),'Y','N') CNE
FROM   
    (
      SELECT TABLE_NAME
      FROM dba_TABLES
      WHERE owner IN ('TRANSNOX_PEL', 'TRANSNOX_EAN', 'TRANSNOX_SSA', 'TRANSNOX_WUMT', 'TRANSNOX_WU', 'TRANSNOX_CNW','TRANSNOX_CNE')
        AND table_name NOT LIKE '%TEMP%'
        AND table_name NOT LIKE '%TEST%'
        AND table_name NOT LIKE '%0%'
        AND table_name NOT LIKE '%BK%'
        AND table_name NOT LIKE '%BKP%'
        AND table_name NOT LIKE '%DROP%'
    )j)
WHERE NOT (EAN = 'Y' AND WU = 'Y' AND SSA = 'Y' AND WUMT = 'Y' AND PEL = 'Y' AND CNW = 'Y' AND CNE = 'Y') 
ORDER BY table_name ASC


-- missing columns list
SELECT table_name, column_name, EAN, WU, SSA, WUMT, PEL, CNW, CNE
FROM
  (
    SELECT DISTINCT j.table_name, j.column_name,
      NVL2((SELECT column_name FROM dba_tab_columns i1 WHERE i1.table_name = j.table_name AND i1.column_name = j.column_name AND owner='TRANSNOX_EAN'),'Y','N') EAN,
      NVL2((SELECT column_name FROM dba_tab_columns i2 WHERE i2.table_name = j.table_name AND i2.column_name = j.column_name AND owner='TRANSNOX_WU'),'Y','N')  WU,
      NVL2((SELECT column_name FROM dba_tab_columns i3 WHERE i3.table_name = j.table_name AND i3.column_name = j.column_name AND owner='TRANSNOX_SSA'),'Y','N') SSA,
      NVL2((SELECT column_name FROM dba_tab_columns i4 WHERE i4.table_name = j.table_name AND i4.column_name = j.column_name AND owner='TRANSNOX_WUMT'),'Y','N') WUMT,
      NVL2((SELECT column_name FROM dba_tab_columns i5 WHERE i5.table_name = j.table_name AND i5.column_name = j.column_name AND owner='TRANSNOX_PEL'),'Y','N') PEL,
      NVL2((SELECT column_name FROM dba_tab_columns i6 WHERE i6.table_name = j.table_name AND i6.column_name = j.column_name AND owner='TRANSNOX_CNW'),'Y','N') CNW,
      NVL2((SELECT column_name FROM dba_tab_columns i7 WHERE i7.table_name = j.table_name AND i7.column_name = j.column_name AND owner='TRANSNOX_CNE'),'Y','N') CNE
    FROM
        (
            SELECT owner, table_name, column_name
            FROM dba_tab_columns
            WHERE owner IN ('TRANSNOX_PEL', 'TRANSNOX_EAN', 'TRANSNOX_SSA', 'TRANSNOX_WUMT', 'TRANSNOX_WU', 'TRANSNOX_CNW','TRANSNOX_CNE')
              AND table_name IN(SELECT table_name
                                FROM (
                                SELECT DISTINCT j.table_name,
                                  NVL2((SELECT table_name FROM dba_tables i1 WHERE i1.table_name = j.table_name AND owner='TRANSNOX_EAN'),'Y','N') EAN,
                                  NVL2((SELECT table_name FROM dba_tables i2 WHERE i2.table_name = j.table_name AND owner='TRANSNOX_WU'),'Y','N')  WU,
                                  NVL2((SELECT table_name FROM dba_tables i3 WHERE i3.table_name = j.table_name AND owner='TRANSNOX_SSA'),'Y','N') SSA,
                                  NVL2((SELECT table_name FROM dba_tables i4 WHERE i4.table_name = j.table_name AND owner='TRANSNOX_WUMT'),'Y','N') WUMT,
                                  NVL2((SELECT table_name FROM dba_tables i5 WHERE i5.table_name = j.table_name AND owner='TRANSNOX_PEL'),'Y','N') PEL,
                                  NVL2((SELECT table_name FROM dba_tables i6 WHERE i6.table_name = j.table_name AND owner='TRANSNOX_CNW'),'Y','N') CNW,
                                  NVL2((SELECT table_name FROM dba_tables i7 WHERE i7.table_name = j.table_name AND owner='TRANSNOX_CNE'),'Y','N') CNE
                                FROM
                                    (
                                      SELECT TABLE_NAME
                                      FROM dba_TABLES
                                      WHERE owner IN ('TRANSNOX_PEL', 'TRANSNOX_EAN', 'TRANSNOX_SSA', 'TRANSNOX_WUMT', 'TRANSNOX_WU', 'TRANSNOX_CNW','TRANSNOX_CNE')
                                        AND table_name NOT LIKE '%TEMP%'
                                        AND table_name NOT LIKE '%TEST%'
                                        AND table_name NOT LIKE '%0%'
                                        AND table_name NOT LIKE '%BK%'
                                        AND table_name NOT LIKE '%BKP%'
                                        AND table_name NOT LIKE '%DROP%'
                                    )j)
                                WHERE EAN = 'Y' AND WU = 'Y' AND SSA = 'Y' AND WUMT = 'Y' AND PEL = 'Y' AND CNW = 'Y' AND CNE = 'Y')
        )j
  )
WHERE NOT (EAN = 'Y' AND WU = 'Y' AND SSA = 'Y' AND WUMT = 'Y' AND PEL = 'Y' AND CNW = 'Y' AND CNE = 'Y')
ORDER BY table_name ASC
;

-- compare missing indexes using database link (DBLink) 
SELECT UNIQUE table_owner, table_name, column_name, index_name, mixs
FROM 
(
    SELECT i.table_owner, i.table_name, i.column_name, i.index_name,
      NVL2((SELECT UNIQUE dic.table_name 
                           FROM dba_ind_columns dic 
                          WHERE DIC.TABLE_NAME = i.table_name 
                            AND dic.table_owner = i.table_owner 
                            AND dic.column_name = i.column_name 
                            AND dic.table_owner IN ('SNOX4TRANSNOX', 'SNOX4TRANSNOX_GCA', 'TRANSNOX_GCA', 'TRANSNOX_GLORY', 'TRANSNOX_RECON', 'TRANSNOX_WM')),'Y','N') mixs 
    FROM     
    (
        SELECT index_owner, index_name, table_owner, table_name, column_name
        FROM DBA_ind_columns@tp22
        WHERE index_owner IN ('SNOX4TRANSNOX', 'SNOX4TRANSNOX_GCA', 'TRANSNOX_GCA', 'TRANSNOX_GLORY', 'TRANSNOX_RECON', 'TRANSNOX_WM')
          AND table_name NOT LIKE '%ORG'
        ORDER BY index_owner,table_owner,table_name ASC
    )i
)
WHERE mixs='N'
ORDER BY 1,2,3 ASC     


-- compare missing constraints indexes using DBLink
SELECT UNIQUE owner, table_name, column_name, mis_conts
FROM 
(
    SELECT dcc.owner, dcc.table_name, dcc.column_name, 
        NVL2((SELECT UNIQUE dc.table_name FROM dba_cons_columns dc WHERE dc.owner=dcc.owner AND dc.table_name = dcc.table_name AND dc.column_name = dcc.column_name AND  dc.table_name NOT LIKE 'BIN$%' AND dc.owner IN ('SNOX4TRANSNOX', 'SNOX4TRANSNOX_GCA', 'TRANSNOX_GCA', 'TRANSNOX_GLORY', 'TRANSNOX_RECON', 'TRANSNOX_WM') AND dc.table_name NOT LIKE '%ORG'),'Y','N') mis_conts
    FROM
    (
        SELECT owner, constraint_name, table_name, column_name 
        FROM dba_cons_columns@t2
        WHERE owner IN ('SNOX4TRANSNOX', 'SNOX4TRANSNOX_GCA', 'TRANSNOX_GCA', 'TRANSNOX_GLORY', 'TRANSNOX_RECON', 'TRANSNOX_WM')
          AND table_name NOT LIKE '%ORG' AND table_name NOT LIKE 'BIN$%'
        ORDER BY owner, constraint_name, table_name, column_name ASC
    )dcc
)
WHERE mis_conts='N'
  AND REGEXP_LIKE(table_name,'[^0-9]$','i')
ORDER BY 1,2,3 ASC  


-- compare the missing objects using dblink
SELECT owner, object_name, object_type, mis_tables, mis_view, mis_proc, mis_func, mis_tri, mis_pac, mis_pac_body, mis_seq 
FROM 
(    
    SELECT UNIQUE doj.owner, doj.object_name, doj.object_type,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='TABLE' AND NOT REGEXP_LIKE(table_name,'s._temp[[:digit:]]','i') AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_tables,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='VIEW' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_view,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='PROCEDURE' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_proc,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='FUNCTION' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_func,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='TRIGGER' AND OBJECT_name NOT LIKE '%REPL' AND oj.object_name NOT LIKE '%REPL' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_tri,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='PACKAGE' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_pac,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='PACKAGE BODY' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_pac_body,
        NVL2((SELECT UNIQUE oj.object_name FROM dba_objects oj WHERE oj.object_type='SEQUENCE' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_seq
    FROM 
    (
        SELECT owner, object_name, object_type  
        FROM dba_objects@tw
        WHERE owner IN ('TRANSNOX_IOX', 'SNOX4TRANSNOX', 'WEBFORT_CPASS', 'TRANSNOX_CAT', 'TRANSTSYSPAYMENTGW','TRANSIT_GATEWAY_TNOX_319','TRANSIT_GATEWAY_SNOX_319','TRANSIT_FE_TNOX_319','TRANSIT_FE_SNOX_319','TRANSIT_SMSNOX_SNOX_318','TRANSIT_SMSNOX_TNOX_318')
          AND object_name NOT LIKE '%ORG' 
          AND object_name NOT LIKE 'BIN$%'
          AND object_name NOT LIKE '%REPL'
          AND object_type IN ('TABLE','PROCEDURE','FUNCTION','TRIGGER','PACKAGE','PACKAGE BODY','SEQUENCE','VIEW')
        ORDER BY owner, object_name, object_type ASC
    ) doj
)
WHERE mis_tables='N'
  AND mis_view='N'
  AND mis_proc='N'
  AND mis_func='N'
  AND mis_tri='N'
  AND mis_pac='N'
  AND mis_pac_body='N'
  AND mis_seq='N'
  AND REGEXP_LIKE(object_name,'[^0-9]$','i')
ORDER BY 1,2,3 ASC



CREATE OR REPLACE FORCE VIEW rchaudhari.chk_missing_objects
(
    OWNER, 
    OBJECT_NAME, 
    OBJECT_TYPE, 
    DBNAME, 
    MIS_TABLES, 
    MIS_VIEW, 
    MIS_PROC, 
    MIS_FUNC, 
    MIS_TRI, 
    MIS_PAC, 
    MIS_PAC_BODY, 
    MIS_SEQ
)
AS    
SELECT OWNER, OBJECT_NAME, OBJECT_TYPE, DBNAME, MIS_TABLES, MIS_VIEW, MIS_PROC, MIS_FUNC, MIS_TRI, MIS_PAC, MIS_PAC_BODY, MIS_SEQ 
FROM 
(    
    SELECT UNIQUE doj.owner, doj.object_name, doj.object_type, 'TE' DBName,
        NVL2((SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type='TABLE' AND NOT REGEXP_LIKE(object_name,'s._temp[[:digit:]]','i') AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_tables,
        NVL2((SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type='VIEW' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_view,
        NVL2((SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type='PROCEDURE' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_proc,
        NVL2((SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type='FUNCTION' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_func,
        NVL2((SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type='TRIGGER' AND OBJECT_name NOT LIKE '%REPL' AND oj.object_name NOT LIKE '%REPL' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_tri,
        NVL2((SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type='PACKAGE' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_pac,
        NVL2((SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type='PACKAGE BODY' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_pac_body,
        NVL2((SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type='SEQUENCE' AND oj.owner = doj.owner AND oj.object_name = doj.object_name),'Y','N') mis_seq
    FROM 
    (
        SELECT owner, object_name, object_type, 'TW' DBName 
        FROM all_objects@tw
        WHERE owner IN ('RCHAUDHARI','TRANSNOX_IOX', 'SNOX4TRANSNOX', 'WEBFORT_CPASS', 'TRANSNOX_CAT', 'TRANSTSYSPAYMENTGW','TRANSIT_GATEWAY_TNOX_319','TRANSIT_GATEWAY_SNOX_319','TRANSIT_FE_TNOX_319','TRANSIT_FE_SNOX_319','TRANSIT_SMSNOX_SNOX_318','TRANSIT_SMSNOX_TNOX_318')
          AND object_name NOT LIKE '%ORG' 
          AND object_name NOT LIKE 'BIN$%'
          AND object_name NOT LIKE '%REPL'
          AND OBJECT_TYPE IN ('TABLE','PROCEDURE','FUNCTION','TRIGGER','PACKAGE','PACKAGE BODY','SEQUENCE','VIEW')
        ORDER BY owner, object_name, object_type ASC
    ) doj
)
WHERE mis_tables='N'
  AND mis_view='N'
  AND mis_proc='N'
  AND mis_func='N'
  AND mis_tri='N'
  AND mis_pac='N'
  AND mis_pac_body='N'
  AND mis_seq='N'
  AND REGEXP_LIKE(object_name,'[^0-9]$','i')
ORDER BY 1,2,3 ASC



CREATE OR REPLACE FORCE VIEW RCHAUDHARI.CHK_indexes
(
   table_owner,
   table_name,
   column_name,
   index_name,
   te_miss_indexes
)
AS
SELECT UNIQUE table_owner, table_name, column_name, index_name, te_miss_indexes
FROM 
(
    SELECT tw.table_owner, tw.table_name, tw.column_name, tw.index_name,
      NVL2((SELECT UNIQUE te.table_name 
              FROM all_ind_columns te 
             WHERE te.TABLE_NAME = tw.table_name 
               AND te.table_owner = tw.table_owner 
               AND te.column_name = tw.column_name 
               AND te.table_owner = tw.table_owner),'Y','N') te_miss_indexes 
    FROM     
    (
        SELECT index_owner, index_name, table_owner, table_name, column_name
        FROM all_ind_columns@tw
        WHERE index_owner IN ('TRANSNOX_IOX', 'SNOX4TRANSNOX', 'WEBFORT_CPASS', 'TRANSNOX_CAT', 'TRANSTSYSPAYMENTGW','TRANSIT_GATEWAY_TNOX_319','TRANSIT_GATEWAY_SNOX_319','TRANSIT_FE_TNOX_319','TRANSIT_FE_SNOX_319','TRANSIT_SMSNOX_SNOX_318','TRANSIT_SMSNOX_TNOX_318')
          AND NOT REGEXP_LIKE(table_name,'s._temp[[:digit:]]','i')
        ORDER BY index_owner,table_owner,table_name ASC
    )tw
)
WHERE te_miss_indexes='N'
ORDER BY 1,2,3 ASC  



CREATE OR REPLACE FORCE VIEW RCHAUDHARI.CHK_Columns_DataTypes
(
   owner,
   table_name,
   column_name,
   data_type,
   data_length,
   TE_miss_Match
)
AS
SELECT UNIQUE owner, table_name, column_name, data_type, data_length, TE_miss_Match
FROM
(
    SELECT tw.owner, tw.table_name, tw.column_name, tw.data_type, tw.data_length,
        NVL2((SELECT UNIQUE te.table_name 
                FROM all_tab_columns te 
               WHERE te.owner=tw.owner 
                 AND te.table_name = tw.table_name 
                 AND te.column_name = tw.column_name 
                 AND te.DATA_TYPE = tw.data_type 
                 AND te.DATA_LENGTH = tw.data_length
                 AND NOT REGEXP_LIKE(table_name,'s._temp[[:digit:]]','i')
                 AND te.table_name NOT LIKE '%ORG'),'Y','N') TE_miss_Match
    FROM
    (
        SELECT owner, table_name, column_name, data_type, data_length
        FROM all_tab_columns@tw
        WHERE owner IN ('TRANSNOX_IOX', 'SNOX4TRANSNOX', 'WEBFORT_CPASS', 'TRANSNOX_CAT', 'TRANSTSYSPAYMENTGW','TRANSIT_GATEWAY_TNOX_319','TRANSIT_GATEWAY_SNOX_319','TRANSIT_FE_TNOX_319','TRANSIT_FE_SNOX_319','TRANSIT_SMSNOX_SNOX_318','TRANSIT_SMSNOX_TNOX_318')
          AND table_name NOT LIKE '%ORG' 
          AND NOT REGEXP_LIKE(table_name,'s._temp[[:digit:]]','i')
        ORDER BY owner, table_name, column_name ASC
    )tw
)
WHERE TE_miss_Match='N'
  AND REGEXP_LIKE(table_name,'[^0-9]$','i')
ORDER BY 1,2,3,4 ASC


CREATE OR REPLACE FORCE VIEW RCHAUDHARI.CHK_SEQUENCES
(
   SEQUENCE_NAME,
   TW_Seq_LastNumber,
   TE_SEQ_LastNumber,
   DIFF_NUMBER,
   CACHE_SIZE
)
AS
     SELECT TW.SEQUENCE_NAME,
            TW.LAST_NUMBER TW_Seq_LastNumber,
            TE.LAST_NUMBER TE_SEQ_LastNumber,
            TE.LAST_NUMBER - TW.LAST_NUMBER diff_number,
            TW.CACHE_SIZE
       FROM ALL_sequences@TW TW, ALL_sequences TE
      WHERE     TW.SEQUENCE_OWNER IN ('TRANSNOX_IOX',
                                        'SNOX4TRANSNOX',
                                        'WEBFORT_CPASS',
                                        'TRANSNOX_CAT',
                                        'TRANSTSYSPAYMENTGW')
            AND TW.SEQUENCE_OWNER = TE.SEQUENCE_OWNER
            AND TW.SEQUENCE_NAME = TE.SEQUENCE_NAME
            AND TE.LAST_NUMBER > TW.LAST_NUMBER
   ORDER BY 5 DESC;
   
   
-- compare the table's columns using dblink
SELECT unique owner, table_name, column_name, data_type, data_length, mis_cols
FROM
(
    SELECT dtc.owner, dtc.table_name, dtc.column_name, dtc.data_type, dtc.data_length,
        NVL2((SELECT UNIQUE dc.table_name 
                 FROM dba_tab_columns dc 
                WHERE dc.owner=dtc.owner 
                  AND dc.table_name = dtc.table_name 
                  AND dc.column_name = dtc.column_name 
                  AND DC.DATA_TYPE = dtc.data_type 
                  AND DC.DATA_LENGTH = dtc.data_length 
                  AND dc.table_name NOT LIKE 'BIN$%' 
                  AND dc.owner IN ('ACM','ACM6000','CHECKCASH','CHECKCASHAPP','EDITH','GCA_PARSER','GCAACH','IDNOX','KEYNOX','MERGECUSTCODE','QCAPP','QCMGR','QCP','QCPAPP','QCPMGR','QCPTESTAPP','QCREDIT','QFAPP','QFCS','QFUND','QKADVANCE','QKADVANCEAPP','QRACM','QRACM_TEST','QRACMQCP','QRQCP','QUIKMEDIA','REALTIMERPT','SNOX','SCORENOX','SCORENOXAPP','SNOXDEVICES','USAP_ADAPTER','VERIBIOMETRICS','WUMT','WUMTAPP') AND dc.table_name NOT LIKE 'SN_TEMP%' AND dc.table_name NOT LIKE '%ORG'),'Y','N') mis_cols
    FROM
    (
        SELECT owner, table_name, column_name, data_type, data_length
        FROM dba_tab_columns@tp62
        WHERE owner IN ('ACM','ACM6000','CHECKCASH','CHECKCASHAPP','EDITH','GCA_PARSER','GCAACH','IDNOX','KEYNOX','MERGECUSTCODE','QCAPP','QCMGR','QCP','QCPAPP','QCPMGR','QCPTESTAPP','QCREDIT','QFAPP','QFCS','QFUND','QKADVANCE','QKADVANCEAPP','QRACM','QRACM_TEST','QRACMQCP','QRQCP','QUIKMEDIA','REALTIMERPT','SNOX','SCORENOX','SCORENOXAPP','SNOXDEVICES','USAP_ADAPTER','VERIBIOMETRICS','WUMT','WUMTAPP')
          AND table_name NOT LIKE '%ORG' AND table_name NOT LIKE 'BIN$%'
          AND table_name NOT LIKE 'SN_TEMP%'
        ORDER BY owner, table_name, column_name ASC
    )dtc
)
WHERE mis_cols='Y'
  AND REGEXP_LIKE(table_name,'[^0-9]$','i')
ORDER BY 1,2,3,4 ASC

-- can use the below query to compare the grants/privileges
-- Need to develop for using dblink
SELECT UNIQUE grantor, listagg(PRIVILEGE,',') WITHIN GROUP (ORDER BY PRIVILEGE)AS privs, grantee, table_name
FROM dba_tab_privs
WHERE owner='ODI'
--AND table_name='APPLICATION_CONFIG'
AND grantee='ODI_USER'
GROUP BY grantor, grantee, table_name
ORDER BY 1,4 ASC;

--- compare all the missing  objects from differetn database schema's
SELECT UNIQUE owner, object_name, object_type, --DBName,
    NVL2((SELECT UNIQUE OBJECT_NAME FROM DBA_OBJECTS@TEMPE_22 t22 WHERE t22.object_type=c121.OBJECT_TYPE AND t22.owner=c121.owner AND t22.object_name=c121.object_name),'x','Not present on Tempe_22') Tempe_22,
    NVL2((SELECT UNIQUE OBJECT_NAME FROM DBA_OBJECTS@tempe_21 t21 WHERE t21.object_type=c121.OBJECT_TYPE AND t21.owner=c121.owner AND t21.object_name=c121.object_name),'x','Not present on Tempe_21') Tempe_21,
    NVL2((SELECT UNIQUE OBJECT_NAME FROM DBA_OBJECTS@col122 c122 WHERE c122.object_type=c121.OBJECT_TYPE AND c122.owner=c121.owner AND c122.object_name=c121.object_name),'x','Not present on COL_122') COl_122,
    NVL2((SELECT UNIQUE OBJECT_NAME FROM DBA_OBJECTS col121 WHERE col121.object_type=c121.OBJECT_TYPE AND col121.owner=c121.owner AND col121.object_name=c121.object_name),'x','Not present on COL_121') COL_121
FROM 
  (
    SELECT owner, object_name, object_type, 'Tempe_22' dbname
    FROM dba_objects@tempe_22
    WHERE owner='TRANSNOX_RECON'
      AND object_type IN ('PROCEDURE','TABLE','FUNCTION','SEQUENCE')
    UNION ALL 
    SELECT owner, object_name, object_type, 'Tempe_21' dbname
    FROM dba_objects@tempe_21
    WHERE owner='TRANSNOX_RECON'
      AND object_type IN ('PROCEDURE','TABLE','FUNCTION','SEQUENCE')
    UNION ALL
    SELECT owner, object_name, object_type, 'col_122' dbname
    FROM dba_objects@col122
    WHERE owner='TRANSNOX_RECON'
      AND object_type IN ('PROCEDURE','TABLE','FUNCTION','SEQUENCE')
    UNION ALL
    SELECT owner, object_name, object_type, 'col_121' dbname
    FROM dba_objects
    WHERE owner='TRANSNOX_RECON'
      AND object_type IN ('PROCEDURE','TABLE','FUNCTION','SEQUENCE')
  ) c121
WHERE owner='TRANSNOX_RECON'
  AND NOT REGEXP_LIKE(object_name,'^tempsri*|^s.temp[[:digit]]','i')   
ORDER BY 3 ASC  


SELECT OWNER, OBJECT_NAME, OBJECT_TYPE, MIS_TABLES, MIS_VIEW, MIS_PROC, MIS_FUNC, MIS_TRI, MIS_PAC, MIS_PAC_BODY, MIS_SEQ
FROM (SELECT UNIQUE
                                    doj.owner,
                                    doj.object_name,
                                    doj.object_type,
                                    NVL2 ( (SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type = 'TABLE' AND NOT REGEXP_LIKE (object_name, 's._temp[[:digit:]]', 'i') AND oj.owner = doj.owner AND oj.object_name = doj.object_name), 'Y', 'N') mis_tables,
                                    NVL2 ( (SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type = 'VIEW' AND oj.owner = doj.owner AND oj.object_name = doj.object_name), 'Y', 'N') mis_view,
                                    NVL2 ( (SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type = 'PROCEDURE' AND oj.owner = doj.owner AND oj.object_name = doj.object_name), 'Y', 'N') mis_proc,
                                    NVL2 ( (SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type = 'FUNCTION' AND oj.owner = doj.owner AND oj.object_name = doj.object_name), 'Y', 'N') mis_func,
                                    NVL2 ( (SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type = 'TRIGGER' AND OBJECT_name NOT LIKE '%REPL' AND oj.object_name NOT LIKE '%REPL' AND oj.owner = doj.owner AND oj.object_name = doj.object_name), 'Y', 'N') mis_tri,
                                    NVL2 ( (SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type = 'PACKAGE' AND oj.owner = doj.owner AND oj.object_name = doj.object_name), 'Y', 'N') mis_pac,
                                    NVL2 ( (SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type = 'PACKAGE BODY' AND oj.owner = doj.owner AND oj.object_name = doj.object_name), 'Y', 'N') mis_pac_body,
                                    NVL2 ( (SELECT UNIQUE oj.object_name FROM all_objects oj WHERE oj.object_type = 'SEQUENCE' AND oj.owner = doj.owner AND oj.object_name = doj.object_name), 'Y', 'N') mis_seq
               FROM (  SELECT owner, object_name, object_type
                                                FROM all_objects@tw_Cpass
                                                WHERE     owner IN ('TRANSNOX_IOX','SNOX4TRANSNOX', 'TRANSIT_GATEWAY_TNOX_3111', 'TRANSIT_GATEWAY_SNOX_3111', 'TRANSIT_FE_TNOX_3111', 'TRANSIT_FE_SNOX_3111', 'TRANSIT_SMSNOX_SNOX_3111', 'TRANSIT_SMSNOX_TNOX_3111')
                                                              AND object_name NOT LIKE '%ORG'
                                                              AND object_name NOT LIKE 'BIN$%'
                                                              AND object_name NOT LIKE '%REPL'
                                                              AND OBJECT_TYPE IN ('TABLE', 'PROCEDURE', 'FUNCTION', 'TRIGGER', 'PACKAGE', 'PACKAGE BODY', 'SEQUENCE', 'VIEW')
                                    ORDER BY owner, object_name, object_type ASC) doj)
WHERE     mis_tables = 'N'
            AND mis_view = 'N'
            AND mis_proc = 'N'
            AND mis_func = 'N'
            AND mis_tri = 'N'
            AND mis_pac = 'N'
            AND mis_pac_body = 'N'
            AND mis_seq = 'N'
            AND REGEXP_LIKE (object_name, '[^0-9]$', 'i')
ORDER BY 1, 2, 3 ASC;
=================================================================================

---- user profiles based on profile
SELECT username, account_status, PROFILE
FROM dba_users 
WHERE PROFILE  IN ('STD_INTERACTIVE_USER_90DAYS','STD_INTERACTIVE_USER_60DAYS')
ORDER BY username ASC;


---- user roles and privileges from objects based on profile
SELECT DISTINCT ds.username,listagg(granted_role,', ') WITHIN GROUP (ORDER BY granted_role) granted_role,
--    (SELECT LISTAGG(ROLE,',') WITHIN GROUP (ORDER BY ROLE)GRANTED_ROLE FROM dba_roles dr WHERE dr.grantee = ds.username GROUP BY grantee) role_granted,
    (SELECT listagg(PRIVILEGE,', ') WITHIN GROUP (ORDER BY PRIVILEGE) privs FROM dba_tab_privs dtp  WHERE PRIVILEGE IN (SELECT PRIVILEGE FROM dba_sys_privs) AND dtp.grantee = ds.username GROUP BY dtp.grantee) sys_privileges,
    (SELECT listagg(PRIVILEGE,', ') WITHIN GROUP (ORDER BY PRIVILEGE) privs FROM (SELECT grantee, PRIVILEGE, row_number() OVER (PARTITION BY grantee, PRIVILEGE ORDER BY grantee) AS rn FROM dba_tab_privs dtp1 WHERE dtp1.grantee = ds.username) WHERE rn=1)  object_privilges
FROM dba_role_privs drp, dba_users ds
WHERE ds.USERNAME = drp.grantee
  AND  ds.PROFILE  IN ('STD_INTERACTIVE_USER_90DAYS','STD_INTERACTIVE_USER_60DAYS')
  GROUP BY ds.username
ORDER BY ds.username ASC
=================================================================================

-- with Clause ref link  
http://psoug.org/reference/OLD/with.html?PHPSESSID=0170804500f330f02e30ddbb1f8e84a2

-- works like a loop in select statment
-- columns data separated by , (comma)
with data as 
( 
    select casinocode, employeecode, 
    row_number() over (partition by casinocode order by employeecode) rn, 
    count(*) over (partition by casinocode) cnt 
    from qcp.employees
    where CASINOCODE = '000012'
) 
select casinocode,
ltrim(sys_connect_by_path(employeecode,','),',') scbp
from data
where rn = cnt
start with rn = 1
connect by prior casinocode = casinocode
and prior rn = rn-1
order by casinocode


--- Script for comma separated 
SELECT parent_id, 
	RTRIM(XMLAGG(XMLELEMENT(e,child_id || ',')).EXTRACT('//text()'),',') AS "Children"   
FROM parentChildTable  
WHERE parent_id = 0  
GROUP BY parent_id 

SELECT parent_id, LISTAGG(child_id, ',') WITHIN GROUP (ORDER BY child_id) AS "Children"   
FROM parentChildTable  
WHERE parent_id = 0  
GROUP BY parent_id 

Or use the Oracle function WM_CONCAT(Column_Name) for comma separator


-- script to create grants for given schema's
with data as
(
    SELECT grantee,table_name,grantor,privilege,
            row_number() over (partition by table_name order by grantor) rn, 
            count(*) over (partition by table_name) cnt 
    from dba_tab_privs
    where grantor in ('SNOX4TRANSNOX','TRANSNOX_CPK')
      AND GRANTEE in ('SNOX4TRANSNOX','TRANSNOX_CPK')
    GROUP BY  grantee,table_name,grantor,privilege
    ORDER BY  table_name asc
)
select --grantor "Grants From",grantee "Grants To", table_name, 
    'GRANT '||ltrim(sys_connect_by_path(privilege,','),',')||' ON '||grantor||'.'||TABLE_NAME||' TO '||decode(grantor,'SNOX4TRANSNOX','TNOX_IOX0059','TRANSNOX_CPK','SNOX_10314')||';' scbp
from data 
where rn = cnt 
start with rn = 1 
connect by prior table_name = table_name 
and prior rn = rn-1 
order by 1 asc  


-- table name which are present in the schema and schema's will output as common separated
with data as
(
    SELECT owner, object_name,
            row_number() over (partition by object_name order by owner) rn, 
            count(*) over (partition by object_name) cnt 
    FROM dba_objects i
    WHERE object_type='TABLE' 
        AND object_name NOT LIKE 'SN_TEMP%'
        AND object_name <> 'RELEASE_HISTORY'
        AND object_name NOT LIKE '%BKP'
        AND object_name NOT LIKE 'TEMP%'
        AND object_name NOT LIKE 'TODROP'
        AND object_name NOT LIKE '%BK'
        AND object_name NOT LIKE 'SC_TEMP%'
        AND object_name NOT LIKE 'BIN$%'
        and  OWNER  IN ('TRANSNOX_PEL', 'TRANSNOX_EAN', 'TRANSNOX_SSA', 'TRANSNOX_WUMT', 'TRANSNOX_WU', 'TRANSNOX_CNW','TRANSNOX_CNE')
    GROUP BY  owner, object_name
    ORDER BY  object_name asc
)
select object_name, 
    ltrim(sys_connect_by_path(owner,','),',') scbp 
from data 
where rn = cnt 
start with rn = 1 
connect by prior object_name = object_name 
and prior rn = rn-1 
order by object_name  

****************************************  SUBQUERY FACTORING ****************************************


-- find 11 latest records
SELECT * 
FROM 
  (
     SELECT  *  FROM   qcp.transactions 
     ORDER BY ROWNUM DESC
  ) 
WHERE ROWNUM < 11;

-------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------
-- This excludes the weekends
CREATE OR REPLACE FUNCTION no_weekends_action (p_date1 IN DATE, p_date2 IN DATE) RETURN NUMBER IS
   l_count NUMBER := 0;
   v_excluded_days number;
   v_minutes       number;
   l_date1 DATE := LEAST(p_date1, p_date2);
   l_date2 DATE := GREATEST(p_date1, p_date2);
BEGIN
   WHILE (l_date1 <= l_date2) LOOP
      IF (TO_CHAR(l_date1,'DY') NOT IN ('SAT','SUN')) THEN
         l_count := l_count + 1;
      END IF;
      l_date1 := l_date1 + 1;
   END LOOP;
   
   v_excluded_days:= floor((l_date2-l_date1)-l_count);
   v_minutes := round(((l_date2-l_date1)-v_excluded_days )*24*60);
   RETURN v_minutes;
END;
/

select no_weekends_action(to_date('06/26/2009 01:23:00 PM','mm/dd/yyyy hh:mi:ss am'),
to_date('07/03/2009 03:42:00 PM','mm/dd/yyyy hh:mi:ss am')) ||' mins 'diff 
from dual

-------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------

--Returns A Day A Specified Number Of Days In The Future Skipping Weekends
CREATE OR REPLACE FUNCTION business_date 
(
	start_date DATE,
	Days2Add NUMBER
) RETURN DATE IS
 Counter  NATURAL := 0;
 CurDate  DATE := start_date;
 DayNum   POSITIVE;
 SkipCntr NATURAL := 0; 
BEGIN
  WHILE Counter < Days2Add LOOP
    CurDate := CurDate+1;
    DayNum := TO_CHAR(CurDate, 'D');

    IF DayNum BETWEEN 2 AND 6 THEN
      Counter := Counter + 1;
    ELSE
      SkipCntr := SkipCntr + 1;
    END IF;
  END LOOP;
  RETURN start_date + Counter + SkipCntr;
END business_date;
/

          
-- date come in wording
SELECT TO_CHAR(TO_DATE('10:30:18', 'HH24:MI:SS'), 'HH24SP:MISP:SSSP') FROM dual;

SELECT TO_CHAR(TO_DATE('01-JAN-2008', 'DD-MON-YYYY'), 'DDSP-MONTH-YYYYSP') FROM dual;

SELECT TO_CHAR(TO_DATE('01-JAN-2008', 'DD-MM-YYYY'), 'DDSP-MMSP-YYYYSP') FROM dual;


-- SQL query to get all user informations (Roles, Privileges, SYSTEM Privs)
SELECT DISTINCT ds.username,listagg(granted_role,', ') WITHIN GROUP (ORDER BY granted_role) granted_role,
--    (SELECT LISTAGG(ROLE,',') WITHIN GROUP (ORDER BY ROLE)GRANTED_ROLE FROM dba_roles dr WHERE dr.grantee = ds.username GROUP BY grantee) role_granted,
    (
       SELECT listagg(PRIVILEGE,', ') WITHIN GROUP (ORDER BY PRIVILEGE) privs 
         FROM dba_tab_privs dtp  
        WHERE PRIVILEGE IN (SELECT PRIVILEGE 
                              FROM dba_sys_privs) 
          AND dtp.grantee = ds.username 
        GROUP BY dtp.grantee
     ) sys_privileges,
    (
       SELECT listagg(PRIVILEGE,', ') WITHIN GROUP (ORDER BY PRIVILEGE) privs 
         FROM (SELECT grantee, PRIVILEGE, row_number() OVER (PARTITION BY grantee, PRIVILEGE ORDER BY grantee) AS rn 
                 FROM dba_tab_privs dtp1 
                WHERE dtp1.grantee = ds.username) 
        WHERE rn=1)  object_privilges
 FROM dba_role_privs drp, dba_users ds
WHERE ds.USERNAME = drp.grantee
  and ds.username  in (select username 
                         from dba_users 
                        where username not in ('ANONYMOUS','APEX_030200','APEX_PUBLIC_USER','APPQOSSYS','BI',
                                               'CTXSYS','DBSNMP','DIP','EXFSYS','FLOWS_FILES','HR','IX','MDDATA',
                                               'MDSYS','MGMT_VIEW','OE','OLAPSYS','ORACLE_OCM','ORDDATA','ORDPLUGINS',
                                               'ORDSYS','OUTLN','OWBSYS','OWBSYS_AUDIT','PM','SCOTT','SH','SI_INFORMTN_SCHEMA',
                                               'SPATIAL_CSW_ADMIN_USR','SPATIAL_WFS_ADMIN_USR','SYS','SYSMAN','SYSTEM','WMSYS',
                                               'XDB','XS$NULL'))
  GROUP BY ds.username
ORDER BY ds.username ASC ; 
=================================================================================

-- gives the list of those table which are not having an reference to/from 
-- any table within the schema
select table_name
from dba_tables o
where not exists (select 'x'    
                  from dba_constraints i
                  where i.TABLE_NAME = o.TABLE_NAME
                    and i.CONSTRAINT_TYPE = 'R'
                    AND i.CONSTRAINT_TYPE NOT IN ('P','U')
                    and i.owner = o.OWNER)
 and o.OWNER = 'TRANSHMS'
=================================================================================


-- script of creating table script for selected tables from selected schemas
WITH DATA AS 
(
    SELECT owner,table_name,column_name,data_type,data_length,column_id,
        row_number() OVER (PARTITION BY table_name ORDER BY column_id) rn, 
        COUNT(*) OVER (PARTITION BY table_name) cnt 
    FROM dba_tab_columns
    WHERE owner='SNOX4TRANSNOX_GCA'
     AND TABLE_NAME IN ('CC_CSR_TASK_ASSIGN_TS','CC_QUEUE_ID_MASTER','CC_TASK_INFO','CORPORATION_CONFIGURATION'
    ORDER BY owner,table_name,column_id ASC 
)
SELECT replace(REPLACE(REPLACE(REPLACE('create table '||owner||'.'||table_name||' ('||
LTRIM(SYS_CONNECT_BY_PATH(column_name ||' ' ||data_type ||'('||DECODE(data_type,'DATE','','CLOB','','BLOB','','LONG','',data_length)||')',', '),',')||');','DATE()','DATE'),'CLOB()','CLOB'),'BLOB()','BLOB'),'LONG()','LONG') scrt 
FROM DATA 
WHERE rn = cnt 
START WITH rn = 1 
CONNECT BY PRIOR table_name = table_name 
AND PRIOR rn = rn-1 
ORDER BY owner 
;

=================================================================================

-- changing index tablespace script for LOB indexes for data type like CLOB / BOLB etc...
SELECT 'ALTER TABLE '||OWNER||'.'||TABLE_NAME||' MOVE LOB ('||COLUMN_NAME||') STORE AS (TABLESPACE INDX);' indx 
FROM dba_tab_columns 
WHERE table_name IN 
 ('ADSMASTER','CALLNOX_AUDIT_TRAIL','CLOB_TEMP','CUST_FACE','CUST_FACE_HISTORY','CUST_FINGER','CUST_FINGER_PRINT','CUST_FINGER_PRINT_HISTORY','CUST_ID_IMAGES_HIST','ENROLLED_CHECK','ENROLLED_CHECK_HISTORY','ENROLLED_CHECK_PROFILE_HISTORY','KFE_REQUEST_RESPONSE','KFE_REQUEST_RESPONSE_BKP','KFE_REQUEST_RESPONSE_HIST','LOGO_IMAGES','MNOX_SERVER_DETAILS','RECON_FILE_CONFIG','SNOX_UPDATE_AUDIT_TRAIL ','SNOX_USER_ACCESS','SN_PRODUCT_DEPLOYMENT ','SN_PRODUCT_MASTER','SN_PRODUCT_TESTING ','SN_PROD_DB_RELEASE ','SUSP_CUST_FACE','SUSP_CUST_FINGER_PRINT','SUSP_CUST_ID_IMAGES','TEMP_CUST_FACE','TEMP_CUST_FINGER_PRINT','TEMP_CUST_ID_IMAGES','TRAN_CHECK_IMAGES','TRAN_CUST_FACE','TRAN_CUST_ID_IMAGE ','USER_FINGER_PRINT','USER_FINGER_PRINT_HISTORY') 
 AND data_type IN ('BOLB','CLOB')
 
 
ALTER TABLE  QCP.CUSTOMER_SIGNATURES
    MOVE TABLESPACE users
    LOB (ENROLLMENT_SIGNATURE) STORE AS (TABLESPACE INDX)
 
---- script for rebuilding index tablespace 
 SELECT 'ALTER INDEX '||OWNER||'.'||INDEX_NAME||' REBUILD TABLESPACE INDX;'
 FROM DBA_INDEXES
 WHERE OWNER IN 
  ('ADSMASTER','CALLNOX_AUDIT_TRAIL','CLOB_TEMP','CUST_FACE','CUST_FACE_HISTORY','CUST_FINGER','CUST_FINGER_PRINT','CUST_FINGER_PRINT_HISTORY','CUST_ID_IMAGES_HIST','ENROLLED_CHECK','ENROLLED_CHECK_HISTORY','ENROLLED_CHECK_PROFILE_HISTORY','KFE_REQUEST_RESPONSE','KFE_REQUEST_RESPONSE_BKP','KFE_REQUEST_RESPONSE_HIST','LOGO_IMAGES','MNOX_SERVER_DETAILS','RECON_FILE_CONFIG','SNOX_UPDATE_AUDIT_TRAIL ','SNOX_USER_ACCESS','SN_PRODUCT_DEPLOYMENT ','SN_PRODUCT_MASTER','SN_PRODUCT_TESTING ','SN_PROD_DB_RELEASE ','SUSP_CUST_FACE','SUSP_CUST_FINGER_PRINT','SUSP_CUST_ID_IMAGES','TEMP_CUST_FACE','TEMP_CUST_FINGER_PRINT','TEMP_CUST_ID_IMAGES','TRAN_CHECK_IMAGES','TRAN_CUST_FACE','TRAN_CUST_ID_IMAGE ','USER_FINGER_PRINT','USER_FINGER_PRINT_HISTORY') 
  AND INDEX_TYPE='NORMAL'
=================================================================================


---- count of primary key columns 
SELECT constraint_name,table_name,owner,COUNT(*) cnt_cons 
FROM dba_cons_columns 
WHERE constraint_name LIKE 'PK%' 
  AND owner NOT IN 
   ('SYS','SYSTEM','WMSYS','ORDSYS','MDSYS','OLAPSYS','CTXSYS','WKSYS','DBSNMP','ISPL_DBA','RMAN','SRC_JAVA_REPL','SRC_C_REPL','TEST_USER') 
GROUP BY constraint_name,table_name,owner 
HAVING COUNT(*) >=1 
ORDER BY cnt_cons DESC
=================================================================================
 
---- tables which are not having PK
SELECT OWNER,TABLE_NAME
FROM DBA_TABLES dt
WHERE NOT EXISTS (SELECT  'TRUE'
                  FROM DBA_CONSTRAINTS dc
                  WHERE dc.TABLE_NAME = dt.TABLE_NAME
                    AND dc.CONSTRAINT_TYPE='P')
  AND OWNER NOT IN ('SYS','SYSTEM','TOAD','OUTLN','WMSYS','ORDSYS','MDSYS','OLAPSYS','WKPROXY','CTXSYS','WKSYS','DBSNMP','ISPL_DBA','RMAN','SRC_JAVA_REPL','SRC_C_REPL','TEST_USER')
--ORDER BY OWNER, TABLE_NAME
=================================================================================

--- table name and constraint name foreigen key plus pk
SELECT distinct 
   uc.owner, uc.table_name, uc.constraint_name, ucc.column_name,
   uc.r_constraint_name, pk_cons.table_name, pk_cons.column_name 
FROM dba_CONSTRAINTS uc, dba_CONS_COLUMNS ucc, 
(
   SELECT ucc2.constraint_name, ucc2.table_name, ucc2.column_name
   FROM dba_CONS_COLUMNS ucc2, dba_CONSTRAINTS uc
   WHERE ucc2.constraint_name = uc.constraint_name
     AND uc.constraint_type = 'P'
     and ucc2.TABLE_NAME='CC_CSR'
  )pk_cons
WHERE uc.constraint_name=ucc.constraint_name  
  AND uc.r_constraint_name = pk_cons.constraint_name
  AND uc.constraint_type='R'
=================================================================================
 
--- primary key and no primary key tables
SELECT table_name, DECODE(constraint_type,'P','PK','NOPK') check_constraints
FROM(
SELECT table_name, constraint_type FROM USER_CONSTRAINTS
WHERE constraint_type='P'
UNION
SELECT table_name, NULL FROM USER_TABLES
WHERE table_name NOT IN(SELECT table_name
                        FROM USER_CONSTRAINTS
                        WHERE constraint_type='P'))
ORDER BY CONSTRAINT_TYPE ASC
=================================================================================
 
--- query to list, all those table name which are having primary for all the column in table
SELECT table_name FROM USER_TABLES a
WHERE (SELECT COUNT(1) 
       FROM USER_CONS_COLUMNS b,USER_CONSTRAINTS c 
       WHERE a.table_name = b.table_name 
         AND b.constraint_name = c.constraint_name 
         AND c.constraint_type='P') = (SELECT COUNT(1) 
                                       FROM USER_TAB_COLUMNS b 
                                       WHERE a.table_name=b.table_name)
=================================================================================
 
-- query to list all those tables which are having primary key but not those 
-- tables which are having primary key to all the columns in a table 
SELECT table_name FROM USER_TABLES
WHERE table_name IN(SELECT table_name
                 FROM USER_CONSTRAINTS
                 WHERE constraint_type='P')
  AND table_name NOT IN(SELECT table_name FROM USER_TABLES a
                        WHERE (SELECT COUNT(1) 
                               FROM USER_CONS_COLUMNS b,USER_CONSTRAINTS c 
                               WHERE a.table_name = b.table_name 
                                 AND b.constraint_name = c.constraint_name 
                                 AND c.constraint_type='P') = (SELECT COUNT(1) 
                                                               FROM USER_TAB_COLUMNS b 
                                                               WHERE a.table_name=b.table_name))
ORDER BY table_name ASC;
=================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
Grants and Roles
3
select upper(sys_context('userenv','db_name'))DB_name, af.type, af.grantee,
	af.privs, af.Admin_Opt, af.table_name, af.owner
from 
(
    select 
        'ROLE' Type, grantee grantee, granted_role privs, 
        admin_option Admin_Opt, '--' table_name, '--' owner
    from dba_role_privs
    --where grantee='MIS'
    union
    select 	
        'SYSTEM' Type, grantee grantee, privilege privs, 
        admin_option Admin_Opt, '--' table_name,'--' owner
    from dba_sys_privs
    --where grantee='MIS'
    union
    select 
        'TABLE' Type, grantee grantee, privilege privs, grantable Admin_Opt, 
        table_name table_name, owner owner
    from dba_tab_privs
    where table_name not like 'BIN$%'
    )af, dba_users du
where af.grantee = du.username
  and du.username in ('APEX','APEX_030200')
order by 2;


-- SQL query to get all user informations (Roles, Privileges, SYSTEM Privs)
SELECT DISTINCT ds.username,listagg(granted_role,', ') WITHIN GROUP (ORDER BY granted_role) granted_role,
--    (SELECT LISTAGG(ROLE,',') WITHIN GROUP (ORDER BY ROLE)GRANTED_ROLE FROM dba_roles dr WHERE dr.grantee = ds.username GROUP BY grantee) role_granted,
    (
       SELECT listagg(PRIVILEGE,', ') WITHIN GROUP (ORDER BY PRIVILEGE) privs 
         FROM dba_tab_privs dtp  
        WHERE PRIVILEGE IN (SELECT PRIVILEGE 
                              FROM dba_sys_privs) 
          AND dtp.grantee = ds.username 
        GROUP BY dtp.grantee
     ) sys_privileges,
    (
       SELECT listagg(PRIVILEGE,', ') WITHIN GROUP (ORDER BY PRIVILEGE) privs 
         FROM (SELECT grantee, PRIVILEGE, row_number() OVER (PARTITION BY grantee, PRIVILEGE ORDER BY grantee) AS rn 
                 FROM dba_tab_privs dtp1 
                WHERE dtp1.grantee = ds.username) 
        WHERE rn=1)  object_privilges
 FROM dba_role_privs drp, dba_users ds
WHERE ds.USERNAME = drp.grantee
  and ds.username  in (select username 
                         from dba_users 
                        where username not in ('CAE0748P'))
  GROUP BY ds.username
ORDER BY ds.username ASC ;


select lpad(' ', 3 * level) || granted_role "User, his roles and privileges"
from
  (
		select null grantee, username granted_role
		from dba_users 
		where username ='CAC6162'
  union
		select grantee, granted_role
		from dba_role_privs
	union
		select grantee, privilege
		from dba_sys_privs
 -- union 
 --   select grantee, 
  )
start with grantee is null
connect by grantee = prior granted_role;

No Title 
List all users who have been assigned a particular role
-- Change 'DBA' to the required role
select * from dba_role_privs where granted_role = 'DBA'
List all roles given to a user
-- Change 'PHIL@ to the required user
select * from dba_role_privs where grantee = 'PHIL';
List all privileges given to a user
select
  lpad(' ', 2*level) || granted_role "User, his roles and privileges"
from
  (
  /* THE USERS */
    select 
      null     grantee, 
      username granted_role
    from 
      dba_users
    where
      username like upper('%&enter_username%')
  /* THE ROLES TO ROLES RELATIONS */ 
  union
    select 
      grantee,
      granted_role
    from
      dba_role_privs
  /* THE ROLES TO PRIVILEGE RELATIONS */ 
  union
    select
      grantee,
      privilege
    from
      dba_sys_privs
  )
start with grantee is null
connect by grantee = prior granted_role;


-- List all users who can SELECT on a particular table (either through being given a relevant role 
-- or through a direct grant (ie grant select on a table to joe))? 
-- The result of this query should also show through which role the user has this access or whether it was a direct grant.
-- Change 'TABLENAME' below
select Grantee,'Granted Through Role' as Grant_Type, role, table_name
  from role_tab_privs rtp, dba_role_privs drp
 where rtp.role = drp.granted_role
   and table_name = 'TABLENAME' 
union
select Grantee,'Direct Grant' as Grant_type, null as role, table_name
  from dba_tab_privs
  where table_name = 'TABLENAME' ;


-- get the list of grants
SELECT grantee, owner, table_name, grantor, 
        DECODE(grantable, 'YES', 'grant '||wm_concat(PRIVILEGE)||' on '||grantee||' WITH GRANT OPTION;',
                                 'grant '||wm_concat(PRIVILEGE)||' on '||grantee||';')
FROM dba_tab_privs
WHERE grantee='DSRBASE'  AND table_name='SALES_ORG_PAYER_MAT_REG_CNTY'
GROUP BY grantee, owner, table_name, grantor,grantable

-- get the list of roles
SELECT --grantee, granted_role, admin_option, 
       DECODE(admin_option,'YES','GRANT '||granted_role||' TO '||grantee||' WITH GRANT OPTION;',
                                 'GRANT '||granted_role||' TO '||grantee||';') role_privs
FROM dba_role_privs
WHERE grantee='AXCP16_PROC'

SELECT --grantee, owner, table_name, grantor, 
        DECODE(grantable, 'YES', 'grant '||wm_concat(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||' WITH GRANT OPTION;',
                                 'grant '||wm_concat(PRIVILEGE)||' on '||grantor||'.'||table_name||' to '||grantee||';') privs_grant
FROM dba_tab_privs
WHERE grantee IN ('ZDA','ZDA_USER','ZDAP_USER')
GROUP BY grantee, owner, table_name, grantor,grantable

SELECT --grantee, granted_role, admin_option, 
       DECODE(admin_option,'YES','GRANT '||granted_role||' TO '||grantee||' WITH GRANT OPTION;',
                                 'GRANT '||granted_role||' TO '||grantee||';') role_privs
FROM dba_role_privs
WHERE grantee IN ('ZDA','ZDA_USER','ZDAP_USER')

-- dynamic query
DECLARE
  v_sql_roles VARCHAR2(4000);
BEGIN 
    FOR i IN (SELECT 'grant select on '||owner||'.'||table_name||' to ARSYSTEM_RO_ROLE ' obj_privs
                FROM dba_tables 
               WHERE owner='ARSYSTEM')
    LOOP
--       v_sql_roles:='grant select on '||i.owner||'.'||i.table_name||' to ARSYSTEM_RO_ROLE ;'
        
         EXECUTE IMMEDIATE i.obj_privs;
         
    END LOOP;
EXCEPTION
    WHEN OTHERS THEN 
        dbms_output.put_line ('SQL : '||SUBSTR(SQLERRM,1,100));
END;
/    
-----------------------------------------------------------------------------------------------

-- gives the table list and it's privileges in the role.
select * from dba_tab_privs where grantee='MABMART_RO_ROLE' and privilege='SELECT' and owner='MABMART'

=====================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
Create Table External
3
Creating an External Table and Loading Data

The following example creates an external table, then uploads the data to a 
database table. We have tested the examples in the Oracle9i Database 
Administrators Guide Release 1 (9.0.1) using Oracle 9.0.1 on Windows 2000.

The file empxt1.dat in C:\Users\Zahn\Work contains the following sample data:

7369,Schmied,Schlosser,7902,17.12.1980,800,0,20
7499,Zaugg,Verkäufer,7698,20.02.1981,1600,300,30
7521,Müller,Verkäufer,7698,22.02.1981,1250,500,30
7566,Holzer,Informatiker,7839,02.04.1981,2975,0,20
7654,Zahn,Verkäufer,7698,28.09.1981,1250,1400,30
7698,Sutter,Informatiker,7839,01.05.1981,2850,0,30
7782,Graf,Informatiker,7839,09.06.1981,2450,0,10

The file empxt2.dat in C:\Users\Zahn\Work contains the following sample data:

7788,Gasser,Analytiker,7566,19.04.1987,3000,0,20
7839,Kiener,Lehrer,,17.11.1981,5000,0,10
7844,Stoller,Verkäufer,7698,08.09.1981,1500,0,30
7876,Amstutz,Automechaniker,7788,23.05.1987,1100,0,20
7900,Weigelt,Automechaniker,7698,03.12.1981,950 ,0,30
7902,Wyss,Analytiker,7566,03.12.1981,3000,0,20
7934,Messerli,Automechaniker,7782,23.01.1982,1300,0,10

The following SQL statements create an external table and load its data into 
database table EMP of the user scott.

sqlplus /nolog

SQL*Plus: Release 9.0.1.0.1 - Production on
Sat Jan 26 10:44:48 2002
(c) Copyright 2001 Oracle Corporation. All rights reserved.

CONNECT  SYS/MANAGER  AS SYSDBA;
SET ECHO ON;

CREATE OR REPLACE DIRECTORY dat_dir AS 'C:\Oracle\Data';
CREATE OR REPLACE DIRECTORY log_dir AS 'C:\Oracle\Log';
CREATE OR REPLACE DIRECTORY bad_dir AS 'C:\Oracle\Bad';

Directory created.

GRANT READ ON DIRECTORY dat_dir TO scott;
GRANT WRITE ON DIRECTORY log_dir TO scott;
GRANT WRITE ON DIRECTORY bad_dir TO scott;

Grant succeeded.

CONNECT scott/tiger;
DROP TABLE empxt;

CREATE TABLE empxt (empno       NUMBER(4),
                    ename       VARCHAR2(20),
                    job         VARCHAR2(20),
                    mgr         NUMBER(4),
                    hiredate    DATE,
                    sal         NUMBER(7,2),
                    comm        NUMBER(7,2),
                    deptno      NUMBER(2)
                   )
 ORGANIZATION EXTERNAL
 (
   TYPE ORACLE_LOADER
   DEFAULT DIRECTORY dat_dir
   ACCESS PARAMETERS
   (
     records delimited by newline
     badfile bad_dir:'empxt%a_%p.bad'
     logfile log_dir:'empxt%a_%p.log'
     fields terminated by ','
     missing field values are null
     ( empno,
       ename,
       job,
       mgr,
       hiredate char date_format date mask "dd.mm.yyyy",
       sal,
       comm,
       deptno
     )
   )
   LOCATION ('empxt1.dat', 'empxt2.dat')
 )
 PARALLEL
 REJECT LIMIT UNLIMITED;

Table created.

ALTER SESSION ENABLE PARALLEL DML;

Session altered.

The first few statements in this example create the directory objects for the 
operating system directories that contain the data sources, and for the bad 
record and log files specified in the access parameters. You must also grant 
READ or WRITE directory object privileges, as appropriate.

The TYPE specification is given only to illustrate its use. If not specified, 
ORACLE_LOADER is the default access driver. The access parameters, specified 
in the ACCESS PARAMETERS clause, are opaque to Oracle. These access parameters
are defined by the access driver, and are provided to the access driver by 
Oracle when the external table is accessed.

The PARALLEL clause enables parallel query on the data sources. The granule 
of parallelism is by default a data source, but parallel access within a data 
source is implemented whenever possible. For example, if PARALLEL=3 were 
specified, then more than one parallel execution server could be working on 
a data source.

The REJECT LIMIT clause specifies that there is no limit on the number of 
errors that can occur during a query of the external data. For parallel 
access, this limit applies to each parallel query slave independently. 
For example, if REJECT LIMIT 10 is specified, each parallel query process 
is allowed 10 rejections. Hence, the only precisely enforced values for 
REJECT LIMIT on parallel query are 0 and UNLIMITED.

<end node> 5P9i0s8y19Z
dt=Text
<node>
delete from bottom
3
-- deleting records from bottom
delete from emp 
where rowid not in ( select rowid from emp minus select rowid from emp where rownum between 70 and 100);

<end node> 5P9i0s8y19Z
dt=Text
<node>
Insert Stmts
3
-- Multiple insert ,,,  link to check the same
http://www.sc.ehu.es/siwebso/KZCC/Oracle_10g_Documentacion/server.101/b10736/transform.htm#sthref712

-- check the customer_id and insert the records in different tables
INSERT FIRST
WHEN customer_id < 'I' THEN
  INTO cust_ah
  VALUES (customer_id, program_id, delivered_date)
WHEN customer_id < 'Q' THEN
  INTO cust_ip
  VALUES (customer_id, program_id, order_date)
WHEN customer_id > 'PZZZ' THEN
  INTO cust_qz
  VALUES (customer_id, program_id, delivered_date)
SELECT program_id, delivered_date, customer_id, order_date
FROM airplanes;


-- insert in to different tables..
INSERT ALL
INTO ap_cust VALUES (customer_id, program_id, delivered_date)
INTO ap_orders VALUES (order_date, program_id)
SELECT program_id, delivered_date, customer_id, order_date
FROM airplanes;


-- check the deptno column and inser as per it
INSERT ALL 
WHEN (deptno=10) THEN
  INTO emp_10 (empno,ename,job,mgr,sal,deptno)
  VALUES (empno,ename,job,mgr,sal,deptno)
WHEN (deptno=20) THEN
  INTO emp_20 (empno,ename,job,mgr,sal,deptno)
  VALUES (empno,ename,job,mgr,sal,deptno)
WHEN (deptno<=30) THEN
  INTO emp_30 (empno,ename,job,mgr,sal,deptno)
  VALUES (empno,ename,job,mgr,sal,deptno)
ELSE
  INTO leftover (empno,ename,job,mgr,sal,deptno)
  VALUES (empno,ename,job,mgr,sal,deptno)
SELECT * FROM emp;

SELECT * FROM emp_10;
SELECT * FROM emp_20;
SELECT * FROM emp_30;
SELECT * FROM leftover;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Generate Scripts SQLs
3
-- Genarating Index Constraint Scripts
SELECT 'DROP INDEX '||OWNER||'.'||SEGMENT_NAME||';' Dropping_Index
FROM dba_segments
WHERE tablespace_name='INDEX_2'
  AND SEGMENT_TYPE='INDEX'
ORDER BY owner,segment_name ASC;  

-- create script for unique primary key index constraints
SELECT 'CREATE UNIQUE INDEX '||owner||'.'||constraint_name||' ON '||owner||'.'||table_name||' ('||wm_concat(column_name)||')'||' tablespace INDEX_3;' "Unique_PrimaryKey_Cons_Index"
FROM 
(
    SELECT dcc.owner, dcc.constraint_name, dcc.table_name, DC.CONSTRAINT_TYPE, dcc.column_name, dcc.position 
    FROM dba_segments ds, dba_constraints dc, dba_cons_columns dcc
    WHERE ds.owner = dc.owner
      AND dc.owner = dcc.owner
      AND ds.segment_name = dc.constraint_name
      AND dc.constraint_name = dcc.constraint_name
      AND ds.tablespace_name='INDEX_2'
      AND ds.segment_type='INDEX'   
      AND dc.constraint_type IN ('P','U')
    ORDER BY dcc.owner, dcc.constraint_name, dcc.table_name, dcc.position  ASC 
)
GROUP BY owner, constraint_name, table_name, constraint_type

-- create script for primary key constraints
SELECT 'ALTER TABLE '||owner||'.'||table_name||' ADD (CONSTRAINT '||constraint_name||' PRIMARY KEY ('||wm_concat(column_name)||')'||' USING INDEX '||owner||'.'||constraint_name||');' "PrimaryKey_Cons"
FROM 
(
    SELECT dcc.owner, dcc.constraint_name, dcc.table_name, DC.CONSTRAINT_TYPE, dcc.column_name, dcc.position 
    FROM dba_segments ds, dba_constraints dc, dba_cons_columns dcc
    WHERE ds.owner = dc.owner
      AND dc.owner = dcc.owner
      AND ds.segment_name = dc.constraint_name
      AND dc.constraint_name = dcc.constraint_name
      AND ds.tablespace_name='INDEX_2'
      AND ds.segment_type='INDEX'   
      AND dc.constraint_type='P'
    ORDER BY dcc.owner, dcc.constraint_name, dcc.table_name, dcc.position  ASC 
)
GROUP BY owner, constraint_name, table_name, constraint_type

--- create script of unique and non-unique indexes
SELECT
    CASE 
        WHEN uniqueness = 'UNIQUE' THEN 'CREATE UNIQUE INDEX '||table_owner||'.'||index_name||' ON '||table_owner||'.'||table_name||' ('||wm_concat(column_name)||') TABLESPACE INDEX_3;' 
        WHEN uniqueness = 'NONUNIQUE' THEN 'CREATE INDEX '||table_owner||'.'||index_name||' ON '||table_owner||'.'||table_name||' ('||wm_concat(column_name)||') TABLESPACE INDEX_3;' 
        ELSE NULL
    END "Unique_NonUnique_Index"   
FROM 
(
    SELECT dic.table_owner, dic.index_owner, dic.index_name, dic.table_name,di.uniqueness, dic.column_name, dic.column_position
    FROM dba_indexes di, dba_ind_columns dic
    WHERE di.owner=dic.index_owner
      AND di.index_name = dic.index_name
       AND di.tablespace_name='INDEX_2'
      AND NOT EXISTS (SELECT 1 FROM dba_constraints dc WHERE dc.owner=di.owner AND dc.constraint_name = di.index_name AND dc.constraint_type IN ('P','U'))
    ORDER BY dic.table_name, dic.column_position ASC
)
GROUP BY table_owner, index_name, table_name, uniqueness


SELECT 'GRANT '||WM_CONCAT(PRIVILEGE)||' ON '||grantor||'.'||table_name||' TO '||grantee||';' 
FROM dba_tab_privs
WHERE owner  IN('SNOX4TRANSNOX_API','SNOX4TRANSNOX_CPASS','SNOX4TRANSNOX_CPASS_UAT','SNOX4TRANSNOX_UID','SNOX4TRANSNOX_UID_00523','SNOX4TRANSNOX_UID_00530',
                'SNOX4TRANSNOX_UID_00532','SNOX4TRANSNOX_UID_00535','SNOXPASS_GWAY_00513','SNOXPASS_GWAY_00515','SNOXPASS_GWAY_00516','SNOXPASS_GWAY_00520',
                'SNOXPASS_GWAY_00521','SNOXPASS_GWAY_00522','SNOXPASS_GWAY_00523','SNOXPASS_GWAY_00524','SNOXPASS_GWAY_00526','SNOXPASS_GWAY_00527','SNOXPASS_GWAY_00528',
                'SNOXPASS_GWAY_00529','SNOXPASS_GWAY_00531','SNOXPASS_GWAY_00532','SNOXPASS_GWAY_00533','SNOXPASS_GWAY_00534','SNOXPASS_GWAY_00534_UAT','SNOXPASS_GWAY_0059',
                'SNOXPASS_GWAY_006','SNOXPASS_GWAY_006_UAT','SNOXPASS_GWAY_007','SNOXPASS_SMSNOX_20170','SNOXPASS_SMSNOX_20176','SNOXPASS_SMSNOX_20179','SNOXPASS_SMSNOX_20189',
                'SNOXPASS_SMSNOX_20191','SNOXPASS_SMSNOX_20193','SNOXPASS_SMSNOX_20194','SNOXPASS_SMSNOX_20195','SNOXPASS_SMSNOX_20197','SNOXPASS_SMSNOX_20198','SNOXPASS_SMSNOX_20199',
                'SNOXPASS_SMSNOX_30001','SNOXPASS_SMSNOX_30001_UAT','SNOXPASS_SMSNOX_301','SNOXPASS_SMSNOX_301_UAT','SNOXPASS_TFE_201116','SNOXPASS_TFE_201124','SNOXPASS_TFE_201124_UAT',
                'SNOXPASS_TFE_20113','SNOXPASS_TFE_20115','SNOXPASS_TFE_20116','SNOXPASS_TFE_2012','SNOXPASS_TFE_2012_UAT','SNOXPASS_TFE_2013','TNOXPASS_GWAY_00513','TNOXPASS_GWAY_00515',
                'TNOXPASS_GWAY_00516','TNOXPASS_GWAY_00520','TNOXPASS_GWAY_00521','TNOXPASS_GWAY_00522','TNOXPASS_GWAY_00523','TNOXPASS_GWAY_00524','TNOXPASS_GWAY_00526','TNOXPASS_GWAY_00527','TNOXPASS_GWAY_00528','TNOXPASS_GWAY_00529','TNOXPASS_GWAY_00531','TNOXPASS_GWAY_00532',
                'TNOXPASS_GWAY_00533','TNOXPASS_GWAY_00534','TNOXPASS_GWAY_00534_UAT','TNOXPASS_GWAY_0059','TNOXPASS_GWAY_006','TNOXPASS_GWAY_006_UAT','TNOXPASS_GWAY_007','TNOXPASS_SMSNOX_20170','TNOXPASS_SMSNOX_20176','TNOXPASS_SMSNOX_20179','TNOXPASS_SMSNOX_20189','TNOXPASS_SMSNOX_20191','TNOXPASS_SMSNOX_20193','TNOXPASS_SMSNOX_20194','TNOXPASS_SMSNOX_20195','TNOXPASS_SMSNOX_20197',
                'TNOXPASS_SMSNOX_20198','TNOXPASS_SMSNOX_20199','TNOXPASS_SMSNOX_30001','TNOXPASS_SMSNOX_30001_UAT','TNOXPASS_SMSNOX_301','TNOXPASS_SMSNOX_301_UAT','TNOXPASS_TFE_201116','TNOXPASS_TFE_201124','TNOXPASS_TFE_201124_UAT','TNOXPASS_TFE_20113','TNOXPASS_TFE_20115','TNOXPASS_TFE_20116','TNOXPASS_TFE_2012','TNOXPASS_TFE_2012_UAT','TNOXPASS_TFE_2013','TRANSNOX_CAT','TRANSNOX_CPASS',
                'TRANSNOX_CPASS_UAT','TRANSNOX_IOX','TRANSNOX_UID','TRANSNOX_UID_00523','TRANSNOX_UID_00530','TRANSNOX_UID_00532','TRANSNOX_UID_00535')
GROUP BY grantor,table_name,grantee
UNION ALL
SELECT 'create or replace synonym '||owner||'.'||synonym_name||' for '||table_owner||'.'||table_name||';' oops
FROM dba_synonyms
WHERE table_owner IN ('SNOX4TRANSNOX_API','SNOX4TRANSNOX_CPASS','SNOX4TRANSNOX_CPASS_UAT','SNOX4TRANSNOX_UID','SNOX4TRANSNOX_UID_00523','SNOX4TRANSNOX_UID_00530',
                'SNOX4TRANSNOX_UID_00532','SNOX4TRANSNOX_UID_00535','SNOXPASS_GWAY_00513','SNOXPASS_GWAY_00515','SNOXPASS_GWAY_00516','SNOXPASS_GWAY_00520',
                'SNOXPASS_GWAY_00521','SNOXPASS_GWAY_00522','SNOXPASS_GWAY_00523','SNOXPASS_GWAY_00524','SNOXPASS_GWAY_00526','SNOXPASS_GWAY_00527','SNOXPASS_GWAY_00528',
                'SNOXPASS_GWAY_00529','SNOXPASS_GWAY_00531','SNOXPASS_GWAY_00532','SNOXPASS_GWAY_00533','SNOXPASS_GWAY_00534','SNOXPASS_GWAY_00534_UAT','SNOXPASS_GWAY_0059',
                'SNOXPASS_GWAY_006','SNOXPASS_GWAY_006_UAT','SNOXPASS_GWAY_007','SNOXPASS_SMSNOX_20170','SNOXPASS_SMSNOX_20176','SNOXPASS_SMSNOX_20179','SNOXPASS_SMSNOX_20189',
                'SNOXPASS_SMSNOX_20191','SNOXPASS_SMSNOX_20193','SNOXPASS_SMSNOX_20194','SNOXPASS_SMSNOX_20195','SNOXPASS_SMSNOX_20197','SNOXPASS_SMSNOX_20198','SNOXPASS_SMSNOX_20199',
                'SNOXPASS_SMSNOX_30001','SNOXPASS_SMSNOX_30001_UAT','SNOXPASS_SMSNOX_301','SNOXPASS_SMSNOX_301_UAT','SNOXPASS_TFE_201116','SNOXPASS_TFE_201124','SNOXPASS_TFE_201124_UAT',
                'SNOXPASS_TFE_20113','SNOXPASS_TFE_20115','SNOXPASS_TFE_20116','SNOXPASS_TFE_2012','SNOXPASS_TFE_2012_UAT','SNOXPASS_TFE_2013','TNOXPASS_GWAY_00513','TNOXPASS_GWAY_00515',
                'TNOXPASS_GWAY_00516','TNOXPASS_GWAY_00520','TNOXPASS_GWAY_00521','TNOXPASS_GWAY_00522','TNOXPASS_GWAY_00523','TNOXPASS_GWAY_00524','TNOXPASS_GWAY_00526','TNOXPASS_GWAY_00527','TNOXPASS_GWAY_00528','TNOXPASS_GWAY_00529','TNOXPASS_GWAY_00531','TNOXPASS_GWAY_00532',
                'TNOXPASS_GWAY_00533','TNOXPASS_GWAY_00534','TNOXPASS_GWAY_00534_UAT','TNOXPASS_GWAY_0059','TNOXPASS_GWAY_006','TNOXPASS_GWAY_006_UAT','TNOXPASS_GWAY_007','TNOXPASS_SMSNOX_20170','TNOXPASS_SMSNOX_20176','TNOXPASS_SMSNOX_20179','TNOXPASS_SMSNOX_20189','TNOXPASS_SMSNOX_20191','TNOXPASS_SMSNOX_20193','TNOXPASS_SMSNOX_20194','TNOXPASS_SMSNOX_20195','TNOXPASS_SMSNOX_20197',
                'TNOXPASS_SMSNOX_20198','TNOXPASS_SMSNOX_20199','TNOXPASS_SMSNOX_30001','TNOXPASS_SMSNOX_30001_UAT','TNOXPASS_SMSNOX_301','TNOXPASS_SMSNOX_301_UAT','TNOXPASS_TFE_201116','TNOXPASS_TFE_201124','TNOXPASS_TFE_201124_UAT','TNOXPASS_TFE_20113','TNOXPASS_TFE_20115','TNOXPASS_TFE_20116','TNOXPASS_TFE_2012','TNOXPASS_TFE_2012_UAT','TNOXPASS_TFE_2013','TRANSNOX_CAT','TRANSNOX_CPASS',
                'TRANSNOX_CPASS_UAT','TRANSNOX_IOX','TRANSNOX_UID','TRANSNOX_UID_00523','TRANSNOX_UID_00530','TRANSNOX_UID_00532','TRANSNOX_UID_00535')
AND owner<>'PUBLIC'

<end node> 5P9i0s8y19Z
dt=Text
<node>
Sequence refresh
3
SELECT 'alter sequence '||SEQUENCE_OWNER||'.'||SEQUENCE_NAME||' increment by '||to_number(diff_number+100)||';'||CHR(10)||
       'select '||SEQUENCE_OWNER||'.'||SEQUENCE_NAME||'.nextval from dual;' ||CHR(10)||
       'alter sequence '||SEQUENCE_OWNER||'.'||SEQUENCE_NAME||' increment by 1;'||CHR(10)||
       'select '||SEQUENCE_OWNER||'.'||SEQUENCE_NAME||'.nextval from dual;' oops
FROM 
 (
     SELECT tw.SEQUENCE_OWNER,
            TW.SEQUENCE_NAME,
            TW.LAST_NUMBER local_db_Seq,
            TE.LAST_NUMBER remote_db_seqs,
            TE.LAST_NUMBER - TW.LAST_NUMBER diff_number,
            TW.CACHE_SIZE            
       FROM dba_sequences TW, dba_sequences@rstgp TE
      WHERE     TW.SEQUENCE_OWNER IN ('RST','RST_NOTIFY','RST_ARCHIVAL')
            AND TW.SEQUENCE_OWNER = TE.SEQUENCE_OWNER
            AND TW.SEQUENCE_NAME = TE.SEQUENCE_NAME
         --   AND TE.LAST_NUMBER > TW.LAST_NUMBER 
   ORDER BY 5 DESC
 );

   
create database link rstgp connect to cae0748p identified by "action201" using 'rstgp';

============================================================================================

-- Generate ODD and EVEN sequences from the existing one

-- Below is script is in working condition

-- check any sequence is in odd number
SELECT sequence_owner,
       sequence_name,
       increment_by,
       cache_size,
       last_number
  FROM dba_sequences
 WHERE sequence_owner IN ('TX_PASS', 'SX_PASS', 'WB_BORT')
   AND MOD (last_number, 2) = 1;

-- even and odd scripts
SELECT sequence_owner,
         sequence_name,
         increment_by,
         cache_size,
         last_number,
         MOD (last_number, 2) even,
         CASE
            WHEN MOD (last_number, 2) = 1 THEN last_number + 1001
            WHEN MOD (last_number, 2) = 0 THEN last_number + 1000
            ELSE last_number
         END
            final_even_no,
         CASE
            WHEN MOD (last_number, 2) = 1
            THEN
                  'alter sequence '
               || sequence_owner
               || '.'
               || sequence_name
               || ' increment by 1001 ;'
               || CHR (10)
               || 'select '
               || sequence_owner
               || '.'
               || sequence_name
               || '.nextval from dual;'
            WHEN MOD (last_number, 2) = 0
            THEN
                  'alter sequence '
               || sequence_owner
               || '.'
               || sequence_name
               || ' increment by 1000 ;'
               || CHR (10)
               || 'select '
               || sequence_owner
               || '.'
               || sequence_name
               || '.nextval from dual;'
            ELSE
               TO_CHAR (last_number)
         END
            first_even_time_increment,
         CASE
            WHEN MOD (last_number, 2) = 1
            THEN
                  'alter sequence '
               || sequence_owner
               || '.'
               || sequence_name
               || ' increment by 1000 ;'
               || CHR (10)
               || 'select '
               || sequence_owner
               || '.'
               || sequence_name
               || '.nextval from dual;'
            WHEN MOD (last_number, 2) = 0
            THEN
                  'alter sequence '
               || sequence_owner
               || '.'
               || sequence_name
               || ' increment by 1001 ;'
               || CHR (10)
               || 'select '
               || sequence_owner
               || '.'
               || sequence_name
               || '.nextval from dual;'
            ELSE
               TO_CHAR (last_number)
         END
            first_odd_time_increment,
            'alter sequence '
         || sequence_owner
         || '.'
         || sequence_name
         || ' increment by 2 ;'
         || CHR (10)
         || 'select '
         || sequence_owner
         || '.'
         || sequence_name
         || '.nextval from dual;'
            final_even_run
    FROM dba_sequences
   WHERE sequence_owner IN ('TX_PASS', 'SX_PASS', 'WB_BORT')
ORDER BY LAST_NUMBER DESC
;
============================================================================================


--get the sequence number 
select rno from ( select rownum rno from dual connect by level <= 10)
============================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
SQL-Loader
3
LOAD DATA
INFILE	‘\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\New folder\crop.csv’
BADFILE	‘\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\New folder\badfile_crop_15022017.bad’
DISCARDFILE	‘\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\New folder\discardfile_crop_15022017.dsc’
INSERT INTO TABLE cs_crop 
FIELDS TERMINATED BY “,” OPTIONALLY ENCLOSED BY ‘”’ TRAILING NULLCOLS
(growerid,region,cropid,cropname,farmid,hybrid,miscdata,phonenumber,preferredbrand,issmrtcrp)

sqlldr userid=DBA_BATCH/UvTuRQyNvJ1L@fsd1.monsanto.com control=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000076626\ctl_corp.ctl log=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000076626\log_cs_crop_fsd1_DEVDB.log
sqlldr userid=DBA_BATCH/UvTuRQyNvJ1L@fsd1.monsanto.com control=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000076626\ctl_fram.ctl log=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000076626\log_cs_fram_fsd_DEVDB.log
sqlldr userid=DBA_BATCH/UvTuRQyNvJ1L@fsd1.monsanto.com control=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000076626\ctl_grower.ctl log=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000076626\log_grower_fsd_DEVDB.log

sqlldr userid=DBA_BATCH/UvTuRQyNvJ1L@fsq1.monsanto.com control=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000080411\cs_crop.ctl log=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000080411\log_cs_crop_fsq1.log
sqlldr userid=DBA_BATCH/UvTuRQyNvJ1L@fsq1.monsanto.com control=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000080411\cs_farm.ctl log=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000080411\log_cs_farm_fsq1.log
sqlldr userid=DBA_BATCH/UvTuRQyNvJ1L@fsq1.monsanto.com control=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000080411\cs_grower.ctl log=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000080411\log_cs_grower_fsq1.log

sqlldr userid=DBA_BATCH/UvTuRQyNvJ1L@fsp1.monsanto.com control=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000080411\cs_crop.ctl log=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000080411\log_cs_crop_fsp1.log
sqlldr userid=DBA_BATCH/UvTuRQyNvJ1L@fsp1.monsanto.com control=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000080411\cs_farm.ctl log=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000080411\log_cs_farm_fsp1.log
sqlldr userid=DBA_BATCH/UvTuRQyNvJ1L@fsp1.monsanto.com control=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000080411\cs_grower.ctl log=\\stlwmondfsprdfs.na.ds.monsanto.com\RKCHAU$\Downloads\TASK000080411\log_cs_grower_fsp1.log

<end node> 5P9i0s8y19Z
dt=Text
<node>
Gather stats
3
SELECT log_date,job_name,status,actual_start_date,run_duration
  FROM DBA_SCHEDULER_JOB_RUN_DETAILS
 WHERE job_name like '%STATS%';

-- gather stats scheduler job information
select * 
from dba_scheduler_jobs
where job_name like '%STAT%'
;
     
-- Another way to check the stats jobs and history
select *
from dba_optstat_operations
order by start_time desc
;

-- when stats where changed on the table
select owner,table_name,stats_update_time
from dba_tab_stats_history
where owner='MIS'
-- and table_name in ('SHR_TRANS','SHR_CONTRACT')
 order by stats_update_time desc
;

-- to have the number of objects per day which had their statistics changed
SELECT TO_CHAR(stats_update_time,'yyyy-mm-dd') AS stats_update_time, COUNT(*)
  FROM dba_tab_stats_history
 where stats_update_time >= add_months(sysdate,-3) -- from last 3 months
 GROUP BY TO_CHAR(stats_update_time,'yyyy-mm-dd')
 ORDER BY 1 DESC;

--------------------------------------------------------------------- 
Procedures in the DBMS_STATS package for gathering statistics on database objects:

Procedure				Collects
---------------------------------------------------------------------
GATHER_INDEX_STATS		Index statistics
GATHER_TABLE_STATS		Table, column, and index statistics
GATHER_SCHEMA_STATS		Statistics for all objects in a schema
GATHER_DICTIONARY_STATS	Statistics for all dictionary objects
GATHER_DATABASE_STATS		Statistics for all objects in a database

EXEC DBMS_STATS.GATHER_DATABASE_STATS;
EXEC DBMS_STATS.GATHER_DATABASE_STATS(ESTIMATE_PERCENT=>20);

EXEC DBMS_STATS.GATHER_SCHEMA_STATS(ownname, estimate_percent, block_sample, method_opt, degree, granularity, cascade, stattab, statid, options, statown, no_invalidate, gather_temp, gather_fixed);
EXEC DBMS_STATS.GATHER_SCHEMA_STATS('SCOTT');
EXEC DBMS_STATS.GATHER_SCHEMA_STATS(OWNNAME=>'MRT');
EXEC DBMS_STATS.GATHER_SCHEMA_STATS('SCOTT',ESTIMATE_PERCENT=>10);

EXEC DBMS_STATS.GATHER_TABLE_STATS('MR_LANDING','PCX_CNAWC7OBJINFO');
EXEC DBMS_STATS.GATHER_TABLE_STATS('SCOTT','EMP',ESTIMATE_PERCENT=>15);

EXEC DBMS_STATS.GATHER_INDEX_STATS('SCOTT','EMP_PK');
EXEC DBMS_STATS.GATHER_INDEX_STATS('SCOTT','EMP_PK',ESTIMATE_PERCENT=>15);

--This package also gives us the ability to delete statistics:
EXEC DBMS_STATS.DELETE_DATABASE_STATS;
EXEC DBMS_STATS.DELETE_SCHEMA_STATS('SCOTT');
EXEC DBMS_STATS.DELETE_TABLE_STATS('SCOTT','EMP');
EXEC DBMS_STATS.DELETE_INDEX_STATS('SCOTT','EMP_PK');
EXEC DBMS_STATS.DELETE_PENDING_STATS('SH','SALES');

EXEC DBMS_STATS.GATHER_SCHEMA_STATS(OWNNAME=>'"DWH"',OPTIONS=>'GATHER AUTO');
EXEC DBMS_STATS.GATHER_SCHEMA_STATS(OWNNAME=>'PERFSTAT',CASCADE=>TRUE); 


select 'EXEC DBMS_STATS.gather_table_stats(''MIS_DM'','''||table_name||''');' tables
from dba_tables
where owner='MIS_DM';

select owner, table_name, to_char(last_analyzed,'mm/dd/yyyy hh24:mi:ss'),'EXEC DBMS_STATS.gather_table_stats(''MIS_DM'','''||table_name||''');' tables
from dba_tables 
where owner='MIS_DM'
  and last_analyzed < sysdate-2
order by to_char(last_analyzed,'mm/dd/yyyy hh24:mi:ss') asc;


--- collect statistics of mentioned table merwhp DB
col owner for a10
col table_name for a30
select owner, table_name, to_char(LAST_ANALYZED,'mm/dd/yyyy hh24:mi:ss')last_analyed 
from dba_tables 
where owner in ('ODSRPT','DMSRPT_STAGE') 
  and regexp_like(table_name,'RPT_ODS_ASSIGNMENT_%' or;

execute DBMS_STATS.gather_table_stats ('MR_PRELOAD', 'EPC_S_RATE_DFM_AUTO');
execute DBMS_STATS.gather_table_stats ('ODSRPT', 'RPT_ODS_ASSIGNMENT_DTL_SNAP');
execute DBMS_STATS.gather_table_stats ('CLAIMODS','D_ACTIVITY');

ODSRPT.RPT_ODS_ASSIGNMENT_DETAIL
ODSRPT.RPT_ODS_ASSIGNMENT_DTL_SNAP

execute DBMS_STATS.gather_table_stats ('CAB9576','ESIGHT_DASH_WEBI_RPT_MSTR');

-- schema stats gather
EXECUTE DBMS_STATS.GATHER_SCHEMA_STATS(ownname => 'ODSRPT', estimate_percent => NULL);
OR
EXECUTE DBMS_STATS.GATHER_SCHEMA_STATS(ownname => 'ODSRPT');

==============================================================================

/* Useful Gather Statistics Commands In Oracle */

--1. Gather dictionary stats:

-- It gathers statistics for dictionary schemas 'SYS', 'SYSTEM' and other internal schemas.
EXEC DBMS_STATS.gather_dictionary_stats;

--2. Gather fixed object stats:

--- Fixed object means gv$ or v$views
EXEC DBMS_STATS.GATHER_FIXED_OBJECTS_STATS;

--3. Gather full database stats:
EXEC DBMS_STATS.gather_database_stats;

-- With estimate_percent to 15 percent or any other value , if the db size very huge.
EXEC DBMS_STATS.gather_database_stats(estimate_percent => 15);
EXEC DBMS_STATS.gather_database_stats(estimate_percent => 15, cascade => TRUE);

-- With auto sample size and parallel degree
EXEC DBMS_STATS.gather_database_stats(estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,degree => 8);

--4. Gather schema statistics:
EXEC DBMS_STATS.gather_schema_stats('DBACLSS');
EXEC DBMS_STATS.gather_schema_stats('DBACLASS', estimate_percent => 25);
EXEC DBMS_STATS.gather_schema_stats('DBACLASS', estimate_percent => 100, cascade => TRUE);

-- STATS WITH AUTO ESTIMATION and degree 8
exec dbms_stats.gather_schema_stats( ownname => 'DBACLASS',method_opt => 'FOR ALL COLUMNS SIZE 1',
granularity => 'ALL', degree => 8, cascade => TRUE, estimate_percent=>dbms_stats.auto_sample_size);

--5. Gather table statistics:
EXEC DBMS_STATS.gather_table_stats('DBACLASS', 'EMP');
EXEC DBMS_STATS.gather_table_stats('DBACLASS', 'EMP', estimate_percent => 15);
EXEC DBMS_STATS.gather_table_stats('DBACLASS', 'EMP', estimate_percent => 15, cascade => TRUE);

exec DBMS_STATS.GATHER_TABLE_STATS (ownname => 'DBACLASS' , tabname => 'EMP',cascade => true,
method_opt=>'for all indexed columns size 1', granularity => 'ALL', degree => 8);

exec DBMS_STATS.GATHER_TABLE_STATS (ownname => 'DBACLASS' , tabname => 'EMP',
cascade => true, method_opt=>'FOR ALL COLUMNS SIZE 1', granularity => 'ALL', degree => 8);

--6. Gather stats for single partition of a table:

BEGIN
 DBMS_STATS.GATHER_TABLE_STATS
  (
	ownname => 'SCOTT',
	tabname => 'TEST', --- TABLE NAME
	partname => 'TEST_JAN2016' --- PARTITOIN NAME
	method_opt=>'for all indexed columns size 1',
	GRANULARITY => 'APPROX_GLOBAL AND PARTITION',
	degree => 8
  );
END;
/

--7. Lock/unlock statistics:

-- Lock stats of a schema:
EXEC DBMS_STATS.lock_schema_stats('DBACLASS');

-- Lock stats of a table:
EXEC DBMS_STATS.lock_table_stats('DBACLASS', 'EMP');

-- Lock stats of a partition:
EXEC DBMS_STATS.lock_partition_stats('DBACLASS', 'EMP', 'EMP');

-- unlock stats of a schema:
EXEC DBMS_STATS.unlock_schema_stats('DBACLASS');

-- unlock stats of a table:
EXEC DBMS_STATS.unlock_table_stats('DBACLASS', 'DBACLASS');

--unlock stats of a partition:
EXEC DBMS_STATS.unlock_partition_stats('DBACLASS', 'EMP', 'TEST_JAN2016');

--- check stats status:
SELECT stattype_locked FROM dba_tab_statistics WHERE table_name = 'TEST' and owner = 'SCOTT';

--8 . Delete statistics:

-- Delete complete db statistics:
EXEC DBMS_STATS.delete_database_stats;

-- Delete schema statistics:
EXEC DBMS_STATS.delete_schema_stats('DBACLASS');

-- Delete table statistics:
EXEC DBMS_STATS.delete_table_stats('DBACLASS', 'EMP');

-- Delete column statistics:
EXEC DBMS_STATS.delete_column_stats('DBACLASS', 'EMP', 'EMPNO');

-- Delete index statistics:
EXEC DBMS_STATS.delete_index_stats('DBACLASS', 'EMP_PK');

-- Delete dictionary statistics:
EXEC DBMS_STATS.delete_dictionary_stats;

-- Delete fixed object statistics:
exec dbms_stats.delete_fixed_objects_stats;

-- Delete system statistics:
exec dbms_stats.delete_system_stats('STAT_TAB');

--8. Setting statistics preference:
-- View preference details for the database:
SELECT dbms_stats.get_prefs('PUBLISH') EST_PCT FROM dual;

-- View Publish preference for table
select dbms_stats.get_prefs('PUBLISH','SCOTT','EMPLOYEE') from dual

-- View Publish preference for schema:
select dbms_stats.get_prefs('PUBLISH', 'SCOTT') from dual

-- View preference details for table
select dbms_stats.get_prefs(ownname=>'DBACLASS',tabname=>'EMP',pname=>'PUBLISH') FROM DUAL;
select DBMS_STATS.get_prefs(ownname=>'DBACLASS',tabname=>'EMP',pname=>'INCREMENTAL') FROM DUAL;
select DBMS_STATS.get_prefs(ownname=>'DBACLASS',tabname=>'EMP',pname=>'GRANULARITY') FROM DUAL;
select DBMS_STATS.get_prefs(ownname=>'DBACLASS',tabname=>'EMP',pname=>'STALE_PERCENT') FROM DUAL;
select DBMS_STATS.get_prefs(ownname=>'DBACLASS',tabname=>'EMP',pname=>'ESTIMATE_PERCENT') FROM DUAL;
select DBMS_STATS.get_prefs(ownname=>'DBACLASS',tabname=>'EMP',pname=>'DEGREE') FROM DUAL;

-- Set table preferences
exec dbms_stats.set_table_prefs('DBACLASS','EMP','PUBLISH','FALSE');
exec dbms_stats.set_table_prefs('DBACLASS','EMP','ESTIMATE_PERCENT','20');
exec dbms_stats.set_table_prefs('DBACLASS','EMP','DEGREE','8');

-- Set schema preferences:
exec dbms_stats.SET_SCHEMA_PREFS('DBATEST','PUBLISH','FALSE');
exec dbms_stats.SET_SCHEMA_PREFS('DBATEST','ESTIMATE_PERCENT','20');
exec dbms_stats.SET_SCHEMA_PREFS('DBATEST','CASCADE','TRUE');

-- Set database preference:
exec dbms_stats.set_database_prefs('PUBLISH', 'TRUE');
exec dbms_stats.set_database_prefs('DEGREE', '16');

-- Set global preference:
exec dbms_stats.set_global_prefs('PUBLISH', 'TRUE');
exec dbms_stats.set_global_prefs('DEGREE', '16');

--9 . Deleting preferences :

-- Deleting schema preference:
exec dbms_stats.delete_schema_prefs('DBACLASS', 'DEGREE');
exec dbms_stats.delete_schema_prefs('DBACLASS', 'CASCADE');

-- Delete database preference:
exec dbms_stats.delete_database_prefs('ESTIMATE_PERCENT', FALSE);
exec dbms_stats.delete_database_prefs('DEGREE', FALSE);

--10 . Publish pending statistics:
-- For schema DBACLASS
exec dbms_stats.publish_pending_stats('DBACLASS',null);

-- For table DBACLASS.EMP
EXEC DBMS_STATS.PUBLISH_PENDING_STATS ('DBACLASS','EMP');

--11. Delete pending statistics:
-- for table DBACLASS.EMP
exec dbms_stats.delete_pending_stats('DBACLASS', 'EMP');

-- For schema DBACLASS
exec dbms_stats.delete_pending_stats('DBACLASS', null);

--12. Upgrade stats table:
-- If we are importing stats table from higher version to lower version,
-- then before importing in the database, we need to upgrade the stats table.
EXECUTE DBMS_STATS.UPGRADE_STAT_TABLE(OWNNAME =>'RAJ',STATTAB =>'STAT_TEST');

--13. View/modify statistics retention period:
-- View current stats retention
select dbms_stats.get_stats_history_retention from dual;

-- Modify the stats retention
exec DBMS_STATS.ALTER_STATS_HISTORY_RETENTION(60);

--14. create stats table:
--- Create staging table to store the statistics data
exec dbms_stats.create_stat_table(ownname => 'SCOTT', stattab => 'STAT_BACKUP',tblspace=>'USERS');

--15. Export stats data:
-- Export full database stats to a table SCOTT.STAT_BACKUP
exec dbms_stats.export_database_stats(statown => 'SCOTT' ,stattab=>'STAT_BACKUP');

-- Export stats for table DBACLASS.EMP to a stats table SCOTT.STAT_BACKUP
exec dbms_stats.export_table_stats(ownname=>'DBACLASS', tabname=>'EMP', statown =>'SCOTT',stattab=>'STAT_BACKUP', cascade=>true);

-- Export stats for schema DBACLASS to a stats table SCOTT.STAT_BACKUP
exec dbms_stats.export_schema_stats(ownname=>'DBACLASS', statown =>'SCOTT' , stattab=>'STAT_BACKUP');

-- Export fixed object stats to table SCOTT.STAT_BACKUP
exec dbms_stats.export_fixed_objects_stats(statown => 'SCOTT' ,stattab=>'STAT_BACKUP');

-- Export dictionary stats to table SCOTT.STAT_BACKUP
exec dbms_stats.export_dictionary_stats(statown => 'SCOTT' ,stattab=>'STAT_BACKUP');

-- Export stats for index DBACLAS.EMP_UK1 to SCOTT.STAT_BACKUP table
exec dbms_stats.export_index_stats(ownname=>'DBACLASS', indname=>'EMP_UK1', statown =>'SCOTT',stattab=>'STAT_BACKUP');

--16. Import stats table data:
-- Import full database stats from stats table SCOTT.STAT_BACKUP
exec dbms_stats.import_database_stats(statown => 'SCOTT' ,stattab=>'STAT_BACKUP');

-- Import stats for table DBACLASS.EMP from stats table SCOTT.STAT_BACKUP
exec dbms_stats.import_table_stats(ownname=>'DBACLASS', tabname=>'EMP', statown =>'SCOTT',stattab=>'STAT_BACKUP', cascade=>true);

-- Import stats for schema DBACLASS from stats table SCOTT.STAT_BACKUP
exec dbms_stats.import_schema_stats(ownname=>'DBACLASS', statown =>'SCOTT' , stattab=>'STAT_BACKUP');

-- Import fixed object stats from stats table SCOTT.STAT_BACKUP
exec dbms_stats.import_fixed_objects_stats(statown => 'SCOTT' ,stattab=>'STAT_BACKUP');

-- Import dictionary stats from table SCOTT.STAT_BACKUP
exec dbms_stats.import_dictionary_stats(statown => 'SCOTT' ,stattab=>'STAT_BACKUP');

-- Import stats for index DBACLAS.EMP_UK1 from SCOTT.STAT_BACKUP table
exec dbms_stats.import_index_stats(ownname=>'DBACLASS', indname=>'EMP_UK1', statown =>'SCOTT',stattab=>'STAT_BACKUP');


--17 . Few stats related sql queries:

-- Check stale stats for table:
select owner,table_name,STALE_STATS 
from dba_tab_statistics 
where owner='&SCHEMA_NAME' 
and table_name='&TABLE_NAME';

--Check stale stats for index:
select owner,INDEX_NAME,TABLE_NAME 
from DBA_IND_STATISTICS 
where owner='&SCHEMA_NAME' 
and index_name='&INDEX_NAME';

-- For getting history of TABLE statistics
setlines 200
col owner for a12
col table_name for a21
select owner,TABLE_NAME,STATS_UPDATE_TIME from dba_tab_stats_history where table_name='&TABLE_NAME';

-- Space used to store statistic data in SYSAUX tablespace:
SQL> select occupant_desc, space_usage_kbytes from v$sysaux_occupants where OCCUPANT_DESC like '%Statistics%';

-- Check whether table stats locked or not:
select owner, table_name, stattype_locked from dba_tab_statistics where stattype_locked is not null and owner not in ('SYS','SYSTEM');

<end node> 5P9i0s8y19Z
dt=Text
<node>
delete stats
3
-- Delete stats of table, index, partition and column in Oracle
-- Check and drop the Stats of the table
 
-- Check the stats
col table_name for a15
SELECT table_name,to_char(last_analyzed,'DD-MON-YYYY HH24:MI:SS') "LASTANALYZED" 
FROM DBA_TABLES 
WHERE owner='SYS' 
  AND table_name='TEST';

-- Drop the stats
EXEC DBMS_STATS.DELETE_TABLE_STATS(OWNNAME=>'SCOTT', TABNAME=>'EMP');

-- Check and drop the stats of partition in table 

-- Check partition stats
Col table_name for a10
col partition_name for a10
col lastanalyzed for a18
SELECT table_name, partition_name,to_char(last_analyzed,'DD-MON-YYYY HH24:MI:SS') "LASTANALYZED" 
FROM DBA_TAB_PARTITIONS
WHERE table_name='EMP' 
  AND partition_name='EMP201701';

-- Drop the partition stats
EXEC DBMS_STATS.DELETE_TABLE_STATS (OWNNAME => 'HR', TABNAME => 'EMP',PARTNAME => 'EMP201701');
 
-- Check and drop the stats of Column level in table

-- Check stats of column in table
Col table_name for a10
col column_name for a10
col lastanalyzed for a18
SELECT table_name,column_name,to_char(last_analyzed,'DD-MON-YYYY HH24:MI:SS') "LASTANALYZED" 
from DBA_TAB_COL_STATISTICS;

-- Drop the column stats
EXEC DBMS_STATS.DELETE_COLUMN_STATS(OWNNAME=>'', TABNAME=>'', COLNAME=>'', CASCADE_PARTS=>TRUE, COL_STAT_TYPE=>'HISTOGRAM');

-- Check and drop the stats of Index
--Check index stats
SELECT table_name,index_name,to_char(last_analyzed,'DD-MON-YYYY HH24:MI:SS') "LASTANALYZED" 
FROM DBA_INDEXES;


-- Drop the index stats
EXEC DBMS_STATS.DELETE_INDEX_STATS('SCOTT', 'EMP_PK');

<end node> 5P9i0s8y19Z
dt=Text
<node>
obj modifications
3
-- which table got insert,update,delete on which table with date
select * 
from dba_tab_modifications 
where table_owner='MIS' 
  and timestamp >=sysdate-1;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Performance Tuning
2
<end node> 5P9i0s8y19Z
dt=Text
<node>
Xplan Plain
3
-- You can restored the explain plan in oracle by below example.

-- Check when was the explain plan was last updated
select table_name,stats_update_time from user_tab_stats_history;

-- table the above timestamp details and put here 
begin
	dbms_stats.restore_table_stats('TRANSNOX_CPASS','TASK',to_timestamp('2014-10-28:11:47:38','yyyy-mm-dd:hh24:mi:ss'));
end;
/


--# Create a report of the Result Cache
SQL> SET SERVEROUTPUT ON;
SQL> execute DBMS_RESULT_CACHE.MEMORY_REPORT(TRUE); 
 
-- check the current utilization of resources 
select * from v$resource_limit;

-- check the explain plan
explain plan for select * from employees;

SELECT * FROM table(DBMS_XPLAN.DISPLAY); 


-- Generate explain plan
EXPLAIN PLAN
  SET STATEMENT_ID = 'st1' FOR
SELECT last_name FROM employees;

SELECT PLAN_TABLE_OUTPUT FROM TABLE(DBMS_XPLAN.DISPLAY());

OR

-- if you have a explain table created as My_PLAB_TABLE then
SELECT PLAN_TABLE_OUTPUT FROM TABLE(DBMS_XPLAN.DISPLAY('MY_PLAN_TABLE', 'st1','TYPICAL'));

OR

SELECT PLAN_TABLE_OUTPUT FROM TABLE(DBMS_XPLAN.DISPLAY(NULL, 'st1','BASIC'));

OR 

-- To display the different execution plans associated with SQL ID
SELECT * FROM TABLE (DBMS_XPLAN.DISPLAY_AWR ('a4zm6z6prxk4u'));


-- check the SQL execution plan
SELECT * FROM table(DBMS_XPLAN.DISPLAY_CURSOR(sql_id=>'a4zm6z6prxk4u')); 

-- basic format
SELECT * FROM table(DBMS_XPLAN.DISPLAY_CURSOR('a4zm6z6prxk4u',0,'BASIC'));

-- serial format
SELECT * FROM table(DBMS_XPLAN.DISPLAY_CURSOR('a4zm6z6prxk4u',0,'SERIAL'));

-- typical format
SELECT * FROM table(DBMS_XPLAN.DISPLAY_CURSOR('a4zm6z6prxk4u',0,'TYPICAL'));

-- all format
SELECT * FROM table(DBMS_XPLAN.DISPLAY_CURSOR('a4zm6z6prxk4u',0,'ALL'));

-- allstats format
SELECT * FROM table(DBMS_XPLAN.DISPLAY_CURSOR('a4zm6z6prxk4u',0,'ALLSTATS'));

-- allstats last format
SELECT * FROM table(DBMS_XPLAN.DISPLAY_CURSOR('a4zm6z6prxk4u',0,'ALLSTATS LAST'));

-- extra output
SELECT * FROM table(DBMS_XPLAN.DISPLAY_CURSOR('94rbz7j43jkcz',0,'ALLSTATS LAST +PEEKED_BINDS +PROJECTION +ALIAS +PREDICATE +COST +BYTES'));

-- parallel, partition and remote (dblink) output
SELECT * FROM table(DBMS_XPLAN.DISPLAY_CURSOR('75chksrfa5fbt',0,'ALLSTATS LAST +PARALLEL +PARTITION +REMOTE +NOTE'));

-- removing output sections
SELECT * FROM table(DBMS_XPLAN.DISPLAY_CURSOR('75chksrfa5fbt',0,'ALLSTATS LAST -NOTE -ROWS -PREDICATE'));

-- indepath
SELECT * FROM table(DBMS_XPLAN.DISPLAY_CURSOR('dkmcbpadz15w1',NULL,'ALLSTATS LAST'));
 


-- sql query from sql_id
select * from v$sqlarea where sql_id='dx4nqvbtu06bx';


-- How do I see the actual number of rows and elapse time for each step in the plan?
-- You will need to do two things in order to see the actual number of rows:
-- 1. Add the GATHER_PLAN_STATISTICS hint to the SQL statement
-- 2. Setting the FORMAT parameter of DBMS_XPLAN.DISPLAY_CURSOR to ‘ALLSTATS LAST’
SELECT /*+ GATHER_PLAN_STATISTICS */ t2.owner, SUM(b.object_id)
FROM  big_table b, t2 ,t1
WHERE b.object_id = t2.object_id
  AND b.data_object_id = t1.data_object_id
  AND t1.object_type='TABLE'
  AND t2.owner ='SSB'
GROUP BY t2.owner;
 
SELECT * FROM TABLE(DBMS_XPLAN.display_cursor(format=>'ALLSTATS LAST'));


-- How do I get the COST of the plan to be displayed when I specify  ALLSTATS LAST for the FORMAT parameter?
-- When you use ‘ALLSTATS LAST’ for the FORMAT parameter, the estimates number of bytes (BYTES) 
-- and the estimated cost for the plan (COST) are not displayed by default. You can easily have 
-- these columns displayed by adding additional predicates to the FORMAT parameter. Each additional 
-- predicate is proceeded with ‘+’ sign.


SELECT * FROM TABLE(DBMS_XPLAN.display_cursor(sql_id=>'d3z7q78jtgxm2',format=>'ALLSTATS LAST +cost +bytes')); 

<end node> 5P9i0s8y19Z
dt=Text
<node>
dbms_xplan
3
-- url
https://www.morganslibrary.org/reference/pkgs/dbms_xplan.html#xplan09


--Oracle DBMS_XPLAN
--Version 21c

--General Information
-- Library Note	
-- Which has the higher priority in your organization: Deploying a new database or securing the 
-- ones you already have? Looking for a website, and resources, dedicated solely to securing Oracle databases? 

-- Purpose Provides an easy way to display the output of the EXPLAIN PLAN command in 
-- several, predefined formats. You can also use the DBMS_XPLAN package to display the plan of a 
-- statement stored in the Automatic Workload Repository (AWR) or stored in a SQL tuning set. 
-- It further provides a way to display the SQL execution plan and SQL execution runtime statistics for 
-- cached SQL cursors based on the information stored in the V$SQL_PLAN and V$SQL_PLAN_STATISTICS_ALL 
-- fixed views. Finally, it displays plans from a SQL plan baseline.
 
 
TYPE plan_table IS TABLE OF plan_record;

TYPE num_tab_type IS TABLE OF NUMBER;
Dependencies	
ADVISOR_OBJECT			DBMS_SQLTUNE_UTIL0			PRVT_REPORT_TAGS
AWR_OBJECT				DBMS_SQLTUNE_UTIL1			PRVT_SQLADV_INFRA
CURSOR_CACHE_OBJECT		DBMS_SQLTUNE_UTIL2			PRVT_SQLPA
DBA_ADVISOR_FINDINGS	DBMS_STANDARD				SDO_RDF
DBA_ADVISOR_SQLPLANS	DBMS_SWRF_INTERNAL			SDO_RDF_INTERNAL
DBA_ADVISOR_TASKS		DBMS_SWRF_REPORT_INTERNAL	SPM_OBJECT
DBMS_ADVISOR			DBMS_SYSTEM					SQLPROF_ATTR
DBMS_ASSERT				DBMS_SYS_ERROR				SQLSET_OBJECT
DBMS_COMPARISON			DBMS_WORKLOAD_REPOSITORY	SQLSET_ROW
DBMS_LOB				DBMS_XPLAN_INTERNAL			SQL_BINDS
DBMS_OUTPUT				DBMS_XPLAN_LIB				SQL_PLAN_TABLE_TYPE
DBMS_REPORT				DBMS_XPLAN_TYPE				SQL_PROFILE_OBJECT
DBMS_SMB_INTERNAL		DBMS_XPLAN_TYPE_TABLE		V$QUERY_BLOCK_ORIGIN
DBMS_SPM_INTERNAL		DUAL						V_$SESSION
DBMS_SQL				GENERIC_PLAN_OBJECT			WRI$_REPT_PLAN_DIFF
DBMS_SQLDIAG			PLAN_OBJECT_LIST			WRI$_REPT_XPLAN
DBMS_SQLTCB_INTERNAL	PLAN_TABLE					XMLSEQUENCETYPE
DBMS_SQLTUNE			PLAN_TABLE_OBJECT			XMLTYPE
DBMS_SQLTUNE_INTERNAL	PLITBLM						XQSEQUENCE
======================================================================

-- Documented	Yes
-- First Available	9.2
-- Security Model	Owned by SYS with EXECUTE granted to PUBLIC
-- Source	{ORACLE_HOME}/rdbms/admin/dbmsxpln.sql
Subprograms	
BUILD_PLAN_XML 			DISPLAY_CURSOR				FORMAT_SIZE2
COMPARE_CURSOR			DISPLAY_PLAN				FORMAT_TIME_S
COMPARE_EXPLAIN			DISPLAY_SHARD_PLANS			GET_CURSOR_ROWS
COMPARE_PLANS			DISPLAY_SQLSET				GET_FINAL_PLAN
DIFF_PLAN				DISPLAY_SQL_PATCH_PLAN		GET_PLANDIFF_REPORT_XML
DIFF_PLAN_AWR			DISPLAY_SQL_PLAN_BASELINE	GET_PLAN_ROWS
DIFF_PLAN_CURSOR		DISPLAY_SQL_PROFILE_PLAN	I_DISPLAY_CURSOR
DIFF_PLAN_OUTLINE		DISPLAY_WORKLOAD_REPOSITORY	I_DISPLAY_SMB_PLAN
DIFF_PLAN_SQL_BASELINE	FORMAT_NUMBER				PREPARE_PLAN_XML_QUERY
DISPLAY					FORMAT_NUMBER2				PREPARE_RECORDS
DISPLAY_AWR				FORMAT_SIZE					VALIDATE_FORMAT
======================================================================

-- BUILD_PLAN_XML
-- -- Return the last plan, or a named plan, explained as XML	
dbms_xplan.build_plan_xml(
table_name   IN VARCHAR2 DEFAULT 'PLAN_TABLE',
statement_id IN VARCHAR2 DEFAULT NULL,
plan_id      IN NUMBER   DEFAULT NULL,
format       IN VARCHAR2 DEFAULT 'TYPICAL',
filter_preds IN VARCHAR2 DEFAULT NULL,
plan_tag     IN VARCHAR2 DEFAULT 'plan',
report_ref   IN VARCHAR2 DEFAULT NULL)
RETURN XMLTYPE;
EXPLAIN PLAN
SET STATEMENT_ID = 'abc' FOR
SELECT DISTINCT s.srvr_id
FROM servers s, serv_inst i
WHERE s.srvr_id = i.srvr_id;

set pagesize 45
set linesize 121
set long 1000000
col xplan format a100

SELECT dbms_xplan.build_plan_xml(statement_id => 'abc') AS XPLAN
FROM dual;
==========================================

-- COMPARE_CURSOR (new 21c) 
-- Compare two plans populated in the cursor cache	
dbms_xplan.compare_cursor(
sql_id1   IN VARCHAR2 DEFAULT NULL,
sql_id2   IN VARCHAR2 DEFAULT NULL,
childnum1 IN INTEGER  DEFAULT NULL,
childnum2 IN INTEGER  DEFAULT NULL,
type      IN VARCHAR2 := 'TEXT',
level     IN VARCHAR2 := 'TYPICAL',
section   IN VARCHAR2 := 'ALL')
RETURN CLOB;
TBD
========================================== 

-- COMPARE_EXPLAIN (new 21c) 
-- Compare two plans generated by EXPLAIN PLAN
-- In the demo, at right, ALPHA and BETA are used to tag the two plans for analysis
-- The plans are forced to be different by the USE_MERGE hint	
dbms_xplan.compare_explain(
statement_id1 IN VARCHAR2 DEFAULT NULL,
statement_id2 IN VARCHAR2 DEFAULT NULL,
plan_id1      IN NUMBER   DEFAULT NULL,
plan_id2      IN NUMBER   DEFAULT NULL,
type          IN VARCHAR2 := 'TEXT',
level         IN VARCHAR2 := 'TYPICAL',
section       IN VARCHAR2 := 'ALL')
RETURN CLOB;
conn sys as sysdba

EXPLAIN PLAN FOR
SELECT /* ALPHA */ DISTINCT s.srvr_id
FROM c##uwclass.servers s, c##uwclass.serv_inst i
WHERE s.srvr_id = i.srvr_id;

SELECT statement_id, plan_id, other FROM plan_table$ WHERE timestamp > SYSDATE-5/1440;

EXPLAIN PLAN FOR
SELECT /*+ USE_MERGE(s,i) BETA */ DISTINCT s.srvr_id
FROM c##uwclass.servers s, c##uwclass.serv_inst i
WHERE s.srvr_id = i.srvr_id;

SELECT statement_id, plan_id, other FROM plan_table$ WHERE timestamp > SYSDATE-5/1440;

DECLARE
 c CLOB;
BEGIN
  c := dbms_xplan.compare_explain(plan_id1=>'9', plan_id2=>'10');
  dbms_output.put_line(c);
END;
/

COMPARE PLANS REPORT
----------------------------------------------------------------------------------------
Current user : SYS
Total number of plans : 2

Number of findings : 1
----------------------------------------------------------------------------------------

COMPARISON DETAILS
----------------------------------------------------------------------------------------
Plan Number : 1 (Reference Plan)

Plan Found : Yes
Plan Source : Plan Table
Plan Table Owner : SYS
Plan Table Name : PLAN_TABLE
Statement ID :

Plan ID : 9
Plan Database Version : 21.0.0.0
Parsing Schema : "SYS"
SQL Text : No SQL Text

Plan
-----------------------------
Plan Hash Value : 3029349409

----------------------------------------------------------------------------------------
|  Id | Operation               | Name                     |Rows| Bytes|Cost| Time     |
----------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT        |                          |  11|   88 |  4 | 00:00:01 |
|   1 |  RESULT CACHE           |g2p4d5h9bvdyvdmz3w5p0gvs99|  11|   88 |  4 | 00:00:01 |
|   2 |   HASH UNIQUE           |                          |  11|   88 |  4 | 00:00:01 |
|   3 |    NESTED LOOPS SEMI    |                          | 999| 7992 |  3 | 00:00:01 |
|   4 |     INDEX FAST FULL SCAN| PK_SERV_INST             | 999| 3996 |  3 | 00:00:01 |
| * 5 |     INDEX UNIQUE SCAN   | PK_SERVERS               |   1|    4 |  0 | 00:00:01 |
----------------------------------------------------------------------------------------

Predicate Information (identified by operation id):
---------------------------------------------------
* 5 - access("S"."SRVR_ID"="I"."SRVR_ID")
----------------------------------------------------------------------------------------

Plan Number : 2

Plan Found : Yes
Plan Source : Plan Table
Plan Table Owner : SYS
Plan Table Name : PLAN_TABLE
Statement ID :
Plan ID : 10
Plan Database Version : 21.0.0.0
Parsing Schema : "SYS"
SQL Text : No SQL Text

Plan
-----------------------------
Plan Hash Value : 3091993341
-----------------------------------------------------------------------------------------
|  Id | Operation                | Name                     |Rows| Bytes|Cost| Time     |
-----------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT         |                          |  11|   88 |  6 | 00:00:01 |
|   1 |  RESULT CACHE            |asc5ncasy3b3491b7u27avv3td|  11|   88 |  6 | 00:00:01 |
|   2 |   SORT UNIQUE NOSORT     |                          |  11|   88 |  6 | 00:00:01 |
|   3 |    MERGE JOIN SEMI       |                          |  11|   88 |  5 | 00:00:01 |
|   4 |     INDEX FULL SCAN      | PK_SERVERS               | 141|  564 |  1 | 00:00:01 |
| * 5 |     SORT UNIQUE          |                          | 999| 3996 |  4 | 00:00:01 |
|   6 |      INDEX FAST FULL SCAN| PK_SERV_INST             | 999| 3996 |  3 | 00:00:01 |
-----------------------------------------------------------------------------------------
Predicate Information (identified by operation id):
---------------------------------------------------
* 5 - access("S"."SRVR_ID"="I"."SRVR_ID")
* 5 - filter("S"."SRVR_ID"="I"."SRVR_ID")

Hint Report
(identified by operation id / Query Block Name / Object Alias):
Total hints for statement: 2 (U - Unused (1), E - Syntax Error (1))
-------------------------------------------------------------------------------

1 - SEL$1
E - BETA

4 - SEL$1 / "S"@"SEL$1"
U - USE_MERGE(s,i)

Comparison Results (1):
-----------------------------
1. Query block SEL$1: Join order is different at position 1
(reference plan: "I"@"SEL$1", current plan: "S"@"SEL$1").

----------------------------------------------------------------------------------------
PL/SQL procedure successfully completed.
==========================================

COMPARE_PLANS
Compare each plan in a list with a reference plan	dbms_xplan.compare_plans(
reference_plan    IN sys.generic_plan_object,
compare_plan_list IN plan_object_list,
type              IN VARCHAR2 := 'TEXT',
level             IN VARCHAR2 := 'TYPICAL',
section           IN VARCHAR2 := 'ALL')
RETURN CLOB;
TBD
==========================================

DIFF_PLAN
Compares two SQL plans reference plan: implicitly defined target plan: a plan generated by the given outline.	dbms_xplan.diff_plan(
sql_text  IN CLOB,
outline   IN CLOB,
user_name IN VARCHAR2 := NULL)
RETURN VARCHAR2;
TBD
==========================================

-- DIFF_PLAN_AWR
-- Compares two sql plans specified by the given plan hash ids

-- Looks like it isnot quite ready for prime time but Oracle will tell me it is an 
-- unsupported proc so we'll just have to keep an eye on it as patches are released.
dbms_xplan.diff_plan_awr(
sql_id           IN VARCHAR2,
plan_hash_value1 IN NUMBER,
plan_hash_value2 IN NUMBER)
RETURN VARCHAR2;

SELECT DISTINCT a.sql_id, a.plan_hash_value, b.plan_hash_value
FROM dba_hist_sql_plan a, dba_hist_sql_plan b
WHERE a.sql_id = b.sql_id
AND a.plan_hash_value <> b.plan_hash_value
AND a.timestamp > sysdate-1
AND b.timestamp > sysdate-1;

SQL_ID        PLAN_HASH_VALUE PLAN_HASH_VALUE
------------- --------------- ---------------
12a2xbmwn5v6z      3607810482       518152518
2crngsbggkkzv      3967021048      1901716261
836b98xx998x3      1844019431      1681323734
836b98xx998x3      1681323734      1844019431
12a2xbmwn5v6z       518152518      3607810482
dp2c6pq28u5jr      3350759982      3059474834
dp2c6pq28u5jr      3059474834      3350759982
2crngsbggkkzv      1901716261      3967021048

set serveroutput on

SELECT dbms_xplan.diff_plan_awr('12a2xbmwn5v6z', 3607810482, 518152518)
FROM dual;
            *
ERROR at line 1:
ORA-14552: cannot perform a DDL, commit or rollback inside a query or DML
ORA-06512: at "SYS.PRVT_ADVISOR", line 4137
ORA-13608: The specified name NULL is invalid.
ORA-06512: at "SYS.PRVT_ADVISOR", line 4181
ORA-06512: at "SYS.DBMS_ADVISOR", line 363
ORA-06512: at "SYS.DBMS_SQLTUNE", line 903
ORA-06512: at "SYS.DBMS_XPLAN", line 7942
ORA-06512: at "SYS.DBMS_XPLAN", line 8769
==========================================

--DIFF_PLAN_CURSOR
--Compares two sql plans derived from the given cursor child #	
dbms_xplan.diff_plan_cursor(
sql_id            IN VARCHAR2,
cursor_child_num1 IN NUMBER,
cursor_child_num2 IN NUMBER)
RETURN VARCHAR2;

conn sys@pdbdev as sysdba

SELECT vs.sql_id, COUNT(*)
FROM v$sql vs
GROUP BY vs.sql_id
HAVING COUNT(*) > 2;

SELECT vs.child_number
FROM v$sql vs
WHERE vs.sql_id = 'bhvyz9bgyrhb2';

set serveroutput on

DECLARE
  2   x VARCHAR2(13) := '1p5grz1gs7fjq';
  3   y NUMBER := 5;
  4   z NUMBER := 8;
  5   r VARCHAR2(4000);
nbsp; 6  BEGIN
  7    r := dbms_xplan.diff_plan_cursor(x, y, z);
  8    dbms_output.put_line(r);
  9  END;
/
URL:
http://stads59.us.oracle.com:8080/orarep/plandiff/all?task_id=71&format=html&method=qbreg
TASK_71

SELECT message
FROM dba_advisor_findings
WHERE task_name = 'TASK_71';

MESSAGE
-----------------------------------------------------------------------------------------
A potentially better execution plan was found for this statement.
Plan for strategy plan comparison with plan directive (hint) IGNORE_OPTIM_EMBEDDED_HINTS has cost 4 with plan hash value 813480514
Q001 (Lvl: 1) P1: Qbc:SEL$1 (Org:PARSER Arg:NA) [FINAL] -*- P2: Qbc:SEL$1 (Org:PARSER Arg:NA) [FINAL] P1: P2:
=009 CR Diff'ing: Object base construct RWS_0 is found in target
=008 CR Diff'ing: Object base construct SYS.OBJ$ is found in target
=007 CR Diff'ing: Feature Index range scan [base final reason1: execution plan, target final reason2: execution plan]
=006 CR Diff'ing: Feature SQL EXECUTION [base final reason1: execution plan, target final reason2: execution plan]
=005 CR Diff'ing: Object base construct SEL$1 is found in target
=004 CR Diff'ing: Feature First rows (optimizer mode) [base final reason1: execution plan, target final reason2: execution plan]
=003 CR Diff'ing: Feature Index range scan [base final reason1: execution plan, target final reason2: execution plan]
=002 CR Diff'ing: Feature SQL EXECUTION [base final reason1: execution plan, target final reason2: execution plan]
=001 CR Diff'ing: Object base construct STATEMENT is found in target
Plan for strategy plan comparison with plan directive (hint) IGNORE_OPTIM_EMBEDDED_HINTS has cost 4 with plan hash value 813480514
Plan for strategy compilation history has cost 4 with plan hash value 813480514
At least one important bind value was missing for this sql statement. The accuracy of the advisor's analysis may depend on all important bind values being supplied.
==========================================

DIFF_PLAN_OUTLINE
Compares two sql plan outlines	dbms_xplan.diff_plan_outline(
sql_text  IN CLOB,
outline1  IN CLOB,
outline2  IN CLOB,
user_name IN VARCHAR2 := NULL)
RETURN VARCHAR2;
TBD
==========================================
 
DIFF_PLAN_SQL_BASELINE
Compares two sql plan baselines	dbms_xplan.diff_plan_sql_baseline(
baseline_plan_name1 IN VARCHAR2,
baseline_plan_name2 IN VARCHAR2)
RETURN VARCHAR2;
TBD
==========================================

-- DISPLAY
-- Display the more recently created plan
dbms_xplan.display(
table_name   IN VARCHAR2 DEFAULT 'PLAN_TABLE',
statement_id IN VARCHAR2 DEFAULT NULL,
format       IN VARCHAR2 DEFAULT 'TYPICAL',
filter_preds IN VARCHAR2 DEFAULT NULL)
RETURN dbms_xplan_type_table PIPELINED;

Format choices are:
BASIC ..... displays minimum information
TYPICAL ... displays most relevant information
SERIAL .... like TYPICAL but without parallel information
ALL ....... displays all information

Follow the link to dbms_stats.gather_system_statistics for information on CPU costing.
==========================================

dbms_xplan.display_awr(
sql_id          IN VARCHAR2,
plan_hash_value IN INTEGER DEFAULT NULL,
db_id           IN INTEGER DEFAULT NULL,
format          IN VARCHAR2 DEFAULT 'TYPICAL')
RETURN dbms_xplan_type_table PIPELINED;


SELECT MAX(io_cost)
FROM dba_hist_sql_plan;

SELECT sql_id
FROM dba_hist_sql_plan
WHERE io_cost = 142775;

SELECT * FROM TABLE(dbms_xplan.display_awr('24033vh7b098h'));

or

SELECT /* XPLAN_CURSOR */ DISTINCT s.srvr_id
FROM servers s, serv_inst i
WHERE s.srvr_id = i.srvr_id;

SELECT tf.*
FROM dba_hist_sqltext ht,
TABLE(dbms_xplan.display_awr(ht.sql_id,NULL,NULL, 'ALL')) tf
WHERE ht.sql_text LIKE '%XPLAN_CURSOR%';
==========================================

dbms_xplan.display_cursor(
sql_id          IN VARCHAR2 DEFAULT NULL,
cursor_child_no IN INTEGER  DEFAULT 0,
format          IN VARCHAR2 DEFAULT 'TYPICAL',
shard_id        IN NUMBER)
RETURN dbms_xplan_type_table PIPELINED;
Format Constants
ADAPTIVE :> Displays the final plan, or the current plan if the execution has not completed. This section includes notes about runtime optimizations that affect the plan, such as switching from a Nested Loops join to a Hash join.
			Plan lineage. This section shows the plans that were run previously due to automatic reoptimization. It also shows the default plan, if the plan changed due to dynamic plans.
			Recommended plan. In reporting mode, the plan is chosen based on execution statistics displayed. Note that displaying the recommended plan for automatic reoptimization requires re-compiling the query with the optimizer adjustments collected in the child cursor. Displaying the recommended plan for a dynamic plan does not require this.
			Dynamic plans. This summarizes the portions of the plan that differ from the default plan chosen by the optimizer.
ADVANCED:>  Similar to â€˜Allâ€™, but also include the Outline information (the set of hints that will reproduce the plan) and the peeked bind variables used to optimize the query
ALIAS:>   	If relevant, shows the "Query Block Name / Object Alias" section
ALL:>		Shows the Query block/Object Alias section, Predicate information, and Column Projections following the plan
ALLSTATS:>	A shortcut for 'IOSTATS MEMSTATS'
BYTES:>		If relevant, shows the number of bytes estimated by the optimizer
COST:>		If relevant, shows optimizer cost information
IOSTATS:>	Assuming that basic plan statistics are collected when SQL statements are executed (either by using the gather_plan_statistics hint or by setting the parameter statistics_level to ALL), this format will show IO statistics for ALL (or only for the LAST as shown below) executions of the cursor
LAST:>		By default, plan statistics are shown for all executions of the cursor. The keyword LAST can be specified to see only the statistics for the last execution
MEMSTATS:>	Assuming that PGA memory management is enabled (that is, pga_aggregate_target parameter is set to a non 0 value), this format allows to display memory management statistics (for example, execution mode of the operator, how much memory was used, number of bytes spilled to disk, and so on). These statistics only apply to memory intensive operations like hash-joins, sort or some bitmap operators
NOTE:>		If relevant, shows the note section of the explain plan
OUTLINE:>	Shows only Outline and Predicate information after the basic plan
PARALLEL:>	If relevant, shows PX information (distribution method and table queue information)
PARTITION:>	If relevant, shows partition pruning information
PREDICATE:>	If relevant, shows the predicate section
PROJECTION:>If relevant, shows the projection section
REMOTE:>	If relevant, shows the information for distributed query (for example, remote from serial distribution and remote SQL)
ROWS:>		If relevant, shows the number of rows estimated by the optimizer
RUNSTATS_LAST:>	Same as IOSTATS LAST: displays the runtime stat for the last execution of the cursor
RUNSTATS_TOT:>	Same as IOSTATS: displays IO statistics for all executions of the specified cursor
==========================================


SELECT /*+ GATHER_PLAN_STATISTICS */ COUNT(*)
FROM plan_table;

-- most recent cursor
SELECT * FROM TABLE(dbms_xplan.display_cursor);

-- named statement
SELECT /* XPLAN_CURSOR */ DISTINCT s.srvr_id
FROM servers s, serv_inst i
WHERE s.srvr_id = i.srvr_id;

SELECT sql_id, child_number
FROM gv$sql
WHERE sql_text LIKE '%XPLAN_CURSOR%';

SELECT * FROM TABLE(dbms_xplan.display_cursor('cpm9ss48qd32f'));

SELECT * FROM TABLE(dbms_xplan.display_cursor('cpm9ss48qd32f', 0));

SELECT * FROM TABLE(dbms_xplan.display_cursor('cpm9ss48qd32f', 0, 'RUNSTATS_TOT'));

SELECT /*+ GATHER_PLAN_STATISTICS */ DISTINCT s.srvr_id
FROM servers s, serv_inst i
WHERE s.srvr_id = i.srvr_id;

SELECT * FROM TABLE(dbms_xplan.display_cursor(FORMAT=>'RUNSTATS_TOT'));

SELECT /*+ GATHER_PLAN_STATISTICS */ DISTINCT s.srvr_id
FROM servers s, serv_inst i
WHERE s.srvr_id = i.srvr_id;

SELECT * FROM TABLE(dbms_xplan.display_cursor(FORMAT=>'IOSTATS'));

SELECT /*+ GATHER_PLAN_STATISTICS */ DISTINCT s.srvr_id
FROM servers s, serv_inst i
WHERE s.srvr_id = i.srvr_id;

SELECT * FROM TABLE(dbms_xplan.display_cursor(FORMAT=>'MEMSTATS'));

spool c:\temp\allstats.txt
set linesize 141
set trim on
set trimspool on

SELECT /*+ gather_plan_statistics */ DISTINCT s.srvr_id
FROM servers s, serv_inst i
WHERE s.srvr_id = i.srvr_id;

SELECT * FROM TABLE(dbms_xplan.display_cursor(FORMAT=>'ALLSTATS LAST'));

spool off

or

SELECT t.*
FROM gv$sql s,
TABLE(dbms_xplan.display_cursor(s.sql_id, s.child_number)) t
WHERE sql_text LIKE '%XPLAN_CURSOR%';
==========================================

EXPLAIN PLAN
SET STATEMENT_ID = 'abc' FOR
SELECT DISTINCT s.srvr_id
FROM servers s, serv_inst i
WHERE s.srvr_id = i.srvr_id;

set pagesize 45
set linesize 121
set long 1000000
col xplan format a100

SELECT dbms_xplan.display_plan(statement_id => 'abc') AS XPLAN
FROM dual;
==========================================

GRANT SELECT ON all_sqlset_statements TO uwclass;
GRANT SELECT ON all_sqlset_plans TO uwclass;

conn uwclass/uwclass@pdbdev

-- create a SQL tuning set

set linesize 121

SELECT hs.snap_id, TO_CHAR(hs.end_interval_time,'DD MON YYYY HH24:MI') SNAP_DAT
FROM dba_hist_snapshot hs, dba_hist_database_instance di
WHERE di.dbid = hs.dbid
AND di.instance_number = hs.instance_number
AND di.startup_time = hs.startup_time
ORDER BY snap_id;

DECLARE
 l_cursor dbms_sqltune.sqlset_cursor;
 x        VARCHAR2(30);
BEGIN
  -- create a sqlset
  dbms_sqltune.create_sqlset('UW Set', 'Test');

  -- load the sqlset
  OPEN l_cursor FOR
  SELECT VALUE(p)
  FROM TABLE(dbms_sqltune.select_workload_repository(
  15782,15792,NULL,NULL,NULL,NULL,NULL,NULL,10)) p;

  dbms_sqltune.load_sqlset(sqlset_name => 'UW Set',
  populate_cursor => l_cursor);

  -- create a tuning task from the sqlset
  x := dbms_sqltune.create_tuning_task(sqlset_name=>'UW Set');

  -- run the tuning task
  dbms_sqltune.execute_tuning_task(x);
END;
/

SELECT sql_id, plan_hash_value
FROM TABLE(dbms_sqltune.select_sqlset ('UW Set'));

desc all_sqlset_statements

SELECT sqlset_name, sqlset_owner, sqlset_id, sql_id, plan_hash_value
FROM all_sqlset_statements;

desc all_sqlset_plans

SELECT ssp.sqlset_name, ssp.sqlset_owner, ssp.sqlset_id, ssp.sql_id, ssp.plan_hash_value
FROM all_sqlset_plans ssp;

SELECT sql_id, plan_hash_value
FROM TABLE(dbms_sqltune.select_sqlset ('UW Set'));

/* display the execution plan for the SQL statement associated with SQL ID '6hwjmjgrpsuaa' and PLAN HASH 2721822575 in the SQL Tuning Set called 'OLTP_optimization_0405" */
SELECT *
FROM TABLE(dbms_xplan.display_sqlset('UW Set','6hwjmjgrpsuaa', 2721822575));

-- to display all execution plans of the SQL ID 'atfwcg8anrykp' stored in the SQL tuning set
SELECT *
FROM TABLE(dbms_xplan.display_sqlset('UW Set', 'dwssdqx28tzf5'));

-- to display runtime statistics for the SQL statement included in the preceding statement
SELECT * FROM TABLE(dbms_xplan.display_sqlset('UW Set', 'dwssdqx28tzf5', NULL, 'ALLSTATS LAST'));

==========================================

dbms_xplan.display_sql_patch_plan(
name   IN VARCHAR2,
format IN VARCHAR2 DEFAULT 'TYPICAL')
RETURN dbms_xplan_type_table PIPELINED;
SELECT * FROM TABLE(dbms_xplan.display_sql_patch_plan('UW_PPLAN'));
==========================================

dbms_xplan.display_sql_plan_baseline(
sql_handle IN VARCHAR2 DEFAULT NULL,
plan_name  IN VARCHAR2 DEFAULT NULL,
format     IN VARCHAR2 DEFAULT 'TYPICAL')
RETURN dbms_xplan_type_table PIPELINED;
conn sys@pdbdev as sysdba

set linesize 121
col name format a40
col value format a30

SELECT p.name, p.value
FROM gv$parameter p
WHERE p.name LIKE 'optimizer_capture%';

ALTER SYSTEM SET optimizer_capture_sql_plan_baselines = TRUE SCOPE=BOTH;

SELECT p.name, p.value
FROM gv$parameter p
WHERE p.name LIKE 'optimizer_capture%';

GRANT select ON dba_sql_plan_baselines TO uwclass;

conn uwclass/uwclass@pdbdev

SELECT /* TEST */ DISTINCT s.srvr_id
FROM servers s, serv_inst i
WHERE s.srvr_id = i.srvr_id;

desc dba_sql_plan_baselines

SELECT spb.sql_handle
FROM dba_sql_plan_baselines spb
WHERE spb.sql_text LIKE '%TEST%';

SELECT * FROM TABLE (dbms_xplan.display_sql_plan_baseline('SYS_SQL_71e1abffb11f9833'));

or

SELECT t.*
FROM (
  SELECT DISTINCT spb.sql_handle
  FROM dba_sql_plan_baselines spb
  WHERE spb.sql_text like '%HR2%') pb,
  TABLE(dbms_xplan.display_sql_plan_baseline(pb.sql_handle, NULL, 'basic')) t;

==========================================

-- DISPLAY_SQL_PROFILE_PLAN
--Display a SQL Profile
dbms_xplan.display_sql_profile_plan(
name   IN VARCHAR2,
format IN VARCHAR2 DEFAULT 'TYPICAL')
RETURN dbms_xplan_type_table PIPELINED;

SELECT * FROM TABLE(dbms_xplan.display_sql_profile_plan('UW_PROFILE'));  
 
 
 dbms_xplan.display_workload_repository(
sql_id          IN VARCHAR2,
plan_hash_value IN INTEGER  DFAULT NULL,
format          IN VARCHAR2 DEFAULT 'TYPICAL',
dbid            IN INTEGER  DEFAULT NULL,
con_dbid        IN INTEGER  DEFAULT NULL,
awr_location    IN VARCHAR2 DEFAULT 'AWR_ROOT')
RETURN dbms_xplan_type_table PIPELINED;

SELECT last_active_time, sql_id
FROM v$sql
WHERE last_active_time > SYSDATE-1/1440
ORDER BY 1;
==========================================

-- DISPLAY_WORKLOAD_REPOSITORY
-- Display from AWR
LAST_ACTIVE_TIME SQL_ID
-------------------- -------------
26-JUN-2018 15:31:17 655vmvf20n9mw
26-JUN-2018 15:31:33 7am4w4pp3nwtm
26-JUN-2018 15:31:33 gjaap3w3qbf8c
26-JUN-2018 15:31:33 7am4w4pp3nwtm
26-JUN-2018 15:31:33 gjaap3w3qbf8c
26-JUN-2018 15:31:33 cgtc5gb7c4g07
26-JUN-2018 15:31:33 c9umxngkc3byq
26-JUN-2018 15:31:42 2t8b3gh7z1v0k
26-JUN-2018 15:31:42 dkubj0p62bd2w
26-JUN-2018 15:31:42 2t8b3gh7z1v0k
26-JUN-2018 15:31:42 3u5ma38bd03qq
26-JUN-2018 15:31:42 dkubj0p62bd2w
26-JUN-2018 15:31:42 bs1vs6u58nayu
26-JUN-2018 15:31:42 bs1vs6u58nayu
26-JUN-2018 15:31:42 3u5ma38bd03qq
26-JUN-2018 15:31:46 6jh4ua3hhf9us
26-JUN-2018 15:31:46 9babjv8yq8ru3
26-JUN-2018 15:31:51 8p447s6p0rv6b
26-JUN-2018 15:31:51 772s25v1y0x8k
26-JUN-2018 15:31:51 aykvshm7zsabd
26-JUN-2018 15:31:51 5yv7yvjgjxugg
26-JUN-2018 15:31:58 bsa0wjtftg3uw
26-JUN-2018 15:32:00 87gaftwrm2h68
26-JUN-2018 15:32:00 089d5jrtq3skb

24 rows selected.

SELECT * FROM TABLE(dbms_xplan.display_workload_repository('87gaftwrm2h68'));

PLAN_TABLE_OUTPUT
---------------------------------------------------------------------
SQL_ID 87gaftwrm2h68
--------------------
select o.owner#,o.name,o.namespace,o.remoteowner,o.linkname,o.subname
from obj$ o where o.obj#=:1

Plan hash value: 1072382624
---------------------------------------------------------------------------------------
| Id | Operation                           | Name  | Rows| Bytes| Cost(%CPU)| Time    |
---------------------------------------------------------------------------------------
|  0 | SELECT STATEMENT                    |       |     |      |    3 (100)|         |
|  1 |  TABLE ACCESS BY INDEX ROWID BATCHED| OBJ$  |   1 |  111 |    3   (0)| 00:00:01|
|  2 |   INDEX RANGE SCAN                  | I_OBJ1|   1 |      |    2   (0)| 00:00:01|

==========================================

-- FORMAT_NUMBER
--Returns a number as a string	dbms_xplan.format_number(num IN NUMBER) RETURN VARCHAR2;
SELECT dump(100.1), dbms_xplan.format_number(100.1), dump(dbms_xplan.format_number(100.1))
FROM dual;

select 1000000 original_number,
	dbms_xplan.format_number(1000000) formated_number
from dual;
 
ORIGINAL_NUMBER FORMATED_NUMBER
--------------- ------------------
1000000         1000K

==========================================

-- FORMAT_NUMBER2
-- Returns a number as a string formatted with a leading space (CHR(32)	
-- dbms_xplan.format_number2(num IN NUMBER) RETURN VARCHAR2;
SELECT dump(100.1), dbms_xplan.format_number2(100.1), dump(dbms_xplan.format_number2(100.1))
FROM dual;
==========================================

-- FORMAT_SIZE
-- Undocumented	dbms_xplan.format_size(num IN NUMBER) RETURN VARCHAR2;
col fsize format a15
col fsizedump format a30

SELECT dump(100.1), dbms_xplan.format_size(100.1) FSIZE, dump(dbms_xplan.format_size(100.1)) FSIZEDUMP
FROM dual;

select file_name, dbms_xplan.format_size(bytes) as file_size
from dba_data_files
where tablespace_name like '%UNDO%' order by bytes;
 
FILE_NAME                                          FILE_SIZE
-------------------------------------------------- ----------
C:\oracle\HRTST\datafile\undotbs1.dbf              100M
C:\oracle\HRTST\datafile\undotbs2.dbf              3G


select segment_name, dbms_xplan.format_size(bytes) as SEG_Size
from dba_segments
where owner='IP'
and segment_name like '%APP%'
and segment_type='TABLE'
order by bytes;
 
SEGMENT_NAME                   SEG_SIZE
------------------------------ ----------
APPLICATION_TABLE              65536
APP_VALIDATION_T               704K
USER_APP_TABLE                 76M
HR_APP_TABLE                   10G

==========================================

-- FORMAT_SIZE2
-- Undocumented	dbms_xplan.format_size2(num IN NUMBER) RETURN VARCHAR2;
col fsize format a15
col fsizedump format a30

SELECT dump(100.1), dbms_xplan.format_size2(100.1) FSIZE, dump(dbms_xplan.format_size2(100.1)) FSIZEDUMP
FROM dual;

select dbms_xplan.format_size(sum(bytes)) as db_size
from dba_data_files;
 
DB_SIZE
--------------
25G
==========================================

-- FORMAT_TIME_S
-- Formats a number representing time in seconds using the format HH:MM:SS	dbms_xplan.format_time_s(num IN NUMBER) RETURN VARCHAR2;
col ftime format a15
col ftimedump format a40

SELECT dump(100.1), dbms_xplan.format_time_s(100.1) FTIME, dump(dbms_xplan.format_time_s(100.1)) FTIMEDUMP
FROM dual;

select dbms_xplan.format_time_s(3600) as display_time
from dual;
 
DISPLAY_TIME
------------
01:00:00
 
select dbms_xplan.format_time_s(4500) as display_time from dual;
 
DISPLAY_TIME
------------
01:15:00

==========================================

-- GET_CURSOR_ROWS
--Intentionally not documented by Oracle	
dbms_xplan.get_cursor_rows(
sql_id          IN VARCHAR2 DEFAULT NULL,
cursor_child_no IN INTEGER  DEFAULT 0,
format          IN VARCHAR2 DEFAULT 'TYPICAL')
RETURN plan_table PIPELINED;
SELECT DISTINCT a.sql_id
FROM dba_hist_sql_plan a, dba_hist_sql_plan b
WHERE a.sql_id = b.sql_id
AND a.plan_hash_value <> b.plan_hash_value;

SELECT * FROM TABLE(dbms_xplan.get_cursor_rows('bwsxc8jzcm635'));
==========================================

-- GET_FINAL_PLAN
-- Intentionally undocumented function ... I have a suspicion this is intended to 
-- return the final plan after Adaptive Query Planning. Testing will determine 
-- whether that is true.
dbms_xplan.get_final_plan(
plan_rows IN plan_table,
format    IN VARCHAR2 DEFAULT 'TYPICAL')
RETURN plan_table PIPELINED;
TBD
==========================================
 
-- GET_PLANDIFF_REPORT_XML
-- Undocumented	
dbms_xplan.get_plandiff_report_xml(
report_ref IN VARCHAR2 := NULL,  -- report name
tid        IN NUMBER,            -- task id
method     IN VARCHAR2)          -- comparison method (for example 'outline')
RETURN XMLTYPE;
TBD
==========================================
 
-- GET_PLAN_ROWS
-- Intentionally not documented by Oracle	
dbms_xplan.get_plan_rows(
table_name   IN VARCHAR2 DEFAULT 'PLAN_TABLE',
statement_id IN VARCHAR2 DEFAULT NULL,
plan_id      IN VARCHAR2 DEFAULT NULL,
format       IN VARCHAR2 DEFAULT 'TYPICAL',
filter_preds IN VARCHAR2 DEFAULT NULL,
mask_cost    IN NUMBER   DEFAULT 0)
RETURN plan_table PIPELINED;
TBD
==========================================

-- I_DISPLAY_CURSOR
-- Undocumented internal function to display cursor interfaces	
dbms_xplan.i_display_cursor(
sql_id          IN VARCHAR2     DEFAULT NULL,
cursor_child_no IN INTEGER      DEFAULT 0,
format          IN VARCHAR2     DEFAULT 'TYPICAL',
shard_ids       IN num_tab_type DEFAULT NULL)
RETURN dbms_xplan_type_table PIPELINED;
SELECT * FROM TABLE(dbms_xplan.i_display_cursor('94qn6y14kw01g'));

PLAN_TABLE_OUTPUT
------------------
SQL_ID 94qn6y14kw01g, child number 0
-------------------------------------
SELECT NVL(TO_NUMBER(EXTRACT(XMLTYPE(:B2 ), :B1 )), 0) FROM DUAL

Plan hash value: 1388734953

---------------------------------------------------------------
| Id | Operation        | Name | Rows | Cost (%CPU)| Time     |
---------------------------------------------------------------
|  0 | SELECT STATEMENT |      |      |     2 (100)|          |
|  1 |  FAST DUAL       |      |    1 |     2   (0)| 00:00:01 |
---------------------------------------------------------------
==========================================
 
-- I_DISPLAY_SMB_PLAN
-- Undocumented	
dbms_xplan.i_display_smb_plan(
name     IN VARCHAR2,
format   IN VARCHAR2 DEFAULT 'TYPICAL',
obj_type IN NUMBER)
RETURN dbms_xplan_type_table PIPELINED;
SELECT * FROM TABLE(dbms_xplan.i_display_smb_plan('UW_SMB', 'ALL', 1));
==========================================

-- PREPARE_PLAN_XML_QUERY
-- Helper function that builds the XML version of the text of a select query that is run 
-- before the display display function to retrieve and display the execution plan of a SQL	
-- dbms_xplan.prepare_plan_xml_query(plan_query IN VARCHAR2) RETURN VARCHAR2;
conn uwclass/uwclass@pdbdev

set linesize 1024
set serveroutput on

DECLARE
 sqlst VARCHAR2(1024) := 'SELECT srvr_id FROM servers
                          INTERSECT
                          SELECT srvr_id FROM serv_inst';
 retval VARCHAR2(4000);
BEGIN
  retval := dbms_xplan.prepare_plan_xml_query(sqlst);
  dbms_output.put_line(retval);
END;
/
==========================================
 
-- PREPARE_RECORDS
-- Private procedure: used internally	
dbms_xplan.prepare_records(
plan_cur        IN sys_refcursor,
i_format_flags  IN NUMBER,
diag_repos_cur  IN sys_refcursor DEFAULT NULL,
sql_id          IN VARCHAR2      DEFAULT NULL,
cursor_child_no IN INTEGER       DEFAULT NULL,
shard_ids       IN num_tab_type  DEFAULT NULL)
RETURN dbms_xplan_type_table PIPELINED;
TBD
==========================================

-- VALIDATE_FORMAT
-- Private function to validate the user format: used internally	
dbms_xplan.validate_format(
hasPlanStats IN  BOOLEAN,
format       IN  VARCHAR2,
format_flags OUT BINARY_INTEGER)
RETURN BOOLEAN;
DECLARE
 b  BOOLEAN;
 bi BINARY_INTEGER;
BEGIN
  IF dbms_xplan.validate_format(TRUE, 'ALL', bi) THEN
    dbms_output.put_line('T: ' || bi);
  ELSE
    dbms_output.put_line('F: ' || bi);
  END IF;
END;
/
==========================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
PT Stuffs
3
-- Performance Tuning 
-- how many pid's are eating more cpu's 
ps -e -o pcpu,pid,user,tty,args | sort -n -k 1 -r | head

-- check on AIX OS
-- top 10 cpu 
ps aux | head -1; ps aux | sort -rn +2 | head -10

-- Displaying the top 10 memory-consuming processes using SZ
# ps -ealf | head -1 ; ps -ealf | sort -rn +9 | head

-- Wait processes bound to CPUs
# ps -mo THREAD -p 516,774,1032,1290

-- Displaying the processes in order of I/O
# ps vx | head -1 ; ps vx | grep -v PID | sort -rn +4 | head -10 
 
-- flushing the result cache
exec dbms_result_cache.flush; 

-- those tables are in stale state for any schema then
-- we can consider it for stat gather
select table_name, stale_stats, last_analyzed,
  'execute DBMS_STATS.gather_table_stats (''MR_PRELOAD'', '''||table_name||''');'stale_state
from dba_tab_statistics 
where owner='MR_PRELOAD'
and stale_stats='YES'
======================================================================================

-- OverAll CPU usage by each Thread and Inst_ID
SELECT S.INST_ID, S.SID,S.SERIAL#,S.SQL_ID,p.spid THREAD, s.SCHEMANAME,
    DECODE(NVL(p.background,0),1,bg.description,s.program ) program,
    ss.VALUE/100 CPU,physical_reads disk_io
 FROM 
    Gv$process p,
    Gv$session s,
    Gv$sesstat ss,
    Gv$sess_io si,
    Gv$bgprocess bg
 WHERE s.paddr=p.addr
  AND ss.SID=s.SID
  AND ss.statistic#=12 
  AND si.SID=s.SID
  AND bg.paddr(+)=p.addr
 ORDER BY ss.VALUE/100 DESC;
======================================================================================

/*
   which active session is bogging down the system with a bad hit ratio.
The ratio of buffer to physical block reads can many times be an indication of the efficiency of the query running. Anything under 
90% is typically bad. Very low hit ratios (< 10-30%) in a process can slow down the entire system.   
*/
SELECT s.inst_id
  , s.SID SID
  , s.serial# serial_id
  , LPAD(P.spid,7) unix_pid
  ,  P.username unix_id
  , s.username oracle_id
  , s.osuser os_user
  , sio.consistent_gets consistent_gets
  , sio.block_gets block_gets
  , sio.physical_reads physical_reads
  , ROUND((consistent_gets+Block_gets-Physical_reads) /
          (Consistent_gets+Block_gets)*100,2) hit_ratio
FROM
    gv$process P
  , gv$session s
  , gv$sess_io sio
WHERE
      P.addr=s.paddr
  AND s.SID = sio.SID
  AND (sio.consistent_gets + sio.block_gets) > 0
  AND s.username IS NOT NULL
ORDER BY hit_ratio ASC 
======================================================================================


-- How to Find Expected Time of Completion of an Oracle Query

select inst_id,sid,serial#,schemaname,username,osuser,sql_id,machine,program
from gv$session where sid=2766;

select * 
from v$sqlarea where sql_id='245k5gsbcm77f';


SELECT sid,serial#,username,target,
	to_char(start_time,'mm/dd/yyyy hh24:mi:ss')start_time,
	to_char(last_update_time,'mm/dd/yyyy hh24:mi:ss')last_update_time,
	ROUND((sofar/totalwork),4)*100 Percentage_Complete,
	opname,
	CEIL(time_remaining/60) Max_Time_Remaining_In_Min,
	FLOOR(elapsed_seconds/60) Time_Spent_In_Min,
    message, sql_id
FROM gv$session_longops
WHERE sofar != totalwork
 -- and regexp_like(target,'MR_PRELOAD.EPC_CA7COST','i')
-- and sql_id='245k5gsbcm77f'
order by target 
;


SELECT l.sid, l.serial#,l.username, AR.PARSING_SCHEMA_NAME, AR.MODULE client_tool,
	opname, target,
  to_char(start_time,'mm/dd/yyyy hh24:mi:ss')start_time,
	to_char(last_update_time,'mm/dd/yyyy hh24:mi:ss')last_update_time,
	ROUND((sofar/totalwork),4)*100 Percentage_Complete,	
	CEIL(TIME_REMAINING  /60) MAX_TIME_REMAINING_IN_MIN,
	FLOOR(ELAPSED_SECONDS/60) TIME_SPENT_IN_MIN,
	AR.SQL_FULLTEXT	
FROM V$SESSION_LONGOPS L, V$SQLAREA AR
WHERE L.SQL_ID = AR.SQL_ID
AND TOTALWORK > 0
AND ar.users_executing > 0
AND sofar != totalwork;
---------------------------------------------------------------------------------

-- scripts to check sga,pga,uga usage
SET LINESIZE 320 pages 1000
COLUMN sid                     FORMAT 999            HEADING 'SID'
COLUMN oracle_username         FORMAT a12            HEADING 'Oracle|User'     JUSTIFY right
COLUMN os_username             FORMAT a9             HEADING 'O/S|User'        JUSTIFY right
COLUMN session_program         FORMAT a18            HEADING 'Session|Program' TRUNC
COLUMN session_machine         FORMAT a8             HEADING 'Machine'         JUSTIFY right TRUNC
COLUMN session_pga_memory      FORMAT 9,999,999,999  HEADING 'PGA|Memory'
COLUMN session_pga_memory_max  FORMAT 9,999,999,999  HEADING 'PGA|Memory Max'
COLUMN session_uga_memory      FORMAT 9,999,999,999  HEADING 'UGA|Memory'
COLUMN session_uga_memory_max  FORMAT 9,999,999,999  HEADING 'UGA|Memory MAX'
SELECT  s.sid sid, lpad(s.username,12) oracle_username, 
      lpad(s.osuser,9) os_username, s.program session_program, 
	  lpad(s.machine,8) session_machine, 
	  (select ss.value 
		 from v$sesstat ss, v$statname sn
		where ss.sid = s.sid 
		  and sn.statistic# = ss.statistic# 
		  and sn.name = 'session pga memory') session_pga_memory, 
		  (select ss.value 
			 from v$sesstat ss, v$statname sn
			where ss.sid = s.sid 
			  and sn.statistic# = ss.statistic# 
			  and sn.name = 'session pga memory max') session_pga_memory_max,
		  (select ss.value 
			 from v$sesstat ss, v$statname sn
			where ss.sid = s.sid 
			  and sn.statistic# = ss.statistic# 
			  and sn.name = 'session uga memory') session_uga_memory,
		  (select ss.value 
			 from v$sesstat ss, v$statname sn
			where ss.sid = s.sid 
			  and sn.statistic# = ss.statistic# 
			  and sn.name = 'session uga memory max') session_uga_memory_max
  FROM
	v$session  s
  -- where s.type <> 'BACKGROUND'
ORDER BY session_pga_memory DESC; 
 

======================================================================================

select snap_id, instance_number, to_char(sample_time,'mm/dd/yyyy hh24:mi:ss'), instance_number, sql_id, session_id, session_serial#
from dba_hist_active_sess_history
where session_id like '890%'
order by to_date(to_char(sample_time,'mm/dd/yyyy hh24:mi:ss'),'mm/dd/yyyy hh24:mi:ss') desc

=======================================================================================
The V$OSSTAT view captures system level information in the database, making it easier 
for you to determine if there are hardware level resource issues. The V$SYSMETRIC_HISTORY 
view shows a one-hour history of the Host CPU Utilization metric, a representation of 
percentage of CPU usage at each one-minute interval. The V$SYS_TIME_MODEL view supplies 
statistics on the CPU usage by the Oracle database. Using both sets of statistics enable 
you to determine whether the Oracle database or other system activity is the cause 
of the CPU problems.

-- We can check how far back in time we can go to restore statistics.
select DBMS_STATS.GET_STATS_HISTORY_AVAILABILITY  from dual;

-- We can see what the retention period is for the statistics and can also alter the 
-- same. In this case we are changing the statistics retention from 10 days to 14 days. 
-- The default is 31 days.
select DBMS_STATS.GET_STATS_HISTORY_RETENTION from dual;

execute DBMS_STATS.ALTER_STATS_HISTORY_RETENTION (14);

select DBMS_STATS.GET_STATS_HISTORY_RETENTION from dual;

-- Let us now look at an example of restoring the statistics from a point in time from the past.
select TABLE_NAME, STATS_UPDATE_TIME 
from dba_tab_stats_history 
where table_name='MYOBJECTS' and owner='SYSTEM';


SQL> select * from dba_hist_wr_control;

 DBID              SNAP_INTERVAL        RETENTION            TOPNSQL

---------- -------------------- -------------------- ---------- ----------------------------

3275747663    +00000 01:00:00.0          +00008 00:00:00.0    DEFAULT

--Here interval is set to 1 hour and retention is set to 8 days.

--You can also create a snapshot manually by executing following procedure

SQL> exec dbms_workload_repository.create_snapshot;

PL/SQL procedure successfully completed.

--Now let’s change the retention and interval settings. Interval will be set to 15 
-- minutes and retention to 35 days (35x24x60 = 50400)

SQL> exec dbms_workload_repository.modify_snapshot_settings(interval => 15, retention => 50400)

PL/SQL procedure successfully completed.

SQL> select * from dba_hist_wr_control;

 DBID              SNAP_INTERVAL        RETENTION            TOPNSQL

---------- -------------------- -------------------- -------------------------------------

3275747663    +00000 00:15:00.0         +00035 00:00:00.0    DEFAULT

======================================================================================

-- Purge a query from Shared pool
select address, hash_value 
from v$sqlarea where sql_id like '<<SQL_ID for the query to purge shared pool>>';

exec dbms_shared_pool.purge('<<Address>>,<<Hash_Value>>','C');

-- Find out the Column values of ADDRESS and HASH_VALUE for the Sqlid: "gqy6jdzvru5kk"
select address, hash_value, executions, loads, version_count, invalidations, parse_calls 
from gv$sqlarea where sql_id = 'gqy6jdzvru5kk';


-- Then append the Column values of ADDRESS and HASH_VALUE in the below command and execute the same :
exec dbms_shared_pool.purge ('ADDRESS,HASH_VALUE','C');
======================================================================================

-- Take the username on which is performance needs to be checked
-- Below query will return the SID
select sid from v$session 
where username = 'ARUP';


-- Once you get the sid, put the sid in below auery and check the performance 
set lines 32000 pages 1000 trimspool on
col event head "Waited for" format a50
col total_waits head "Total|Waits" format 999,999
col tw_ms head "Waited|for (ms)" format 999,9999999.99
col aw_ms head "Average|Wait (ms)" format 999,9999999.99
col mw_ms head "Max|Wait (ms)" format 999,9999999.99
select event, total_waits, time_waited*10 tw_ms,
       average_wait*10 aw_ms, max_wait*10 mw_ms
from v$session_event
where sid = 575;


-- Identify Database Sid Based On Os Process Id
col sid format 999999
col username format a20
col osuser format a15
select b.spid,a.sid, a.serial#,a.username, a.osuser
from v$session a, v$process b
where a.paddr= b.addr
and b.spid='2848'
order by b.spid;



-- Take a look at the sql query of sid which you got
select sql_fulltext
from v$sql l, v$session s
where s.sid = 7
and l.sql_id = s.sql_id;


-- check the CPU consumption for the give SID
select s.value
from v$sesstat s, v$statname n
where s.sid = 1560
and n.statistic# = s.statistic#
and n.name = 'CPU used by this session';

-- cause of CPU consumption is the parsing of SQL statement
select name, value
from v$sesstat s, v$statname n
where sid = 1560
and n.statistic# = s.statistic#
order by value desc
----------------------------------------------------------------------------------------

-- Here is a handy script to locate Highly fragmented tables:
select 
   table_name,round((blocks*8),2) "size (kb)" , 
   round((num_rows*avg_row_len/1024),2) "actual_data (kb)",
   (round((blocks*8),2) - round((num_rows*avg_row_len/1024),2)) "wasted_space (kb)"
from 
   dba_tables
where 
   (round((blocks*8),2) > round((num_rows*avg_row_len/1024),2))
order by 4 desc;
----------------------------------------------------------------------------------------

-----------------------------------------
--
-- Top 10 CPU consumers in last 5 minutes
--
-----------------------------------------
SQL> select * from
(
select session_id, session_serial#, count(*)
from v$active_session_history
where session_state= 'ON CPU' and
 sample_time > sysdate - interval '5' minute
group by session_id, session_serial#
order by count(*) desc
)
where rownum <= 10;
======================================================================================

-- Most active SQL in previous hour.
SELECT sql_id,COUNT(*),ROUND(COUNT(*)/SUM(COUNT(*)) OVER(), 2) PCTLOAD
  FROM gv$active_session_history
 WHERE sample_time > SYSDATE - 1/24
   AND session_type = 'BACKGROUND'
 GROUP BY sql_id
 ORDER BY COUNT(*) DESC;

SELECT sql_id,COUNT(*),ROUND(COUNT(*)/SUM(COUNT(*)) OVER(), 2) PCTLOAD
  FROM gv$active_session_history
 WHERE sample_time > SYSDATE - 1/24
   AND session_type = 'FOREGROUND'
 GROUP BY sql_id
 ORDER BY COUNT(*) DESC;

-- Top 10 CPU consumers in last 60 minutes
select * from
(
	select session_id, session_serial#, count(*)
	  from v$active_session_history
	 where session_state= 'ON CPU'
	   and sample_time > sysdate - interval '60' minute
	 group by session_id, session_serial#
	 order by count(*) desc
)
where rownum <= 10;

-- Top 10 waiting sessions in last 60 minutes
select * from
(
	select session_id, session_serial#,count(*)
	  from v$active_session_history
	 where session_state='WAITING'
	   and sample_time >  sysdate - interval '60' minute
	 group by session_id, session_tab
	 order by count(*) desc
)
where rownum <= 10;
======================================================================================

Here is an example of using this hint on the following SQL.  We remove the 
full-table scan by building the index and analyzing the index.  
This should be enough to avoid the full-table scan.  However, you may still want 
to use hints to force an index scan over an unnecessary full-table scan::

create index emp_id_idx on sals_2011;
exec dbms_stats.gather_index_stats('emp_id_idx');
 
select /*+ use_nl index (sals_2011, emp_id_idx) */ * 
from sals_2011 
where emp_id >500 
and date < 01-feb-2011

--- Check the full table scan for given dates
SELECT snap_id, instance_number, sample_time, session_id,sql_id,sql_opname,
       top_level_sql_id, sql_plan_operation, sql_plan_options,sql_exec_start,
       program,machine,to_char(tm_delta_time) tm_delta_time, 
       to_char(tm_delta_cpu_time) tm_delta_cpu_time, 
       SUM(TM_DELTA_CPU_TIME)/1000000 CPU_SECONDS_USED
       to_char(tm_delta_db_time) tm_delta_db_time, delta_time
FROM dba_hist_active_sess_history
WHERE sql_plan_options = 'FULL'
  AND  sql_exec_start BETWEEN TO_DATE('08/25/2017 22:00:00','mm/dd/yyyy hh24:mi:ss')
                         AND TO_DATE('08/25/2017 23:00:00','mm/dd/yyyy hh24:mi:ss')
ORDER BY sample_time DESC;

-- good url and content most of the queries
http://select-star-from.blogspot.in/2013/07/how-to-find-sqlsqlid-history-on-oracle.html


--- Check the session is doing the full table scan
SELECT      ss.username
            || '('
            || se.sid
            || ') ' "User Process",
SUM (DECODE (NAME, 'table scans (short tables)', VALUE)) "Short Scans",
SUM (DECODE (NAME, 'table scans (long tables)', VALUE)) "Long Scans",
SUM (DECODE (NAME, 'table scan rows gotten', VALUE)) "Rows Retrieved"
          FROM v$session ss, v$sesstat se, v$statname sn
         WHERE se.statistic# = sn.statistic#
           AND ( NAME LIKE '%table scans (short tables)%'
               OR NAME LIKE '%table scans (long tables)%'
               OR NAME LIKE '%table scan rows gotten%'
               )
           AND se.sid = ss.sid
           AND ss.username IS NOT NULL
      GROUP BY ss.username
               || '('
               || se.sid
               || ') ';
-------------------------------------------------------------------------------------------


(1) Look for sessions that are currently waiting for I/O resources:
SELECT username,
       program,
       machine,
       sql_id
  FROM v$session
 WHERE event LIKE 'db file%read';
 
(2) which SQL statements are using a lots of disks:
 
 col schema format a20
 SELECT *
  FROM (  SELECT parsing_schema_name Schema, SQL_ID,
                 SUBSTR (sql_text, 1, 75) SQL,
                 disk_reads
            FROM v$sql
        ORDER BY disk_reads DESC)
 WHERE ROWNUM < 20;
 
 And with the result set of (1) or (2):
 set long 1000
 select SQL_FULLTEXT from v$sql where sql_id='xxxxxxxxxxx'
 
--> Tune your SQL Statement or execute it less times.
-------------------------------------------------------------------------------------------



-- ############################################################
-- # Creator: Vincent Fenoll
-- # Created: 2011/03/&
-- # Name: Display cursor
-- ############################################################
-- #
-- # Compatible: Oracle 10g 11g
-- #
-- ############################################################
-- #
-- # How to display more informations than explain 
-- # plan about the cursor: binds variables, 
-- #  estimated vs real rows (tuning with cardinalities)...
-- # 
-- # pre-requisite:
-- # - statistics_level=ALL
-- # - CBO used and tables analyzed
-- # - cursor_sharing=force (for "SERIAL PEEKED_BINDS IOSTATS LAST")
-- # - Better to have enough SGA to find old statements (1G)
-- # 
-- ############################################################
 
 
--      INPUTS (v$sql_area): 
--  &1 = SQL_ID (in lowercase)
--  &2 = child_number
 
 
-- Informations about the last SQL Statement:
SELECT * FROM TABLE(dbms_xplan.display_cursor(null, null, 'ALLSTATS LAST'));
 
 
-- Informations about another statement identified with sql_id and child_number:
SELECT * FROM TABLE(dbms_xplan.display_cursor('&1', &2, 'ALLSTATS LAST'));
 
 
-- To display the values of bind variables
select * from table(dbms_xplan.display_cursor('&1', &2, 'SERIAL PEEKED_BINDS IOSTATS LAST'));
 
 
-- To read the result:
--   "E-Rows" is the number of estimated rows that Oracle expects that step in the plan to return
--   "A-Rows" is the actual number. 
--   "Starts" column is the number of times that that step in the plan is "executed"
--    Note: "A-Rows" column is the cumulative count over all executions, 
--          "E-Rows" is the estimate for each execution of the step. 
 
 
Output example:
 
 
-----------------------------------------------------------------------------------------------
| Id  | Operation                    | Name | Starts | E-Rows | A-Rows |   A-Time   | Buffers |
-----------------------------------------------------------------------------------------------
|   1 |  SORT AGGREGATE              |      |      1 |      1 |      1 |00:00:00.02 |     196 |
|   2 |   TABLE ACCESS BY INDEX ROWID| T1   |      1 |     40 |    225 |00:00:00.02 |     196 |
|   3 |    NESTED LOOPS              |      |      1 |    225 |    241 |00:00:00.03 |     196 |
|*  4 |     TABLE ACCESS FULL        | T2   |      1 |     40 |     40 |00:00:00.01 |      45 |
|*  5 |     INDEX RANGE SCAN         | T_I1 |     10 |     40 |    400 |00:00:00.01 |       8 |
-----------------------------------------------------------------------------------------------        
 
In this example, in line 5:  E-rows = 40 and A-rows = 400, because line 5 starts 10 times: 
so 400 actual rows = (10 starts) * (40 estimated rows per start).
-------------------------------------------------------------------------------------------

-- ############################################################
-- #
-- # How to calculate Library cache hit ratio
-- # Other ratios see: "Quick tune"
-- # Compatible: Oracle 7i 8i 9i 10g 11g
-- #
-- ############################################################
 
Calculate the cache hit ratio for the library cache with the following query:
 
    Select sum(pinhits) / sum(pins) "Hit Ratio",
        sum(reloads) / sum(pins) "Reload percent"
    From v$librarycache
    Where namespace in
    ('SQL AREA', 'TABLE/PROCEDURE', 'BODY', 'TRIGGER');
 
-- The hit ratio should be above 85 percent. 
-- The reload percent should be very low, 2% or less. 
-- If this is not the case, increase the initialisation parameter SHARED_POOL_SIZE. 
-- OPEN_CURSORS may also need to increased.
-------------------------------------------------------------------------------------------


-- Top CPU Consuming SQL During A Certain Time Period
-- check more performance tunning related queries
-- URL : https://dbpost.wordpress.com/category/performance/performance-analysis/
SELECT * 
 FROM 
 (
	SELECT
		SQL_ID,
		SUM(CPU_TIME_DELTA),
		SUM(DISK_READS_DELTA),
		COUNT(*)
	  FROM DBA_HIST_SQLSTAT A, DBA_HIST_SNAPSHOT S
	 WHERE S.SNAP_ID = A.SNAP_ID
       AND S.BEGIN_INTERVAL_TIME > SYSDATE -1
       AND EXTRACT(HOUR FROM S.END_INTERVAL_TIME) BETWEEN 9 AND 11
     GROUP BY SQL_ID
     ORDER BY SUM(CPU_TIME_DELTA) DESC
 )
 WHERE ROWNUM;
-------------------------------------------------------------------------------------------

<end node> 5P9i0s8y19Z
dt=Text
<node>
SQL Advisor
3
-- In this below tutorial we will explain how to run sql tuning advisor against sql_Id.

-- Suppose the sql id is – 87s8z2zzpsg88

1. Create Tuning Task
 
DECLARE
  l_sql_tune_task_id  VARCHAR2(100);
BEGIN
  l_sql_tune_task_id := DBMS_SQLTUNE.create_tuning_task (
                          sql_id      => '87s8z2zzpsg88',
                          scope       => DBMS_SQLTUNE.scope_comprehensive,
                          time_limit  => 500,
                          task_name   => '87s8z2zzpsg88_tuning_task11',
                          description => 'Tuning task1 for statement 87s8z2zzpsg88');
  DBMS_OUTPUT.put_line('l_sql_tune_task_id: ' || l_sql_tune_task_id);
END;
/

2. Execute Tuning task:

EXEC DBMS_SQLTUNE.execute_tuning_task(task_name => '87s8z2zzpsg88_tuning_task11'); 

3. Get the Tuning advisor report.

set long 65536
set longchunksize 65536
set linesize 100
select dbms_sqltune.report_tuning_task('87s8z2zzpsg88_tuning_task11') from dual;

4. Get list of tuning task present in database:
We can get the list of tuning tasks present in database from DBA_ADVISOR_LOG
 
SELECT TASK_NAME, STATUS FROM DBA_ADVISOR_LOG WHERE TASK_NAME ;
 
5. Drop a tuning task:

execute dbms_sqltune.drop_tuning_task('87s8z2zzpsg88_tuning_task11');

-------------------------------------------------------------------------------------------------------------------
-- Working and tested 

-- take the sql id
select sid,serial#,inst_id,schemaname, osuser, sql_id, state, module,program
from gv$session where schemaname='MIS'

DECLARE
  l_sql_tune_task_id  VARCHAR2(100);
BEGIN
  l_sql_tune_task_id := DBMS_SQLTUNE.create_tuning_task (
                          sql_id      => 'fpxmjd63ju7c2',
                          scope       => DBMS_SQLTUNE.scope_comprehensive,
                          time_limit  => 500,
                          task_name   => 'fpxmjd63ju7c2_tuning_task11',
                          description => 'Tuning task1 for statement fpxmjd63ju7c2');
  DBMS_OUTPUT.put_line('l_sql_tune_task_id: ' || l_sql_tune_task_id);
END;
/

EXEC DBMS_SQLTUNE.execute_tuning_task(task_name => 'fpxmjd63ju7c2_tuning_task11'); 

select dbms_sqltune.report_tuning_task('fpxmjd63ju7c2_tuning_task11') from dual;

--------------------------------------------------------------------------------------------------------------------

What if the sql_id is not present in the cursor , but present in AWR snap?
SQL_ID =24pzs2d6a6b13

First we need to find the begin snap and end snap of the sql_id.

select a.instance_number inst_id, a.snap_id,a.plan_hash_value, to_char(begin_interval_time,'dd-mon-yy hh24:mi') btime, abs(extract(minute from (end_interval_time-begin_interval_time)) + extract(hour from (end_interval_time-begin_interval_time))*60 + extract(day from (end_interval_time-begin_interval_time))*24*60) minutes,
executions_delta executions, round(ELAPSED_TIME_delta/1000000/greatest(executions_delta,1),4) "avg duration (sec)" from dba_hist_SQLSTAT a, dba_hist_snapshot b
where sql_id='&sql_id' and a.snap_id=b.snap_id
and a.instance_number=b.instance_number
order by snap_id desc, a.instance_number;

From here we can get the begin snap and end snap of the sql_id.

begin_snap -> 235
end_snap -> 240

1. Create the tuning task:

DECLARE
  l_sql_tune_task_id  VARCHAR2(100);
BEGIN
  l_sql_tune_task_id := DBMS_SQLTUNE.create_tuning_task (
                          begin_snap  => 235,
                          end_snap    => 240,
                          sql_id      => '24pzs2d6a6b13',
                          scope       => DBMS_SQLTUNE.scope_comprehensive,
                          time_limit  => 60,
                          task_name   => '24pzs2d6a6b13_AWR_tuning_task',
                          description => 'Tuning task for statement 24pzs2d6a6b13  in AWR');
  DBMS_OUTPUT.put_line('l_sql_tune_task_id: ' || l_sql_tune_task_id);
END;
/

2. Execute the tuning task:
 
EXEC DBMS_SQLTUNE.execute_tuning_task(task_name => '24pzs2d6a6b13_AWR_tuning_task');
 

3. Get the tuning task recommendation report

 
SET LONG 10000000;
SET PAGESIZE 100000000
 
SET LINESIZE 200
SELECT DBMS_SQLTUNE.report_tuning_task('24pzs2d6a6b13_AWR_tuning_task') AS recommendations FROM dual;
SET PAGESIZE 24

<end node> 5P9i0s8y19Z
dt=Text
<node>
Fragmentation
3

-- RE: RITM0532487
-- best site for Oracle 9i stat pack execution informations
https://www.tutorialdba.com/2017/09/using-statspack-report-in-oracle-9i.html 
 


What are the reasons to reorganization of table?

a) Slower response time (from that table)
b) High number of chained (actually migrated) rows. 
c) Table has grown many folds and the old space is not getting reused.

Note: Index based queries may not get that much benefited by reorg as compared to 
queries which does Full table scan.

How to find Table Fragmentation?

Steps to Check and Remove Table Fragmentation 

1. Gather table stats:
----------------------------
    To check exact difference in table actual size (dba_segments) and stats size (dba_tables). The 
    difference between these value will report actual fragmentation to DBA. So, We have to have 
    updated stats on the table stored in dba_tables. Check LAST_ANALYZED value for table in 
    dba_tables. If this value is recent you can skip this step. Other wise i would suggest to gather 
    table stats to get updated stats

exec dbms_stats.gather_table_stats('&schema_name','&table_name');

2. Check Table size:
----------------------------
    Now again check table size using and will find reduced size of the table.

select table_name,bytes/(1024*1024*1024) from dba_table where table_name='&table_name';

3. Check for Fragmentation in table:
-----------------------------
    Below query will show the total size of table with fragmentation, expected without fragmentation 
    and how much % of size we can reclaim after removing table fragmentation. Database Administrator 
    has to provide table_name and schema_name as input to this query.

set pages 50000 lines 32767

select owner, table_name, round((blocks*8),2)||'kb' "Fragmented size", 
       round((num_rows*avg_row_len/1024),2)||'kb' "Actual size", 
       round((blocks*8),2)-round((num_rows*avg_row_len/1024),2)||'kb',
	  ((round((blocks*8),2)-round((num_rows*avg_row_len/1024),2))/round((blocks*8),2))*100 -10 "reclaimable space % " 
from dba_tables 
where table_name ='&table_Name' 
  AND OWNER LIKE '&schema_name'
/

OR

-- Used for getting the fragmentation reports
select owner, table_name, avg_row_len,
  round(((blocks*16/1024))) "Total_Size_in_MB",
	round((num_rows*avg_row_len/1024/1024)) "Actual_Size_in_MB",
	round(((blocks*16/1024)-(num_rows*avg_row_len/1024/1024))) "Fragmented_Space_in_MB",
	round((round(((blocks*16/1024)-(num_rows*avg_row_len/1024/1024)),2)/round(((blocks*16/1024)),2))*100) "Percentage"
from dba_tables 
where
  (round((blocks*16/1024),2) > round((num_rows*avg_row_len/1024/1024),2))
   and owner in ('BAR','BO','BUREAU','STAGING','TBL_MAINT','PERFSTAT','BUREAU_LKU')
order by owner asc,5 desc;


Note: This query fetch data from dba_tables, so the accuracy of result depends on dba_table stats.

If you find reclaimable space % value more than 20% then we can expect fragmentation in the table. 
Suppose, DBA find 50% reclaimable space by above query, So he can proceed for removing fragmentation.

4. How to reset HWM / remove fragemenation?
---------------------------------------
We have four options to reorganize fragmented tables:

1. Alter table move (to another tablespace, or same tablespace) and rebuild indexes:- 
   (Depends upon the free space available in the tablespace) 
2. Export and import the table:- (difficult to implement in production environment)
3. Shrink command (fron Oracle 10g)
   (Shrink command is only applicable for tables which are tablespace with auto segment space management)

Here, I am following Options 1 and 3 option by keeping table availability in mind. 


Option: 1 Alter table move (to another tablespace, or same tablespace) and rebuild indexes:-
------------------------------------------------------------------------------------------
Collect status of all the indexes on the table:-
----------------------------------------------
We will record Index status at one place, So that we get back them after completion of this exercise,  

select index_name,status from dba_indexes where table_name like '&table_name';

Move table in to same or new tablespace:
---------------------------------------
In this step we will move fragmented table to same tablespace or from one tablespace to another tablespace to reclaim fragmented space. Find Current size of you table from dba_segments and check if same or any other tablespace has same free space available. So, that we can move this table to same or new tablespace.

Steps to Move table in to same tablespace:
-----------------------------------------
alter table <table_name> move; ------> Move to same tablespace

OR

Steps to Move table in to new tablespace:
----------------------------------------
alter table <table_name> enable row movement;
alter table <table_name> move tablespace <new_tablespace_name>;

Now, get back table to old tablespaces using below command

alter table table_name move tablespace old_tablespace_name;

Now,Rebuild all indexes:
-----------------------
We need to rebuild all the indexes on the table because of move command all the index goes into unusable state.

SQL> select status,index_name from dba_indexes where table_name = '&table_name';

STATUS INDEX_NAME
-------- ------------------------------
UNUSABLE INDEX_NAME                            -------> Here, value in status field may be valid or unusable.

SQL> alter index <INDEX_NAME> rebuild online;  -------> Use this command for each index
Index altered.

SQL> select status,index_name from dba_indexes where table_name = '&table_name';

STATUS INDEX_NAME
-------- ------------------------------
VALID INDEX_NAME                               -------> Here, value in status field must be valid.

Gather table stats:
------------------
SQL> exec dbms_stats.gather_table_stats('&owner_name','&table_name');
PL/SQL procedure successfully completed.

Check Table size:
-----------------
Now again check table size using and will find reduced size of the table.

select table_name,bytes/(1024*1024*1024) from dba_table where table_name='&table_name';

Check for Fragmentation in table:
--------------------------------
set pages 50000 lines 32767
select owner,table_name,round((blocks*8),2)||'kb' "Fragmented size", round((num_rows*avg_row_len/1024),2)||'kb' "Actual size", round((blocks*8),2)-round((num_rows*avg_row_len/1024),2)||'kb',
((round((blocks*8),2)-round((num_rows*avg_row_len/1024),2))/round((blocks*8),2))*100 -10 "reclaimable space % " from dba_tables where table_name ='&table_Name' AND OWNER LIKE '&schema_name'
 /
==================================================================================================================
Option: 3 Shrink command (fron Oracle 10g):-
------------------------------------------

Shrink command: 
--------------
Its a new 10g feature to shrink (reorg) the tables (almost) online which can be used with automatic segment space management.

This command is only applicable for tables which are tablespace with auto segment space management.

Before using this command, you should have row movement enabled.

SQL> alter table <table_name> enable row movement;
Table altered.

There are 2 ways of using this command.

1. Rearrange rows and reset the HWM:
-----------------------------------
Part 1: Rearrange (All DML's can happen during this time)
SQL> alter table <table_name> shrink space compact;
Table altered.

Part 2: Reset HWM (No DML can happen. but this is fairly quick, infact goes unnoticed.)
SQL> alter table <table_name> shrink space;
Table altered.

2. Directly reset the HWM:
-------------------------
SQL> alter table <table_name> shrink space; (Both rearrange and restting HWM happens in one statement)
Table altered.

Advantages over the conventional methods are:
--------------------------------------------
1. Unlike "alter table move ..",indexes are not in UNUSABLE state.After shrink command,indexes are updated also.
2. Its an online operation, So you dont need downtime to do this reorg.
3. It doesnot require any extra space for the process to complete.    

<end node> 5P9i0s8y19Z
dt=Text
<node>
Lock Types
3
https://gerardnico.com/db/oracle/table_lock 

-- Below the abbreviations means:
R = Row
S = Shared
SS= Sub-shared
X = Exclusive 

<end node> 5P9i0s8y19Z
dt=Text
<node>
sql hash change
3
SPO coe_xfr_sql_profile.log;
SET DEF ON TERM OFF ECHO ON FEED OFF VER OFF HEA ON LIN 2000 PAGES 100 LONG 8000000 LONGC 800000 TRIMS ON TI OFF TIMI OFF SERVEROUT ON SIZE 1000000 NUMF "" SQLP SQL>;
REM
REM $Header: 215187.1 coe_xfr_sql_profile.sql 11.4.1.4 2010/07/12 csierra $
REM
REM Copyright (c) 2000-2010, Oracle Corporation. All rights reserved.
REM
REM AUTHOR
REM   carlos.sierra@oracle.com
REM
REM SCRIPT
REM   coe_xfr_sql_profile.sql
REM
REM DESCRIPTION
REM   This script generates another that contains the commands to
REM   create a manual custom SQL Profile out of a known plan from
REM   memory or AWR. The manual custom profile can be implemented
REM   into the same SOURCE system where the plan was retrieved,
REM   or into another similar TARGET system that has same schema
REM   objects referenced by the SQL that generated the known plan.
REM
REM PRE-REQUISITES
REM   1. Oracle Tuning Pack license.
REM
REM PARAMETERS
REM   1. SQL_ID (required)
REM   2. Plan Hash Value for which a manual custom SQL Profile is
REM      needed (required). A list of known plans is presented.
REM
REM EXECUTION
REM   1. Connect into SQL*Plus as SYSDBA or user with access to
REM      data dictionary.
REM   2. Execute script coe_xfr_sql_profile.sql passing SQL_ID and
REM      plan hash value (parameters can be passed inline or until
REM      requested).
REM
REM EXAMPLE
REM   # sqlplus system
REM   SQL> START coe_xfr_sql_profile.sql [SQL_ID] [PLAN_HASH_VALUE];
REM   SQL> START coe_xfr_sql_profile.sql gnjy0mn4y9pbm 2055843663;
REM   SQL> START coe_xfr_sql_profile.sql gnjy0mn4y9pbm;
REM   SQL> START coe_xfr_sql_profile.sql;
REM
REM NOTES
REM   1. For possible errors see coe_xfr_sql_profile.log
REM   2. If SQLT is installed in SOURCE, you can use instead:
REM      sqlt/utl/sqltprofile.sql
REM   3. Be aware that using DBMS_SQLTUNE requires a license for
REM      Oracle Tuning Pack.
REM
SET TERM ON ECHO OFF;
PRO
PRO Parameter 1:
PRO SQL_ID (required)
PRO
DEF sql_id = '&1';
PRO
WITH
p AS (
SELECT plan_hash_value
  FROM gv$sql_plan
 WHERE sql_id = TRIM('&&sql_id.')
   AND other_xml IS NOT NULL
 UNION
SELECT plan_hash_value
  FROM dba_hist_sql_plan
 WHERE sql_id = TRIM('&&sql_id.')
   AND other_xml IS NOT NULL ),
m AS (
SELECT plan_hash_value,
       SUM(elapsed_time)/SUM(executions) avg_et_secs
  FROM gv$sql
 WHERE sql_id = TRIM('&&sql_id.')
   AND executions > 0
 GROUP BY
       plan_hash_value ),
a AS (
SELECT plan_hash_value,
       SUM(elapsed_time_total)/SUM(executions_total) avg_et_secs
  FROM dba_hist_sqlstat
 WHERE sql_id = TRIM('&&sql_id.')
   AND executions_total > 0
 GROUP BY
       plan_hash_value )
SELECT p.plan_hash_value,
       ROUND(NVL(m.avg_et_secs, a.avg_et_secs)/1e6, 3) avg_et_secs
  FROM p, m, a
 WHERE p.plan_hash_value = m.plan_hash_value(+)
   AND p.plan_hash_value = a.plan_hash_value(+)
 ORDER BY
       avg_et_secs NULLS LAST;
PRO
PRO Parameter 2:
PRO PLAN_HASH_VALUE (required)
PRO
DEF plan_hash_value = '&2';
PRO
PRO Values passed:
PRO ~~~~~~~~~~~~~
PRO SQL_ID         : "&&sql_id."
PRO PLAN_HASH_VALUE: "&&plan_hash_value."
PRO
SET TERM OFF ECHO ON;
WHENEVER SQLERROR EXIT SQL.SQLCODE;

VAR sql_text CLOB;
VAR other_xml CLOB;
EXEC :sql_text := NULL;
EXEC :other_xml := NULL;

-- get sql_text from memory
DECLARE
  l_sql_text VARCHAR2(32767);
BEGIN -- 10g see bug 5017909
  FOR i IN (SELECT DISTINCT piece, sql_text
              FROM gv$sqltext_with_newlines
             WHERE sql_id = TRIM('&&sql_id.')
             ORDER BY 1, 2)
  LOOP
    IF :sql_text IS NULL THEN
      DBMS_LOB.CREATETEMPORARY(:sql_text, TRUE);
      DBMS_LOB.OPEN(:sql_text, DBMS_LOB.LOB_READWRITE);
    END IF;
    l_sql_text := REPLACE(i.sql_text, CHR(00), ' ');
    DBMS_LOB.WRITEAPPEND(:sql_text, LENGTH(l_sql_text), l_sql_text);
  END LOOP;
  IF :sql_text IS NOT NULL THEN
    DBMS_LOB.CLOSE(:sql_text);
  END IF;
EXCEPTION
  WHEN OTHERS THEN
    DBMS_OUTPUT.PUT_LINE('getting sql_text from memory: '||SQLERRM);
    :sql_text := NULL;
END;
/

-- get sql_text from awr
BEGIN
  IF :sql_text IS NULL OR NVL(DBMS_LOB.GETLENGTH(:sql_text), 0) = 0 THEN
    SELECT REPLACE(sql_text, CHR(00), ' ')
      INTO :sql_text
      FROM dba_hist_sqltext
     WHERE sql_id = TRIM('&&sql_id.')
       AND sql_text IS NOT NULL
       AND ROWNUM = 1;
  END IF;
EXCEPTION
  WHEN OTHERS THEN
    DBMS_OUTPUT.PUT_LINE('getting sql_text from awr: '||SQLERRM);
    :sql_text := NULL;
END;
/

SELECT :sql_text FROM DUAL;

-- get other_xml from memory
BEGIN
  FOR i IN (SELECT other_xml
              FROM gv$sql_plan
             WHERE sql_id = TRIM('&&sql_id.')
               AND plan_hash_value = TO_NUMBER(TRIM('&&plan_hash_value.'))
               AND other_xml IS NOT NULL
             ORDER BY
                   child_number, id)
  LOOP
    :other_xml := i.other_xml;
    EXIT; -- 1st
  END LOOP;
EXCEPTION
  WHEN OTHERS THEN
    DBMS_OUTPUT.PUT_LINE('getting other_xml from memory: '||SQLERRM);
    :other_xml := NULL;
END;
/

-- get other_xml from awr
BEGIN
  IF :other_xml IS NULL OR NVL(DBMS_LOB.GETLENGTH(:other_xml), 0) = 0 THEN
    FOR i IN (SELECT other_xml
                FROM dba_hist_sql_plan
               WHERE sql_id = TRIM('&&sql_id.')
                 AND plan_hash_value = TO_NUMBER(TRIM('&&plan_hash_value.'))
                 AND other_xml IS NOT NULL
               ORDER BY
                     id)
    LOOP
      :other_xml := i.other_xml;
      EXIT; -- 1st
    END LOOP;
  END IF;
EXCEPTION
  WHEN OTHERS THEN
    DBMS_OUTPUT.PUT_LINE('getting other_xml from awr: '||SQLERRM);
    :other_xml := NULL;
END;
/

SELECT :other_xml FROM DUAL;

-- generates script that creates sql profile in target system:
SET ECHO OFF;
PRO coe_xfr_sql_profile_&&sql_id._&&plan_hash_value..sql.
SET FEED OFF LIN 666 TRIMS ON TI OFF TIMI OFF SERVEROUT ON SIZE 1000000 FOR WOR;
SPO OFF;
SPO coe_xfr_sql_profile_&&sql_id._&&plan_hash_value..sql;
DECLARE
  l_pos NUMBER;
  l_hint VARCHAR2(32767);
BEGIN
  DBMS_OUTPUT.PUT_LINE('SPO coe_xfr_sql_profile_&&sql_id._&&plan_hash_value..log;');
  DBMS_OUTPUT.PUT_LINE('SET ECHO ON TERM ON LIN 2000 TRIMS ON NUMF 99999999999999999999;');
  DBMS_OUTPUT.PUT_LINE('REM');
  DBMS_OUTPUT.PUT_LINE('REM $Header: 215187.1 coe_xfr_sql_profile_&&sql_id._&&plan_hash_value..sql 11.4.1.4 '||TO_CHAR(SYSDATE, 'YYYY/MM/DD')||' csierra $');
  DBMS_OUTPUT.PUT_LINE('REM');
  DBMS_OUTPUT.PUT_LINE('REM Copyright (c) 2000-2010, Oracle Corporation. All rights reserved.');
  DBMS_OUTPUT.PUT_LINE('REM');
  DBMS_OUTPUT.PUT_LINE('REM AUTHOR');
  DBMS_OUTPUT.PUT_LINE('REM   carlos.sierra@oracle.com');
  DBMS_OUTPUT.PUT_LINE('REM');
  DBMS_OUTPUT.PUT_LINE('REM SCRIPT');
  DBMS_OUTPUT.PUT_LINE('REM   coe_xfr_sql_profile_&&sql_id._&&plan_hash_value..sql');
  DBMS_OUTPUT.PUT_LINE('REM');
  DBMS_OUTPUT.PUT_LINE('REM DESCRIPTION');
  DBMS_OUTPUT.PUT_LINE('REM   This script is generated by coe_xfr_sql_profile.sql');
  DBMS_OUTPUT.PUT_LINE('REM   It contains the SQL*Plus commands to create a custom');
  DBMS_OUTPUT.PUT_LINE('REM   SQL Profile for SQL_ID &&sql_id. based on plan hash');
  DBMS_OUTPUT.PUT_LINE('REM   value &&plan_hash_value..');
  DBMS_OUTPUT.PUT_LINE('REM   The custom SQL Profile to be created by this script');
  DBMS_OUTPUT.PUT_LINE('REM   will affect plans for SQL commands with signature');
  DBMS_OUTPUT.PUT_LINE('REM   matching the one for SQL Text below.');
  DBMS_OUTPUT.PUT_LINE('REM   Review SQL Text and adjust accordingly.');
  DBMS_OUTPUT.PUT_LINE('REM');
  DBMS_OUTPUT.PUT_LINE('REM PARAMETERS');
  DBMS_OUTPUT.PUT_LINE('REM   None.');
  DBMS_OUTPUT.PUT_LINE('REM');
  DBMS_OUTPUT.PUT_LINE('REM EXAMPLE');
  DBMS_OUTPUT.PUT_LINE('REM   SQL> START coe_xfr_sql_profile_&&sql_id._&&plan_hash_value..sql;');
  DBMS_OUTPUT.PUT_LINE('REM');
  DBMS_OUTPUT.PUT_LINE('REM NOTES');
  DBMS_OUTPUT.PUT_LINE('REM   1. Should be run as SYSTEM or SYSDBA.');
  DBMS_OUTPUT.PUT_LINE('REM   2. User must have CREATE ANY SQL PROFILE privilege.');
  DBMS_OUTPUT.PUT_LINE('REM   3. SOURCE and TARGET systems can be the same or similar.');
  DBMS_OUTPUT.PUT_LINE('REM   4. To drop this custom SQL Profile after it has been created:');
  DBMS_OUTPUT.PUT_LINE('REM      EXEC DBMS_SQLTUNE.DROP_SQL_PROFILE(''coe_&&sql_id._&&plan_hash_value.'');');
  DBMS_OUTPUT.PUT_LINE('REM   5. Be aware that using DBMS_SQLTUNE requires a license');
  DBMS_OUTPUT.PUT_LINE('REM      for the Oracle Tuning Pack.');
  DBMS_OUTPUT.PUT_LINE('REM');
  DBMS_OUTPUT.PUT_LINE('WHENEVER SQLERROR EXIT SQL.SQLCODE;');
  DBMS_OUTPUT.PUT_LINE('REM');
  DBMS_OUTPUT.PUT_LINE('VAR signature NUMBER;');
  DBMS_OUTPUT.PUT_LINE('REM');
  DBMS_OUTPUT.PUT_LINE('DECLARE');
  DBMS_OUTPUT.PUT_LINE('sql_txt CLOB;');
  DBMS_OUTPUT.PUT_LINE('h       SYS.SQLPROF_ATTR;');
  DBMS_OUTPUT.PUT_LINE('BEGIN');
  DBMS_OUTPUT.PUT_LINE('sql_txt := q''[');
  WHILE NVL(LENGTH(:sql_text), 0) > 0
  LOOP
    l_pos := INSTR(:sql_text, CHR(10));
    IF l_pos > 0 THEN
      DBMS_OUTPUT.PUT_LINE(SUBSTR(:sql_text, 1, l_pos - 1));
      :sql_text := SUBSTR(:sql_text, l_pos + 1);
    ELSE
      DBMS_OUTPUT.PUT_LINE(:sql_text);
      :sql_text := NULL;
    END IF;
  END LOOP;
  DBMS_OUTPUT.PUT_LINE(']'';');
  DBMS_OUTPUT.PUT_LINE('h := SYS.SQLPROF_ATTR(');
  DBMS_OUTPUT.PUT_LINE('q''[BEGIN_OUTLINE_DATA]'',');
  FOR i IN (SELECT /*+ opt_param('parallel_execution_enabled', 'false') */
                   SUBSTR(EXTRACTVALUE(VALUE(d), '/hint'), 1, 4000) hint
              FROM TABLE(XMLSEQUENCE(EXTRACT(XMLTYPE(:other_xml), '/*/outline_data/hint'))) d)
  LOOP
    l_hint := i.hint;
    WHILE NVL(LENGTH(l_hint), 0) > 0
    LOOP
      IF LENGTH(l_hint) <= 500 THEN
        DBMS_OUTPUT.PUT_LINE('q''['||l_hint||']'',');
        l_hint := NULL;
      ELSE
        l_pos := INSTR(SUBSTR(l_hint, 1, 500), ' ', -1);
        DBMS_OUTPUT.PUT_LINE('q''['||SUBSTR(l_hint, 1, l_pos)||']'',');
        l_hint := '   '||SUBSTR(l_hint, l_pos);
      END IF;
    END LOOP;
  END LOOP;
  DBMS_OUTPUT.PUT_LINE('q''[END_OUTLINE_DATA]'');');
  DBMS_OUTPUT.PUT_LINE(':signature := DBMS_SQLTUNE.SQLTEXT_TO_SIGNATURE(sql_txt);');
  DBMS_OUTPUT.PUT_LINE('DBMS_SQLTUNE.IMPORT_SQL_PROFILE (');
  DBMS_OUTPUT.PUT_LINE('sql_text    => sql_txt,');
  DBMS_OUTPUT.PUT_LINE('profile     => h,');
  DBMS_OUTPUT.PUT_LINE('name        => ''coe_&&sql_id._&&plan_hash_value.'',');
  DBMS_OUTPUT.PUT_LINE('description => ''coe &&sql_id. &&plan_hash_value. ''||:signature||'''',');
  DBMS_OUTPUT.PUT_LINE('category    => ''DEFAULT'',');
  DBMS_OUTPUT.PUT_LINE('validate    => TRUE,');
  DBMS_OUTPUT.PUT_LINE('replace     => TRUE,');
  DBMS_OUTPUT.PUT_LINE('force_match => FALSE /* TRUE:FORCE (match even when different literals in SQL). FALSE:EXACT (similar to CURSOR_SHARING) */ );');
  DBMS_OUTPUT.PUT_LINE('END;');
  DBMS_OUTPUT.PUT_LINE('/');
  DBMS_OUTPUT.PUT_LINE('WHENEVER SQLERROR CONTINUE');
  DBMS_OUTPUT.PUT_LINE('SET ECHO OFF;');
  DBMS_OUTPUT.PUT_LINE('PRINT signature');
  DBMS_OUTPUT.PUT_LINE('PRO');
  DBMS_OUTPUT.PUT_LINE('PRO ... manual custom SQL Profile has been created');
  DBMS_OUTPUT.PUT_LINE('PRO');
  DBMS_OUTPUT.PUT_LINE('SET TERM ON ECHO OFF LIN 80 TRIMS OFF NUMF "";');
  DBMS_OUTPUT.PUT_LINE('SPO OFF;');
  DBMS_OUTPUT.PUT_LINE('PRO');
  DBMS_OUTPUT.PUT_LINE('PRO COE_XFR_SQL_PROFILE_&&sql_id._&&plan_hash_value. completed');
END;
/
SPO OFF;
SET DEF ON TERM ON ECHO OFF FEED 6 VER ON HEA ON LIN 80 PAGES 14 LONG 80 LONGC 80 TRIMS OFF TI OFF TIMI OFF SERVEROUT OFF NUMF "" SQLP SQL>;
PRO
PRO Execute coe_xfr_sql_profile_&&sql_id._&&plan_hash_value..sql
PRO on TARGET system in order to create a custom SQL Profile
PRO with plan &&plan_hash_value linked to adjusted sql_text.
PRO
UNDEFINE 1 2 sql_id plan_hash_value
PRO
PRO COE_XFR_SQL_PROFILE completed.

<end node> 5P9i0s8y19Z
dt=Text
<node>
shared memory kill
3
ps -ef |grep -e rstgp |grep -e "LOCAL=NO" |awk '{print$2}' | xargs kill -9

ps -ef |grep -e rstg1e |grep -e "LOCAL=NO" |awk '{print$2}' | xargs kill -9

No Title 



Purpose:
========

The purpose of this bulletin is to introduce a new utility, "sysresv",
provided in Oracle 8.1.5 and above.

For additional information, please refer to 
  Oracle® Database Administrator's Reference
  11g Release 2 (11.2) for Linux and UNIX-Based Operating Systems
  Chapter 8 - Tuning Oracle Database
  Section 8.6.2 - System Resource Verifier Utility
  URL: http://docs.oracle.com/cd/E11882_01/server.112/e10839/tuning.htm#UNXAR405

 
Scope & Application:
====================

This bulletin is intended for database administrators and system 
administrators.  

Examples of using the sysresv utility are provided below.


SYSRESV Utility:
================

This utility was the result of enhancement request 566223 Bug:566223:

  "Currently, many Oracle applications determine whether a particular 
  instance is up by checking for the presence of the sgadef file.  
  We should provide a separate utility for this purpose instead, 
  based on the contents of the SGA."
 
The sysresv utility included with Oracle 8.1.5 and above provides instance 
status (and OS resources used) for specified ORACLE_SIDs.  This utility is 
especially useful when multiple instances are running.  OS resources can be 
removed using this utility if the specified instance is detected to be dead.

This utility may be useful when an instance has crashed or was aborted 
and memory and semaphores related to this instance were not cleaned up 
automatically.  This utility is also helpful in determining which instance 
is running. 

The sysresv utility, located in $O_H/bin, can be used from locations other 
than $O_H/bin.

Point your environment to the instance of interest before using sysresv.

NOTE: (9i 64-bit):

   Must set up as follows to get sysresv to work. 

   Oracle 9.X.X (64Bit) on Solaris (64Bit) OS
       - Set LD_LIBRARY_PATH=$ORACLE_HOME/lib32  
       - Set LD_LIBRARY_PATH_64=$ORACLE_HOME/lib



Usage:
------

sysresv: 
usage   : sysresv [-if] [-d <on/off>] [-l sid1 <sid2> ...]
          -i : Prompt before removing ipc resources for each sid
          -f : Remove ipc resources silently, oevrrides -i option
          -d <on/off> : List ipc resources for each sid if on
          -l sid1 <sid2> .. : apply sysresv to each sid
Default : sysresv -d on -l $ORACLE_SID
Note    : ipc resources are attempted to be deleted for a
          sid only if there is no currently running instance
          with that sid. 

   
Examples:
---------

o  Instance is not running:

   /u02/app/oracle/product/8.1.7> sysresv

   IPC Resources for ORACLE_SID "R817" :
   Shared Memory
   ID              KEY
   No shared memory segments used
   Semaphores:
   ID              KEY
   No semaphore resources used
   Oracle Instance not alive for sid "R817" 


o  Instance is running:

   /u03/app/oracle/product/8.1.6> sysresv

   IPC Resources for ORACLE_SID "ORCL" :
   Shared Memory:
   ID              KEY
   16437           0xe4efa8dc
   Semaphores:
   ID              KEY
   12320802        0x09d48346
   Oracle Instance alive for sid "ORCL"


o  Attempting to remove memory and semphores using sysresv when Oracle 
   detects an instance is running:

   /u03/app/oracle/product/8.1.6> sysresv -f

   IPC Resources for ORACLE_SID "ORCL" :
   Shared Memory:
   ID              KEY
   16437           0xe4efa8dc
   Semaphores:
   ID              KEY
   12320802        0x09d48346
   Oracle Instance alive for sid "ORCL"
   SYSRESV-005: Warning
           Instance maybe alive - aborting remove for sid "ORCL" 


o  Removing IPC resources:

   [Sysresv shows memory and semaphores exist but Oracle determines the 
    instance is not alive.  Cleanup is needed.]

   /u03/app/oracle/product/8.1.6> sysresv

   IPC Resources for ORACLE_SID "ORCL" :
   Shared Memory:
   ID              KEY
   16837           0xe4efa8dc
   Semaphores:
   ID              KEY
   12714018        0x09d48346
   Oracle Instance not alive for sid "ORCL" 
 

o  Removing IPC resources using sysresv:

   /u03/app/oracle/product/8.1.6> sysresv -i

   IPC Resources for ORACLE_SID "ORCL" :
   Shared Memory
   ID              KEY
   No shared memory segments used
   Semaphores:
   ID              KEY
   No semaphore resources used
   Oracle Instance not alive for sid "ORCL"
   Remove ipc resources for sid "ORCL" (y/n)?y
   Done removing ipc resources for sid "ORCL"
   /u03/app/oracle/product/8.1.6


   Verify the resources were removed:

   /u03/app/oracle/product/8.1.6> sysresv

   IPC Resources for ORACLE_SID "ORCL" :
   Shared Memory
   ID              KEY
   No shared memory segments used
   Semaphores:
   ID              KEY
   No semaphore resources used
   Oracle Instance not alive for sid "ORCL"  

     
o  If you need to remove memory segments, and Oracle detects the
   instance is alive through sysresv:

   % ipcrm -m <memid>

   Where <memid> is the memory id shown in the sysresv output.

   Example:
   % ipcrm -m 16437

   If you need to remove semaphores, and Oracle detects the
   instance is alive through sysresv:

   % ipcrm -s <semid>

   where <semid> is the semaphore id shown in the sysresv output.

   Example:
   % ipcrm -s 12320802 

<end node> 5P9i0s8y19Z
dt=Text
<node>
Ongoing SQLs
3
select *
from gv$session
where username='WAS'



alter session set nls_date_format='MON/DD/YYYY HH24:MI:SS';


-- sql bind variable capture 
col name              format a15
col value_string      format a40
col value_string      format a40
select sql_id, name, datatype, datatype_string, was_captured, to_char(last_captured,'mm/dd/yyyy hh24:mi:ss'), value_string
from v$sql_bind_capture
where was_captured='YES'
 and regexp_like(value_string,'POLLOCK RESEARCH%','i')
 -- and regexp_like(value_string,'all','i')
  --and value_string is not null
  --and last_captured is not null
order by 6 desc;


select * from gv$session where sql_id='3mnh27xnnmx4k'

select owner, object_name, object_type, status
from dba_objects
where owner in ('SQLTXADMIN','SQLTXPLAIN')
 and status='INVALID'
 
SELECT owner, object_name, object_type
FROM dba_invalid_objects
WHERE owner in ('SQLTXADMIN', 'SQLTXPLAIN')
ORDER BY 1, 2, 3;


alter package SQLTXADMIN.sqlt$d compile body

grant SQLT_USER_ROLE to oltp

SELECT * FROM SQLTXADMIN.sqlt$_log_v;

select * from v$sqlarea 
where regexp_like(sql_text,'SELECT ACCT.ACCT_ID*','i')
  --and module='JDBC Thin Client'
order by first_load_time desc

2f4p9hhmraz6m
4qasq0ntjb1z7
fx6tsf5dbsq2k
g2n6cksu9duhk

select sbc.*
from v$sql_bind_capture sbc, v$sqlarea sa
where sbc.hash_value = sa.hash_value
 and regexp_like(sa.sql_text,'SELECT ACCT.ACCT_ID*','i')
  and sa.module='JDBC Thin Client'



3mnh27xnnmx4k

2f4p9hhmraz6m
3mnh27xnnmx4k




select s.sid,
s.username,
sq.sql_text,
s.sql_hash_value,
s.sql_id,
s.sql_child_number,
spc.name,
spc.value_string,
last_captured
from v$sql_bind_capture spc, v$session s,v$sql sq
where s.sql_hash_value = spc.hash_value
and s.sql_address = spc.address
and sq.sql_id=s.sql_id
and spc.was_captured=’YES’
and s.type<>’BACKGROUND’
and s.status=’ACTIVE’ 




select sesion.sid, sesion.serial#, sesion.username, 
sesion.sql_id, sesion.sql_child_number, optimizer_mode, hash_value, 
address, sql_text 
from v$sqlarea sqlarea, v$session sesion 
where sesion.sql_hash_value = sqlarea.hash_value 
 and sesion.sql_address = sqlarea.address 
 and sesion.username is not null 




select sesion.sid, sesion.username, sesion.sql_id, sesion.sql_child_number, 
 sql_bind_capture.name, sql_bind_capture.value_string 
from v$sql_bind_capture sql_bind_capture, v$session sesion 
where sesion.sql_hash_value = sql_bind_capture.hash_value 
 and sesion.sql_address = sql_bind_capture.address 
 and sesion.username is not null 
 



63sduz1zu17nz



select * from v$sqlarea where sql_id='fxqt7u2g3awv1'


select s.sid,
s.username,
–sq.sql_text,
s.sql_hash_value,
s.sql_id,
s.sql_child_number,
spc.name,
spc.value_string,
last_captured
from v$sql_bind_capture spc, v$session s,v$sql sq
where s.sql_hash_value = spc.hash_value
and s.sql_address = spc.address
and sq.sql_id=s.sql_id
and spc.was_captured=’YES’
and s.type<>’BACKGROUND’
and s.status=’ACTIVE’; 


select sesion.sid, sesion.serial#, sesion.username, 
	sesion.sql_id, sesion.sql_child_number, optimizer_mode, 
	hash_value, address, sql_text 
from v$sqlarea sqlarea, v$session sesion 
where sesion.sql_hash_value = sqlarea.hash_value 
  and sesion.sql_address = sqlarea.address 
  and sesion.username is not null 

select sesion.sid, sesion.username, sesion.sql_id, sesion.sql_child_number, 
	sql_bind_capture.name, sql_bind_capture.value_string 
from v$sql_bind_capture sql_bind_capture, v$session sesion 
where sesion.sql_hash_value = sql_bind_capture.hash_value 
  and sesion.sql_address = sql_bind_capture.address 
  and sesion.username is not null 
 

SELECT ACCT.ACCT_ID , ACCT.ACCT_KEY, ACCT.ACCT_NM, ACCTM.ACCT_MBR_ID,
  ACCTM.VALID_IND,   PTY.ORG_LEGAL_NM as ACCT_MBR_NM,  PTY.DUN_ID,
  PTY.PARTY_TAX_ID, ACCT.ACCT_STATUS_TP_CD, ACCT.LGCY_BRANCH_OFFICE_BP_KEY,
  ACCT.ACCT_TP_CD, OFFICE.HO_OFFICE_BP_KEY, LOC.CITY_NM,  LOC.STATE_PROV_CD
FROM
 ACCOUNT ACCT, ACCOUNT_MEMBER ACCTM, PARTY PTY,  LOCATION LOC, SITE, OFFICE
  WHERE ACCT.ACCT_KEY = ACCTM.ACCT_KEY  AND ACCTM.PARTY_KEY = PTY.PARTY_KEY
  AND PTY.PARTY_KEY = SITE.PARTY_KEY(+)  AND SITE.LOC_KEY = LOC.LOC_KEY(+)
  AND ACCT.LGCY_BRANCH_OFFICE_BP_KEY = OFFICE.OFFICE_BP_KEY(+)  AND
  SITE.PRIM_BUS_USE_IND(+) = 'Y' AND (UPPER(ACCT.ACCT_NM) LIKE 'POLLOCK RESEARCH%'
  OR UPPER(PTY.ORG_LEGAL_NM) LIKE 'POLLOCK RESEARCH%')  
  AND ACCT.VALID_IND = 'Y'  AND
  ACCTM.VALID_IND = 'Y'  AND PTY.VALID_IND = 'Y'  
ORDER BY  ACCT.ACCT_NM, ACCT_MBR_NM; 

<end node> 5P9i0s8y19Z
dt=Text
<node>
tune sql plans
3
-- the below will give the result of some sql id's find out your sql id which is taking more time 
-- copy and paste when asked
SQL> set serveroutput on
SQL> @?/rdbms/admin/sqltrpt.sql;

<end node> 5P9i0s8y19Z
dt=Text
<node>
SQL Hash Value
3

-- This query will give you the SQL_ID hash values for last 20 days
SELECT DISTINCT sql_id, plan_hash_value, s.interval_time
  FROM dba_hist_sqlstat q, 
      (SELECT /*+ NO_MERGE */ MIN(snap_id) min_snap, MAX(snap_id) max_snap, ss.begin_interval_time  interval_time
         FROM dba_hist_snapshot ss 
        WHERE ss.begin_interval_time BETWEEN (SYSDATE - 20) AND SYSDATE
        group by ss.begin_interval_time) s 
  WHERE q.snap_id BETWEEN s.min_snap AND s.max_snap 
    AND q.sql_id IN ('ax0rk2wtsjw5g')
    order by 3 desc;


select dbms_sqltune_util0.sqltext_to_sqlid(sql_text||chr(0)) sql_id,
( select to_number(regexp_replace(plan_table_output,'^[^0-9]*')) 
from table(dbms_xplan.display_sql_plan_baseline(sql_handle,plan_name)) 
where plan_table_output like 'Plan hash value: %') plan_hash_value
,plan_name,enabled,accepted,fixed,reproduced 
,dbms_xplan.format_time_s(elapsed_time/1e6) hours,creator,origin,created,last_modified,last_executed
,sql_text
from dba_sql_plan_baselines b 
where sql_text like 'INSERT INTO MR_PRELOAD.EPC_S_RATE_AUTO_JOIN_WRK1 %'
order by sql_id,hours desc
; 

<end node> 5P9i0s8y19Z
dt=Text
<node>
ASH Reports
3
---- Get the most taking or busy events and waits information like ASH report
SELECT * 
FROM dba_hist_active_sess_history 
WHERE sample_time BETWEEN TO_DATE('10/24/2015 09:38:00','mm/dd/yyyy hh24:mi:ss') 
                      AND TO_DATE('10/24/2015 09:42:30','mm/dd/yyyy hh24:mi:ss')
ORDER BY sample_time ASC


SELECT sql_id,event_id, event, COUNT(*) cnt
FROM dba_hist_active_sess_history
WHERE snap_id BETWEEN 15046 AND 15047
  AND wait_class_id=3871361733
GROUP BY sql_id,event_id, event
ORDER BY 4 DESC;

SELECT sql_id,  COUNT(*) cnt
FROM dba_hist_active_sess_history
WHERE snap_id BETWEEN 15046 AND 15046
  AND wait_class_id=3871361733 AND event_id='105117041'
GROUP BY sql_id
ORDER BY cnt DESC;

SELECT *
FROM v$sql WHERE sql_id='6mtbknc8a6x59'

SELECT *
FROM V$SQL_BIND_CAPTURE
WHERE sql_id='6mtbknc8a6x59'

SELECT *
FROM V$SQL_BIND_METADATA
WHERE address='0000000502B59DE8'

SELECT *
FROM V$SQL_BIND_DATA
--where buf_address='0000000502B59DE8'
--

<end node> 5P9i0s8y19Z
dt=Text
<node>
AWR/ADDM Report
3
-- AWR / ADDM / ASH Reports

-- You can get the test based reports 

@?/rdbms/admin/ashrpt.sql
	-- will ask for the report format, sepecify text
	-- will ask for the timestamp
	-- will ask for the duration, if entered 10, it means 10 mins after the above given date time
	-- will ask for the report name.
	

@?/rdbms/admin/awrrpt.sql
@?/rdbms/admin/awrsqlrpt.sql


-- To generate the reports over the RAC DBs
@?/rdbms/admin/awrgrpt.sql


---------------------------------------------------------------------------

How to check AWR interval and retention Settings
AWR interval and retention Settings

The following query can be used to check the current settings for the AWR interval and AWR retention.
The query returns the current AWR interval values in minutes.

set pages 50000 lines 32767
col snap_interval format a20
col retention format a20
col topnsql format a20
select extract( day from snap_interval) *24*60+
       extract( hour from snap_interval) *60+
       extract( minute from snap_interval ) "Snapshot Interval",
       extract( day from retention) *24*60+
       extract( hour from retention) *60+
       extract( minute from retention ) "Retention Interval"
from dba_hist_wr_control;


The script returns the current AWR interval values in minutes:
---------------------------------------------------------------------------

-- get the explan plan for th top SQL_ID
SELECT * FROM TABLE (DBMS_XPLAN.DISPLAY_AWR ('6mtbknc8a6x59'));

-- get the information of the SANP_ID with event name
  SELECT INSTANCE_NUMBER, SQL_ID, COUNT (EVENT)
    FROM DBA_HIST_ACTIVE_SESS_HISTORY
   WHERE SNAP_ID > 16322 AND SNAP_ID <= 16324 AND EVENT LIKE '%busy acquire%'
GROUP BY sql_id, INSTANCE_NUMBER
ORDER BY 3 DESC;

-- get the count of the SNAP_ID for SQL_ID and for perticular time frame
SELECT snap_id,COUNT(*) 
FROM dba_hist_active_sess_history 
WHERE sql_id='6mtbknc8a6x59'
 AND  sql_exec_start BETWEEN TO_DATE('12/16/2015 13:30:48','mm/dd/yyyy hh24:mi:ss')
                         AND TO_DATE('12/16/2015 13:40:06','mm/dd/yyyy hh24:mi:ss')
GROUP BY snap_id


SELECT SQL_ID, COUNT(*), COUNT(*)*100/SUM(COUNT(*)) OVER() PCTLOAD
  FROM V$ACTIVE_SESSION_HISTORY
 WHERE SAMPLE_TIME BETWEEN TO_DATE('02/14/2016 08:19:00','mm/dd/yyyy hh24:mi:ss')
                       AND TO_DATE('02/14/2016 08:23:59','mm/dd/yyyy hh24:mi:ss')
--   AND SESSION_ID = :B1
 GROUP BY SQL_ID 
 ORDER BY  COUNT(*)  DESC ;


-- What resource is currently in high demand?
-- This query will give you for the last 30 minutes those resources that are in high demand on your system.

-- TIME-TO-LIVE (TTL) - how much time the data will be present in cache
-- This specifies how long (in seconds) this data will be cached in the database before it is 
-- disregarded and new information is requested from a server. By leaving this field blank, the ttl defaults to 
-- the minimum time specified in the Start-Of-Authority (SOA) resource record. 

select ash.event,
        sum(ash.wait_time + ash.time_waited) ttl_wait_time
   from v$active_session_history ash
  where ash.sample_time between sysdate - 60/2880 and sysdate
 group by ash.event
 order by 2;

-- What user is waiting the most?
-- who is waiting the most for resources at a point in time. If a user calls you up on the phone and says 
-- they are experiencing delays, you can use this query to verify that they are actually waiting in the database 
-- for a result set for a given time period. This SQL is written for a 30-minute interval from current system 
-- time so you may need to change.
  SELECT sesion.SID,
         sesion.username,
         SUM (
              ash.wait_time
            + ash.time_waited)
            ttl_wait_time
    FROM v$active_session_history ash, v$session sesion
   WHERE     ash.sample_time BETWEEN SYSDATE - 60 / 2880 AND SYSDATE
         AND ash.session_id = sesion.SID
GROUP BY sesion.SID, sesion.username
ORDER BY 3 DESC; 

-- What SQL is currently using the most resources?
-- This query will get you started in the proper direction of zeroing in on what SQL statement is consuming the most resource 
-- wait times on your system. No longer do you have to go to the V$SQLAREA and try to pick out the top 10 or 20 SQL hogs on 
-- your system by disk reads or executions. Now you really know what SQL statements are consuming resources and waiting the most. 
-- These are the SQL that you really need to tune because the fact that a SQL statement performs 20,000 reads does not mean 
-- that it is a bottleneck in your system.
SELECT active_session_history.user_id,
         dba_users.username,
         sqlarea.sql_text,
         SUM (
              active_session_history.wait_time
            + active_session_history.time_waited)
            ttl_wait_time
    FROM v$active_session_history active_session_history,
         v$sqlarea sqlarea,
         dba_users
   WHERE     active_session_history.sample_time BETWEEN SYSDATE - 60 / 2880 AND SYSDATE
         AND active_session_history.sql_id = sqlarea.sql_id
         AND active_session_history.user_id = dba_users.user_id
GROUP BY active_session_history.user_id, sqlarea.sql_text, dba_users.username
ORDER BY 4 DESC;


-- What object is currently causing the highest resource waits?
-- This is a great query. Now we can actually see which objects a SQL statement is hitting. Moreover, if you take a further look at 
-- the V$ACTIVE_SESSION_HISTORY view you will see that you can tailor this query to report on the actual blocks that are being accessed 
-- within the objects for the SQL statement. This is great help in determining if you may need to reorg your object or redistribute to 
-- reduce the contention on that object.

  SELECT dba_objects.object_name,
         dba_objects.object_type,
         active_session_history.event,
         SUM (
              active_session_history.wait_time
            + active_session_history.time_waited)
            ttl_wait_time
    FROM v$active_session_history active_session_history, dba_objects
   WHERE     active_session_history.sample_time BETWEEN SYSDATE - 60 / 2880 AND SYSDATE
         AND active_session_history.current_obj# = dba_objects.object_id
GROUP BY dba_objects.object_name,
         dba_objects.object_type,
         active_session_history.event
ORDER BY 4 DESC;
-------------------------------------------------------------------------------------------------------------------------

-- What is a GC buffer busy wait? 
-- Best URL http://www.oaktable.net/category/tags/gc-buffer-busy

-- gc buffer busy acquire and gc buffer busy release
Event ‘gc buffer busy’ event means that a session is trying to access a buffer,but there is an open request for Global cache lock 
for that block already, and so, the session must wait for the GC lock request to complete before proceeding. This wait is 
instrumented as ‘gc buffer busy’ event. 

In a simple sense, GC buffer busy means that the buffer in the buffer cache, that the session is trying to access is already 
involved in another ongoing global cache operation. Until that global cache operation completes, session must wait.

I will explain this with an example: Let’s say that session #1 is trying to access a block of file #7 block ID 420. That 
block is in the remote cache and so, session #1 opened a BL lock on that block, requested the remote LMS process to send the block, 
and waiting for the block shipping to complete. Session #2 comes along shortly thereafter and tries to access the same buffer. But, 
the block is already involved in a global cache operation and so, session #2 must wait for the session #1 to complete GC (Global Cache) 
activity before proceeding. In this case, Session #2 will wait for ‘gc buffer busy’ wait event with a time-out and repeatedly tries to 
access that buffer in a loop.

Consider the scenario if the block is a hot block such as segment header, index branch block or transaction table header block etc. 
In this case, you can see that many such sessions waiting for the ‘Gc buffer busy’ wait event. This can lead to complex wait scenario 
quickly as few background processes also can wait for ‘gc buffer busy’ event leading to an eventual database hang situation. If you 
kill the processes, then pmon might need to access that block to do a rollback, which means that pmon can get stuck waiting 
for ‘gc buffer busy’ waits too. 

-- Increase the Freelist and Freelist Group of Table/Index
freelist advice would definitely apply if you are using manual segement space management, otherwise, we use bitmap freelists in the segment 
itself - there are no separate freelist/freelist groups. If you use ASSM (automatic segment space management) there are no freelist/freelist group 
settings for you to consider or make. 

/*

I might suggest that you adopt an iterative process to determine the optimum number of freelists:

 1)   Add freelists one at a time, during low usage times:
    alter table mytable storage (freelists 2);

 2)   Measure the buffer wait changes during peak processing (statspack)

 3)   Repeat until buffer waits disappear

*/
-------------------------------------------------------------------------------------------------------------------------

-- Find a session which are generating more archive logs

/*

To find sessions generating lots of redo, you can use either of the following methods. Both methods examine 
the amount of undo generated. When a transaction generates undo, it will automatically generate redo as well.

*/

-- 1) Query V$SESS_IO. This view contains the column BLOCK_CHANGES which indicates how much blocks have been 
-- changed by the session. High values indicate a session generating lots of redo.

SQL>  SELECT s.sid, s.serial#, s.username, 
		   s.program, i.block_changes
	  FROM v$session s, v$sess_io i
	  WHERE s.sid = i.sid
	  ORDER BY 5 asc, 1, 2, 3, 4;


	 SID SERIAL# USERNAME      PROGRAM       BLOCK_CHANGES
	---------- ---------- ------------ -----------------------
	 158 6 SCOTT               sqlplus.exe       630295
	 159 3 SYS                 sqlplus.exe       97
	 161 1                     ORACLE.EXE (MMON) 58
	 164 1 ORACLE.EXE          (SMON)            34
	 148 5 ORACLE.EXE          (q001)            0
	........ 
	19 rows selected.

-- Run the query multiple times and examine the delta between each occurrence of BLOCK_CHANGES. Large deltas 
-- indicate high redo generation by the session. Like Scott user with Sid 158 is having high value for 
-- Block_changes and is the main session for generating more archive logs.


-- 2) Query V$TRANSACTION. This view contains information about the amount of undo blocks and undo records 
-- accessed by the transaction (as found in the USED_UBLK and USED_UREC columns).

 SQL> SELECT s.sid, s.serial#, s.username, s.program, 
  			 t.used_ublk, t.used_urec
	  FROM v$session s, v$transaction t
	  WHERE s.taddr = t.addr
	  ORDER BY 5 desc, 6 desc, 1, 2, 3, 4;

	 SID SERIAL# USERNAME PROGRAM        USED_UBLK USED_UREC
	---------- ---------- ------------ ---------------------------
	 158 6       SCOTT    sqlplus.exe    4929      157526


-- Run the query multiple times and examine the delta between each occurrence of USED_UBLK and USED_UREC. 
-- Large deltas indicate high redo generation by the session.

-- You use the first query when you need to check for programs generating lots of redo when these programs activate 
-- more than one transaction. The latter query can be used to find out which particular transactions are generating redo.

-- From the above example we can see that user Scott is generating more archive logs. To know which SQL statment Scott user 
-- is executed

SQL> select sql.sql_text sql_text, t.USED_UREC Records, t.USED_UBLK Blocks,
 			(t.USED_UBLK*8192/1024) KBytes from v$transaction t,
 v$session s,
 v$sql sql
 where t.addr = s.taddr
 and s.sql_id = sql.sql_id
 and s.username ='&USERNAME';
Enter value for username: SCOTT
old 7: and s.username ='&USERNAME'
new 7: and s.username ='SCOTT'
SQL_TEXT                                 RECORDS BLOCKS KBYTES
---------- ---------- ----------
insert into emp_c select * from emp_c    157526   4929  39432
SQL>

-------------------------------------------------------------------------------------------------------------------------

select nvl(a.event,'ON CPU') as event, count(*) as total_wait_time
from v$active_session_history a
where a.sample_time between to_date('03/02/2017 00:00:00','mm/dd/yyyy hh24:mi:ss')
 					and to_date('03/02/2017 23:59:59','mm/dd/yyyy hh24:mi:ss')
group by a.event
order by total_wait_time desc;


select *
from v$active_session_history a
where a.sample_time between to_date('03/02/2017 00:00:00','mm/dd/yyyy hh24:mi:ss')
 					and to_date('03/02/2017 23:59:59','mm/dd/yyyy hh24:mi:ss')
;






-- check the SPID from session process column which will be getting from below
-- active processes query
SELECT s.SCHEMANAME, s.OSUSER, P.SPID 
FROM V$SESSION s, v$process P
WHERE s.paddr = P.addr
  AND s.process='6008:3528'

-- Show the currently active processes. top CPU
SELECT SUBSTR(s.USERNAME,1,8) USERNAME, s.OSUSER OSUSER,
     DECODE(s.SERVER,'DEDICATED','D','SHARED','S','O') SERVER,
     sa.DISK_READS DISK_READS, sa.BUFFER_GETS BUFFER_GETS,
     SUBSTR(s.LOCKWAIT,1,10) LOCKWAIT, s.PROCESS PID,
     sw.EVENT EVENT, sa.SQL_TEXT SQL
FROM V$SESSION_WAIT sw, V$SQLAREA sa, V$SESSION s
WHERE s.SQL_ADDRESS = sa.ADDRESS
  and s.SQL_HASH_VALUE = sa.HASH_VALUE
  and s.SID = sw.SID (+)
  and s.STATUS = 'ACTIVE'
  and sw.EVENT != 'client message'
ORDER BY s.LOCKWAIT ASC, s.USERNAME;

-- difference between 2 dates
select end_date,start_date,
--  trunc(months_between(end_date,start_date)/12) as yrs ,
--  trunc(mod( months_between(end_date,start_date) ,12)) as mnts,
 trunc(end_date - add_months( start_date, months_between(end_date,start_date))) as dys,
 trunc(24*mod(end_date - start_date,1)) as hrs,
 trunc( mod(mod(end_date - start_date,1)*24,1)*60 ) as mins ,
 mod(mod(mod(end_date - start_date,1)*24,1)*60,1)*60 as secs
from ( select y end_date , x start_date from t );


-- Query which shows the spid which is running from long time like 2hrs 3hrs 4 hrs
SELECT /*+ ordered */ 
    P.spid, s.SID, s.serial#, s.username, 
    TO_CHAR(s.logon_time, 'mm-dd-yyyy hh24:mi') logon_time, s.last_call_et,
    TRUNC(24*MOD(SYSDATE - s.logon_time,1)) ||':'|| TRUNC( MOD(MOD(SYSDATE - s.logon_time,1)*24,1)*60 ) mins,  
    sq.sql_text
FROM v$statname sn, v$sesstat st, v$process P, v$session s, v$sql sq 
WHERE s.paddr=P.addr 
  AND s.sql_hash_value = sq.hash_value AND s.sql_Address = sq.address 
  AND s.SID = st.SID 
  AND st.STATISTIC# = sn.statistic# 
  AND sn.NAME = 'CPU used by this session' 
  AND P.spid IN (118940,123723) ---- os PID parameter to restrict for a specific PID 
  AND s.status = 'ACTIVE' 
--  AND RAWTOHEX (s.sql_address) <> '00'
--  AND s.username IS NOT NULL
ORDER BY st.VALUE DESC


-- check the top query
SELECT /*+ ordered */ 
    P.spid, s.SID, s.serial#, s.username, 
    TO_CHAR(s.logon_time, 'mm-dd-yyyy hh24:mi') logon_time, s.last_call_et, st.VALUE, 
    s.sql_hash_value, s.sql_address, sq.sql_text 
FROM v$statname sn, v$sesstat st, v$process P, v$session s, v$sql sq 
WHERE s.paddr=P.addr 
  AND s.sql_hash_value = sq.hash_value AND s.sql_Address = sq.address 
  AND s.SID = st.SID 
  AND st.STATISTIC# = sn.statistic# 
  AND sn.NAME = 'CPU used by this session' 
  AND P.spid = 20386 ---- os PID parameter to restrict for a specific PID 
  AND s.status = 'ACTIVE' 
ORDER BY st.VALUE DESC



-- Collect Extended SQL Trace Data (Event 10046)
-- How to start tracing 
SQL> SELECT p.spid, s.sid, s.serial#, s.schemaname, s.machine, s.osuser
FROM v$session s, v$process p 
WHERE s.paddr = p.addr AND p.spid = 24078 
 


- Top CPU Consuming SQL During A Certain Time Period
-- Note – in this case we are finding the Top 5 CPU intensive SQL statements executed between 9.00 AM and 11.00 AM

SELECT * 
FROM 
(
	SELECT SQL_ID, SUM(CPU_TIME_DELTA), 
		   SUM(DISK_READS_DELTA), COUNT(*)
	FROM DBA_HIST_SQLSTAT a, DBA_HIST_SNAPSHOT s
	WHERE s.SNAP_ID = a.SNAP_ID
	  AND s.Begin_Interval_Time > SYSDATE -1
	  AND EXTRACT(HOUR FROM S.END_INTERVAL_TIME) BETWEEN 9 AND 11
	GROUP BY SQL_ID 
	ORDER BY SUM(CPU_TIME_DELTA) DESC
)
WHERE ROWNUM

-- Top 5 SQL statements IN THE past one HOUR
SELECT * 
FROM 
(
    SELECT ash.SQL_ID, DBA_USERS.USERNAME,
     sqlarea.SQL_TEXT, SUM(ash.wait_time + ash.time_waited) ttl_wait_time
    FROM v$active_session_history ash, v$sqlarea sqlarea, dba_users
    WHERE ash.SAMPLE_TIME BETWEEN SYSDATE -  1/24  AND SYSDATE
      AND ash.sql_id = sqlarea.sql_id
      AND ash.user_id = dba_users.user_id
    GROUP BY ash.sql_id,sqlarea.sql_text, dba_users.username
    ORDER BY 4 DESC 
)
WHERE ROWNUM = 2


-- Top CPU consuming queries since past one day
SELECT * 
FROM 
(
	SELECT 
		SQL_ID, 
		SUM(CPU_TIME_DELTA), 
		SUM(DISK_READS_DELTA),
		COUNT(*)
	FROM 
		DBA_HIST_SQLSTAT A, DBA_HIST_SNAPSHOT S
	WHERE S.SNAP_ID = A.SNAP_ID
	 AND S.BEGIN_INTERVAL_TIME > SYSDATE -1
	GROUP BY SQL_ID
	ORDER BY SUM(CPU_TIME_DELTA) DESC
)
WHERE ROWNUM=1


-- Find what the top SQL was at a particular reported time of day
-- First determine the snapshot id values for the period in question.
-- In thos example we need to find the SNAP_ID for the period 10 PM to 11 PM on the 14th of November, 2012.

SELECT SNAP_ID,BEGIN_INTERVAL_TIME,END_INTERVAL_TIME
FROM DBA_HIST_SNAPSHOT
WHERE TO_CHAR(BEGIN_INTERVAL_TIME,'DD-MON-YYYY')='14-NOV-2012'
AND EXTRACT(HOUR FROM BEGIN_INTERVAL_TIME) BETWEEN 22 AND 23;


SELECT * FROM
(
	SELECT SQL.SQL_ID C1, SQL.BUFFER_GETS_DELTA C2, SQL.DISK_READS_DELTA C3, SQL.IOWAIT_DELTA C4
	FROM DBA_HIST_SQLSTAT SQL, DBA_HIST_SNAPSHOT S
	WHERE S.SNAP_ID = SQL.SNAP_ID AND S.SNAP_ID= &SNAPID ORDER BY C3 DESC
)
WHERE ROWNUM < 6 


-- Top 5 Queries for past week based on ADDM recommendations

/*

Top 10 SQL_ID's for the last 7 days as identified by ADDM
from DBA_ADVISOR_RECOMMENDATIONS and dba_advisor_log

*/
col SQL_ID form a16
col Benefit form 9999999999999

SELECT * 
FROM 
(
	SELECT B.ATTR1 AS SQL_ID, MAX(A.BENEFIT) AS "BENEFIT" 
	FROM DBA_ADVISOR_RECOMMENDATIONS A, DBA_ADVISOR_OBJECTS B 
	WHERE A.REC_ID = B.OBJECT_ID
	  AND A.TASK_ID = B.TASK_ID
	  AND A.TASK_ID IN (SELECT DISTINCT B.TASK_ID
						FROM DBA_HIST_SNAPSHOT A, DBA_ADVISOR_TASKS B, DBA_ADVISOR_LOG L
						WHERE A.BEGIN_INTERVAL_TIME > SYSDATE - 7 
						  AND  A.DBID = (SELECT DBID FROM V$DATABASE) 
						  AND A.INSTANCE_NUMBER = (SELECT INSTANCE_NUMBER FROM V$INSTANCE) 
						  AND TO_CHAR(A.BEGIN_INTERVAL_TIME, 'YYYYMMDDHH24') = TO_CHAR(B.CREATED, 'YYYYMMDDHH24') 
						  AND B.ADVISOR_NAME = 'ADDM' 
						  AND B.TASK_ID = L.TASK_ID 
						  AND L.STATUS = 'COMPLETED') 
	 AND LENGTH(B.ATTR4) > 1 GROUP BY B.ATTR1
   ORDER BY MAX(A.BENEFIT) DESC
) 
WHERE ROWNUM < 6;
=========================================================================================


--SELECT FROM v$SQL TOP 10 BUFFER GETS
select * from (select buffer_gets,disk_reads,rows_processed,optimizer_mode,executions,sorts,loaded_versions,loads,sql_text 
from v$sql order by buffer_gets desc) 
where rownum < 11; 

--SELECT FROM v$SQL TOP 10 ELAPSED_TIME
select sql_text,ELAPSED_TIME from (select sql_text,ELAPSED_TIME 
from v$sql order by ELAPSED_TIME desc ) 
where rownum < 11; 

-- SELECT FROM v$SQL TOP 10 DISK_READS
select * from (select disk_reads,buffer_gets,rows_processed,optimizer_mode,executions,sorts,loaded_versions,loads,sql_text 
from v$sql order by disk_reads desc) 
where rownum < 11; 

-- SELECT FROM v$SQL TOP 10 ROWS_PROCESSED  
select * from (select rows_processed,buffer_gets,disk_reads,optimizer_mode,executions,sorts,loaded_versions,loads,sql_text 
from v$sql order by rows_processed desc) 
where rownum < 11; 

-- SELECT FROM v$SQL TOP 10 EXECUTIONS  
select * from (select executions,rows_processed,buffer_gets,disk_reads,optimizer_mode,sorts,loaded_versions,loads,sql_text 
            from v$sql 
            order by executions desc) 
where rownum < 11; 

-- SELECT FROM v$SQL TOP 10 SORTS  
select * from (select sorts,executions,rows_processed,buffer_gets,disk_reads,optimizer_mode,loaded_versions,loads,sql_text 
                from v$sql order by sorts desc) 
where rownum < 11; 

-- SELECT FROM v$SQL TOP 10 CPU_TIME  
select sql_text,cpu_time from (select sql_text,cpu_time from v$sql order by cpu_time desc ) where rownum < 11; 


-- 1.0 Oracle BUFFER CACHE Hit Ratio - Oracle MEMORY TUNING Calculate BUFFER CACHE hit ratio IN THE 
--DATABASE. Make sure it IS more THAN 80 FOR an oltp environment AND 99 IS THE best VALUE.
SELECT A.VALUE + b.VALUE "logical_reads", c.VALUE "phys_reads",ROUND(100 * ((A.VALUE+b.VALUE)-c.VALUE) /(A.VALUE+b.VALUE))"BUFFER HIT RATIO" 
FROM v$sysstat A, v$sysstat b, v$sysstat c
WHERE A.statistic# = 38 
  AND b.statistic# = 39 
  AND c.statistic# = 40;


--Check Session Level Hit Ratio - Oracle tuning THE Hit Ratio should be higher THAN 90%
SELECT Username, OSUSER, Consistent_Gets, Block_Gets, Physical_Reads, 100*( Consistent_Gets + Block_Gets - Physical_Reads)/( Consistent_Gets + Block_Gets ) "Hit Ratio %"
FROM V$SESSION,V$SESS_IO
WHERE V$SESSION.SID = V$SESS_IO.SID
  AND ( Consistent_Gets + Block_Gets )>0
  AND username IS NOT NULL
ORDER BY Username,"Hit Ratio %";


--List SESSION specific MEMORY - oracle memory tuning, list the uga and pga used by each session on the server 
SELECT se.SID,n.NAME, MAX(se.VALUE) maxmem 
FROM v$sesstat se,v$statname n
WHERE n.statistic# = se.statistic#
  AND n.NAME IN ('session pga memory','session pga memory max','session uga memory','session uga memory max')
GROUP BY n.NAME,se.SID
ORDER BY 3


-- List the size of Oracle stored procedures and use it to tune Oracle shared pool - Oracle memory tuning
-- This script LISTS THE SIZE OF stored objects 

--column num_instances heading "Num" format 999 
--column TYPE heading "Object Type" format a12 
--column source_size heading "Source" format 99,999,999 
--column parsed_size heading "Parsed" format 99,999,999 
--column code_size heading "Code" format 99,999,999 
--column error_size heading "Errors" format 999,999 
--column size_required heading "Total" format 999,999,999 
--compute SUM OF size_required ON report 

SELECT COUNT(NAME) num_instances, 
       TYPE 
    ,SUM(source_size) source_size 
    ,SUM(parsed_size) parsed_size 
    ,SUM(code_size) code_size 
    ,SUM(error_size) error_size 
    ,SUM(source_size) 
    +SUM(parsed_size) 
    +SUM(code_size) 
    +SUM(error_size) size_required 
FROM dba_object_size 
GROUP BY TYPE 
ORDER BY 2


-- Oracle sorts MONITORING Scripts - Oracle MEMORY TUNING
--Monitor THE sorts IN MEMORY vs DISK. Try TO KEEP THE DISK/MEMORY ratio TO LESS THAN .10 BY increasing THE sort_area_size 

SELECT NAME, VALUE FROM v$sysstat 
WHERE NAME IN ('sorts (memory)', 'sorts (disk)');
====================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
dba_hist
3
set lines 178 
set pages 80
break on sql_id on sql_text on report
compute sum of rows_pro on sql_id
compute sum of calls on sql_id
compute sum of executions on sql_id
compute avg of elapsed on sql_id
compute avg of cpu_time on sql_id
column sql_id format a15
column calls format 9,999,999 heading "Num of|Calls"
column executions format 9,999,999 heading "Num of|Executions"
column rows_pro format 9,999,999 heading "Rows|Processed"
column cpu_time format 99,999.999 heading "CPU Time|(Secs)"
column elapsed format 999,999,999 heading "Elapsed T.|(Secs)"
column avg_cput_row format 999,999.9 heading "Avg Rows|/CPU Sec"
column avg_elat_row format 9,999.999 heading "Avg Rows|/Ela Sec"
column sql_text format a45
column day format a9



SELECT h.sql_id 
     , TO_CHAR(hs.sql_text) sql_text
     , h.plan_hash_value
     , h.day
     , h.calls
     , h.executions
     , h.rows_pro
     , h.cpu_time
     , h.elapsed
     , CASE WHEN NVL(h.cpu_time,0) != 0  THEN h.rows_pro/h.cpu_time ELSE NULL END avg_cput_row
     , CASE WHEN h.elapsed != 0 THEN h.rows_pro/h.elapsed ELSE NULL END avg_elat_row
  FROM (SELECT q.dbid
             , q.sql_id
             , q.plan_hash_value
             , TRUNC(s.begin_interval_time,'DD') day
             , SUM(q.executions_delta) calls
             , SUM(q.END_OF_FETCH_COUNT_DELTA) executions
             , SUM(q.ROWS_PROCESSED_DELTA) rows_pro
             , SUM(q.CPU_TIME_DELTA)/1000000 cpu_time
             , SUM(q.ELAPSED_TIME_DELTA)/1000000 elapsed
          from dba_hist_sqlstat q,
               dba_hist_snapshot s
         where q.dbid = 4172635351
           and q.sql_id in ('99qfyjgj03w6c')
           and q.dbid = s.dbid
           and q.instance_number = s.instance_number
           and q.snap_id = s.snap_id
--           and s.begin_interval_time between sysdate-30 and sysdate
         group by q.dbid, q.sql_id
                , TRUNC(s.begin_interval_time,'DD')
                , q.plan_hash_value) h
     , dba_hist_sqltext hs
 WHERE h.dbid   = hs.dbid
   AND h.sql_id = hs.sql_id
 ORDER BY 1,4 DESC

<end node> 5P9i0s8y19Z
dt=Text
<node>
sql_id b4 sql query coming in DB
3


SQL> set feedback only sql_id
SQL> SELECT * FROM SCOTT.EMP;

14 rows selected.

SQL_ID: 4ay6mhcbhvbf2

SQL> set feedback on
SQL> select dbms_sql_translator.sql_id('SELECT * FROM SCOTT.EMP')  from   dual;

DBMS_SQL_TRANSLATOR.SQL_ID('SELECT*FROMSCOTT.EMP')
--------------------------------------------------
4ay6mhcbhvbf21 row selected.

<end node> 5P9i0s8y19Z
dt=Text
<node>
Sess Trace
3
<end node> 5P9i0s8y19Z
dt=Text
<node>
SQL Trace01
4
-- SQL Trace ,100046 event
-- Normal trace
alter session set sql_trace = true;  -- To put trace on
alter session set sql_trace = false;  -- To put trace off
 
-- Full level with wait event And bind trace
alter session set events = '10046 trace name context forever, level 12';
 
-- To put tracing off
alter session set events = '10046 trace name context off';
 
-- Further trace can be limited to a set of SQL_IDs if you include a filter for it. E.g.
alter session set events 'sql_trace [sql: sql_id=g3yc1js3g2689 | sql_id=7ujay4u33g337]bind=true, wait=true';
--------------------------------------------------------------------------------------
 
-- Same as Normal trace
exec DBMS_SESSION.set_sql_trace(sql_trace => TRUE);
exec DBMS_SESSION.set_sql_trace(sql_trace => FALSE);
 
-- Normal trace
execute dbms_system.set_sql_trace_in_session ('sid','serial',true);  -- To put tracing on
execute dbms_system.set_sql_trace_in_session ('sid','serial',true);   -- To put tracing off
 
-- Full level with wait event And bind trace
execute dbms_system.set_ev('sid','serial',10046,12,'');
 
-- To put trace off
execute dbms_system.set_ev('sid','serial',10046,0,'');
--------------------------------------------------------------------------------------
 
(1) ORADEBUG
This requires login as sysdba
 
oradebug setospid   1111   -- Debug session with the specified Oracle  process id
oradebug setorapid  1111  --- Debug session with the specified OS process
 
oradebug event 10046 trace name context forever, level 4;
oradebug event 10046 trace name context off;   --- This disable the trace
 
oradebug close_trace  --- This closes  the trace file
Oradebug TRACEFILE_NAME;
--------------------------------------------------------------------------------------
 
-- With Oracle 10g the SQL tracing options have been  extended using the DBMS_MONITOR package
EXECUTE dbms_monitor.session_trace_enable
 
-- Which is similar
ALTER SESSION SET EVENTS '10046 trace name context forever, level 2';
EXECUTE dbms_monitor.session_trace_enable (binds=>true);
 
-- Which is similar
ALTER SESSION SET EVENTS '10046 trace name context forever, level 4';
EXECUTE dbms_monitor.session_trace_enable (waits=>true);
 
-- Which is similar
ALTER SESSION SET EVENTS '10046 trace name context forever, level 8';
EXECUTE dbms_monitor.session_trace_enable('sid','serial#')
 
-- Which is similar
execute dbms_system.set_ev('sid','serial',10046,2,'');
EXECUTE dbms_monitor.session_trace_enable ('sid','serial#',binds=>true);
 
-- Which is similar
execute dbms_system.set_ev('sid','serial',10046,4,'');
EXECUTE dbms_monitor.session_trace_enable ('sid','serial#',waits=>true);
 
-- Which is similar
execute dbms_system.set_ev('sid','serial',10046,8,'');
--------------------------------------------------------------------------------------
 
-- How to identify the Trace files
-- We can identify the trace files using the spid of the session. Also the trace file will  
-- contain sid,serial#  pair at the start of the trace file.
-- Below query can be used to find the local session trace file
select c.value || '/' || d.instance_name ||'_ora_' || a.spid || '.trc' trace
from v$process a, v$session b, v$parameter c, v$instance d
where a.addr = b.paddr
and b.audsid = userenv('sessionid')
and c.name = 'user_dump_dest'
;
 
-- There is another easy way to identify the trace file  which is called trace identifier
alter session set tracefile_identifer='ORAC';  This is identifier
--------------------------------------------------------------------------------------
-- how to check if trace is enabled in oracle
 
-- If you have enabled tracing using DBMS_MONITOR package, we can check if trace is enabled using below query
set lines 180
col module for a45
col sql_trace_waits for a20
col sql_trace_binds for a20
col sql_trace for a20
select username,module,sid,sql_trace,sql_trace_waits,sql_trace_binds 
from v$session 
where sql_trace='ENABLED'
;
--------------------------------------------------------------------------------------
 
-- Oracle tkprof utility
-- The trace files obtained from above method is in raw  form which can be converted into more readable 
-- format using tkprof utility  (Transient Kernel PROFile  utility)
-- explain=user/password Connect to ORACLE and issue EXPLAIN PLAN.
tkprof file.trc file.txt sys=no explain=cae0748p/password sort=prsela,exeela,fchela
tkprof file.trc file.txt sys=no explain=cae0748p/password  sort=prsela,exeela,fchela
tkprof file.trc file.txt sys=no
tkprof file.trc file.txt sys=no explain=cae0748p/password sort=prsela,exeela,fchela
 
-- This print 10 sql only
tkprof .trc elaps.prf sys=no explain=apps/ sort=(prsela,exeela,fchela) print=10
 
-- This print all the sql
tkprof .trc elaps.prf sys=no explain=apps/apps sort=prsela,exeela,fchela
--------------------------------------------------------------------------------------



-- Enabling Trace using ORADEBUG
-- SQL_TRACE is a synonym for event 10046 and can be set using ORADEBUG 

-- The syntax is: 
SQL> ORADEBUG DOC EVENT NAME SQL_TRACE

sql_trace: event for sql trace

Usage
-------
sql_trace
   wait            < false | true >,
   bind            < false | true >,
   plan_stat       < never | first_execution | all_executions | adaptive >,
   level   
   
-- The default level is 1. 

-- For example to enable default trace: 
ORADEBUG EVENT SQL_TRACE

-- To enable trace including bind variables: 
ORADEBUG EVENT SQL_TRACE BIND=TRUE

-- To enable trace including bind variables and wait events: 
ORADEBUG EVENT SQL_TRACE BIND=TRUE,WAIT=TRUE

-- To enable trace including plan statistics for every statement execution: 
ORADEBUG EVENT SQL_TRACE PLAN_STAT=ALL_EXECUTIONS

-- Numeric event levels are still supported: 
ORADEBUG EVENT SQL_TRACE LEVEL=4

-- To disable trace: 
ORADEBUG EVENT SQL_TRACE OFF


-- ** Enabling Trace at Instance Level

-- Trace can be enabled when the instance is started by adding the following line to the init.ora file. 
sql_trace = TRUE

-- This will enable trace for all sessions including background processes. Note that enabling this 
-- parameter may generate large amounts of trace and consume significant system resources. 

-- Trace can also be enabled at instance level using event 10046. For example to 
-- enable event 10046 level 8 add the following line to the init.ora file: 
event="10046 trace name context forever, level 8"

-- When the instance is already running, trace can be enabled directly using the ALTER SYSTEM command. 
ALTER SYSTEM SET trace_enabled = TRUE;

-- This will enable trace for all newly created sessions. Currently executing sessions and 
-- background processes will be unaffected. 

-- Instance-wide trace can be disabled again using: 
ALTER SYSTEM SET trace_enabled = FALSE;

-- In Oracle 11.1 and above, SQL_TRACE is an event and can be enabled using the following syntax: 
ALTER SYSTEM SET EVENTS 'sql_trace wait=true';
ALTER SYSTEM SET EVENTS 'sql_trace bind=true';
ALTER SYSTEM SET EVENTS 'sql_trace bind=true,wait=true';
ALTER SYSTEM SET EVENTS 'sql_trace plan_stat=all_executions';

-- In Oracle 11.1 and above trace can be restricteed to a specific SQL ID by specifying a filter: 
ALTER SYSTEM SET EVENTS sql_trace  [sql: sql_id=3s1yukp05bzg6] bind=true, wait=true';

-- Multiple SQL IDs can be specified using the | symbol as a separator: 
ALTER SYSTEM SET EVENTS sql_trace [sql: sql_id=3s1yukp05bzg6|aca4xvmz0rzup] bind=true, wait=true';

-- In Oracle 11.1 and above, trace can be restricted to specific components. For example: 
ALTER SYSTEM SET EVENTS 'trace[rdbms.SQL_Optimizer.*]';

-- The library name can optionally be ommitted. For example: 
ALTER SYSTEM SET EVENTS 'trace[SQL_Optimizer.*]';

-- Disable trace again using: 
ALTER SYSTEM SET EVENTS 'trace[SQL_Optimizer.*] off';

-- Individual components can also be filtered. For example: 
ALTER SYSTEM SET EVENTS 'trace[SQL_Optimizer.*][sql:3bnxc7htmf2ad]';

-- In all versions trace can also be enabled using event 10046. For example to enable event 10046 level 8 use the command: 
ALTER SYSTEM SET EVENTS '10046 trace name context forever, level 8';

-- Instance-wide trace can be disabled again using: 
ALTER SYSTEM SET EVENTS '10046 trace name context off';

-- Enabling Trace at Session Level
-- Trace can be enabled at session level using the command: 
ALTER SESSION SET sql_trace = TRUE;

-- Trace is disabled at session level using: 
ALTER SESSION SET sql_trace = FALSE;

-- In Oracle 11.1 and above, SQL_TRACE is an event and can be enabled using the following syntax: 
ALTER SESSION SET EVENTS 'sql_trace wait=true';
ALTER SESSION SET EVENTS 'sql_trace bind=true';
ALTER SESSION SET EVENTS 'sql_trace bind=true,wait=true';
ALTER SESSION SET EVENTS 'sql_trace plan_stat=all_executions';

-- In Oracle 11.1 and above trace can be restricteed to a specific SQL ID by specifying a filter: 
ALTER SYSTEM SET EVENTS sql_trace [sql: sql_id=3s1yukp05bzg6] bind=true, wait=true';

-- Multiple SQL IDs can be specified using the | symbol as a separator: 
ALTER SYSTEM SET EVENTS sql_trace [sql: sql_id=3s1yukp05bzg6|aca4xvmz0rzup] bind=true, wait=true';

-- In Oracle 11.1 and above, trace can be restricted to specific components. For example: 
ALTER SESSION SET EVENTS 'trace[rdbms.SQL_Optimizer.*]';

-- The library name can optionally be ommitted. For example: 
ALTER SESSION SET EVENTS 'trace[SQL_Optimizer.*]';
-- Disable trace again using: 
ALTER SESSION SET EVENTS 'trace[SQL_Optimizer.*] off';

-- Individual components can also be filtered. For example: 
ALTER SESSION SET EVENTS 'trace[SQL_Optimizer.*][sql:3bnxc7htmf2ad]';

-- In all versions trace can also be enabled at session level using event 10046. 
-- For example to enable event 10046 level 8 use the command: 
ALTER SESSION SET EVENTS '10046 trace name context forever, level 8';

-- Event 10046 trace is disabled at session level using: 
ALTER SESSION SET EVENTS '10046 trace name context off';

-- Trace can be enabled in the current session using the DBMS_SESSION package. This can be 
-- useful if you need to enable trace from within a PL/SQL package. 

-- Trace is enabled at session level using: 
EXECUTE dbms_session.set_sql_trace (TRUE);

-- Trace is disabled at session level using: 
EXECUTE dbms_session.set_sql_trace (FALSE);

-- Trace can be enabled in the current session using the DBMS_SUPPORT package. This provides more flexibility 
-- than DBMS_SESSION. 

-- Trace is enabled at session level using: 
EXECUTE dbms_support.start_trace;

-- With no parameters, this procedure enables level 1 trace: 
-- Event 10046 level 4 trace can be enabled using: 
EXECUTE dbms_support.start_trace (binds=>true);

-- Event 10046 level 8 trace can be enabled using: 
EXECUTE dbms_support.start_trace (waits=>true);

-- Event 10046 level 12 trace can be enabled using: 
EXECUTE dbms_support.start_trace (binds=>true,waits=>true);

-- Trace can be disabled using: 
EXECUTE dbms_support.stop_trace;

-- Enabling Trace in another Session
-- Trace can be enabled in another session using the DBMS_SUPPORT package. 
-- The SID and optionally the serial number if the target session must be obtained from V$SESSION. 
-- The serial number can optionally be specified as 0. 
-- For example to enable level 1 trace in a session with SID 9 and serial number 29 use: 
EXECUTE dbms_support.start_trace_in_session (9,29);

-- With no parameters, this procedure enables level 1 trace: 
-- Event 10046 level 4 trace can be enabled using: 
EXECUTE dbms_support.start_trace_in_session (9,29,binds=>true);

-- Event 10046 level 8 trace can be enabled using: 
EXECUTE dbms_support.start_trace_in_session (9,29,waits=>true);

-- Event 10046 level 12 trace can be enabled using: 
EXECUTE dbms_support.start_trace_in_session (9,29,binds=>true,waits=>true);

-- Trace can be disabled using: 
dbms_support.stop_trace_in_session (9,29);

-- Trace can be also be enabled in another session using the DBMS_SYSTEM package. 
-- The SID and the serial number of the target session must be obtained from V$SESSION. 
-- In this case the serial number must be specified. 
-- For example to enable trace in a session with SID 9 and serial number 29 use: 
EXECUTE dbms_system.set_sql_trace_in_session (9,29,TRUE);

-- Note this is equivalent to enabling event 10046 level 1: 

-- To disable trace in the same session use: 
EXECUTE dbms_system.set_sql_trace_in_session (9,29,FALSE);

-- Event 10046 trace can also be enabled in another session using the DBMS_SYSTEM package. 
-- The SID and the serial number of the target session must be obtained from V$SESSION. 

--For example to enable event 10046 level 8 in a session with SID 9 and serial number 29 use: 
EXECUTE dbms_system.set_ev (9,29,10046,8,'');

--To disable event 10046 in the same session use: 
EXECUTE dbms_system.set_ev (9,29,10046,0,'');

<end node> 5P9i0s8y19Z
dt=Text
<node>
Event Trace
4

-- Good URL for Trace File handling
-- https://oracle-base.com/articles/misc/sql-trace-10046-trcsess-and-tkprof

-- Start tracing  
SQL> begin dbms_system.set_ev(18,5, 10046,12,''); end; -- trace on 
 
-- collect trace information for approximately 15 minutes during the problem  
SQL> begin dbms_system.set_ev(18, 5, 10046,0,''); end; -- trace off 

-- This produced a trace file in the user_dump_dest directory. We used the tkprof 
-- utility to format the trace file and sort the SQL statements in descending order of highest fetch elapsed 
-- time as follows: 

tkprof ora_24078.trc 24078.prf sort=fchela 
 
$ cat 24078.prf 
<some lines removed for brevity> 

<end node> 5P9i0s8y19Z
dt=Text
<node>
enable sql trace
4



=============================================================================================================
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
1. Enabling 10053 trace for problem SQLID : 3mnh27xnnmx4k 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 

-- Enable trace -- 
SQL> alter system set events 'trace[rdbms.SQL_Optimizer.*][sql:3jm5js3q9wvt8]'; 

-- Execute SQL from application with SEARCH string producing wrong rows ex : POLLOCK RESEARCH% --- 
Finding the trace file : 
SELECT value FROM v$diag_info WHERE name='Default Trace File'; 
- Trace will be generated on above location with latest timestamp -- 

Disable the trace immediately after required traces are collected : 
SQL> alter system set events 'trace[rdbms.SQL_Optimizer.*][sql:3mnh27xnnmx4k]' off; 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
2. Collect 10046 and 10053 TRACE from SQL*Plus fetching right rows 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 

alter session set timed_statistics = true; 
alter session set statistics_level=ALL; 
alter session set max_dump_file_size=UNLIMITED; 
alter session set tracefile_identifier='RIGHT_RESULT_PROD_SQLPLUS'; 
alter session set events '10046 trace name context forever, level 12'; 
alter session set events '10053 trace name context forever, level 1'; 

-- RUN the offending SQL statements here. Use a comment in the query to force a hard parse. e.g select /*+ HARD PARSE ME */ 

select 1 from dual; 

exit 

Find trc with suffix "RIGHT_RESULT_PROD_SQLPLUS" in <user_dump_dest> and upload 


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
3. Get SQLHC Report from both PROD and TEST database 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 

SQL Tuning Health-Check Script (SQLHC) Video( Doc ID 1455583.1 ) 
 
 
=============================================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
statpack Oracle 9i
4
https://www.tutorialdba.com/2017/09/using-statspack-report-in-oracle-9i.html

<end node> 5P9i0s8y19Z
dt=Text
<node>
TKProf
4
Procedure to enable SQL trace for users on your database:
=========================================================

1. Get the SID and SERIAL# for the process you want to trace.

	SQL> select sid, serial# from sys.v_$session where ...
	       SID    SERIAL#
	---------- ----------
	         8      13607

2. Enable tracing for your selected process:

	SQL> ALTER SYSTEM SET TIMED_STATISTICS = TRUE;
	SQL> execute dbms_system.set_sql_trace_in_session(8, 13607, true); 

3. Ask user to run just the necessary to demonstrate his problem.

4. Disable tracing for your selected process:

	SQL> execute dbms_system.set_sql_trace_in_session(8,13607, false); 
	SQL> ALTER SYSTEM SET TIMED_STATISTICS = FALSE;

5. Look for trace file in USER_DUMP_DEST

	$ cd /app/oracle/admin/oradba/udump  
	$ ls -ltr
	total 8
	-rw-r-----    1 oracle   dba         2764 Mar 30 12:37 ora_9294.trc

OR

SQL> col name for a30
SQL> col value for a70
sql> select name,value from v$diag_info; -- here you can find the latested trace file name Oracle 11G

6. Run TKPROF to analyse trace output

	$ tkprof ora_9294.trc x EXPLAIN=monitor/oramon SYS=NO 

7. View or print the output file x.prf.


=================================================================================================


-- tkproof for sql queries

@?/rdbms/admin/utlxplan.sql
CREATE PUBLIC SYNONYM PLAN_TABLE FOR SYS.PLAN_TABLE;
GRANT SELECT, INSERT, UPDATE, DELETE ON SYS.PLAN_TABLE TO PUBLIC;

-- the user dump dest where the files will be created
SQL> col name for a30
SQL> col value for a70
sql> select name,value from v$diag_info; -- here you can find the latested trace file name Oracle 11G

-- now start tracing
ALTER SESSION SET SQL_TRACE = TRUE;

-- your queries goes here
SELECT COUNT(*)
FROM   dual;

-- disable the tracing
ALTER SESSION SET SQL_TRACE = FALSE;

-- once the tracing is disable you can check the dump desk file and check the results
TKPROF <trace-file> <output-file> explain=user/password@service table=sys.plan_table
============================================================================================

-- session level tracing
CREATE OR REPLACE TRIGGER tri_oltp_check
	AFTER LOGON ON DATABASE
WHEN ( USER = 'OLTP' )
BEGIN
	execute immediate 'alter session set events ''10046 trace name context forever, level 12''';
--	execute immediate 'alter session set tracefile_identifier=''OLTP_CHECK''';
EXCEPTION
 WHEN OTHERS THEN
	NULL;
END;
/

ALTER SESSION SET EVENTS '10046 trace name context off';

DROP TRIGGER TRI_OLTP_CHECK;

CREATE OR REPLACE TRIGGER USER_TRACE_TRG
AFTER LOGON ON DATABASE
BEGIN
    IF USER = '&USER_ID'
  THEN
--   execute immediate 'alter session set events ''10046 trace name context forever, level 12''';
--   execute immediate 'alter session set events ''10046 level 1''; -- 11g onwatds simplier syntax is available. 
--   execute immediate 'alter session set events ''8103 trace name errorstack level 3''';
--   execute immediate 'alter session set events ''10236 trace name context forever, level 1''';
--   execute immediate 'alter session set max_dump_file_size=''UNLIMITED''';
--   execute immediate 'alter session set db_file_multiblock_read_count=1';
--   execute immediate 'alter session set tracefile_identifier=''ORA8103''';
  END IF;
EXCEPTION
WHEN OTHERS THEN
NULL;
END;
/


SQL> ALTER SESSION SET sql_trace=TRUE;
SQL> ALTER SESSION SET sql_trace=FALSE;

SQL> EXEC DBMS_SESSION.set_sql_trace(sql_trace => TRUE);
SQL> EXEC DBMS_SESSION.set_sql_trace(sql_trace => FALSE);

-- to start the tracing best on leves 8 or 12
SQL> ALTER SESSION SET EVENTS '10046 trace name context forever, level 8'; -- less details

or 

-- will provide more information in trace files
SQL> alter session set events '10046 trace name context forever, level 12'

-- to stop the tracing
SQL> ALTER SESSION SET EVENTS '10046 trace name context off';

SQL> EXEC DBMS_SYSTEM.set_sql_trace_in_session(sid=>123, serial#=>1234, sql_trace=>TRUE);
SQL> EXEC DBMS_SYSTEM.set_sql_trace_in_session(sid=>123, serial#=>1234, sql_trace=>FALSE);

SQL> EXEC DBMS_SYSTEM.set_ev(si=>123, se=>1234, ev=>10046, le=>8, nm=>'');
SQL> EXEC DBMS_SYSTEM.set_ev(si=>123, se=>1234, ev=>10046, le=>0, nm=>'');

-- Available from SQL*Plus since 8i (commandline utility prior to this.
SQL> CONN sys/password AS SYSDBA;  -- User must have SYSDBA.
SQL> ORADEBUG SETMYPID;            -- Debug current session.
SQL> ORADEBUG SETOSPID 1234;       -- Debug session with the specified OS process.
SQL> ORADEBUG SETORAPID 123456;    -- Debug session with the specified Oracle process ID.

SQL> ORADEBUG EVENT 10046 TRACE NAME CONTEXT FOREVER, LEVEL 12;
SQL> ORADEBUG TRACEFILE_NAME;      -- Display the current trace file.
SQL> ORADEBUG EVENT 10046 TRACE NAME CONTEXT OFF;
 
-- All versions, requires DBMS_SUPPORT package to be loaded.
SQL> EXEC DBMS_SUPPORT.start_trace(waits=>TRUE, binds=>FALSE);
SQL> EXEC DBMS_SUPPORT.stop_trace;

SQL> EXEC DBMS_SUPPORT.start_trace_in_session(sid=>123, serial=>1234, waits=>TRUE, binds=>FALSE);
SQL> EXEC DBMS_SUPPORT.stop_trace_in_session(sid=>123, serial=>1234);

--------------------------------------------------------------------



-- sql tracing for DB level and session level
ALTER SYSTEM SET TIMED_STATISTICS = TRUE; 
ALTER SESSION SET sql_trace=TRUE;
EXEC DBMS_SESSION.set_sql_trace(sql_trace => TRUE);

alter session set events '10046 trace name context forever, level 12';

ALTER SESSION SET EVENTS '10046 trace name context off';
EXEC DBMS_SESSION.set_sql_trace(sql_trace=>FALSE);
ALTER SESSION SET sql_trace=FALSE;
ALTER SYSTEM SET TIMED_STATISTICS=FALSE;  

<end node> 5P9i0s8y19Z
dt=Text
<node>
sqldb360
3
<end node> 5P9i0s8y19Z
dt=Text
<node>
indx > then estimated
4
-- indexes with actual size greater than estimated
set serveroutput on lines 300 pages 1000
DECLARE
  l_used_bytes  NUMBER;
  l_alloc_bytes NUMBER;
  l_percent     NUMBER;
BEGIN
  DBMS_OUTPUT.PUT_LINE('PDB: '||SYS_CONTEXT('USERENV', 'CON_NAME'));
  DBMS_OUTPUT.PUT_LINE('---');
  DBMS_OUTPUT.PUT_LINE(
    RPAD('TABLE_NAME', 30)||' '||
    RPAD('OWNER.INDEX_NAME', 35)||' '||
    LPAD('SAVING %', 10)||' '||
    LPAD('CURRENT SIZE', 20)||' '||
    LPAD('ESTIMATED SIZE', 20)||'  '||
    RPAD('COMMAND', 75));
  DBMS_OUTPUT.PUT_LINE(
    RPAD('-', 30, '-')||' '||
    RPAD('-', 35, '-')||' '||
    LPAD('-', 10, '-')||' '||
    LPAD('-', 20, '-')||' '||
    LPAD('-', 20, '-')||'  '||
    RPAD('-', 75, '-'));
  FOR i IN (SELECT x.table_name, x.owner, x.index_name, SUM(s.leaf_blocks) * TO_NUMBER(p.value) index_size,
                   REPLACE(DBMS_METADATA.GET_DDL('INDEX',x.index_name,x.owner),CHR(10),CHR(32)) ddl
              FROM dba_ind_statistics s, dba_indexes x, dba_users u, v$parameter p
             WHERE u.oracle_maintained = 'N'
               AND x.owner = u.username
               AND x.tablespace_name NOT IN ('SYSTEM','SYSAUX')
               AND x.index_type LIKE '%NORMAL%'
               AND x.table_type = 'TABLE'
               AND x.status = 'VALID'
               AND x.temporary = 'N'
               AND x.dropped = 'NO'
               AND x.visibility = 'VISIBLE'
               AND x.segment_created = 'YES'
               AND x.orphaned_entries = 'NO'
               AND p.name = 'db_block_size'
               AND s.owner = x.owner
               AND s.index_name = x.index_name
             GROUP BY x.table_name, x.owner, x.index_name, p.value
             HAVING SUM(s.leaf_blocks) * TO_NUMBER(p.value) > 1 * POWER(2,20)
             ORDER BY index_size DESC)
    LOOP
    DBMS_SPACE.CREATE_INDEX_COST(i.ddl,l_used_bytes,l_alloc_bytes);
    IF i.index_size * (100 - 30) / 100 > l_alloc_bytes THEN
      l_percent := 100 * (i.index_size - l_alloc_bytes) / i.index_size;
      DBMS_OUTPUT.PUT_LINE(
        RPAD(i.table_name, 30)||' '||
        RPAD(i.owner||'.'||i.index_name, 35)||' '||
        LPAD(TO_CHAR(ROUND(l_percent, 1), '990.0')||' % ', 10)||' '||
        LPAD(TO_CHAR(ROUND(i.index_size / POWER(2,20), 1), '999,999,990.0')||' MB', 20)||' '||
        LPAD(TO_CHAR(ROUND(l_alloc_bytes / POWER(2,20), 1), '999,999,990.0')||' MB', 20)||'  '||
        RPAD('ALTER INDEX '||LOWER(i.owner||'.'||i.index_name)||' REBUILD ONLINE;', 75));
    END IF;
  END LOOP;
END;
/

<end node> 5P9i0s8y19Z
dt=Text
<node>
DB Monthly Growth
4
-- DB monthly growth size
SELECT /*+  NO_MERGE  */ /* 2b.215 */
       TO_CHAR(creation_time, 'YYYY-MM') creation_month,
       ROUND(SUM(bytes)/POWER(10,6)) mb_growth,
       ROUND(SUM(bytes)/POWER(10,9)) gb_growth,
       ROUND(SUM(bytes)/POWER(10,12), 1) tb_growth
  FROM v$datafile
 GROUP BY
       TO_CHAR(creation_time, 'YYYY-MM')
 ORDER BY
       TO_CHAR(creation_time, 'YYYY-MM') desc;

<end node> 5P9i0s8y19Z
dt=Text
<node>
perfm 01
4
-- hash value performance sql
 SELECT /*+ NO_MERGE */
       source, plan_hash_value, force_matching_signature, SUM(executions) execs, SUM(end_of_fetch_count) eof_count, ROUND(SUM(buffer_gets)/DECODE(SUM(executions),0,1,SUM(executions))) avg_buffer_gets,
       ROUND(SUM(elapsed_time)/1e6/DECODE(SUM(executions),0,1,SUM(executions)),6) avg_elapsed_time_secs, ROUND(SUM(cpu_time)/1e6/DECODE(SUM(executions),0,1,SUM(executions)),6) avg_cpu_time_secs,
       ROUND(SUM(io_time)/1e6/DECODE(SUM(executions),0,1,SUM(executions)),6) avg_io_time_secs, ROUND(SUM(rows_processed)/DECODE(SUM(executions),0,1,SUM(executions)),3) avg_rows_processed,
       ROUND(SUM(rows_processed)/DECODE(SUM(fetches),0,1,SUM(fetches)),3) avg_rows_per_fetch,
       sql_profile,
       sql_plan_baseline, sql_patch,
       ROUND(AVG(cost)) avg_cost, MIN(cost) min_cost, MAX(cost) max_cost,
       MIN(first_load_time) first_load_time, MAX(last_load_time) last_load_time,
       MIN(optimizer_env_hash_value) min_cbo_env, max(optimizer_env_hash_value) max_cbo_env,
       MIN(min_dop) min_req_dop, MAX(max_dop) max_req_dop
  FROM (SELECT 'MEM' source, a.plan_hash_value, a.force_matching_signature, a.sql_profile,
                a.sql_plan_baseline, a.sql_patch,
                executions, fetches, end_of_fetch_count, elapsed_time, cpu_time, rows_processed, buffer_gets, first_load_time, last_load_time, optimizer_cost cost, optimizer_env_hash_value, min_dop, max_dop, user_io_wait_time io_time
          FROM gv$sql a,
               (SELECT plan_hash_value, MIN(TO_NUMBER(extractValue(XMLType(other_xml),'/other_xml/info[@type="dop"]'))) min_dop,
                       MAX(TO_NUMBER(extractValue(XMLType(other_xml),'/other_xml/info[@type="dop"]'))) max_dop
                  FROM gv$sql_plan
                 WHERE sql_id = 'f56a8mg7dcm4x'
                   AND other_xml IS NOT NULL
                 GROUP BY plan_hash_value) dop
         WHERE sql_id = 'f56a8mg7dcm4x'
           AND a.plan_hash_value = dop.plan_hash_value(+)
        UNION ALL
        SELECT 'HIST' source, a.plan_hash_value, a.force_matching_signature, a.sql_profile,
               'N/A' sql_plan_baseline, 'N/A' sql_patch,
               executions_delta executions, fetches_delta fetches,  end_of_fetch_count_delta end_of_fetch_count, elapsed_time_delta elapsed_time, cpu_time_delta cpu_time, rows_processed_delta rows_processed,
               buffer_gets_delta buffer_gets, null first_load_time, null last_load_time, optimizer_cost, optimizer_env_hash_value, min_dop, max_dop, iowait_delta
          FROM dba_hist_sqlstat a,
               (SELECT plan_hash_value, MIN(TO_NUMBER(extractValue(XMLType(other_xml),'/other_xml/info[@type="dop"]'))) min_dop,
                       MAX(TO_NUMBER(extractValue(XMLType(other_xml),'/other_xml/info[@type="dop"]'))) max_dop
                  FROM dba_hist_sql_plan
                 WHERE sql_id = 'f56a8mg7dcm4x'
                   AND 'Y' = 'Y'
                   AND other_xml IS NOT NULL
                 GROUP BY plan_hash_value) dop
         WHERE sql_id = 'f56a8mg7dcm4x'
           AND 'Y' = 'Y'
       --    AND snap_id BETWEEN &&minimum_snap_id. AND &&maximum_snap_id.
           AND a.plan_hash_value = dop.plan_hash_value(+))
 GROUP BY source, plan_hash_value, force_matching_signature,
          sql_plan_baseline, sql_patch,
          sql_profile
;


-----------------------------------------------------

<end node> 5P9i0s8y19Z
dt=Text
<node>
temp usage consumg > 10gb
4
-- temporary tablespace consuming more then 10G usage
SELECT /*+  MATERIALIZE NO_MERGE   DYNAMIC_SAMPLING(4)   FULL(h.ash) FULL(h.evt) FULL(h.sn) USE_HASH(h.sn h.ash h.evt)   FULL(h.INT$DBA_HIST_ACT_SESS_HISTORY.sn) FULL(h.INT$DBA_HIST_ACT_SESS_HISTORY.ash) FULL(h.INT$DBA_HIST_ACT_SESS_HISTORY.evt)   USE_HASH(h.INT$DBA_HIST_ACT_SESS_HISTORY.sn h.INT$DBA_HIST_ACT_SESS_HISTORY.ash h.INT$DBA_HIST_ACT_SESS_HISTORY.evt)  */
       /* 2a.173 */
       h.sql_id,
       ROUND(MAX(h.temp_space_allocated)/POWER(10,9),1) max_temp_space_gb,
       DBMS_LOB.SUBSTR(s.sql_text, 1000) sql_text
  FROM dba_hist_active_sess_history h,
       dba_hist_sqltext s
 WHERE h.temp_space_allocated > 10*POWER(10,9)
   AND h.sql_id IS NOT NULL
   AND h.snap_id BETWEEN 50934 AND 50999
   AND h.dbid = 4172635351
   AND s.sql_id(+) = h.sql_id AND s.dbid(+) = 4172635351
   AND s.con_id(+) = h.con_id
 GROUP BY
       h.sql_id,
       DBMS_LOB.SUBSTR(s.sql_text, 1000)
 ORDER BY
       2 DESC, 1;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Top plains
4
-- 3d.340. Top Plans (DBA_HIST_ACTIVE_SESS_HISTORY) 
WITH
hist AS (
SELECT /*+  MATERIALIZE NO_MERGE   DYNAMIC_SAMPLING(4)   FULL(h.ash) FULL(h.evt) FULL(h.sn) USE_HASH(h.sn h.ash h.evt)   FULL(h.INT$DBA_HIST_ACT_SESS_HISTORY.sn) FULL(h.INT$DBA_HIST_ACT_SESS_HISTORY.ash) FULL(h.INT$DBA_HIST_ACT_SESS_HISTORY.evt)   USE_HASH(h.INT$DBA_HIST_ACT_SESS_HISTORY.sn h.INT$DBA_HIST_ACT_SESS_HISTORY.ash h.INT$DBA_HIST_ACT_SESS_HISTORY.evt)  */
       /* 3d.340 */
       h.sql_id,
       h.sql_plan_hash_value,
       h.dbid,
       COUNT(*) samples
  FROM dba_hist_active_sess_history h
 WHERE --h.snap_id BETWEEN 50934 AND 50999
   --AND h.dbid = 4172635351
   --AND h.sql_id IS NOT NULL
    h.sql_id='0qpjmtrnf1mrd' 
   AND h.sql_plan_hash_value > 0
GROUP BY
       h.sql_id,
       h.sql_plan_hash_value,
       h.dbid
), hist2 as (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.340 */
       DISTINCT
       h.sql_id
     , h.sql_plan_hash_value
     , h.dbid
     , h.samples
     , CASE WHEN s.rowid IS NOT NULL THEN samples ELSE 0 END sql_samples
     , SUM(h.samples) over (partition by h.dbid, h.sql_plan_hash_value) plan_samples
     , DBMS_LOB.SUBSTR(s.sql_text, 1000) sql_text
  FROM hist h
    LEFT OUTER JOIN dba_hist_sqltext s
    ON s.sql_id = h.sql_id AND s.dbid = h.dbid
), hist3 AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.340 */
       hist2.*
     , ROW_NUMBER() over (partition by dbid, sql_plan_hash_value order by sql_samples DESC) sql_id_rank
   FROM hist2
), hist4 AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.340 */
       hist3.*
     , ROW_NUMBER() over (order by sql_samples DESC) rn
  FROM hist3
WHERE sql_id_rank = 1
), total AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.340 */
       SUM(samples) samples FROM hist
)
SELECT /*+  NO_MERGE  */ /* 3d.340 */
       h.sql_id plan_top_sql_id,
       h.sql_plan_hash_value,
       h.plan_samples,
       ROUND(100 * h.plan_samples / t.samples, 1) percent,
       h.sql_text
  FROM hist4 h,
       total t
WHERE h.samples >= t.samples / 1000 AND h.rn <= 14
UNION ALL
SELECT 'Others',
       TO_NUMBER(NULL),
       NVL(SUM(h.plan_samples), 0) samples,
       NVL(ROUND(100 * SUM(h.plan_samples) / AVG(t.samples), 1), 0) percent,
       NULL sql_text
  FROM hist4 h,
       total t
WHERE h.plan_samples < t.samples / 1000 OR rn > 14
ORDER BY 3 DESC NULLS LAST;

<end node> 5P9i0s8y19Z
dt=Text
<node>
sql with mult exec. plans
4
-- 3d.339. SQL with multiple Execution Plans (DBA_HIST_SQLSTAT)

WITH
per_phv AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.339 */
       h.dbid,
       h.sql_id,
       h.plan_hash_value,
       MIN(s.begin_interval_time) min_time,
       MAX(s.end_interval_time) max_time,
       MEDIAN(h.elapsed_time_total / h.executions_total) med_time_per_exec,
       STDDEV(h.elapsed_time_total / h.executions_total) std_time_per_exec,
       AVG(h.elapsed_time_total / h.executions_total)    avg_time_per_exec,
       MIN(h.elapsed_time_total / h.executions_total)    min_time_per_exec,
       MAX(h.elapsed_time_total / h.executions_total)    max_time_per_exec,
       STDDEV(h.elapsed_time_total / h.executions_total) / AVG(h.elapsed_time_total / h.executions_total) std_dev,
       MAX(h.executions_total) executions_total,
       MEDIAN(h.elapsed_time_total / h.executions_total) * MAX(h.executions_total) total_elapsed_time
  FROM dba_hist_sqlstat h,
       dba_hist_snapshot s
 WHERE --h.snap_id BETWEEN 50934 AND 50999
  -- AND h.dbid = 4172635351
    h.sql_id='av7mhnmm017my'
   AND h.executions_total > 1
   AND h.plan_hash_value > 0
   AND s.snap_id = h.snap_id
   AND s.dbid = h.dbid
   AND s.instance_number = h.instance_number
   AND CAST(s.end_interval_time AS DATE) > SYSDATE - 31
 GROUP BY
       h.dbid,
       h.sql_id,
       h.plan_hash_value
),
ranked1 AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.339 */
       RANK () OVER (ORDER BY STDDEV(med_time_per_exec)/AVG(med_time_per_exec) DESC) rank_num1,
       dbid,
       sql_id,
       COUNT(*) plans,
       SUM(total_elapsed_time) total_elapsed_time,
       MIN(med_time_per_exec) min_med_time_per_exec,
       MAX(med_time_per_exec) max_med_time_per_exec
  FROM per_phv
 GROUP BY
       dbid,
       sql_id
HAVING COUNT(*) > 1
),
ranked2 AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.339 */
       RANK () OVER (ORDER BY r.total_elapsed_time DESC) rank_num2,
       r.rank_num1,
       r.sql_id,
       r.plans,
       p.plan_hash_value,
       TO_CHAR(CAST(p.min_time AS DATE), 'YYYY-MM-DD/HH24') min_time,
       TO_CHAR(CAST(p.max_time AS DATE), 'YYYY-MM-DD/HH24') max_time,
       ROUND(p.med_time_per_exec / 1e6, 3) med_secs_per_exec,
       p.executions_total executions,
       ROUND(p.med_time_per_exec * p.executions_total / 1e6, 3) aprox_tot_secs,
       ROUND(p.std_time_per_exec / 1e6, 3) std_secs_per_exec,
       ROUND(p.avg_time_per_exec / 1e6, 3) avg_secs_per_exec,
       ROUND(p.min_time_per_exec / 1e6, 3) min_secs_per_exec,
       ROUND(p.max_time_per_exec / 1e6, 3) max_secs_per_exec,
       REPLACE(DBMS_LOB.SUBSTR(s.sql_text, 1000), CHR(10)) sql_text
  FROM ranked1 r,
       per_phv p,
       dba_hist_sqltext s
 WHERE r.rank_num1 <= 20 * 5
   AND p.dbid = r.dbid
   AND p.sql_id = r.sql_id
   AND s.dbid(+) = r.dbid AND s.sql_id(+) = r.sql_id
)
SELECT /*+  NO_MERGE  */ /* 3d.339 */
       r.sql_id,
       r.plans,
       r.plan_hash_value,
       r.min_time,
       r.max_time,
       dbms_xplan.format_time_s(r.med_secs_per_exec)med_secs_per_exec,
       r.executions,
       dbms_xplan.format_time_s(r.aprox_tot_secs)aprox_tot_secs,
       dbms_xplan.format_time_s(r.std_secs_per_exec)std_secs_per_exec,
       dbms_xplan.format_time_s(r.avg_secs_per_exec)avg_secs_per_exec,
       dbms_xplan.format_time_s(r.min_secs_per_exec)min_secs_per_exec,
       dbms_xplan.format_time_s(r.max_secs_per_exec)max_secs_per_exec,
       r.sql_text
  FROM ranked2 r
 WHERE rank_num2 <= 20
 ORDER BY
       r.rank_num2,
       r.sql_id,
       r.min_time,
       r.plan_hash_value;


=====================================================================================================================
WITH
per_phv AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.339 */
       h.dbid,
       h.sql_id,
       h.plan_hash_value,
       MIN(s.begin_interval_time) min_time,
       MAX(s.end_interval_time) max_time,
       MEDIAN(h.elapsed_time_total / h.executions_total) med_time_per_exec,
       STDDEV(h.elapsed_time_total / h.executions_total) std_time_per_exec,
       AVG(h.elapsed_time_total / h.executions_total)    avg_time_per_exec,
       MIN(h.elapsed_time_total / h.executions_total)    min_time_per_exec,
       MAX(h.elapsed_time_total / h.executions_total)    max_time_per_exec,
       STDDEV(h.elapsed_time_total / h.executions_total) / AVG(h.elapsed_time_total / h.executions_total) std_dev,
       MAX(h.executions_total) executions_total,
       MEDIAN(h.elapsed_time_total / h.executions_total) * MAX(h.executions_total) total_elapsed_time
  FROM dba_hist_sqlstat h,
       dba_hist_snapshot s
 WHERE --h.snap_id BETWEEN 50934 AND 50999
  -- AND h.dbid = 4172635351
  h.sql_id='0qpjmtrnf1mrd'
   AND h.executions_total > 1
   AND h.plan_hash_value > 0
   AND s.snap_id = h.snap_id
   AND s.dbid = h.dbid
   AND s.instance_number = h.instance_number
   AND CAST(s.end_interval_time AS DATE) > SYSDATE - 31
 GROUP BY
       h.dbid,
       h.sql_id,
       h.plan_hash_value
),
ranked1 AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.339 */
       RANK () OVER (ORDER BY STDDEV(med_time_per_exec)/AVG(med_time_per_exec) DESC) rank_num1,
       dbid,
       sql_id,
       COUNT(*) plans,
       SUM(total_elapsed_time) total_elapsed_time,
       MIN(med_time_per_exec) min_med_time_per_exec,
       MAX(med_time_per_exec) max_med_time_per_exec
  FROM per_phv
 GROUP BY
       dbid,
       sql_id
HAVING COUNT(*) > 1
),
ranked2 AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.339 */
       RANK () OVER (ORDER BY r.total_elapsed_time DESC) rank_num2,
       r.rank_num1,
       r.sql_id,
       r.plans,
       p.plan_hash_value,
       TO_CHAR(CAST(p.min_time AS DATE), 'YYYY-MM-DD/HH24') min_time,
       TO_CHAR(CAST(p.max_time AS DATE), 'YYYY-MM-DD/HH24') max_time,
       ROUND(p.med_time_per_exec / 1e6, 3) med_secs_per_exec,
       p.executions_total executions,
       ROUND(p.med_time_per_exec * p.executions_total / 1e6, 3) aprox_tot_secs,
       ROUND(p.std_time_per_exec / 1e6, 3) std_secs_per_exec,
       ROUND(p.avg_time_per_exec / 1e6, 3) avg_secs_per_exec,
       ROUND(p.min_time_per_exec / 1e6, 3) min_secs_per_exec,
       ROUND(p.max_time_per_exec / 1e6, 3) max_secs_per_exec,
       REPLACE(DBMS_LOB.SUBSTR(s.sql_text, 1000), CHR(10)) sql_text
  FROM ranked1 r,
       per_phv p,
       dba_hist_sqltext s
 WHERE r.rank_num1 <= 20 * 5
   AND p.dbid = r.dbid
   AND p.sql_id = r.sql_id
   AND s.dbid(+) = r.dbid AND s.sql_id(+) = r.sql_id
)
SELECT /*+  NO_MERGE  */ /* 3d.339 */
       r.sql_id,
       r.plans,
       r.plan_hash_value,
       r.min_time,
       r.max_time,
       r.med_secs_per_exec,
       r.executions,
       r.aprox_tot_secs,
       r.std_secs_per_exec,
       r.avg_secs_per_exec,
       r.min_secs_per_exec,
       r.max_secs_per_exec,
       r.sql_text
  FROM ranked2 r
 WHERE rank_num2 <= 20
 ORDER BY
       r.rank_num2,
       r.sql_id,
       r.min_time,
       r.plan_hash_value;

<end node> 5P9i0s8y19Z
dt=Text
<node>
sql with chgn elapsed time per exec.
4
-- 3d.338. SQL with changing Elapsed Time per Execution (time series) (DBA_HIST_SQLSTAT) 
WITH
per_time AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.338 */
       h.dbid,
       h.sql_id,
       SYSDATE - CAST(s.end_interval_time AS DATE) days_ago,
       SUM(h.elapsed_time_total) / SUM(h.executions_total) time_per_exec
  FROM dba_hist_sqlstat h,
       dba_hist_snapshot s
 WHERE h.snap_id BETWEEN 50934 AND 50999
   AND h.dbid = 4172635351
   AND h.executions_total > 0
   AND h.plan_hash_value > 0
   AND s.snap_id = h.snap_id
   AND s.dbid = h.dbid
   AND s.instance_number = h.instance_number
   AND CAST(s.end_interval_time AS DATE) > SYSDATE - 31
 GROUP BY
       h.dbid,
       h.sql_id,
       SYSDATE - CAST(s.end_interval_time AS DATE)
),
avg_time AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.338 */
       dbid,
       sql_id,
       MEDIAN(time_per_exec) med_time_per_exec,
       STDDEV(time_per_exec) std_time_per_exec,
       AVG(time_per_exec)    avg_time_per_exec,
       MIN(time_per_exec)    min_time_per_exec,
       MAX(time_per_exec)    max_time_per_exec
  FROM per_time
 GROUP BY
       dbid,
       sql_id
HAVING COUNT(*) >= 10
   AND MAX(days_ago) - MIN(days_ago) >= 5
   AND MEDIAN(time_per_exec) > 1e4
),
time_over_median AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.338 */
       h.dbid,
       h.sql_id,
       h.days_ago,
       (h.time_per_exec / a.med_time_per_exec) time_per_exec_over_med,
       a.med_time_per_exec,
       a.std_time_per_exec,
       a.avg_time_per_exec,
       a.min_time_per_exec,
       a.max_time_per_exec
  FROM per_time h, avg_time a
 WHERE a.sql_id = h.sql_id
),
ranked AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.338 */
       RANK () OVER (ORDER BY ABS(REGR_SLOPE(t.time_per_exec_over_med, t.days_ago)) DESC) rank_num,
       t.dbid,
       t.sql_id,
       CASE WHEN REGR_SLOPE(t.time_per_exec_over_med, t.days_ago) > 0 THEN 'IMPROVING' ELSE 'REGRESSING' END change,
       ROUND(REGR_SLOPE(t.time_per_exec_over_med, t.days_ago), 3) slope,
       ROUND(AVG(t.med_time_per_exec)/1e6, 3) med_secs_per_exec,
       ROUND(AVG(t.std_time_per_exec)/1e6, 3) std_secs_per_exec,
       ROUND(AVG(t.avg_time_per_exec)/1e6, 3) avg_secs_per_exec,
       ROUND(MIN(t.min_time_per_exec)/1e6, 3) min_secs_per_exec,
       ROUND(MAX(t.max_time_per_exec)/1e6, 3) max_secs_per_exec
  FROM time_over_median t
 GROUP BY
       t.dbid,
       t.sql_id
HAVING ABS(REGR_SLOPE(t.time_per_exec_over_med, t.days_ago)) > 0.1
)
SELECT /*+  NO_MERGE  */ /* 3d.338 */
         r.rank_num
       , h.sql_id
       , h.instance_number instance_number_x
       , TO_CHAR(CAST(s.end_interval_time AS DATE), 'YYYY-MM-DD HH24:MI:SS') end_time_x
       , h.plan_hash_value plan_hash_value_x
       , h.executions_total executions_total_x
       , ROUND(h.rows_processed_total / h.executions_total) rows_per_exec
       , ROUND(h.elapsed_time_total   / h.executions_total / 1e6, 3) et_secs_per_exec
       , ROUND(h.cpu_time_total       / h.executions_total / 1e6, 3) cpu_secs_per_exec
       , ROUND(h.iowait_total         / h.executions_total / 1e6, 3) io_secs_per_exec
       , ROUND(h.clwait_total         / h.executions_total / 1e6, 3) cl_secs_per_exec
       , ROUND(h.apwait_total         / h.executions_total / 1e6, 3) ap_secs_per_exec
       , ROUND(h.ccwait_total         / h.executions_total / 1e6, 3) cc_secs_per_exec
       , ROUND(h.plsexec_time_total   / h.executions_total / 1e6, 3) pl_secs_per_exec
       , ROUND(h.javexec_time_total   / h.executions_total / 1e6, 3) ja_secs_per_exec
       , ROUND(h.buffer_gets_total    / h.executions_total) bg_per_exec
       , ROUND(h.disk_reads_total     / h.executions_total) dr_per_exec
       , ROUND(h.direct_writes_total  / h.executions_total) dw_per_exec
       , ROUND(h.physical_read_requests_total   / h.executions_total) prr_per_exec
       , ROUND(h.physical_read_bytes_total      / h.executions_total) prb_per_exec
       , ROUND(h.physical_write_requests_total  / h.executions_total) pwr_per_exec
       , ROUND(h.physical_write_bytes_total     / h.executions_total) pwb_per_exec
       , ROUND(h.io_offload_elig_bytes_total    / h.executions_total) ofb_per_exec
       , ROUND(h.io_interconnect_bytes_total    / h.executions_total) icb_per_exec
       , ROUND(h.optimized_physical_reads_total / h.executions_total) opr_per_exec
       , ROUND(h.cell_uncompressed_bytes_total  / h.executions_total) unb_per_exec
       , ROUND(h.io_offload_return_bytes_total  / h.executions_total) orb_per_exec
  FROM ranked r,
       dba_hist_sqlstat h,
       dba_hist_snapshot s
 WHERE r.rank_num <= 20
   AND h.sql_id = r.sql_id
   AND h.snap_id BETWEEN 50934 AND 50999
   AND h.dbid = 4172635351
   AND h.executions_total > 0
   AND s.snap_id = h.snap_id
   AND s.dbid = h.dbid
   AND s.instance_number = h.instance_number
 ORDER BY
       r.rank_num,
       h.sql_id,
       h.instance_number,
       s.end_interval_time,
       h.plan_hash_value;

<end node> 5P9i0s8y19Z
dt=Text
<node>
sql profile
4

-- gives detail sql profile information about the sql_id
select *
from dba_sql_profiles p, dba_hist_sqlstat s
where p.name=s.sql_profile
  and s.sql_id='1pdhqbh09gk0j'
;



--- in memory sql profile
select distinct(s.sql_id)
from dba_sql_profiles p, v$sql s
where p.name=s.sql_profile
  and s.sql_id='1pdhqbh09gk0j'
;

<end node> 5P9i0s8y19Z
dt=Text
<node>
exec. Plan
4
SELECT h.sql_id, h.plan_hash_value, h.day, h.calls, h.executions, h.rows_pro, 
    dbms_xplan.format_time_s(h.cpu_time) cpu_time, 
    dbms_xplan.format_time_s(h.elapsed) elapsed,
	round(CASE WHEN NVL(h.cpu_time,0) != 0 THEN h.rows_pro/h.cpu_time ELSE NULL END) avg_cput_row,
	round(CASE WHEN h.elapsed != 0 THEN h.rows_pro/h.elapsed ELSE NULL END) avg_elat_row
FROM 
  (
	SELECT q.dbid, q.sql_id, q.plan_hash_value,
		TRUNC(s.begin_interval_time,'DD') day,
		SUM(q.executions_delta) calls,
		SUM(q.END_OF_FETCH_COUNT_DELTA) executions,
		SUM(q.ROWS_PROCESSED_DELTA) rows_pro,
		SUM(q.CPU_TIME_DELTA)/1000000 cpu_time,
		SUM(q.ELAPSED_TIME_DELTA)/1000000 elapsed
	from dba_hist_sqlstat q,
		dba_hist_snapshot s
	where --q.dbid = 4172635351 and 
		q.sql_id = '12sz80gwt72yp' --'11y2ddmxq23yz'
		and q.dbid = s.dbid
		and q.instance_number = s.instance_number
		and q.snap_id = s.snap_id
	-- and s.begin_interval_time between sysdate-30 and sysdate
	group by q.dbid, q.sql_id, TRUNC(s.begin_interval_time,'DD'), q.plan_hash_value
   ) h
	,dba_hist_sqltext hs
WHERE h.dbid = hs.dbid
  AND h.sql_id = hs.sql_id 
  and day >= sysdate-10
ORDER BY to_date(to_char(day,'dd-mon-yy'),'dd-mon-yy') desc
;

<end node> 5P9i0s8y19Z
dt=Text
<node>
edb360
3
<end node> 5P9i0s8y19Z
dt=Text
<node>
event matrics
4
-- inspired by Kyle Hailey blogs
-- http://www.kylehailey.com/wait-event-and-wait-class-metrics-vs-vsystem_event/
-- http://www.kylehailey.com/oracle-cpu-time/
SELECT /*+  NO_MERGE  */ /* 3d.348 */
       en.wait_class,
       en.name event,
       em.*,
       ROUND(em.time_waited / em.intsize_csec, 3) aas,
       CASE WHEN en.wait_class = 'User I/O' THEN 10 * em.time_waited  / em.wait_count END avg_io_ms
  FROM gv$eventmetric em,
       gv$event_name en
 WHERE em.inst_id = en.inst_id
   AND em.event_id = en.event_id
   AND em.event# = en.event#
   AND em.time_waited > 0
   AND em.wait_count > 0
   AND en.wait_class != 'Idle'
 ORDER BY
       em.inst_id,
       en.wait_class,
       en.name;

<end node> 5P9i0s8y19Z
dt=Text
<node>
top plans
4
-- provided by David Kurtz
WITH
hist AS (
SELECT /*+  MATERIALIZE NO_MERGE   DYNAMIC_SAMPLING(4)   FULL(h.ash) FULL(h.evt) FULL(h.sn) USE_HASH(h.sn h.ash h.evt)   FULL(h.INT$DBA_HIST_ACT_SESS_HISTORY.sn) FULL(h.INT$DBA_HIST_ACT_SESS_HISTORY.ash) FULL(h.INT$DBA_HIST_ACT_SESS_HISTORY.evt)   USE_HASH(h.INT$DBA_HIST_ACT_SESS_HISTORY.sn h.INT$DBA_HIST_ACT_SESS_HISTORY.ash h.INT$DBA_HIST_ACT_SESS_HISTORY.evt)  */
       /* 3d.340 */
       h.sql_id,
       h.sql_plan_hash_value,
       h.dbid,
       COUNT(*) samples
  FROM dba_hist_active_sess_history h
 WHERE h.snap_id BETWEEN 50964 AND 51703
   AND h.dbid = 4172635351
   AND h.sql_id IS NOT NULL
   AND h.sql_plan_hash_value > 0
GROUP BY
       h.sql_id,
       h.sql_plan_hash_value,
       h.dbid
), hist2 as (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.340 */
       DISTINCT
       h.sql_id
     , h.sql_plan_hash_value
     , h.dbid
     , h.samples
     , CASE WHEN s.rowid IS NOT NULL THEN samples ELSE 0 END sql_samples
     , SUM(h.samples) over (partition by h.dbid, h.sql_plan_hash_value) plan_samples
     , DBMS_LOB.SUBSTR(s.sql_text, 1000) sql_text
  FROM hist h
    LEFT OUTER JOIN dba_hist_sqltext s
    ON s.sql_id = h.sql_id AND s.dbid = h.dbid
), hist3 AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.340 */
       hist2.*
     , ROW_NUMBER() over (partition by dbid, sql_plan_hash_value order by sql_samples DESC) sql_id_rank
   FROM hist2
), hist4 AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.340 */
       hist3.*
     , ROW_NUMBER() over (order by sql_samples DESC) rn
  FROM hist3
WHERE sql_id_rank = 1
), total AS (
SELECT /*+  MATERIALIZE NO_MERGE  */ /* 3d.340 */
       SUM(samples) samples FROM hist
)
SELECT /*+  NO_MERGE  */ /* 3d.340 */
       h.sql_id plan_top_sql_id,
       h.sql_plan_hash_value,
       h.plan_samples,
       ROUND(100 * h.plan_samples / t.samples, 1) percent,
       h.sql_text
  FROM hist4 h,
       total t
WHERE h.samples >= t.samples / 1000 AND h.rn <= 14
UNION ALL
SELECT 'Others',
       TO_NUMBER(NULL),
       NVL(SUM(h.plan_samples), 0) samples,
       NVL(ROUND(100 * SUM(h.plan_samples) / AVG(t.samples), 1), 0) percent,
       NULL sql_text
  FROM hist4 h,
       total t
WHERE h.plan_samples < t.samples / 1000 OR rn > 14
ORDER BY 3 DESC NULLS LAST;

<end node> 5P9i0s8y19Z
dt=Text
<node>
pf - DBA kevlar
3

===============================================================================================

-- Run this query on Oracle Source database to find out long running transactions.
select /*+ RULE */ 
     s.inst_id, s.SID, s.serial#, s.status, s.sql_id,
     client_identifier, start_time, s.schemaname, 
	 s.MACHINE, s.module
from gv$session s, gv$transaction t 
where s.saddr = t.ses_addr
order by start_time desc
;

-- mem_alloc.sql
--Check Memory Allocation Per User/Process
SET PAGESIZE 9999
COLUMN sid FORMAT 999 HEADING 'SID'
COLUMN oracle_username FORMAT a12 HEADING 'Oracle User' JUSTIFY right
COLUMN os_username FORMAT a9 HEADING 'O/S User' JUSTIFY right
COLUMN session_program FORMAT a18 HEADING 'Session Program' TRUNC
COLUMN session_machine FORMAT a8 HEADING 'Machine' JUSTIFY right TRUNC
COLUMN session_pga_memory FORMAT 9,999,999,999 HEADING 'PGA Memory'
COLUMN session_pga_memory_max FORMAT 9,999,999,999 HEADING 'PGA Memory Max'
COLUMN session_uga_memory FORMAT 9,999,999,999 HEADING 'UGA Memory'
COLUMN session_uga_memory_max FORMAT 9,999,999,999 HEADING 'UGA Memory MAX'
SELECT
	 s.inst_id, s.sid, s.serial#, s.sql_id,
	 lpad(s.username,12) oracle_username,
	 lpad(s.osuser,9) os_username,
	 s.program session_program,
	 lpad(s.machine,8) session_machine,
	 (select round(sum(ss.value/1024/1024)) 
		from gv$sesstat ss, gv$statname sn
		where ss.sid = s.sid 
		  and sn.statistic# = ss.statistic# 
		  and sn.name = 'session pga memory') session_pga_memory,
	 (select round(sum(ss.value/1024/1024)) 
		from gv$sesstat ss, gv$statname sn 
		where ss.sid = s.sid 
		  and sn.statistic# = ss.statistic# 
		  and sn.name = 'session pga memory max') session_pga_memory_max,
	 (select round(sum(ss.value/1024/1024)) 
		from gv$sesstat ss, gv$statname sn 
		where ss.sid = s.sid 
		  and sn.statistic# = ss.statistic# 
		  and sn.name = 'session uga memory') session_uga_memory,
	 (select round(sum(ss.value/1024/1024)) 
		from gv$sesstat ss, gv$statname sn 
		where ss.sid = s.sid 
		  and sn.statistic# = ss.statistic# 
		  and sn.name = 'session uga memory max') session_uga_memory_max
 FROM gv$session s
ORDER BY session_pga_memory DESC;


--- RMAN
--Rman Backups check Async
select device_type, type, filename, to_char(open_time, 'mm/dd/yyyy hh24:mi:ss') open,
to_char(close_time, 'mm/dd/yyyy hh24:mi:ss') close, elapsed_time ET, effective_bytes_per_second EPS
from v$backup_async_io
where close_time >sysdate -1
order by close_time desc
/

-- Check DB Object Cache Info
--Info on what is in the db object_cache
select OWNER,NAME,DB_LINK,NAMESPACE,TYPE,
	SHARABLE_MEM,LOADS,EXECUTIONS,LOCKS,PINS
  from v$db_object_cache
 where owner ='DW_PROD'
   and executions <1
 order by OWNER, NAME
/

-- User Privilege Report
SELECT DECODE(SA1.GRANTEE#, 1, 'PUBLIC', U1.NAME) User, SUBSTR(U2.NAME,1,20) “Priv Granted”,
	SUBSTR(SPM.NAME,1,27) “Role Granted”
FROM SYS.SYSAUTH$ SA1, SYS.SYSAUTH$ SA2, SYS.USER$ U1,
	SYS.USER$ U2, SYS.SYSTEM_PRIVILEGE_MAP SPM
WHERE SA1.GRANTEE# = U1.USER#
	AND SA1.PRIVILEGE# = U2.USER#
	AND U2.USER# = SA2.GRANTEE#
	AND SA2.PRIVILEGE# = SPM.PRIVILEGE
UNION
SELECT U.NAME, NULL, SUBSTR(SPM.NAME,1,27)
FROM SYS.SYSTEM_PRIVILEGE_MAP SPM, SYS.SYSAUTH$ SA, SYS.USER$ U
WHERE SA.GRANTEE#=U.USER#
	AND SA.PRIVILEGE#=SPM.PRIVILEGE


-- User Last Login
select username, count(*) "SESSIONS", trunc(last_call_et/3600) "IDLE_HOURS", module
from v$session
group by username, trunc(last_call_et/3600), module
order by 4, 3, 1;

OR


select osuser, program, count(program) "Active Count"
from v$session
where program not like '%$program%'
and (status = 'ACTIVE'
or last_call_et < 900)
group by osuser, program



--Long Running Operations, Can be detailed to SID(s)
select opname "Description", round(totalwork/60/60) "Minutes Spent", 
	round(time_remaining/60/60) "Minutes Left", sid
from v$session_longops
--where sid in (695)--,830,685,613,761,572,566,812,630,833,838,663,813,773,775,705)
where time_remaining>0
order by time_remaining desc


--Search for duplicate SQL
select distinct a.hash_value, a.sql_text 
from v$sqlarea a, v$sqlarea b, dba_users c
where a.hash_value=b.hash_value 
  and a.parsing_user_id = c.user_id
  and c.username='&OWNER'
  and a.FIRST_LOAD_TIME != b.FIRST_LOAD_TIME


--Check Full Scans in DB
COLUMN user_process FORMAT A20 HEADING "Username(Process ID)"
COLUMN short_scans FORMAT 999,999,999 HEADING "Short Scans"
COLUMN long_scans FORMAT 999,999,999 HEADING "Long Scans"
COLUMN blocks_retrieved FORMAT 999,999,999 HEADING "Blocks Retrieved"
COLUMN avr_scan_blocks FORMAT 999,999,999.99 HEADING "Avr Scan (blocks)"

SELECT SS.username || '(' || se.sid || ') ' AS user_process,
	Sum( Decode(name, 'table scans (short tables)', value) ) AS short_scans,
	Sum( Decode(name, 'table scans (long tables)', value) ) AS long_scans,
	Sum( Decode(name, 'table scan blocks gotten', value) ) AS block_retrieved,
	(Sum( Decode(name, 'table scan blocks gotten', value) ) - (Sum( Decode(name, 'table scans (short tables)', value) ) * 5)),
	Sum( Decode(name, 'table scans (long tables)', value) ) AS avr_scan_blocks
FROM v$session SS,
	v$sesstat SE,
	v$statname SN
WHERE SE.statistic# = SN.statistic#
	AND (name Like '%table scans (short tables)%'
	OR
	name Like '%table scans (long tables)%'
	OR
	name Like '%table scan blocks gotten%')
	AND SE.sid = SS.sid
	AND SS.username IS NOT NULL
GROUP BY SS.username || '(' || SE.sid || ') '
HAVING Sum( Decode(name, 'table scans (long tables)', value) ) <> 0
ORDER BY long_scans DESC;


--Check execution in Memory
select OWNER,
NAME||' - '||TYPE object,
EXECUTIONS
from v$db_object_cache
where EXECUTIONS > 100
and type in ('PACKAGE','PACKAGE BODY','FUNCTION','PROCEDURE')
and owner='&&SCHEMA'
order by EXECUTIONS desc
/


-- ASH CPU by User
SELECT sql_id, COUNT(*)
FROM gv$active_session_history ash, gv$event_name evt
WHERE ash.sample_time > SYSDATE - 5/(24*60)
AND ash.session_state = 'WAITING'
AND ash.event_id = evt.event_id
AND evt.wait_class = 'User I/O'
GROUP BY sql_id
ORDER BY COUNT(*) DESC;


-- ASH IO Waits
SELECT sql_id, COUNT(*)
FROM gv$active_session_history ash, gv$event_name evt
WHERE ash.sample_time > SYSDATE - 5/(24*60)
AND ash.session_state = 'WAITING'
AND ash.event_id = evt.event_id
AND evt.wait_class = 'User I/O'
GROUP BY sql_id
ORDER BY COUNT(*) DESC
/


-- ASH SQL_ID CPU Use
select * from (
select sql_id,  inst_id,
      sum(decode(vash.session_state,'ON CPU',1,0))  as "Number on CPU",
      sum(decode(vash.session_state,'WAITING',1,0)) as "Number Waiting on CPU"
from  gv$active_session_history vash
where sample_time > sysdate - 5 /( 60*24)
group by sql_id, inst_id
order by 3 desc
) where rownum < 11
/


-- ASH SQL_ID CPU Use
select * from (
select sql_id,  inst_id,
   sum(decode(vash.session_state,'ON CPU',1,0)) as  "ON CPU",
   sum(decode(vash.session_state,'WAITING',1,0))  as "WAITING FOR CPU",
   event , count(distinct(session_id||session_serial#)) as "SESSION COUNT"
from  gv$active_session_history vash
where sample_time > sysdate - 5 /( 60*24)
group by event ,inst_id, sql_id , event
order by 4 desc
) where rownum <11
/


--- ASH Wait for CPU
select * from (
select sql_id,  inst_id,
   sum(decode(vash.session_state,'ON CPU',1,0)) as  "ON CPU",
   sum(decode(vash.session_state,'WAITING',1,0)) as  "WAITING ON CPU" ,
   event , count(distinct(session_id||session_serial#)) as "SESSION COUNT"
from gv$active_session_history vash
where sample_time > sysdate - 5 /( 60*24)
group by event, inst_id, sql_id
order by 4 desc
) where rownum < 11
/



-- Tyler Muth ASH Resource Query
REPHEADER PAGE LEFT '~~BEGIN-MAIN-METRICS~~'
REPFOOTER PAGE LEFT '~~END-MAIN-METRICS~~'
--Tyler Muth's ASH Mining, subsection of his full set of code

 select snap_id "snap",num_interval "dur_m", end_time "end",inst "inst",
  max(decode(metric_name,'Host CPU Utilization (%)',					average,null)) "os_cpu",
  max(decode(metric_name,'Host CPU Utilization (%)',					maxval,null)) "os_cpu_max",
  max(decode(metric_name,'Database Wait Time Ratio',                   round(average,1),null)) "db_wait_ratio",
max(decode(metric_name,'Database CPU Time Ratio',                   round(average,1),null)) "db_cpu_ratio",
max(decode(metric_name,'SQL Service Response Time',                   average,null)) "sql_res_t_cs",
max(decode(metric_name,'Executions Per Sec',                        average,null)) "exec_s",
max(decode(metric_name,'Logical Reads Per Sec',                     average,null)) "l_reads_s",
max(decode(metric_name,'User Commits Per Sec',                      average,null)) "commits_s",
max(decode(metric_name,'Physical Read Total Bytes Per Sec',         round((maxval)/1024/1024,1),null)) "read_mb_s_max"
  from(
  select  snap_id,num_interval,to_char(end_time,'YY/MM/DD HH24:MI') end_time,instance_number inst,metric_name,round(average,1) average,
  round(maxval,1) maxval
 from dba_hist_sysmetric_summary
where 
snap_id between &SNAP_ID_MIN and &SNAP_ID_MAX
 and metric_name in ('Host CPU Utilization (%)','Average Active Sessions','Executions Per Sec','Hard Parse Count Per Sec','Logical Reads Per Sec','Logons Per Sec',
 'Physical Read Total Bytes Per Sec','Physical Read Total IO Requests Per Sec','Physical Write Total Bytes Per Sec','Physical Write Total IO Requests Per Sec',
 'Redo Generated Per Sec','User Commits Per Sec','Current Logons Count','DB Block Gets Per Sec','DB Block Changes Per Sec',
 'Database Wait Time Ratio','Database CPU Time Ratio','SQL Service Response Time','Background Time Per Sec'))
 group by snap_id,num_interval, end_time,inst
 order by snap_id, end_time,inst;

-- check the rman backup is running , status of rman backup
select SESSION_KEY, INPUT_TYPE, STATUS, 
	to_char(START_TIME,'mm/dd/yy hh24:mi') start_time,
	to_char(END_TIME,'mm/dd/yy hh24:mi')end_time, elapsed_seconds/3600 hrs
from V$RMAN_BACKUP_JOB_DETAILS oter
where START_TIME = (select max(start_time) from v$RMAN_BACKUP_JOB_DETAILS iner where iner.start_time = oter.start_time)-1
order by session_key;
===============================================================================================

-- Show's the currently active processes.
SELECT SUBSTR(s.USERNAME,1,8) USERNAME, s.OSUSER OSUSER,
     DECODE(s.SERVER,'DEDICATED','D','SHARED','S','O') SERVER,
     sa.DISK_READS DISK_READS, sa.BUFFER_GETS BUFFER_GETS,
     SUBSTR(s.LOCKWAIT,1,10) LOCKWAIT, s.PROCESS PID,
     sw.EVENT EVENT, sa.SQL_TEXT SQL
FROM V$SESSION_WAIT sw, V$SQLAREA sa, V$SESSION s
WHERE s.SQL_ADDRESS = sa.ADDRESS
  and s.SQL_HASH_VALUE = sa.HASH_VALUE
  and s.SID = sw.SID (+)
  and s.STATUS = 'ACTIVE'
  and sw.EVENT != 'client message'
ORDER BY s.LOCKWAIT ASC, s.USERNAME;
===============================================================================================

-- Count the load of CPU and with SQL Query
SELECT unique se.username, se.machine, ROUND (value/100) "CPU Usage", SQL_EXEC_START, LOGON_TIME, sa.DISK_READS DISK_READS,
       sa.SQL_TEXT SQL
FROM v$session se, v$sesstat ss, v$statname st, v$sqlarea sa
WHERE ss.statistic# = st.statistic#
   AND se.sid = ss.SID 
   and se.SQL_ADDRESS = sa.ADDRESS
   and se.SQL_HASH_VALUE = sa.HASH_VALUE
   and se.STATUS = 'ACTIVE'
--   and sw.EVENT != 'client message'
   AND se.username IS NOT NULL
   AND name LIKE  '%CPU used by this session%'
   and username='SYSTEM'
===============================================================================================

--- https://dbakevlar.com/scripts/

**********************************************************************
--- AWR Warehouse Scripts, (NEW!!)

-- AWRW Top IO Waits
SELECT * FROM
(
	SELECT /*+LEADING(x h) USE_NL(h)*/
	   h.sql_id, SUM(10) ash_secs
	FROM dba_hist_snapshot x,
		 dba_hist_active_sess_history h, 
		 dbsnmp.caw_dbid_mapping m
	WHERE LOWER(m.target_name) = '&dbname'
	  AND x.dbid = m.new_dbid
	  AND h.dbid = x.dbid
	  AND x.begin_interval_time > sysdate -&days_bk
	  AND h.SNAP_id = X.SNAP_id
	  AND h.instance_number = x.instance_number
	  AND h.event in  ('db file sequential read','db file scattered read')
	GROUP BY h.sql_id
	ORDER BY ash_secs desc
)
where rownum <= &num_rows;

-- AWRW Top CPU
select * from 
(
	select
		SQL_ID,
		sum(CPU_TIME_DELTA),
		sum(DISK_READS_DELTA),
		count(*)
	from DBA_HIST_SQLSTAT a, 
		 dba_hist_snapshot s, 
		 dbsnmp.caw_dbid_mapping m
	where lower(m.target_name) = '&dbname'
	  and m.new_dbid = a.dbid
	  and a.dbid = s.dbid
	  and s.snap_id = a.snap_id
	  and s.begin_interval_time > sysdate - &days_bk
	  and EXTRACT(HOUR FROM S.END_INTERVAL_TIME) between &begin_hr and &end_hr
	group by SQL_ID
	order by sum(CPU_TIME_DELTA) desc
)
where rownum <= &num_rows;

-- AWRW Analyze SQLID Data
select
	s.snap_id,
	to_char(s.begin_interval_time,'HH24:MI') "Begin Time",
	sql.executions_delta "Exec Delta",
	sql.buffer_gets_delta "Buffer Gets",
	sql.disk_reads_delta "Disk Reads",
	sql.iowait_delta "IO Waits",
	sql.cpu_time_delta "CPU Time",
	sql.elapsed_time_delta "Elapsed"
from dba_hist_sqlstat sql,
	dba_hist_snapshot s,
	dbsnmp.caw_dbid_mapping m
where lower(m.target_name) = '&dbname'
  and m.new_dbid = s.dbid
  and s.dbid = sql.dbid
  and s.snap_id = sql.snap_id
  and s.begin_interval_time > sysdate -&days_bk
  and sql.sql_id = '&sqlid'
order by "Elapsed";

-- AWRW Multiple Hash Plans for SQLID
select
  SQL_ID
, PLAN_HASH_VALUE
, sum(EXECUTIONS_DELTA) EXECUTIONS
, sum(ROWS_PROCESSED_DELTA) CROWS
, trunc(sum(CPU_TIME_DELTA)/1000000/60) CPU_MINS
, trunc(sum(ELAPSED_TIME_DELTA)/1000000/60)  ELA_MINS
from DBA_HIST_SQLSTAT S, DBSNMP.CAW_DBID_MAPPING M
where LOWER(M.TARGET_NAME) = '&dbname'
and M.NEW_DBID = S.DBID
and S.SQL_ID in ('&sqlid')
group by SQL_ID , PLAN_HASH_VALUE
order by SQL_ID, CPU_MINS;

==================================================================================
-- CPU History by DBID

set echo off feedback off timing off pause off verify off
set pagesize 500 linesize 90 trimout on trimspool on
col inst_id format 90 heading "Inst"
col begin_tm format a12 heading "Begin Time"
col end_tm format a12 heading "End Time"
col ela_secs format 999,999,990 heading "Wall-Clock|Secs|Elapsed"
col cpu_ela_secs format 999,999,990 heading "CPU Secs|Elapsed|(Secs*CPUs)"
col used_secs format 999,999,990 heading "CPU Secs|Used"
col pct format 99,990.00 heading "% Used"
col arrow format a5 heading "When?"
col name new_value V_DBNAME noprint

define V_PCT_THRESHOLD="40"

select name from v$database;
clear breaks computes
break on inst_id skip 1
compute max of pct on inst_id
--ttitle center '&&V_DBNAME - CPU Utilization by instance - daily summary' skip line

select inst_id,
	begin_tm,
	ela_secs,
	cpu_ela_secs,
	used_secs,
	pct,
	decode(greatest(this_pct,&&V_PCT_THRESHOLD),this_pct,'<==','') arrow
from	(select	inst_id,
		to_char(to_date(begin_tm,'DD-MON HH24:MI'), 'DD-MON') begin_tm,
		sum(ela_secs) ela_secs,
		sum(cpu_ela_secs) cpu_ela_secs,
		sum(used_secs) used_secs,
		(sum(used_secs)/sum(cpu_ela_secs))*100 pct,
		max(nvl(this_pct,0)) this_pct,
		max_pct
	 from	(select	inst_id,
			begin_tm,
			end_tm,
			ela_secs,
			cpu_ela_secs,
			sum(used_secs) used_secs,
			sum(pct) this_pct,
			max(sum(pct)) over () max_pct
		 from	(select	stm.instance_number inst_id,
				to_char(s.begin_interval_time,'DD-MON HH24:MI') begin_tm,
				to_char(s.end_interval_time,'DD-MON HH24:MI') end_tm,
				(to_date(to_char(s.end_interval_time,'YYYYMMDDHH24MISS'), 'YYYYMMDDHH24MISS')
				 - to_date(to_char(s.begin_interval_time,'YYYYMMDDHH24MISS'), 'YYYYMMDDHH24MISS'))*86400 ela_secs,
				((to_date(to_char(s.end_interval_time,'YYYYMMDDHH24MISS'), 'YYYYMMDDHH24MISS')
				  - to_date(to_char(s.begin_interval_time,'YYYYMMDDHH24MISS'), 'YYYYMMDDHH24MISS'))*86400)*
					p.value cpu_ela_secs,
				decode(greatest(stm.value, lag(stm.value,1,999999999999999999)
							   over (partition by	stm.dbid,
										stm.instance_number,
										stm.stat_name
								 order by	stm.snap_id)),
					999999999999999999, 0,
					stm.value, ((stm.value - lag(stm.value,1,null)
								 over (partition by	stm.dbid,
											stm.instance_number,
											stm.stat_name
									order by	stm.snap_id))/1000000),
					stm.value/1000000) used_secs,
				(decode(greatest(stm.value, lag(stm.value,1,999999999999999999)
							    over (partition by	stm.dbid,
										stm.instance_number,
										stm.stat_name
								  order by	stm.snap_id)),
					999999999999999999, 0,
					stm.value, ((stm.value - lag(stm.value,1,null)
								 over (partition by	stm.dbid,
											stm.instance_number,
											stm.stat_name
									order by	stm.snap_id))/1000000),
					stm.value/1000000) /
				 (((to_date(to_char(s.end_interval_time,'YYYYMMDDHH24MISS'), 'YYYYMMDDHH24MISS')
				    - to_date(to_char(s.begin_interval_time,'YYYYMMDDHH24MISS'), 'YYYYMMDDHH24MISS'))*86400)*p.value))
					*100 pct
			 from	dba_hist_sys_time_model stm,
				dba_hist_snapshot s,
				gv$parameter p,
                                dbsnmp.caw_dbid_mapping m
			 where	stm.stat_name in ('DB CPU','background cpu time')
                         and    LOWER(m.target_name)= '&dbname'
                         and    s.dbid= m.new_dbid
			 and	s.snap_id = stm.snap_id
			 and	s.dbid = stm.dbid
			 and	s.instance_number = stm.instance_number
			 and	p.name = 'cpu_count'
			 and	p.inst_id = s.instance_number)
		 group by inst_id,
			  begin_tm,
			  end_tm,
			  ela_secs,
			  cpu_ela_secs)
	 group by inst_id,
		  to_char(to_date(begin_tm,'DD-MON HH24:MI'), 'DD-MON'),
		  max_pct)
/*
where	max_pct >= &&V_PCT_THRESHOLD
*/
order by inst_id,
	 begin_tm;

ttitle center '&&V_DBNAME - CPU Utilization by instance - AWR snapshot detail' skip line
select	inst_id,
	begin_tm,
	end_tm,
	ela_secs,
	cpu_ela_secs,
	used_secs,
	pct,
	decode(greatest(&&V_PCT_THRESHOLD,nvl(pct,0)),pct,'<==','') 
from	(select	inst_id,
		begin_tm,
		end_tm,
		ela_secs,
		cpu_ela_secs,
		sum(used_secs) used_secs,
		sum(pct) pct,
		max(sum(pct)) over () max_pct
	 from	(select	stm.instance_number inst_id,
			to_char(s.begin_interval_time,'DD-MON HH24:MI') begin_tm,
			to_char(s.end_interval_time,'DD-MON HH24:MI') end_tm,
			(to_date(to_char(s.end_interval_time,'YYYYMMDDHH24MISS'), 'YYYYMMDDHH24MISS')
			 - to_date(to_char(s.begin_interval_time,'YYYYMMDDHH24MISS'), 'YYYYMMDDHH24MISS'))*86400 ela_secs,
			((to_date(to_char(s.end_interval_time,'YYYYMMDDHH24MISS'), 'YYYYMMDDHH24MISS')
			  - to_date(to_char(s.begin_interval_time,'YYYYMMDDHH24MISS'), 'YYYYMMDDHH24MISS'))*86400)*
				p.value cpu_ela_secs,
			decode(greatest(stm.value, lag(stm.value,1,999999999999999999)
						   over (partition by stm.dbid, stm.instance_number, stm.stat_name
							 order by stm.snap_id)),
				999999999999999999, to_number(null),
				stm.value, ((stm.value - lag(stm.value,1,null)
							 over (partition by stm.dbid, stm.instance_number, stm.stat_name
								order by stm.snap_id))/1000000),
				stm.value/1000000) used_secs,
			(decode(greatest(stm.value, lag(stm.value,1,999999999999999999)
						    over (partition by stm.dbid, stm.instance_number, stm.stat_name
							  order by stm.snap_id)),
				999999999999999999, to_number(null),
				stm.value, ((stm.value - lag(stm.value,1,null)
							 over (partition by stm.dbid, stm.instance_number, stm.stat_name
								order by stm.snap_id))/1000000),
				stm.value/1000000) /
			 (((to_date(to_char(s.end_interval_time,'YYYYMMDDHH24MISS'), 'YYYYMMDDHH24MISS')
			    - to_date(to_char(s.begin_interval_time,'YYYYMMDDHH24MISS'), 'YYYYMMDDHH24MISS'))*86400)*p.value))
				*100 pct
		 from	dba_hist_sys_time_model stm,
			dba_hist_snapshot s,
			gv$parameter p,
                        dbsnmp.CAW_DBID_MAPPING m
		 where	stm.stat_name in ('DB CPU','background cpu time')
                 and    LOWER(m.target_name)= '&&dbname'
                 and    s.dbid=m.new_dbid
		 and	s.snap_id = stm.snap_id
		 and	s.dbid = stm.dbid
		 and	s.instance_number = stm.instance_number
		 and	p.name = 'cpu_count'
		 and	p.inst_id = s.instance_number)
	 group by inst_id,
		  begin_tm,
		  end_tm,
		  ela_secs,
		  cpu_ela_secs)
/*
where	max_pct >= &&V_PCT_THRESHOLD
*/
order by inst_id,
	 begin_tm;

clear breaks computes
set feedback 6 pagesize 100 linesize 130 verify on
ttitle off
==================================================================================

-- High Level AWR Data by DBID and Instance
set echo off verify off

COLUMN blocksize NEW_VALUE _blocksize NOPRINT
select distinct block_size blocksize from v$datafile;

COLUMN dbid NEW_VALUE _dbid NOPRINT
select new_dbid from dbsnmp.caw_dbid_mapping
where lower(target_name)= '&dbname';
--select dbid from v$database;

COLUMN instancenumber NEW_VALUE _instancenumber NOPRINT
select instance_number from  DBA_HIST_DATABASE_INSTANCE I, dbsnmp.caw_dbid_mapping m
where I.DBID=m.new_dbid 
AND lower(m.target_name)= '&dbname';
--select instance_number instancenumber from v$instance;

ttitle center 'AWR CPU and IO Workload Report' skip 2
set pagesize 50000
set linesize 250

col tm          format a15              heading "Snap|Start|Time"
col id          format 99999            heading "Snap|ID"
col inst        format 90               heading "i|n|s|t|#"
col dur         format 999990.00        heading "Snap|Dur|(m)"
col cpu         format 90               heading "C|P|U"
col cap         format 9999990.00       heading "***|Total|CPU|Time|(s)"
col dbt         format 999990.00        heading "DB|Time"
col dbc         format 99990.00         heading "DB|CPU"
col bgc         format 99990.00         heading "Bg|CPU"
col rman        format 9990.00          heading "RMAN|CPU"
col aas         format 90.0             heading "A|A|S"
col totora      format 9999990.00       heading "***|Total|Oracle|CPU|(s)"
col busy        format 9999990.00       heading "Busy|Time"
col load        format 990.00           heading "OS|Load"
col totos       format 9999990.00       heading "***|Total|OS|CPU|(s)"
col mem         format 999990.00        heading "Physical|Memory|(mb)"
col IORs        format 9990.000         heading "IOPs|r"
col IOWs        format 9990.000         heading "IOPs|w"
col IORedo      format 9990.000         heading "IOPs|redo"
col IORmbs      format 9990.000         heading "IO r|(mb)/s"
col IOWmbs      format 9990.000         heading "IO w|(mb)/s"
col redosizesec format 9990.000         heading "Redo|(mb)/s"
col logons      format 990              heading "Sess"
col logone      format 990              heading "Sess|End"
col exsraw      format 99990.000        heading "Exec|raw|delta"
col exs         format 9990.000         heading "Exec|/s"
col oracpupct   format 990              heading "Oracle|CPU|%"
col rmancpupct  format 990              heading "RMAN|CPU|%"
col oscpupct    format 990              heading "OS|CPU|%"
col oscpuusr    format 990              heading "U|S|R|%"
col oscpusys    format 990              heading "S|Y|S|%"
col oscpuio     format 990              heading "I|O|%"

SELECT s0.snap_id id,
  TO_CHAR(s0.END_INTERVAL_TIME,'YY/MM/DD HH24:MI') tm,
  s0.instance_number inst,
  round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                  + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                  + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                  + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2) dur,
  s3t1.value AS cpu,
  (round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                  + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                  + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                  + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2)*60)*s3t1.value cap,
  (s5t1.value - s5t0.value) / 1000000 as dbt,
  (s6t1.value - s6t0.value) / 1000000 as dbc,
  (s7t1.value - s7t0.value) / 1000000 as bgc,
  round(DECODE(s8t1.value,null,'null',(s8t1.value - s8t0.value) / 1000000),2) as rman,
  ((s5t1.value - s5t0.value) / 1000000)/60 /  round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                  + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                  + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                  + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2) aas,
  round(((s6t1.value - s6t0.value) / 1000000) + ((s7t1.value - s7t0.value) / 1000000),2) totora,
  round(s2t1.value,2) AS load,
  (s1t1.value - s1t0.value)/100 AS totos,
  s4t1.value/1024/1024 AS mem, 
   ((s15t1.value - s15t0.value)  / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                  + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                  + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                  + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2))*60)
    ) as IORs, 
   ((s16t1.value - s16t0.value)  / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                  + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                  + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                  + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2))*60)
    ) as IOWs, 
   ((s13t1.value - s13t0.value)  / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                  + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                  + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                  + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2))*60)
    ) as IORedo, 
   (((s11t1.value - s11t0.value)* &_blocksize)/1024/1024)  / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                  + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                  + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                  + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2))*60) 
      as IORmbs, 
   (((s12t1.value - s12t0.value)* &_blocksize)/1024/1024)  / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                  + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                  + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                  + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2))*60) 
      as IOWmbs, 
   ((s14t1.value - s14t0.value)/1024/1024)  / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                  + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                  + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                  + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2))*60)
     as redosizesec, 
     s9t0.value logons, 
  -- s9t1.value logone,    -- logons end value
   ((s10t1.value - s10t0.value)  / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                  + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                  + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                  + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2))*60)
    ) as exs, 
  ((round(((s6t1.value - s6t0.value) / 1000000) + ((s7t1.value - s7t0.value) / 1000000),2)) / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                                                                              + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                                                                              + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                                                                              + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2)*60)*s3t1.value))*100 as oracpupct,
  ((round(DECODE(s8t1.value,null,'null',(s8t1.value - s8t0.value) / 1000000),2)) / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                                                                              + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                                                                              + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                                                                              + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2)*60)*s3t1.value))*100 as rmancpupct,
  (((s1t1.value - s1t0.value)/100) / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                                                                              + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                                                                              + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                                                                              + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2)*60)*s3t1.value))*100 as oscpupct,
  (((s17t1.value - s17t0.value)/100) / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                                                                              + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                                                                              + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                                                                              + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2)*60)*s3t1.value))*100 as oscpuusr,
  (((s18t1.value - s18t0.value)/100) / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                                                                              + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                                                                              + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                                                                              + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2)*60)*s3t1.value))*100 as oscpusys,
  (((s19t1.value - s19t0.value)/100) / ((round(EXTRACT(DAY FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 1440 
                                                                                              + EXTRACT(HOUR FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) * 60 
                                                                                              + EXTRACT(MINUTE FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) 
                                                                                              + EXTRACT(SECOND FROM s1.END_INTERVAL_TIME - s0.END_INTERVAL_TIME) / 60, 2)*60)*s3t1.value))*100 as oscpuio
FROM dba_hist_snapshot s0,
  dba_hist_snapshot s1,
  dba_hist_osstat s1t0,         -- BUSY_TIME
  dba_hist_osstat s1t1,
  dba_hist_osstat s17t0,        -- USER_TIME
  dba_hist_osstat s17t1,
  dba_hist_osstat s18t0,        -- SYS_TIME
  dba_hist_osstat s18t1,
  dba_hist_osstat s19t0,        -- IOWAIT_TIME
  dba_hist_osstat s19t1,
  dba_hist_osstat s2t1,         -- osstat just get the end value
  dba_hist_osstat s3t1,         -- osstat just get the end value
  dba_hist_osstat s4t1,         -- osstat just get the end value 
  dba_hist_sys_time_model s5t0,
  dba_hist_sys_time_model s5t1,
  dba_hist_sys_time_model s6t0,
  dba_hist_sys_time_model s6t1,
  dba_hist_sys_time_model s7t0,
  dba_hist_sys_time_model s7t1,
  dba_hist_sys_time_model s8t0,
  dba_hist_sys_time_model s8t1,
  dba_hist_sysstat s9t0,        -- logons current, sysstat absolute value should not be diffed
  dba_hist_sysstat s9t1,        
  dba_hist_sysstat s10t0,       -- execute count, diffed
  dba_hist_sysstat s10t1,
  dba_hist_sysstat s11t0,       -- physical reads, diffed
  dba_hist_sysstat s11t1,
  dba_hist_sysstat s12t0,       -- physical writes, diffed
  dba_hist_sysstat s12t1,
  dba_hist_sysstat s13t0,       -- redo writes, diffed
  dba_hist_sysstat s13t1,
  dba_hist_sysstat s14t0,       -- redo size, diffed
  dba_hist_sysstat s14t1,
  dba_hist_sysstat s15t0,       -- physical read IO requests, diffed
  dba_hist_sysstat s15t1,
  dba_hist_sysstat s16t0,       -- physical write IO requests, diffed
  dba_hist_sysstat s16t1,
  dbsnmp.caw_dbid_mapping m     -- to use with the AWR Warehouse- KP
WHERE s0.dbid            = &_dbid    -- Now the join for the AWR Warehouse
AND s1.dbid              = s0.dbid
AND s1t0.dbid            = s0.dbid
AND s1t1.dbid            = s0.dbid
AND s2t1.dbid            = s0.dbid
AND s3t1.dbid            = s0.dbid
AND s4t1.dbid            = s0.dbid
AND s5t0.dbid            = s0.dbid
AND s5t1.dbid            = s0.dbid
AND s6t0.dbid            = s0.dbid
AND s6t1.dbid            = s0.dbid
AND s7t0.dbid            = s0.dbid
AND s7t1.dbid            = s0.dbid
AND s8t0.dbid            = s0.dbid
AND s8t1.dbid            = s0.dbid
AND s9t0.dbid            = s0.dbid
AND s9t1.dbid            = s0.dbid
AND s10t0.dbid            = s0.dbid
AND s10t1.dbid            = s0.dbid
AND s11t0.dbid            = s0.dbid
AND s11t1.dbid            = s0.dbid
AND s12t0.dbid            = s0.dbid
AND s12t1.dbid            = s0.dbid
AND s13t0.dbid            = s0.dbid
AND s13t1.dbid            = s0.dbid
AND s14t0.dbid            = s0.dbid
AND s14t1.dbid            = s0.dbid
AND s15t0.dbid            = s0.dbid
AND s15t1.dbid            = s0.dbid
AND s16t0.dbid            = s0.dbid
AND s16t1.dbid            = s0.dbid
AND s17t0.dbid            = s0.dbid
AND s17t1.dbid            = s0.dbid
AND s18t0.dbid            = s0.dbid
AND s18t1.dbid            = s0.dbid
AND s19t0.dbid            = s0.dbid
AND s19t1.dbid            = s0.dbid
AND s0.instance_number   = &_instancenumber   -- CHANGE THE INSTANCE_NUMBER HERE!
AND s1.instance_number   = s0.instance_number
AND s1t0.instance_number = s0.instance_number
AND s1t1.instance_number = s0.instance_number
AND s2t1.instance_number = s0.instance_number
AND s3t1.instance_number = s0.instance_number
AND s4t1.instance_number = s0.instance_number
AND s5t0.instance_number = s0.instance_number
AND s5t1.instance_number = s0.instance_number
AND s6t0.instance_number = s0.instance_number
AND s6t1.instance_number = s0.instance_number
AND s7t0.instance_number = s0.instance_number
AND s7t1.instance_number = s0.instance_number
AND s8t0.instance_number = s0.instance_number
AND s8t1.instance_number = s0.instance_number
AND s9t0.instance_number = s0.instance_number
AND s9t1.instance_number = s0.instance_number
AND s10t0.instance_number = s0.instance_number
AND s10t1.instance_number = s0.instance_number
AND s11t0.instance_number = s0.instance_number
AND s11t1.instance_number = s0.instance_number
AND s12t0.instance_number = s0.instance_number
AND s12t1.instance_number = s0.instance_number
AND s13t0.instance_number = s0.instance_number
AND s13t1.instance_number = s0.instance_number
AND s14t0.instance_number = s0.instance_number
AND s14t1.instance_number = s0.instance_number
AND s15t0.instance_number = s0.instance_number
AND s15t1.instance_number = s0.instance_number
AND s16t0.instance_number = s0.instance_number
AND s16t1.instance_number = s0.instance_number
AND s17t0.instance_number = s0.instance_number
AND s17t1.instance_number = s0.instance_number
AND s18t0.instance_number = s0.instance_number
AND s18t1.instance_number = s0.instance_number
AND s19t0.instance_number = s0.instance_number
AND s19t1.instance_number = s0.instance_number
AND s1.snap_id           = s0.snap_id + 1
AND s1t0.snap_id         = s0.snap_id
AND s1t1.snap_id         = s0.snap_id + 1
AND s2t1.snap_id         = s0.snap_id + 1
AND s3t1.snap_id         = s0.snap_id + 1
AND s4t1.snap_id         = s0.snap_id + 1
AND s5t0.snap_id         = s0.snap_id
AND s5t1.snap_id         = s0.snap_id + 1
AND s6t0.snap_id         = s0.snap_id
AND s6t1.snap_id         = s0.snap_id + 1
AND s7t0.snap_id         = s0.snap_id
AND s7t1.snap_id         = s0.snap_id + 1
AND s8t0.snap_id         = s0.snap_id
AND s8t1.snap_id         = s0.snap_id + 1
AND s9t0.snap_id         = s0.snap_id
AND s9t1.snap_id         = s0.snap_id + 1
AND s10t0.snap_id         = s0.snap_id
AND s10t1.snap_id         = s0.snap_id + 1
AND s11t0.snap_id         = s0.snap_id
AND s11t1.snap_id         = s0.snap_id + 1
AND s12t0.snap_id         = s0.snap_id
AND s12t1.snap_id         = s0.snap_id + 1
AND s13t0.snap_id         = s0.snap_id
AND s13t1.snap_id         = s0.snap_id + 1
AND s14t0.snap_id         = s0.snap_id
AND s14t1.snap_id         = s0.snap_id + 1
AND s15t0.snap_id         = s0.snap_id
AND s15t1.snap_id         = s0.snap_id + 1
AND s16t0.snap_id         = s0.snap_id
AND s16t1.snap_id         = s0.snap_id + 1
AND s17t0.snap_id         = s0.snap_id
AND s17t1.snap_id         = s0.snap_id + 1
AND s18t0.snap_id         = s0.snap_id
AND s18t1.snap_id         = s0.snap_id + 1
AND s19t0.snap_id         = s0.snap_id
AND s19t1.snap_id         = s0.snap_id + 1
AND s1t0.stat_name       = 'BUSY_TIME'
AND s1t1.stat_name       = s1t0.stat_name
AND s17t0.stat_name       = 'USER_TIME'
AND s17t1.stat_name       = s17t0.stat_name
AND s18t0.stat_name       = 'SYS_TIME'
AND s18t1.stat_name       = s18t0.stat_name
AND s19t0.stat_name       = 'IOWAIT_TIME'
AND s19t1.stat_name       = s19t0.stat_name
AND s2t1.stat_name       = 'LOAD'
AND s3t1.stat_name       = 'NUM_CPUS'
AND s4t1.stat_name       = 'PHYSICAL_MEMORY_BYTES'
AND s5t0.stat_name       = 'DB time'
AND s5t1.stat_name       = s5t0.stat_name
AND s6t0.stat_name       = 'DB CPU'
AND s6t1.stat_name       = s6t0.stat_name
AND s7t0.stat_name       = 'background cpu time'
AND s7t1.stat_name       = s7t0.stat_name
AND s8t0.stat_name       = 'RMAN cpu time (backup/restore)'
AND s8t1.stat_name       = s8t0.stat_name
AND s9t0.stat_name       = 'logons current'
AND s9t1.stat_name       = s9t0.stat_name
AND s10t0.stat_name       = 'execute count'
AND s10t1.stat_name       = s10t0.stat_name
AND s11t0.stat_name       = 'physical reads'
AND s11t1.stat_name       = s11t0.stat_name
AND s12t0.stat_name       = 'physical writes'
AND s12t1.stat_name       = s12t0.stat_name
AND s13t0.stat_name       = 'redo writes'
AND s13t1.stat_name       = s13t0.stat_name
AND s14t0.stat_name       = 'redo size'
AND s14t1.stat_name       = s14t0.stat_name
AND s15t0.stat_name       = 'physical read IO requests'
AND s15t1.stat_name       = s15t0.stat_name
AND s16t0.stat_name       = 'physical write IO requests'
AND s16t1.stat_name       = s16t0.stat_name
ORDER BY id ASC;

<end node> 5P9i0s8y19Z
dt=Text
<node>
baseline sqls
3
<end node> 5P9i0s8y19Z
dt=Text
<node>
baseline_fga
4

-- recreate user test

conn / as sysdba

drop user test cascade;

create user test identified by test;
grant dba to test;


-- connect as test and create a table and an index on the table; gather statistics on these objects:
conn test/test

-- table 1 
create table test.t1 
(col1  number 
,col2  varchar2(50) 
,flag  varchar2(1)); 
 
insert into test.t1 
select rownum 
,      lpad(rownum,50,rownum) 
,      case when mod(rownum,10000) = 0 
            then 'Y' 
            else 'N' 
       end 
from   dual 
connect by rownum <= 100000; 
 
create index test.i1 on test.t1 (col1);
exec dbms_stats.gather_table_stats('TEST','T1',cascade=>true); 

-- Test the introduction of the FGA over queries with plan stability enabled.
-- The baselines are disabled and this is the expected behavior.

-- check the execution plan for a simple query. Expected: index access.

conn test/test
set linesize 150
set pagesize 300
select t1.* from t1 where t1.col1=100;
	
-- the plan details are exposed using the query below. Note the SQL ID and the Plan hash value (PHV):
	
select * from table(dbms_xplan.display_cursor(format=>'+OUTLINE'));

PLAN_TABLE_OUTPUT
------------------------------------------------------------------------------------------------------------------------------------------------------
SQL_ID  cm4srnxmzrx2s, child number 0
-------------------------------------
select t1.* from t1 where t1.col1=100

Plan hash value: 37133972

--------------------------------------------------------------------------------------------
| Id  | Operation                           | Name | Rows  | Bytes | Cost (%CPU)| Time     |
--------------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT                    |      |       |       |     2 (100)|          |
|   1 |  TABLE ACCESS BY INDEX ROWID BATCHED| T1   |     1 |    58 |     2   (0)| 00:00:01 |
|*  2 |   INDEX RANGE SCAN                  | I1   |     1 |       |     1   (0)| 00:00:01 |
--------------------------------------------------------------------------------------------

-- enforce another plan using baselines, which is use FTS instead of the INDEX RANGE SCAN.
-- For this purpose, follow the note:
-- Loading Hinted Execution Plans into SQL Plan Baseline. (Doc ID 787692.1)
	
--1- Capture sql plan baseline for the original SQL .

-- check existing baselines:
select sql_text, sql_handle, plan_name, enabled, accepted from dba_sql_plan_baselines;

-- clean up existing baselines:
DECLARE
	cursor bsln_crs IS 
		select sql_text, sql_handle, plan_name, enabled, accepted from dba_sql_plan_baselines;
	res number;
BEGIN
	FOR bsln_rec IN bsln_crs LOOP
		res:=DBMS_SPM.DROP_SQL_PLAN_BASELINE(bsln_rec.sql_handle,bsln_rec.plan_name);
	END LOOP;
END;
/

-- generate the default plan and create a baseline for it (use the queries indicated above to get the SQL ID and the PHV):

select t1.* from t1 where t1.col1=100;

DECLARE
	res number ;
BEGIN
	res := dbms_spm.load_plans_from_cursor_cache(sql_id => 'cm4srnxmzrx2s', plan_hash_value => '37133972' );
END;
/

-- verify the creation of the baseline and its usage:
select sql_text, sql_handle, plan_name, enabled, accepted from dba_sql_plan_baselines;

SQL_TEXT
--------------------------------------------------------------------------------
SQL_HANDLE
--------------------------------------------------------------------------------------------------------------------------------
PLAN_NAME                                                                                                                        ENA ACC
-------------------------------------------------------------------------------------------------------------------------------- --- ---
select t1.* from t1 where t1.col1=100
SQL_7e1b5bfc71618c48
SQL_PLAN_7w6uvzjsq332870ebf2ed                                                                                                   YES YES

select t1.* from t1 where t1.col1=100;
select * from table(dbms_xplan.display_cursor(format=>'+OUTLINE'));


-- 2- Execute the hinted SQL. Force the FTS and create a new baseline for it using the above captured one:
select /*+ FULL(T1) */ t1.* from t1 where t1.col1=100;

-- 3- Find the SQL_ID and plan_hash_value from V$SQL or directly running this command after the SQL is successfully completed ( keep note of the SQL_ID and plan_hash_value for the hinted SQL , these will be used in step5)

select * from table(dbms_xplan.display_cursor);

PLAN_TABLE_OUTPUT
------------------------------------------------------------------------------------------------------------------------------------------------------
SQL_ID  532xgdgmwnsuw, child number 0
-------------------------------------
select /*+ FULL(T1) */ t1.* from t1 where t1.col1=100

Plan hash value: 3617692013

--------------------------------------------------------------------------
| Id  | Operation         | Name | Rows  | Bytes | Cost (%CPU)| Time     |
--------------------------------------------------------------------------
|   0 | SELECT STATEMENT  |      |       |       |   239 (100)|          |
|*  1 |  TABLE ACCESS FULL| T1   |     1 |    58 |   239   (1)| 00:00:01 |
--------------------------------------------------------------------------

Predicate Information (identified by operation id):
---------------------------------------------------

   1 - filter("T1"."COL1"=100)

-- 4- Verify original SQL baseline exist . ( keep note of the sql_handle for the original SQL, will be used in step5 )

select sql_text, sql_handle, plan_name, enabled, accepted from dba_sql_plan_baselines;
SQL_TEXT
--------------------------------------------------------------------------------
SQL_HANDLE
--------------------------------------------------------------------------------------------------------------------------------
PLAN_NAME                                                                                                                        ENA ACC
-------------------------------------------------------------------------------------------------------------------------------- --- ---
select t1.* from t1 where t1.col1=100
SQL_7e1b5bfc71618c48
SQL_PLAN_7w6uvzjsq332870ebf2ed                                                                                                   YES YES


-- 5- Associate the hinted execution plan to the original sql_handle.

DECLARE
	res number;
BEGIN
	res := dbms_spm.load_plans_from_cursor_cache( 
	sql_id => '532xgdgmwnsuw', 
	plan_hash_value => 3617692013, 
	sql_handle => 'SQL_7e1b5bfc71618c48');
END;
/

-- 6- Verify the new baseline was added.

select sql_text, sql_handle, plan_name, enabled, accepted,created from dba_sql_plan_baselines;

--7- If the plan captured initially is not needed, it can be dropped, or disabled.

DECLARE
	res number;
BEGIN
	res := DBMS_SPM.DROP_SQL_PLAN_BASELINE (
	sql_handle => 'SQL_7e1b5bfc71618c48',
	plan_name => 'SQL_PLAN_7w6uvzjsq332870ebf2ed');
END;
/

-- 8- Execute the SQL from application and verify that SQL is now using the the SQL Plan baseline, run the SQL against V$SQL

conn test/test
select t1.* from t1 where t1.col1=100;
select * from table(dbms_xplan.display_cursor(format=>'+OUTLINE'));

-- 9- Create the FGA policy

BEGIN
	sys.DBMS_FGA.ADD_POLICY(
	object_schema => 'TEST',
	object_name => 'T1',
	policy_name => 'TEST_T1', 
	audit_condition => 'FLAG=''Y''', 
	audit_column => 'FLAG', 
	enable => TRUE, 
	statement_types => 'select,insert,update,delete',
	audit_column_opts=>dbms_fga.any_columns);
END;
/

-- 10- The baseline is no longer used; the plan switches back to INDEX RANGE SCAN:
conn test/test
select t1.* from t1 where t1.col1=100;
select * from table(dbms_xplan.display_cursor(format=>'+OUTLINE'));

-- Up to this point, the behavior is the one that is expected. Introducing FGA over plan stability is supposed to function this way, because the FGA is introducing, transparently, a SYS_AUDIT filter that alters the query blocks.

-- Test the creation of baselines on tables with FGA enabled. The expected behavior is to use the baseline, but this is not happening.
-- This is the subject of Bug 25659655 - FGA DISABLES THE USAGE OF BASELINES

-- 1- Clean the baselines:
select sql_text, sql_handle, plan_name, enabled, accepted from dba_sql_plan_baselines;

DECLARE
	cursor bsln_crs IS 
		select sql_text, sql_handle, plan_name, enabled, accepted from dba_sql_plan_baselines;
	res number;
BEGIN
	FOR bsln_rec IN bsln_crs LOOP
		res:=DBMS_SPM.DROP_SQL_PLAN_BASELINE(bsln_rec.sql_handle,bsln_rec.plan_name);
	END LOOP;
END;
/ 


-- 2- Capture sql plan baseline for the original SQL with FGA enabled .

conn test/test
select t1.* from t1 where t1.col1=100;
select * from table(dbms_xplan.display_cursor(format=>'+OUTLINE'));

DECLARE
	res number ;
BEGIN
	res := dbms_spm.load_plans_from_cursor_cache(sql_id => 'cm4srnxmzrx2s', plan_hash_value => '32162156' );
END;
/

SQL_TEXT
--------------------------------------------------------------------------------
SQL_HANDLE
--------------------------------------------------------------------------------------------------------------------------------
PLAN_NAME                                                                                                                        ENA ACC
-------------------------------------------------------------------------------------------------------------------------------- --- ---
select t1.* from t1 where t1.col1=100
SQL_7e1b5bfc71618c48
SQL_PLAN_7w6uvzjsq33285b575b6a                                                                                                   YES YES


-- 3- Execute the hinted SQL.
select /*+ FULL(T1) */ t1.* from t1 where t1.col1=100;

--4- Find the SQL_ID and plan_hash_value from V$SQL or directly running this command after the SQL is successfully completed ( keep note of the SQL_ID and plan_hash_value for the hinted SQL , these will be used at step5)

select * from table(dbms_xplan.display_cursor(format=>'+OUTLINE'));

PLAN_TABLE_OUTPUT
--------------------------------------------------------------------------------
SQL_ID  532xgdgmwnsuw, child number 0
-------------------------------------
select /*+ FULL(T1) */ t1.* from t1 where t1.col1=100

Plan hash value: 3332582666

-- 5- Verify original SQL baseline exist . ( keep note of the sql_handle for the original SQL, will be used in step5 )

select sql_text, sql_handle, plan_name, enabled, accepted, created from dba_sql_plan_baselines;


SQL_TEXT
--------------------------------------------------------------------------------
SQL_HANDLE
--------------------------------------------------------------------------------
PLAN_NAME
--------------------------------------------------------------------------------
ENA ACC
--- ---
select t1.* from t1 where t1.col1=100
SQL_7e1b5bfc71618c48
SQL_PLAN_7w6uvzjsq33285b575b6a                                                                                                   YES YES
                                                                                          YES YES
-- 6- Associate the hinted execution plan to the original sql_handle.

DECLARE
	res number;
BEGIN
	res := dbms_spm.load_plans_from_cursor_cache( 
		sql_id => '532xgdgmwnsuw', 
		plan_hash_value => 3332582666, 
		sql_handle => 'SQL_7e1b5bfc71618c48');
END;
/

--7- Verify the new baseline was added.

set linesize 150
select sql_text, sql_handle, plan_name, enabled, accepted, created from dba_sql_plan_baselines order by created;


-- 8- If the original plan captured initially is not needed, it can be dropped, or disabled.

DECLARE
	res number;
BEGIN
	res :=DBMS_SPM.DROP_SQL_PLAN_BASELINE ('SQL_7e1b5bfc71618c48','SQL_PLAN_7w6uvzjsq33285b575b6a');
END;
/

-- 9- Execute the SQL from application and verify that SQL is now using the the SQL Plan baseline
select t1.* from t1 where t1.col1=100;
select * from table(dbms_xplan.display_cursor(format=>'+OUTLINE'));

PLAN_TABLE_OUTPUT
------------------------------------------------------------------------------------------------------------------------------------------------------
SQL_ID  cm4srnxmzrx2s, child number 1
-------------------------------------
select t1.* from t1 where t1.col1=100

Plan hash value: 32162156

---------------------------------------------------------------------------------------------
| Id  | Operation                            | Name | Rows  | Bytes | Cost (%CPU)| Time     |
---------------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT                     |      |       |       |     2 (100)|          |
|*  1 |  FILTER                              |      |       |       |            |          |
|   2 |   TABLE ACCESS BY INDEX ROWID BATCHED| T1   |     1 |    58 |     2   (0)| 00:00:01 |
|*  3 |    INDEX RANGE SCAN                  | I1   |     1 |       |     1   (0)| 00:00:01 |
---------------------------------------------------------------------------------------------

-- As seen above, despite the baseline being enforced after the FGA, it is still not being employed by the query.

<end node> 5P9i0s8y19Z
dt=Text
<node>
SQL Basline
4
-- url
http://cheatsheet4oracledba.blogspot.com/2014/07/my-query-is-picking-bad-execution-plan.html


col sql_handle for a30
col plan_name for a40
select sql_handle, plan_name, enabled, accepted, fixed 
  from dba_sql_plan_baselines;

-- Oracle 11g – How to force a sql_id to use a plan_hash_value using SQL Baselines

select 
	DBMS_SQLTUNE.REPORT_SQL_MONITOR (type=>'HTML',report_level=>'ALL',sql_id=>'939abmqmvcc4d') as report
FROM dual; 


/* 
	Set up a SQL Baseline using known-good plan, sourced from AWR snapshots
 
	In this example, sql_id is 939abmqmvcc4d and the plan_hash_value of the good plan that we 
	want to force is 1239572551
*/

-- Drop SQL Tuning Set (STS)
-- this will drop any sqlset_name which has been created previously
-- with name MySTS01
BEGIN
  DBMS_SQLTUNE.DROP_SQLSET(sqlset_name => 'MySTS01');
END;
/
 
-- Create SQL Tuning Set (STS)
BEGIN
  DBMS_SQLTUNE.CREATE_SQLSET
   (
  	 sqlset_name => 'MySTS01',
     description => 'SQL Tuning Set for loading plan into SQL Plan Baseline'
   );
END;
/
 
-- Populate STS from AWR, using a time duration when the desired plan was used
--  List out snapshot times using :   SELECT SNAP_ID, BEGIN_INTERVAL_TIME, END_INTERVAL_TIME FROM dba_hist_snapshot ORDER BY END_INTERVAL_TIME DESC;
--  Specify the sql_id in the basic_filter (other predicates are available, see documentation)
DECLARE
  cur sys_refcursor;
BEGIN
  OPEN cur FOR
    SELECT VALUE(P)
      FROM TABLE(
      			  dbms_sqltune.select_workload_repository
      			  				(
      			  					begin_snap=>22673, 
      			  					end_snap=>22710,
      			  					basic_filter=>'sql_id = ''939abmqmvcc4d''',
      			  					attribute_list=>'ALL'
      			  				)
               ) p;
     DBMS_SQLTUNE.LOAD_SQLSET( sqlset_name=> 'MySTS01', populate_cursor=>cur);
  CLOSE cur;
END;
/
 
-- List out SQL Tuning Set contents to check we got what we wanted
SELECT
	first_load_time, executions as execs, parsing_schema_name,
	elapsed_time  / 1000000 as elapsed_time_secs,
	cpu_time / 1000000 as cpu_time_secs, buffer_gets, disk_reads,
	direct_writes, rows_processed, fetches, optimizer_cost,
	sql_plan, plan_hash_value, sql_id, sql_text
  FROM TABLE(DBMS_SQLTUNE.SELECT_SQLSET(sqlset_name => 'MySTS01'));
 
-- List out the Baselines to see what's there
SELECT * FROM dba_sql_plan_baselines ;
 
-- Load desired plan from STS as SQL Plan Baseline
-- Filter explicitly for the plan_hash_value here if you want
DECLARE
	my_plans pls_integer;
BEGIN
	my_plans := DBMS_SPM.LOAD_PLANS_FROM_SQLSET
	 (
		sqlset_name => 'MySTS01', 
		basic_filter=>'plan_hash_value = ''1239572551'''
	 );
END;
/
 
-- List out the Baselines
SELECT * FROM dba_sql_plan_baselines ; 

<end node> 5P9i0s8y19Z
dt=Text
<node>
baseline sqls2
3
-- awr-trans-counts.sql
-- see: 'How to Calculate the Number of Transactions in a Database (Doc ID 1292114.1)'
-- Jared Still - still@pythian.com jkstill@gmail.com
-- Pythian 
-- 2016-05-18 initial script
--
-- also included are redo log synch write waits, as that is the overhead wait caused by commit
col instance_number head 'I#' format 999
col begin_interval_time format a30 
col end_interval_time format a30 


with deltas as (
select
	snap.instance_number
	, to_char(trunc(snap.begin_interval_time),'yyyy-mm-dd') snap_date
	--, snap.end_interval_time
	, stat.stat_name
	-- the stat.value and lag_value columns are used for data verification
	--, stat.value
	--, lag(stat.value)
		--over (partition by stat.stat_name order by  snap.instance_number, snap.snap_id)
	--lag_value
	, stat.value -
		lag(stat.value)
		over (partition by stat.stat_name order by  snap.instance_number, snap.snap_id)
	stat_delta
from dba_hist_snapshot snap, dba_hist_sysstat stat
where snap.instance_number = stat.instance_number
	and snap.snap_id = stat.snap_id
	and stat.stat_name in ('user commits','transaction rollbacks','redo synch writes')
	--and snap.begin_interval_time between timestamp '2016-05-16 00:00:00.000'
		--and timestamp '2016-05-16 23:59:59.999'
order by snap.instance_number, stat.stat_name, snap.snap_id
)
select
	p.instance_number
	, p.snap_date
	, p.user_commits
	, p.transaction_rollbacks
	, p.redo_sync_writes
from deltas d
pivot (
	sum(d.stat_delta)
	for stat_name in (
		'user commits' as "USER_COMMITS"
		, 'transaction rollbacks' as "TRANSACTION_ROLLBACKS"
		, 'redo synch writes' as "REDO_SYNC_WRITES"
	)
) p
order by p.snap_date, p.instance_number
/


-----------------------------------------------------------------------------

-- awr_blockers.sql
-- show historic blocking , sql_id and whether mode 4 (ITL) or mode 6 (rowlock)
-- Jared Still
-- still@pythian.com
-- jkstill@gmail.com

/*
As seen in an AWR report for 'Top Event P1/P2/P3 Values'
Event	                     % Event P1, P2, P3 Values	               % Activity  Parameter 1 Parameter 2   Parameter 3
enq: TX - index contention	22.52	  "1415053316","19529734","1548062"	1.65 	      name|mode   usn<<16|slot   sequence
P1 of 1415053316 is a mode 4 ITL wait
P1 of 1415053318 is a mode 6 ITL wait
This can be seen from the binary representation of these values
Mode 4
1415053316
0x54580004
1010100010110000000000000000100
$  perl -e 'print 1415053316 & 0xFFFF, "\n"'
4
Mode 6
1415053318
0x54580006
1010100010110000000000000000110
$  perl -e 'print 1415053318 & 0xFFFF, "\n"'
6
*/

@clears

@get_date_range

-- d_date_format set by get_date_range.sql

with waits as (
	select
		sh.instance_number
		, sh.blocking_inst_id
		, sh.sql_id
		, bitand(sh.p1,65535) lockmode
	from DBA_HIST_ACTIVE_SESS_HISTORY sh
	join dba_hist_snapshot s on s.snap_id = sh.snap_id
   	and s.snap_id = sh.snap_id
   	and s.instance_number = sh.instance_number
	where sh.blocking_inst_id is not null
	and sh.event_id = ( select event_id from v$event_name where name like 'enq: TX - row lock contention')
	and s.begin_interval_time between to_date('&&d_begin_date','&&d_date_format') and to_date('&&d_end_date','&&d_date_format')
)
select
	w.instance_number
	, w.blocking_inst_id
	, w.sql_id
	, decode(w.lockmode, 4,'ITL',6,'ROWLOCK','UNKNOWN') lockmode
	, count(*) * 10 waitcount -- only sampled every 10 seconds from gv$active_session_history
from waits w
group by 
	w.instance_number
	, w.blocking_inst_id
	, w.sql_id
	, w.lockmode
order by waitcount
/

-----------------------------------------------------------------------------
--- Historical IO times on ASM files
col tablespace_name format a25
col instance_number format 999 head 'INST'
col con_id format 999 head 'CON'
set linesize 200 trimspool on
set pagesize 60

set term off
spool awr_file_io_times.log

with iotimes as (
	select f.snap_id
		, f.instance_number
		--, f.con_id
		, tbs.name tablespace_name
		, f.file#
		, f.phyrds - lag(f.phyrds) over(partition by f.file#,f.instance_number order by f.snap_id,f.file#) phyrdstot
		, f.phywrts - lag(f.phywrts) over(partition by f.file#,f.instance_number order by f.snap_id,f.file#) phywrtstot
		, f.readtim - lag(f.readtim) over(partition by f.file#,f.instance_number order by f.snap_id,f.file#) readtimtot
		, f.writetim - lag(f.writetim) over(partition by f.file#,f.instance_number order by f.snap_id,f.file#) writetimtot
	from DBA_HIST_FILESTATXS f,
		v$tablespace tbs
	where tbs.ts# = f.ts#
		--and tbs.con_id = f.con_id
)
select
	to_char(s.end_interval_time,'yyyy-mm-dd hh24:mi:ss') end_interval_time
	, io.file#
	, io.instance_number
	--, io.con_id
	, io.tablespace_name
	, io.phyrdstot
	, trunc(io.readtimtot * 10,1) readtimtot_ms
	, trunc(io.readtimtot / decode(io.phyrdstot,0,0.000001,io.phyrdstot) *10,1) avg_read_tim_ms
	, io.phywrtstot
	, trunc(io.writetimtot * 10,1) writetimtot_ms
	, trunc(io.writetimtot / decode(io.phywrtstot,0,0.000001,io.phywrtstot) * 10,1) avg_write_tim_ms
from iotimes io
join dba_hist_snapshot s on s.snap_id = io.snap_id
	and s.instance_number = io.instance_number
	--and s.con_id = io.con_id
	--and DATE'2016-01-13' = trunc(s.end_interval_time)
order by end_interval_time, io.file#, io.instance_number
	--, io.con_id
/

spool off

set term on
-----------------------------------------------------------------------------
--
-- cpu-busy.sql -  what is keeping CPU busy?

@clears

col opname format a20

set linesize 200 trimspool on
set pagesize 60

@get_date_range


@clear_for_spool
set term off
spool cpu-busy.csv

prompt begin_interval_time,sql_id, username, opcode, opcode_count

with snaps as (
	select snap_id
	from dba_hist_snapshot
	where begin_interval_time 
		between to_date(:v_begin_date, '&d_date_format')
		and to_date(:v_end_date, '&d_date_format')
)
, opcodes as (
-- 10g- only
-- @@opcodes
--
-- 11g+
select command_type id
	,command_name opname
from v$sqlcommand
)
, cpu_states as (
	select sn.begin_interval_time
		, u.username
		, sh.sql_id
		--, sh.sql_opcode
		, o.opname
		, count(*) opcode_count
	from
	dba_hist_active_sess_history sh
	join snaps ss on ss.snap_id = sh.snap_id
	join dba_users u on u.user_id = sh.user_id
	join dba_hist_snapshot sn on sn.snap_id = sh.snap_id 
		and sn.instance_number = sh.instance_number
		and sh.session_state = 'ON CPU'
		and sh.user_id > 0 -- no SYS
		--and sn.snap_id = 270298
	join opcodes o on o.id = sh.sql_opcode
	group by sn.begin_interval_time
		, u.username
		, sh.sql_id
		, o.opname
	order by 1,2,3,4
) 
select 
/*
	to_char(begin_interval_time,'yyyy-mm-dd hh24:mi:ss') begin_interval_time
	, username
	, sql_id
	, opname
	, opcode_count
*/
	to_char(begin_interval_time,'yyyy-mm-dd hh24:mi:ss')
	|| ',' || username
	|| ',' || sql_id
	|| ',' || opname
	|| ',' || opcode_count
from cpu_states
/

spool off
@clears
undef 1 2
ed cpu-busy.csv
-----------------------------------------------------------------------------

---  count of plans matched with force_matching_signature
-- plan-counts-force.sql
-- Jared Still 2016-02-21
-- still@pythian.com
-- jkstill@gmail.com
-- 
-- find the  number of plans per sql_id using force_matching_signature

with plans as (
	select distinct force_matching_signature , sql_id, plan_hash_value
	from dba_hist_sqlstat
),
plancounts as (
	select distinct force_matching_signature , sql_id,
		count(*) over (partition by force_matching_signature , sql_id) plan_count
	from plans
)
select force_matching_signature , sql_id, plan_count
from plancounts
where plan_count > 1
order by 1,2,3
/

-----------------------------------------------------------------------------
-- rowlock history
-- rowlock-hist.sql
-- get top 5 events per AWR snapshot, per instance
-- Jared Still still@pythian.com jkstill@gmail.com

-- requires https://github.com/jkstill/oracle-script-lib/blob/master/get_date_range.sql

-- prompt for date range
--@get_date_range 

set verify off
-- or just specify it here
@get_date_range '2016-09-19 00:00:00' '2016-12-30 16:00:00'


set linesize 200 trimspool on
set pagesize 100 

clear break

@clear_for_spool

col begin_interval_time noprint

spool rowlock-hist.csv

prompt timestamp,instance,count

select  distinct hs.begin_interval_time,
	to_char(hs.begin_interval_time,'&d_date_format')
	|| ',' || nvl(d.instance_number,1)
	|| ',' || count(d.event) over (partition by d.snap_id, d.event, d.instance_number)
from dba_hist_active_sess_history d
join dba_hist_event_name n on n.event_id = d.event_id
	and n.event_name = 'enq: TX - row lock contention'
full outer join dba_hist_snapshot hs on hs.snap_id = d.snap_id
	and hs.instance_number = d.instance_number
	and hs.dbid = d.dbid
where hs.begin_interval_time between
	to_date(:v_begin_date,'&d_date_format')
	and to_date(:v_end_date,'&d_date_format')
order by hs.begin_interval_time
/

spool off

ed rowlock-hist.csv

@clears

-----------------------------------------------------------------------------
-- get sql_id where there are 2+ sql_id per force_matching signature from ASH/AWR
-- sql-counts-fms.sql
-- show SQL_ID for force_matching_signature when there are
-- two or more SQL_IDs associated to the FMS

-- which ever is an empty string indicates the mode used
break on force_matching_signature

define ash_mode='--'
define awr_mode=''

with fms as (
	-- get distinct list of force matching signatures and sql_id
	select distinct
		force_matching_signature
		, sql_id
	from 
		&ash_mode v$active_session_history
		&awr_mode dba_hist_sqlstat
),
fms_multi as (
-- now get data where there are 2+ fms
	select force_matching_signature
	from fms
	where force_matching_signature is not null 
		and force_matching_signature != 0
	group by force_matching_signature
	having count(*) > 1
)
-- now join back to ASH to get the SQL_IDs per FMS
select
	m.force_matching_signature
	, s.sql_id
from fms_multi m
join fms s on s.force_matching_signature = m.force_matching_signature
order by 1,2
/
-----------------------------------------------------------------------------
-- Show plans used by a selected SQL for a date and time range
-- sa.sql - sql activity

@clears
set linesize 200 trimspool on
set pagesize 60

@get_date_range

col u_sql_id new_value u_sql_id noprint

prompt
prompt SQL_ID: 
prompt

-- def vars 1 and 2 already set by get_date_range
set head off term off feed off verify off
select '&3' u_sql_id from dual;

var v_sql_id varchar2(15)

exec :v_sql_id := '&u_sql_id' 

@clear_for_spool

set term off

spool sql-plans.csv

prompt begin_interval_time,sql_id, sql_plan_hash_value, sql_id_count

select to_char(begin_interval_time,'yyyy-mm-dd hh24:mi:ss')
	|| ',' || sql_id
	|| ',' || sql_plan_hash_value
	|| ',' || sql_id_count
from (
select sn.begin_interval_time
	, sh.sql_id
	, sh.sql_plan_hash_value
	, count(*) sql_id_count
from
dba_hist_active_sess_history sh
join dba_hist_snapshot sn on sn.snap_id = sh.snap_id 
	and sn.instance_number = sh.instance_number
	and sh.SQL_ID = :v_sql_id
where sn.begin_interval_time 
	between to_date(:v_begin_date,'&d_date_format')
	and to_date(:v_end_date,'&d_date_format')
group by sn.begin_interval_time
	, sh.sql_id
	, sh.sql_plan_hash_value
order by 1,2
)
/

spool off
set term on
ed sql-plans.csv

-----------------------------------------------------------------------------

<end node> 5P9i0s8y19Z
dt=Text
<node>
SQL Queries
2
===============================================================================================

-- Oracle default schema List, which we can ignore it
('ANONYMOUS','APEX_030200','APEX_PUBLIC_USER','APPQOSSYS','BI','CTXSYS','DBSNMP','DIP','EXFSYS','FLOWS_FILES','HR','IX','MDDATA','MDSYS','MGMT_VIEW','OE','OLAPSYS','ORACLE_OCM','ORDDATA','ORDPLUGINS','ORDSYS','OUTLN','OWBSYS','OWBSYS_AUDIT','PM','SCOTT','SH','SI_INFORMTN_SCHEMA','SPATIAL_CSW_ADMIN_USR','SPATIAL_WFS_ADMIN_USR','SYS','SYSMAN','SYSTEM','WMSYS','XDB','XS$NULL')

 select username, temporary_tablespace
 from dba_users 
 where username --='MIS'
  not in ('CAE0748','MIS','ANONYMOUS','AUDSYS','SYSBACKUP','SYSDG','SYSKM','APEX_030200','APEX_PUBLIC_USER','APPQOSSYS','BI','CTXSYS','DBSNMP',
          'DIP','EXFSYS','FLOWS_FILES','HR','IX','MDDATA','MDSYS','MGMT_VIEW','OE','OLAPSYS','ORACLE_OCM','ORDDATA','ORDPLUGINS',
          'ORDSYS','OUTLN','OWBSYS','OWBSYS_AUDIT','PM','SCOTT','SH','SI_INFORMTN_SCHEMA','SPATIAL_CSW_ADMIN_USR','SPATIAL_WFS_ADMIN_USR',
          'SYS','SYSMAN','SYSTEM','WMSYS','XDB','XS$NULL')
order by 1 asc
 ;

===============================================================================================


--   Returining Days count between to days except saturday & sunday
select count(*)
      from (select rownum rnum
              from all_objects
              where rownum <= to_date('15-nov-2004') - to_date('1-nov-2004')+1 )
     where to_char( to_date('1-nov-2004')+rnum-1, 'DY' ) 
                      not in ( 'SAT', 'SUN' )
;

-- get the date from the day
select next_day(last_day(sysdate),'sat') from dual;
select next_day(sysdate,'sat') from dual;

-- get the instance name
select sys_context('USERENV','instance_name') from dual;

select sys_context('USERENV','db_name') from dual;

select instance_name, host_name, version, status from v$instance;

-- check the database startup time
select inst_id, to_char(startup_time, 'mm/dd/yyyy hh24:mi:ss') "Startup time" from gv$instance;

col HOST_NAME for a25
select inst_id, instance_name, host_name, status DB_status, 
	 to_char(startup_time, 'mm/dd/yyyy hh24:mi:ss') "Startup time" 
from gv$instance;

-- kill session scripts
select sid, serial#, schemaname, osuser, status, 
	state, program, machine, 
	'alter system kill session ' || ''''|| sid || ',' || serial# || ''' immediate;'  "Kill_Command"
from gv$session
where schemaname='PCSYSTEM'
;
===============================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
Archive log switch time
3
-- archive log switches per hour
select to_char(first_time,'dd-MON-yyyy') Day,
		to_char(sum(decode(to_char(first_time,'hh24'),'00',1,0)),'99') "00",
		to_char(sum(decode(to_char(first_time,'hh24'),'01',1,0)),'99') "01",
		to_char(sum(decode(to_char(first_time,'hh24'),'02',1,0)),'99') "02",
		to_char(sum(decode(to_char(first_time,'hh24'),'03',1,0)),'99') "03",
		to_char(sum(decode(to_char(first_time,'hh24'),'04',1,0)),'99') "04",
		to_char(sum(decode(to_char(first_time,'hh24'),'05',1,0)),'99') "05",
		to_char(sum(decode(to_char(first_time,'hh24'),'06',1,0)),'99') "06",
		to_char(sum(decode(to_char(first_time,'hh24'),'07',1,0)),'99') "07",
		to_char(sum(decode(to_char(first_time,'hh24'),'08',1,0)),'99') "08",
		to_char(sum(decode(to_char(first_time,'hh24'),'09',1,0)),'99') "09",
		to_char(sum(decode(to_char(first_time,'hh24'),'10',1,0)),'99') "10",
		to_char(sum(decode(to_char(first_time,'hh24'),'11',1,0)),'99') "11",
		to_char(sum(decode(to_char(first_time,'hh24'),'12',1,0)),'99') "12",
		to_char(sum(decode(to_char(first_time,'hh24'),'13',1,0)),'99') "13",
		to_char(sum(decode(to_char(first_time,'hh24'),'14',1,0)),'99') "14",
		to_char(sum(decode(to_char(first_time,'hh24'),'15',1,0)),'99') "15",
		to_char(sum(decode(to_char(first_time,'hh24'),'16',1,0)),'99') "16",
		to_char(sum(decode(to_char(first_time,'hh24'),'17',1,0)),'99') "17",
		to_char(sum(decode(to_char(first_time,'hh24'),'18',1,0)),'99') "18",
		to_char(sum(decode(to_char(first_time,'hh24'),'19',1,0)),'99') "19",
		to_char(sum(decode(to_char(first_time,'hh24'),'20',1,0)),'99') "20",
		to_char(sum(decode(to_char(first_time,'hh24'),'21',1,0)),'99') "21",
		to_char(sum(decode(to_char(first_time,'hh24'),'22',1,0)),'99') "22",
		to_char(sum(decode(to_char(first_time,'hh24'),'23',1,0)),'99') "23"
from v$log_history
where first_time between to_date('10/23/2018 00:00:00','mm/dd/yyyy hh24:mi:ss')
 				  and to_date('10/23/2018 23:59:59','mm/dd/yyyy hh24:mi:ss')
group by to_char(first_time,'dd-MON-yyyy')	
order by to_date(to_char(first_time,'dd-MON-yyyy'),'dd-MON-yyyy') asc

<end node> 5P9i0s8y19Z
dt=Text
<node>
Send Mail Excel
3
CREATE OR REPLACE PROCEDURE RAHULC.SEND_MAiL_wrapped
as
    v_Connection            UTL_SMTP.Connection;
    v_reply                 UTL_SMTP.REPLY;
    Message                 VARCHAR2(4000);
    crlf                    VARCHAR2(2):=chr(13)||chr(10);

    v_Sender                VARCHAR2(100);
    v_Recipient             VARCHAR2(100);
    v_Subject               VARCHAR2(100);
    v_Body                  VARCHAR2(1000);
    v_cc_recipt1            VARCHAR2(100);
    v_cc_recipt2            VARCHAR2(100);
    v_cc_recipt3            VARCHAR2(100);

    v_data                  varchar2(32000);

BEGIN

    v_Sender        := 'rahulc@infonox.com';
    v_Recipient     := 'rahulc@infonox.com';
    v_Subject       := 'Mail with attachment from PL/SQL'; -- mail subject line

/*
   -- If i_Error
    v_Body          := 'Hi All,'||chr(10)||chr(10)
                       ||chr(32)||chr(32)||'This is a first mail for an Attachement from Oracle version 10G '||chr(10)||chr(10)||
                       'Regards'||chr(10)||
                       '- DB Team';
*/

    v_cc_recipt1  := 'milindb@infonox.com';
    v_cc_recipt2  := 'gaurav@infonox.com';
    v_cc_recipt3  := 'srikanth@infonox.com';

     for i in (select CODE||','||DESCRIPTION||','||PATH||','||VALUE||','||B_OPTION||','||HELP_TEXT||','||OPERATION_TYPE||','||ACTION_TYPE||','||ACTIVITY_ACCESS oops
               from LOOKUP_POSTOFFICE_ACTION)
     loop

        v_data:= v_data||chr(10)||i.oops;

     end loop;

    dbms_output.put_line(v_Body);

    v_Connection := UTL_SMTP.OPEN_CONNECTION('MAIL.INFONOX.COM',25) ;
    v_reply      := UTL_SMTP.HELO(v_Connection,'MAIL.INFONOX.COM') ;
    v_reply      := UTL_SMTP.MAIL(v_Connection,v_Sender);
    v_reply      := UTL_SMTP.RCPT(v_Connection,v_Recipient);

    --IF v_cc_recipt1 is not null then
        UTL_SMTP.rcpt(v_Connection,v_cc_recipt1);
        UTL_SMTP.rcpt(v_Connection,v_cc_recipt2);
        UTL_SMTP.rcpt(v_Connection,v_cc_recipt3);
    --END IF;


    utl_smtp.Data(
                    v_Connection,

                    --- list of to, from, cc and subject line
                    'Date: '   || to_char(sysdate, 'Dy, DD Mon YYYY hh24:mi:ss') || crlf ||
                    'From: '||v_Sender||crlf||
                    'To: '||v_Recipient||crlf||
                    'Cc: '||v_cc_recipt1||crlf||
                    'Cc: '||v_cc_recipt2||crlf||
                    'Cc: '||v_cc_recipt3||crlf||
                    'Subject: '||v_Subject || crlf ||

                    'MIME-Version: 1.0'|| crlf ||       -- Use MIME mail standard
                    'Content-Type: multipart/mixed;'|| crlf ||
                    ' boundary="-----SECBOUND"'|| crlf ||

                    '-------SECBOUND'|| crlf ||
                    'Content-Type: text/plain;'|| crlf ||
                    'Content-Transfer_Encoding: 7bit'|| crlf ||

                    crlf ||
                    -- text message body
                    'Hi All,'||crlf||crlf||
                       chr(32)||chr(32)||'Testing email with Attachment from PL/SQL from Oracle version 10G '||crlf||crlf||
                    'Regards'||crlf||
                    '- DB Team'||crlf ||

                    '-------SECBOUND'|| crlf ||
                    'Content-Type: text/plain;'|| crlf ||
                    ' name="Attachment_Excel.cvs"'|| crlf ||
                    'Content-Transfer_Encoding: 8bit'|| crlf ||
                    'Content-Disposition: attachment;'|| crlf ||
                    ' filename="Attachment_Excel.cvs"'|| crlf ||
                    crlf || -- columns headline in excel file
                    'CODE, DESCRIPTION, PATH, VALUE, B_OPTION, HELP_TEXT, OPERATION_TYPE, ACTION_TYPE, ACTIVITY_ACCESS'||crlf||
                    v_data ||  -- Content / data in the excel file.
                    crlf ||
                    '-------SECBOUND--'
                                -- End MIME mail
                     -- any more text here can be added...

                  );

   -- UTL_SMTP.DATA(v_Connection,'MIME-Version: 1.0'||crlf||'Content-type: text/html' || crlf||Message);
    UTL_SMTP.QUIT(v_Connection);
END SEND_MAiL_wrapped;
/

<end node> 5P9i0s8y19Z
dt=Text
<node>
Shared Pool
3
--- to flush the shared_pool
alter system flush shared_pool

*Determine if the data block buffers is set high enough:

select 1-(sum(decode(name, 'physical reads', value,0))/ 	
	 (sum(decode(name, 'db block gets', value,0)) + 	
	 (sum(decode(name, 'consistent gets', value,0))))) * 100
	 "Read Hit Ratio" 
from   v$sysstat;

Read Hit Ratio
      98.415926

*Determine library cache hit ratio: 

select  sum(pins) Executions, sum(pinhits) Execution_Hits, 
        ((sum(pinhits) / sum(pins)) * 100) phitrat,
        sum(reloads) Misses,
        ((sum(pins) / (sum(pins) + sum(reloads))) * 100)  hitrat
from v$librarycache;

Executions 	Execution Hits   PHITRAT       Misses  HITRAT
  3,582              3,454        96.43        6       99.83

Tip: If the hit ratio or reloads is high, increase the shared_pool_size INIT.ora parameter.  Reloads indicate that
statements that were once in memory now had to be reloaded because they were pushed out, whereas misses include statements
that are loaded for the first time.

*Determine dictionary cache miss ratio: 

select 	sum(gets) Gets, sum(getmisses) Misses,
       	(1 - (sum(getmisses) / (sum(gets) +     	
	sum(getmisses))))*100 HitRate
from  	v$rowcache;

Gets 	Misses 	HitRate
10233    508 	95.270459

*How much memory is left for SHARED_POOL_SIZE:

col value for 999,999,999,999 heading SharedPoolSize
col bytes for 999,999,999,999 heading FreeBytes

select   	to_number(v$parameter.value) value, v$sgastat.bytes, 
(v$sgastat.bytes/v$parameter.value)*100 PercentFree
from 	v$sgastat, v$parameter
where	v$sgastat.name = 'free memory'
and v$sgastat.pool='shared pool'
and	v$parameter .name = 'shared_pool_size';

Shared Pool Size	Free Bytes	Percent Free
     100,000,000 	82,278,960	82.27896

*select sum(ksmchsiz) Bytes, ksmchcls Status
 from 	x$ksmsp
 group by 	ksmchcls;

BYTES       	STATUS 
    350,000	R-free                                                                                
         40 	R-freea                                                                               
     25,056 	free                                                                                  
  2,571,948	freeabl                                                                               
  4,113,872 	perm                                                                                  
  1,165,504 	recr
  
Tip: 
  
  An ORA-4031 is usually caused when the shared pool gets fragmented (you’re not necessarily out of shared pool) into
  smaller pieces over the course of a day and a request for a large piece of memory is issued which can not be filled. 
  
Tip:
  
  Retrieving information from memory is over 10,000 times (depending on the memory you have) faster than retrieving it from
  disk so make sure that the SGA is large enough

*select 	decode(state,0, 'FREE', 1, decode(lrba_seq,0,'AVAILABLE','BEING USED'), 
   	3, 'BEING USED', state) "BLOCK STATUS", count(*)
from 	x$bh
group by 	decode(state,0,'FREE',1,decode(lrba_seq,0,
   	'AVAILABLE','BEING USED'),3, 'BEING USED', state);


*Example 1 (Create a table with CACHE):

CREATE TABLE TEST_TAB (COL1 NUMBER)
TABLESPACE USERS
CACHE;

NOCACHE is the Default!

Example 2 (Alter a table to CACHE):

ALTER TABLE TEST_TAB
CACHE;

Example 3 (The CACHE Hint):

SELECT 	/*+ CACHE(CUST) */ ENAME, JOB
FROM   	CUST
WHERE  	TABLE_NAME = 'EMP';

Example 4 (The NOCACHE Hint):

SELECT 	/*+ FULL(CUST)  NOCACHE(CUST) */  ENAME, JOB
FROM   	CUST
WHERE  	TABLE_NAME = 'EMP';

*You may also pin (cache) PL/SQL object statements into memory: In the event that you cannot maintain a sufficient
SHARED_POOL_SIZE, it may become important to keep the most important objects cached (pinned) in memory.  The following
example shows how to pin PL/SQL object statements in memory using the DBMS_SHARED_POOL.KEEP procedure.  For additional
PL/SQL tips see chapter 10 which focus exclusively on PL/SQL. 

BEGIN 
  DBMS_SHARED_POOL.KEEP(‘PROCESS_DATE’,’P’);
END;

Tip: Pin PL/SQL objects into memory immediately upon starting the database to avoid insufficient memory errors later in the
day.  To accomplish this, use the DBMS_SHARED_POOL.KEEP procedure for PL/SQL object statements.  Ensure that the STANDARD
procedure is pinned soon after startup since it is so large.


Goal#3: Find problem queries hurting memory

A single index or a single query can bring an entire system to a near standstill.  By using v$sqlarea, you can find the
problem queries on your system.  Below, the example shows how to find the problem queries.  I am searching for queries
where the disk reads are greater than 10,000.  If your system is much larger, you may need to set this to a higher number.

--Example 5 (Finding the largest amount of physical reads by query): 

select 	disk_reads, sql_text 
from   	v$sqlarea
where  	disk_reads > 10000 
order 	by disk_reads desc;

--Example 6 (Finding the largest amount of logical reads by query):

select 	buffer_gets, sql_text
from   	v$sqlarea
where  	buffer_gets > 200000
order by 	buffer_gets desc;

BUFFER_GETS	SQL_TEXT
------------------	-----------------------------------------------------------------
300219		select order#,cust_no, from orders 
		where division = ‘1’    


You may need to join to the v$sqltext view:

You may have to join in the v$sqltext table to get the full text since
v$sqlarea only shows a portion of the SQL_TEXT.  

Break on User_Name On Disk_Reads on Buffer_Gets on Rows_Processed

Select 	A.User_Name, B.Disk_Reads, B.Buffer_Gets,
       	B.Rows_Processed, C.SQL_Text
From 	V$Open_Cursor A, V$SQLArea B, V$SQLText C
Where	A.User_Name = Upper('&&User')
  And  	A.Address = C.Address
  And  	A.Address = B.Address
Order By 	A.User_Name, A.Address, C.Piece;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Audit SQLs
3
SELECT /*+ FIRST_ROWS(10) */ userid, userhost, DECODE(action#, 2,'INSERT',3,'SELECT',6,'UPDATE',7,'DELETE') operation, 
    obj$creator, obj$name, SPARE1, ntimestamp#, instance#, sqltext
FROM sys.aud$ ot
WHERE EXISTS  (SELECT 1 FROM AUDIT_ACTIONS iner 
                WHERE iner.action = ot.action# 
                  AND iner.NAME IN ('INSERT','UPDATE','DELETE','SELECT'))
  and ntimestamp# >=SYSDATE -1
  and not regexp_like(obj$name,'*EXPORT*|import|expdp|impdp|AUDIT_DDL','i')
;

-- for perticular user
SELECT /*+ FIRST_ROWS(10) */ userid, userhost, DECODE(action#, 2,'INSERT',3,'SELECT',6,'UPDATE',7,'DELETE') operation, 
    obj$creator, obj$name, SPARE1, ntimestamp#, instance#, sqltext
FROM sys.aud$ ot
WHERE ntimestamp# >=SYSDATE -1
  AND userid in ('PESDBO','CEDESTAGE')
  AND EXISTS  (SELECT 1 FROM AUDIT_ACTIONS iner 
                WHERE iner.action = ot.action# 
                  AND iner.NAME IN ('INSERT','UPDATE','DELETE','SELECT'));
                  
                  
select * from sys.aud$ ot;

SELECT os_username,
        USERNAME,
        USERHOST,
        TERMINAL,
        to_char(TIMESTAMP, 'MM/DD/YY HH24:MI:SS') ts,
        substr(action_name,0,8) ACTION,
        (CASE returncode
               WHEN 0 THEN 'Successful'
               WHEN 1017 THEN 'Incorrect Password'
               WHEN 1035 THEN 'user lacks RESTRICTED SESSION privilege'
               WHEN 1045 THEN 'user lacks CREATE SESSION'
               WHEN 28000 THEN 'Account Locked'
               ELSE 'returncode'
               END) result
FROM dba_audit_session
WHERE username in ('PESDBO','CEDESTAGE') 
  --AND TIMESTAMP > trunc(sysdate) - 1
ORDER BY TIMESTAMP desc;


delete /*+ NOLOGGING PARALLEL(aud$, 10) */ 
from sys.aud$ 
where to_timestamp(to_char(ntimestamp#,'DD-MON-YYYY')) < to_timestamp('1-FEB-2017'); 


create index sys.idx_aud$_ntimestamp on sys.aud$(ntimestamp#) tablespace CNA_ATABLES online;


-- audit query
SELECT os_username,
        USERNAME,
        USERHOST,
        TERMINAL,
        to_char(TIMESTAMP, 'MM/DD/YY HH24:MI:SS') ts,
        substr(action_name,0,8) ACTION,
        (CASE returncode
               WHEN 0 THEN 'Successful'
               WHEN 1017 THEN 'Incorrect Password'
               WHEN 1035 THEN 'user lacks RESTRICTED SESSION privilege'
               WHEN 1045 THEN 'user lacks CREATE SESSION'
               WHEN 28000 THEN 'Account Locked'
               ELSE 'returncode'
               END) result
FROM dba_audit_session
WHERE username = 'LIMS_PI' 
  AND TIMESTAMP > trunc(sysdate) - 1
ORDER BY TIMESTAMP desc;


--  query to determine the operating system process identifier (spid):
SELECT spid
FROM   v$process
WHERE NOT EXISTS (SELECT 1
                  FROM v$session
                  WHERE paddr = addr);


-- query to check the last call of the query
select sql_id, status, last_call_et from v$session where sid = 147;


-- Query will return which user had done insert,update,delete,select in last 1 day
SELECT /*+ FIRST_ROWS(10) */ userid, userhost, DECODE(action#, 2,'INSERT',3,'SELECT',6,'UPDATE',7,'DELETE') operation, 
    obj$creator, obj$name, SPARE1, ntimestamp#, instance#, sqltext
FROM sys.aud$ ot
WHERE ntimestamp# >=SYSDATE -1
AND EXISTS  (SELECT 1 FROM AUDIT_ACTIONS iner 
             WHERE iner.action = ot.action# 
               AND iner.NAME IN ('INSERT','UPDATE','DELETE','SELECT'))

-- for perticular user
SELECT /*+ FIRST_ROWS(10) */ userid, userhost, DECODE(action#, 2,'INSERT',3,'SELECT',6,'UPDATE',7,'DELETE') operation, 
    obj$creator, obj$name, SPARE1, ntimestamp#, instance#, sqltext
FROM sys.aud$ ot
WHERE ntimestamp# >=SYSDATE -1
  AND userid='IRD'
  AND EXISTS  (SELECT 1 FROM AUDIT_ACTIONS iner 
                WHERE iner.action = ot.action# 
                  AND iner.NAME IN ('INSERT','UPDATE','DELETE','SELECT'))


-- find the last time database users logged on to the database
SELECT    
    A.username, os_username, A.TIMESTAMP, A.logoff_time, 
    A.returncode, A.terminal, A.userhost, A.ACTION_NAME
FROM dba_audit_session A
WHERE (A.username,A.TIMESTAMP) IN 
                                (SELECT b.username,MAX(b.TIMESTAMP)
                                 FROM dba_audit_session b
                                 GROUP BY b.username)
  AND A.TIMESTAMP<(SYSDATE-3)


--- The most basic view of the database audit trail is provided by the DBA_AUDIT_TRAIL view, 
-- which contains a wide variety of information. The following query displays the some of the 
-- information from the database audit trail.
SELECT username,
       extended_timestamp,
       owner,
       obj_name,
       action_name
FROM   dba_audit_trail
WHERE  owner = 'AUDIT_TEST'
ORDER BY timestamp;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Locking/Blocking Sessions
3


-- who locks whoms (MASTER) 
col oracle_username for a15
col owner for a15
col object_name for a30
col object_type for a15
SELECT Oracle_Username Username, owner Object_Owner, Object_Name, Object_Type, s.osuser, s.SID SID,
    s.SERIAL# SERIAL,s.inst_id,S.MACHINE,s.module,
  'alter system kill session ' || ''''|| s.sid || ',' || s.serial# || ',@'||s.inst_id ||''' immediate;'  "Kill_Command"
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s
WHERE v.object_id = d.object_id
  AND (v.object_id = l.id1)
  AND v.session_id = s.SID
 and (d.owner <>'SYS' or s.type <> 'BACKGROUND')
ORDER BY oracle_username, session_id;


set lines 320
set pages 1000
col username for a14
col owner for a15
col object_name heading "Object|Name" for a20
col object_type heading "Object|Type" for a10
SELECT Oracle_Username Username, owner, Object_Name, Object_Type, s.osuser, s.SID SID,p.spid,
    s.SERIAL# SERIAL,s.inst_id,S.MACHINE,s.module,
    DECODE(l.BLOCK, 0, 'Not Blocking', 1, 'Blocking', 2, 'Global') STATUS,
    DECODE(v.locked_mode, 0, 'None', 1, 'Null', 2, 'Row-S (SS)', 3, 'Row-X (SX)', 4, 'Share', 5, 'S/Row-X (SSX)', 6, 'Exclusive', TO_CHAR(lmode) ) MODE_HELD
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s, gv$process p
WHERE v.object_id = d.object_id
  AND (v.object_id = l.id1)
  AND v.session_id = s.SID
  and s.paddr = p.addr
  and (d.owner <>'SYS' or s.type <> 'BACKGROUND')
--  and oracle_username='MIS_DM'
--  and object_name='D_DNB_HQ_LOC_ALL'
ORDER BY oracle_username, session_id;


--   Session waiting for the locks
SELECT holding_session bsession_id, waiting_session wsession_id,
       b.username busername, a.username wusername, c.lock_type TYPE, mode_held,
       mode_requested, lock_id1, lock_id2
  FROM sys.v_$session b, sys.dba_waiters c, sys.v_$session a
 WHERE c.holding_session = b.sid AND c.waiting_session = a.sid
;

set lines 320
set pages 1000
col username for a14
col owner for a15
col object_name heading "Object|Name" for a20
col object_type heading "Object|Type" for a10
SELECT Oracle_Username Username, owner, Object_Name, Object_Type, s.osuser, s.SID SID,p.spid,
    s.SERIAL# SERIAL,s.inst_id,S.MACHINE,s.module,
    DECODE(l.BLOCK, 0, 'Not Blocking', 1, 'Blocking', 2, 'Global') STATUS,
    DECODE(v.locked_mode, 0, 'None', 1, 'Null', 2, 'Row-S (SS)', 3, 'Row-X (SX)', 4, 'Share', 5, 'S/Row-X (SSX)', 6, 'Exclusive', TO_CHAR(lmode) ) MODE_HELD
    ,'alter system kill session ' || ''''|| s.sid || ',' || s.serial# || ',@'||s.inst_id ||''' immediate;'  "Kill_Command"
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s, gv$process p
WHERE v.object_id = d.object_id
  AND (v.object_id = l.id1)
  AND v.session_id = s.SID
  and s.paddr = p.addr
  and (d.owner <>'SYS' or s.type <> 'BACKGROUND') and s.sid=2339
ORDER BY oracle_username, session_id;

select unique Kill_Command
from (
SELECT Oracle_Username Username, owner Object_Owner, Object_Name, Object_Type, s.osuser, s.SID SID,p.spid,
    s.SERIAL# SERIAL,s.inst_id,S.MACHINE,s.module,
    DECODE(l.BLOCK, 0, 'Not Blocking', 1, 'Blocking', 2, 'Global') STATUS,
    DECODE(v.locked_mode, 0, 'None', 1, 'Null', 2, 'Row-S (SS)', 3, 'Row-X (SX)', 4, 'Share', 5, 'S/Row-X (SSX)', 6, 'Exclusive', TO_CHAR(lmode) ) MODE_HELD,
    'alter system kill session ' || ''''|| s.sid || ',' || s.serial# || ',@'||s.inst_id ||''' immediate;' Kill_Command
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s, gv$process p
WHERE v.object_id = d.object_id
  AND (v.object_id = l.id1)
  AND v.session_id = s.SID
  and s.paddr = p.addr
  and (d.owner <>'SYS' or s.type <> 'BACKGROUND')
and Oracle_Username ='W94BAT'
ORDER BY oracle_username, session_id
);

select s.inst_id, p.spid, s.sid, s.serial#, s.schemaname, s.machine, s.osuser,s.module
from gv$session s, gv$process p
where s.paddr = p.addr
  and s.sid=180

--- which object is access
col type for a13
col object for a30
col username for a30
col schemaname for a30
col osuser for a30
select a.object, a.type, b.inst_id,a.sid, b.username, b.schemaname, 
	b.osuser, b.module, b.program, b.sql_id
from gv$access a, gv$session b
where a.sid=b.sid
--  and b.schemaname='W94BAT'
  and a.object like 'PFT%'
and b.sid=612
order by a.type asc;


-- who locks whoms (MASTER) 
SELECT Oracle_Username Username, owner Object_Owner, Object_Name, Object_Type, s.osuser, s.SID SID,
    s.SERIAL# SERIAL,s.inst_id,S.MACHINE,s.module,DECODE(l.BLOCK, 0, 'Not Blocking', 1, 'Blocking', 2, 'Global') STATUS,
    DECODE(v.locked_mode, 0, 'None', 1, 'Null', 2, 'Row-S (SS)', 3, 'Row-X (SX)', 4, 'Share', 5, 'S/Row-X (SSX)', 6, 'Exclusive', TO_CHAR(lmode) ) MODE_HELD
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s
WHERE v.object_id = d.object_id
  AND (v.object_id = l.id1)
  AND v.session_id = s.SID
and Object_Name not in ('OBJ$','CON$')
ORDER BY oracle_username, session_id;


-- This report will produce a list of all locks taken in the system and the mode in 
-- which the lock has been taken.
SELECT s.username, s.sid,
       DECODE (
          l.TYPE,
          'MR', 'Media Recovery',
          'RT', 'Redo Thread',
          'UN', 'User Name',
          'TX', 'Transaction',
          'TM', 'DML',
          'UL', 'PL/SQL User Lock',
          'DX', 'Distributed Xaction',
          'CF', 'Control File',
          'IS', 'Instance State',
          'DS', 'File Set',
          'IR', 'Instance Recovery',
          'ST', 'Disk Space Transaction',
          'TS', 'Temp Segment',
          'IV', 'Library Cache Invalidation',
          'LS', 'Log Start or Switch',
          'RW', 'Row Wait',
          'SQ', 'Sequence Number',
          'TE', 'Extend Table',
          'TT', 'Temp Table'
       ) ltype,
       o.object_name,
       DECODE (
          l.lmode,
          2, 'Row-S(SS)',
          3, 'Row-X(SX)',
          4, 'Share',
          5, 'S/Row-X(SSX)',
          6, 'Exclusive',
          'Other'
       ) mode_held
  FROM dba_objects o, v$session s, v$lock l
 WHERE s.sid = l.sid AND o.object_id = l.id1;
===============================================================================================

-- modified -- who locked whoms
SELECT Oracle_Username Username, owner Object_Owner, Object_Name, Object_Type, s.osuser, s.SID SID,s.sql_id,s.status account_status,
    s.SERIAL# SERIAL,S.MACHINE,s.module,DECODE(l.BLOCK, 0, 'Not Blocking', 1, 'Blocking', 2, 'Global') STATUS,
    DECODE(v.locked_mode, 0, 'None', 1, 'Null', 2, 'Row-S (SS)', 3, 'Row-X (SX)', 4, 'Share', 5, 'S/Row-X (SSX)', 6, 'Exclusive', TO_CHAR(lmode) ) MODE_HELD
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s
WHERE v.object_id = d.object_id
  AND (v.object_id = l.id1)
  AND v.session_id = s.SID
  and s.schemaname='CAE0748'
ORDER BY oracle_username, session_id;
 
-- who locks whoms (child ) 		 
SELECT 
  oracle_username, os_user_name, locked_mode,
  object_name,object_type
FROM v$locked_object a,DBA_OBJECTS b
WHERE a.object_id = b.object_id 



-- check the blockers and lockers 
select * from dba_blockers;

alter system kill session '1450,23934,@1' immediate;

-- sql query to check the lock holders
SELECT vh.sid locking_sid,vw.sid waiter_sid, vs.status status,  
	vs.schemaname, vs.sql_id, vs.machine,vs.inst_id,
	vs.program program_holding, vsw.program program_waiting,
    'alter system kill session ' || ''''|| vsw.sid || ',' || vsw.serial# || ''' immediate;'  "Kill_Command"
FROM v$lock vh,  v$lock vw,  gv$session vs,  gv$session vsw
WHERE (vh.id1, vh.id2) IN (SELECT id1, id2  
						     FROM v$lock  
						    WHERE request = 0 
						  INTERSECT  
						   SELECT id1, id2
						     FROM v$lock
						    WHERE lmode = 0)
   AND vh.id1 = vw.id1 
   AND vh.id2 = vw.id2 
   AND vh.request = 0 
   AND vw.lmode = 0 
   AND vh.sid = vs.sid 
   AND vw.sid = vsw.sid; 


col MODULE for a30
col Kill_Command for a50
col PROGRAM_WAITING for a20
col job_name for a5
col PROGRAM_HOLDING for a15
col osuser for a10
col username for a11
SELECT vs.username, vs.osuser, vh.sid locking_sid, vs.status status,
 vs.program program_holding, jrh.job_name, vsw.username, vsw.osuser,
 vw.sid waiter_sid, vsw.program program_waiting, jrw.job_name,
 'alter system kill session ' || ''''|| vh.sid || ',' || vs.serial# || ''' immediate;'  "Kill_Command",
 vs.module
FROM v$lock vh, v$lock vw, v$session vs,
 v$session vsw,
 dba_scheduler_running_jobs jrh,
 dba_scheduler_running_jobs jrw
WHERE (vh.id1, vh.id2) IN (SELECT id1, id2
						     FROM v$lock
						    WHERE request = 0
						  INTERSECT
						   SELECT id1, id2
						     FROM v$lock
						    WHERE lmode = 0)
 AND vh.id1 = vw.id1
 AND vh.id2 = vw.id2
 AND vh.request = 0
 AND vw.lmode = 0
 AND vh.sid = vs.sid
 AND vw.sid = vsw.sid
 AND vh.sid = jrh.session_id(+)
 AND vw.sid = jrw.session_id(+);


--- blocking session Rahul		
SELECT sess.SID, sess.schemaname, sess.osuser, sess.machine, s.* 
FROM v$lock s, v$session sess 
WHERE s.BLOCK>0 AND s.SID = sess.SID;	

---	blocking session (lock2)
set timing on
set pages 999

SELECT TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS') as SYSTEM_DATE_TIME FROM DUAL;

SELECT l1.sid SID, ' IS BLOCKING ' blk ,l2.sid SID2 
FROM v$lock l1, v$lock l2
WHERE l1.block =1 
  AND l2.request > 0 
  AND l1.id1=l2.id1 
  AND l1.id2=l2.id2;

---blocking session (lock)
set timing on
set lines 120 pages 999
select s1.username || '@' || s1.machine
|| ' ( SID=' || s1.sid || ' ) is blocking '
|| s2.username || '@' || s2.machine || ' ( SID=' || s2.sid || ' ) ' AS blocking_status
from v$lock l1, v$session s1, v$lock l2, v$session s2
where s1.sid=l1.sid 
  and s2.sid=l2.sid
  and l1.BLOCK=1 and l2.request > 0
  and l1.id1 = l2.id1
  and l2.id2 = l2.id2 ; 

-- Locking/Blocking Sessions
set serveroutput on 
BEGIN
  DBMS_OUTPUT.ENABLE(1000000);
  
      FOR do_loop IN (SELECT session_id, A.object_id, xidsqn, oracle_username, b.owner owner,
                          b.object_name object_name, b.object_type object_type
                      FROM v$locked_object A, dba_objects b
                      WHERE xidsqn != 0
                          AND b.object_id = A.object_id)
  LOOP
      DBMS_OUTPUT.PUT_LINE('.');
      DBMS_OUTPUT.PUT_LINE('Blocking Session : '||do_loop.session_id);
      DBMS_OUTPUT.PUT_LINE('Object (Owner/Name): '||do_loop.owner||'.'||do_loop.object_name);
      DBMS_OUTPUT.PUT_LINE('Object Type : '||do_loop.object_type);
      FOR next_loop IN (SELECT SID 
                          FROM v$lock
                        WHERE id2 = do_loop.xidsqn
                            AND SID != do_loop.session_id)
      LOOP
      DBMS_OUTPUT.PUT_LINE('Sessions being blocked : '||next_loop.SID);
      END LOOP;
  END LOOP;
  END;
/


----------------------------------------------------------------------------------------

-- deadlocks
-- https://oracle-base.com/articles/misc/deadlocks

Select 
   s.sid SID,
   s.serial# Serial#,
   l.type type,
   ' ' object_name,
   lmode held,
   request request
from 
   v$lock l, 
   v$session s, 
   v$process p
where 
   s.sid = l.sid and
   s.username <> ' ' and
   s.paddr = p.addr and
   l.type <> 'TM' and
   (l.type <> 'TX' or l.type = 'TX' and l.lmode <> 6)
union
select 
   s.sid SID,
   s.serial# Serial#,
   l.type type,
   object_name object_name,
   lmode held,
   request request
from 
   v$lock l,
   v$session s,
   v$process p, 
   sys.dba_objects o
where 
   s.sid = l.sid and
   o.object_id = l.id1 and
   l.type = 'TM' and
   s.username <> ' ' and
   s.paddr = p.addr
union
select 
   s.sid SID,
   s.serial# Serial#,
   l.type type,
   '(Rollback='||rtrim(r.name)||')' object_name,
   lmode held,
   request request
from 
   v$lock l, 
   v$session s, 
   v$process p, 
   v$rollname r
where 
   s.sid = l.sid and
   l.type = 'TX' and
   l.lmode = 6 and
   trunc(l.id1/65536) = r.usn and
   s.username <> ' ' and
   s.paddr = p.addr
order by 5, 6;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Blocking and locking Sessions
3
-- Here is a query that gives us a list of blocking sessions and the 
-- sessions that they are blocking:

-- Recipe #1 - find blocking sessions with v$session
select 
   blocking_session, 
   sid, 
   serial#, 
   wait_class,
   seconds_in_wait
from 
   v$session
where 
   blocking_session is not NULL
order by 
   blocking_session;


-- Recipe #2 - find blocking sessions using v$lock
SELECT l1.sid || ' is blocking ' || l2.sid blocking_sessions
FROM v$lock l1, v$lock l2
WHERE l1.block = 1 AND
   l2.request > 0 AND
   l1.id1 = l2.id1 AND
   l1.id2 = l2.id2


-- Recipe #3 - blocking sessions with all available information
-- The next query prints a few more information, it let's you quickly see who's blocking 
-- who. Run this query and you can immediately call the colleague who's locking your table:
SELECT s1.username || '@' || s1.machine
    || ' ( SID=' || s1.sid || ' )  is blocking '
    || s2.username || '@' || s2.machine || ' ( SID=' || s2.sid || ' ) ' AS blocking_status
    FROM v$lock l1, v$session s1, v$lock l2, v$session s2
    WHERE s1.sid=l1.sid AND s2.sid=l2.sid
    AND l1.BLOCK=1 AND l2.request > 0
    AND l1.id1 = l2.id1
    AND l1.id2 = l2.id2


-- Recipe #4 - identifying blocked objects
-- If you encounter a TM lock is means that two sessions are trying to modify 
-- some data but blocking each other. Unless one sessions finished (commit or rollback), 
-- you'll never have to wait forever.
SELECT sid, id1 
FROM v$lock 
WHERE TYPE='TM'

-- The ID you get from this above query refers to the actual database object which can 
-- help you to identify the problem, look at the next query:
SELECT owner, object_name, object_type, status
FROM dba_objects 
WHERE object_id=20127


--- who is locking what?
SELECT 
  oracle_username, os_user_name, locked_mode,
  object_name,object_type
FROM v$locked_object a,DBA_OBJECTS b
WHERE a.object_id = b.object_id    


-- objects locked
SELECT Oracle_Username Username, owner Object_Owner, Object_Name, Object_Type, s.osuser, s.SID SID,
		s.SERIAL# SERIAL,DECODE(l.BLOCK, 0, 'Not Blocking', 1, 'Blocking', 2, 'Global') STATUS,
		DECODE(v.locked_mode, 0, 'None', 1, 'Null', 2, 'Row-S (SS)', 3, 'Row-X (SX)', 4, 'Share', 5, 'S/Row-X (SSX)', 6, 'Exclusive', TO_CHAR(lmode) ) MODE_HELD
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s
WHERE v.object_id = d.object_id
  AND (v.object_id = l.id1)
  AND v.session_id = s.SID
ORDER BY oracle_username, session_id;

--Show which row is locked
select do.object_name
,	row_wait_obj#
,	row_wait_file#
,	row_wait_block#
,	row_wait_row#
,	dbms_rowid.rowid_create (1, ROW_WAIT_OBJ#, ROW_WAIT_FILE#, 
				ROW_WAIT_BLOCK#, ROW_WAIT_ROW#)
from	v$session s
,	dba_objects do
where	sid=&sid
and 	s.ROW_WAIT_OBJ# = do.OBJECT_ID
/

-- view all currently locked objects: 
SELECT username U_NAME, owner OBJ_OWNER,
object_name, object_type, s.osuser,
DECODE(l.block,
  0, 'Not Blocking',
  1, 'Blocking',
  2, 'Global') STATUS,
  DECODE(v.locked_mode,
    0, 'None',
    1, 'Null',
    2, 'Row-S (SS)',
    3, 'Row-X (SX)',
    4, 'Share',
    5, 'S/Row-X (SSX)',
    6, 'Exclusive', TO_CHAR(lmode)
  ) MODE_HELD
FROM gv$locked_object v, dba_objects d,
gv$lock l, gv$session s
WHERE v.object_id = d.object_id
AND (v.object_id = l.id1)
AND v.session_id = s.sid
ORDER BY username, session_id;
 
 
-- list current locks 
SELECT session_id,lock_type, 
	mode_held, 
	mode_requested, 
	blocking_others, 
	lock_id1
FROM dba_lock l
WHERE lock_type 
NOT IN ('Media Recovery', 'Redo Thread');
 
 
-- list objects that have been 
-- locked for 60 seconds or more: 
 SELECT SUBSTR(TO_CHAR(w.session_id),1,5) WSID, p1.spid WPID,
	SUBSTR(s1.username,1,12) "WAITING User",
	SUBSTR(s1.osuser,1,8) "OS User",
	SUBSTR(s1.program,1,20) "WAITING Program",
	s1.client_info "WAITING Client",
	SUBSTR(TO_CHAR(h.session_id),1,5) HSID, p2.spid HPID,
	SUBSTR(s2.username,1,12) "HOLDING User",
	SUBSTR(s2.osuser,1,8) "OS User",
	SUBSTR(s2.program,1,20) "HOLDING Program",
	s2.client_info "HOLDING Client",
	o.object_name "HOLDING Object"
FROM gv$process p1, gv$process p2, gv$session s1, gv$session s2, dba_locks w, dba_locks h, dba_objects o
WHERE w.last_convert > 60
	AND h.mode_held != 'None'
	AND h.mode_held != 'Null'
	AND w.mode_requested != 'None'
	AND s1.row_wait_obj# = o.object_id
	AND w.lock_type(+) = h.lock_type
	AND w.lock_id1(+) = h.lock_id1
	AND w.lock_id2 (+) = h.lock_id2
	AND w.session_id = s1.sid (+)
	AND h.session_id = s2.sid (+)
	AND s1.paddr = p1.addr (+)
	AND s2.paddr = p2.addr (+)
ORDER BY w.last_convert DESC;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Memory check sql
3

-- gives perfect picture of background process and there usage
SELECT to_char(ssn.sid, '9999') || ' - ' || nvl(ssn.username, nvl(bgp.name, 'background')) ||
	nvl(lower(ssn.machine), ins.host_name) "SESSION",
	to_char(prc.spid, '999999999') "PID/THREAD",
	to_char((se1.value/1024)/1024, '999G999G990D00') || ' MB' " CURRENT SIZE",
	to_char((se2.value/1024)/1024, '999G999G990D00') || ' MB' " MAXIMUM SIZE"
FROM v$sesstat se1, v$sesstat se2, v$session ssn, v$bgprocess bgp, v$process prc,
	v$instance ins, v$statname stat1, v$statname stat2
WHERE se1.statistic# = stat1.statistic# and stat1.name = 'session pga memory'
  AND se2.statistic# = stat2.statistic# and stat2.name = 'session pga memory max'
  AND se1.sid = ssn.sid
  AND se2.sid = ssn.sid
  AND ssn.paddr = bgp.paddr (+)
  AND ssn.paddr = prc.addr (+);

-- sga memory usage
select sum(value) from v$sga;

<end node> 5P9i0s8y19Z
dt=Text
<node>
sql to check new features 
3
-- Each new version—both major and minor—of Oracle Database brings with it numerous modifications 
-- and additions to the optimizer algorithms, so query plans can and will change—not always for 
-- the better—if you upgrade the database. There were 105 such modifications and additions just 
-- in the 11.2.0.2 upgrade.

SELECT sql_feature, description 
  FROM v$system_fix_control
 WHERE optimizer_feature_enable = '11.2.0.2'
 ORDER BY sql_feature;


-- modified sql query 
SELECT sql_feature, description, REPLACE(optimizer_feature_enable,'.')
FROM v$system_fix_control 
WHERE TO_NUMBER(REPLACE(optimizer_feature_enable,'.')) = 11204

<end node> 5P9i0s8y19Z
dt=Text
<node>
Tuning Undo Retention
3
-- Automatic Tuning of Undo Retention and Optimization
-- The following query will helps to optimize the UNDO_RETENTION parameter:

-- Otimal Undo Retention

/*

URL : https://dbpost.wordpress.com/tag/calculating-undo_retention-for-given-undo-tabespace/

Oracle Database automatically tunes the undo retention period based on how the undo tablespace 
is configured.

If the undo tablespace is fixed size, the database tunes the retention period for the best possible 
undo retention for that tablespace size and the current system load. This tuned retention period 
can be significantly greater than the specified minimum retention period.

If the undo tablespace is configured with the AUTOEXTEND option, the database tunes the undo 
retention period to be somewhat longer than the longest-running query on the system at that 
time. Again, this tuned retention period can be greater than the specified minimum 
retention period.

Determine the current retention period by querying the TUNED_UNDORETENTION column of 
the V$UNDOSTAT view. This view contains one row for each 10-minute statistics collection interval 
over the last 4 days. (Beyond 4 days, the data is available in the DBA_HIST_UNDOSTAT view.) 
TUNED_UNDORETENTION is given in seconds.
*/

-- Calculating required UNDO Size for given Database Activity
-- or Optimal Undo Retention
SELECT d.undo_size/(1024*1024) "ACTUAL UNDO SIZE [MByte]",
	  SUBSTR(e.value,1,25) "UNDO RETENTION [Sec]",
	  ROUND((d.undo_size / (to_number(f.value) * g.undo_block_per_sec))) "OPTIMAL UNDO RETENTION [Sec]"
FROM (SELECT SUM(a.bytes) undo_size
	    FROM v$datafile a, v$tablespace b,
             dba_tablespaces c
       WHERE c.contents = 'UNDO'
         AND c.status = 'ONLINE'
         AND b.name = c.tablespace_name
         AND a.ts# = b.ts#
      ) d,
    v$parameter e,
    v$parameter f,
   (
     SELECT MAX(undoblks/((end_time-begin_time)*3600*24))
            undo_block_per_sec
       FROM v$undostat) g
WHERE e.name = 'undo_retention'
  AND f.name = 'db_block_size';


-- If you are not limited by disk space, then it would be better to choose the UNDO_RETENTION 
-- time that is best for you (for FLASHBACK, etc.). Allocate the appropriate size to the UNDO 
-- tablespace according to the database activity:
SELECT d.undo_size/(1024*1024) "ACTUAL UNDO SIZE [MByte]",
 		SUBSTR(e.value,1,25) "UNDO RETENTION [Sec]",
 		(TO_NUMBER(e.value) * TO_NUMBER(f.value) * g.undo_block_per_sec) / (1024*1024)  "NEEDED UNDO SIZE [MByte]"
  FROM (
 		  SELECT SUM(a.bytes) undo_size
 		    FROM v$datafile a,
 			     v$tablespace b,
			     dba_tablespaces c
		   WHERE c.contents = 'UNDO'
		     AND c.status = 'ONLINE'
		     AND b.name = c.tablespace_name
		     AND a.ts# = b.ts#
 	   ) d,
	  v$parameter e,
	  v$parameter f,
	  (
		 SELECT MAX(undoblks/((end_time-begin_time)*3600*24))
		 	undo_block_per_sec
		   FROM v$undostat
	  ) g
 WHERE e.name = 'undo_retention'
 AND f.name = 'db_block_size'
/

<end node> 5P9i0s8y19Z
dt=Text
<node>
Password extend
3
SELECT SYS_CONTEXT('USERENV','DB_NAME')Database_Name,
       username, account_status, lock_date, expiry_date, 
       su.PASSWORD, du.PROFILE profile_set, dp.PROFILE Null_Pass_Profile,
  ' ALTER USER '||USERNAME|| ' PROFILE DEFAULT; '||CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' IDENTIFIED BY VALUES '''||SU.PASSWORD||''';' ||CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' PROFILE '||du.PROFILE||'; '|| CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' ACCOUNT UNLOCK;' RESET_CMD
FROM dba_users du, sys.user$ su, 
    (SELECT PROFILE 
       FROM (
              SELECT  PROFILE, RANK() OVER(ORDER BY PROFILE) AS rn
                FROM dba_profiles 
               WHERE resource_name='PASSWORD_VERIFY_FUNCTION'
                 AND LIMIT='NULL' 
            )WHERE rn=1) dp
WHERE du.username = su.NAME
  AND du.username = 'CNAOMON'
ORDER BY username ASC;  



begin
	for i in (
				SELECT 
				  ' ALTER USER '||USERNAME|| ' PROFILE DEFAULT; '||CHR(10)||CHR(10)||
				  ' ALTER USER '||USERNAME|| ' IDENTIFIED BY VALUES '''||SU.PASSWORD||''';' ||CHR(10)||CHR(10)||
				  ' ALTER USER '||USERNAME|| ' PROFILE '||du.PROFILE||'; '|| CHR(10)||CHR(10)||
				  ' ALTER USER '||USERNAME|| ' ACCOUNT UNLOCK;' RESET_CMD
				FROM dba_users du, sys.user$ su, 
					(SELECT PROFILE 
					   FROM (
							  SELECT  PROFILE, RANK() OVER(ORDER BY PROFILE) AS rn
								FROM dba_profiles 
							   WHERE resource_name='PASSWORD_VERIFY_FUNCTION'
								 AND LIMIT='NULL' 
							)WHERE rn=1) dp
				WHERE du.username = su.NAME
				  AND du.username = 'CNAOMON'
				ORDER BY username ASC)
	loop
		execute immediate (i.RESET_CMD)
	end loo;
end;
/

<end node> 5P9i0s8y19Z
dt=Text
<node>
Compile Objs
3

-- MY_SCHEMA = schemaname to be compile
-- MY_PACKAGE = Object name to be compile based on the object_type mentioned at starting 
EXEC DBMS_DDL.alter_compile('PACKAGE', 'MY_SCHEMA', 'MY_PACKAGE');
EXEC DBMS_DDL.alter_compile('PACKAGE BODY', 'MY_SCHEMA', 'MY_PACKAGE');
EXEC DBMS_DDL.alter_compile('PROCEDURE', 'MY_SCHEMA', 'MY_PROCEDURE');
EXEC DBMS_DDL.alter_compile('FUNCTION', 'MY_SCHEMA', 'MY_FUNCTION');
EXEC DBMS_DDL.alter_compile('TRIGGER', 'MY_SCHEMA', 'MY_TRIGGER'); 

--- below script will compile all invalid package and package body 
SET SERVEROUTPUT ON SIZE 1000000
BEGIN
  FOR cur_rec IN (SELECT owner,
                         object_name,
                         object_type,
                         DECODE(object_type, 'PACKAGE', 1,
                                             'PACKAGE BODY', 2, 2) AS recompile_order
                    FROM dba_objects
                   WHERE object_type IN ('PACKAGE', 'PACKAGE BODY')
				AND owner in ('BATCHUSER','CEDEBAT','CEDECODE','CEDELITE','PESDBO')
                     AND status != 'VALID'
                   ORDER BY 4)
  LOOP
    BEGIN
      IF cur_rec.object_type = 'PACKAGE' THEN
        EXECUTE IMMEDIATE 'ALTER ' || cur_rec.object_type || ' "' || cur_rec.owner || '"."' || cur_rec.object_name || '" COMPILE';
      ElSE
        EXECUTE IMMEDIATE 'ALTER PACKAGE "' || cur_rec.owner || '"."' || cur_rec.object_name || '" COMPILE BODY';
      END IF;
    EXCEPTION
      WHEN OTHERS THEN
        DBMS_OUTPUT.put_line(cur_rec.object_type || ' : ' || cur_rec.owner || ' : ' || cur_rec.object_name);
    END;
  END LOOP;
END;
/

<end node> 5P9i0s8y19Z
dt=Text
<node>
compare schema
3
-- compare schema using dblink
select owner, object_type, count(*) source_cnt_cedpp, 
    nvl((select count(*) target_cnt_cedrp 
       from dba_objects@cedrp crp 
      where crp.owner = cpp.owner 
        and crp.object_type = cpp.object_type 
      group by owner, object_type),0) target_cnt_cedrp
from dba_objects cpp
where owner in ('CEDEBAT','CEDECODE','CEDELITE','PESDBO')
group by owner, object_type
order by owner, object_type asc

<end node> 5P9i0s8y19Z
dt=Text
<node>
Session Wait info
3

--- Use this query to determine possible blocking locks:
SELECT se.username,
       NULL,
       se.sid,
       DECODE( se.command,
               0, 'No command',
               1, 'CREATE TABLE',
               2, 'INSERT',
               3, 'SELECT',
               4, 'CREATE CLUSTER',
               5, 'ALTER CLUSTER',
               6, 'UPDATE',
               7, 'DELETE',
               8, 'DROP CLUSTER',
               9, 'CREATE INDEX',
               10, 'DROP INDEX',
               11, 'ALTER INDEX',
               12, 'DROP TABLE',
               13, 'CREATE SEQUENCE',
               14, 'ALTER SEQUENCE',
               15, 'ALTER TABLE',
               16, 'DROP SEQUENCE',
               17, 'GRANT',
               18, 'REVOKE',
               19, 'CREATE SYNONYM',
               20, 'DROP SYNONYM',
               21, 'CREATE VIEW',
               22, 'DROP VIEW',
               23, 'VALIDATE INDEX',
               24, 'CREATE PROCEDURE',
               25, 'ALTER PROCEDURE',
               26, 'LOCK TABLE',
               27, 'NO OPERATION',
               28, 'RENAME',
               29, 'COMMENT',
               30, 'AUDIT',
               31, 'NOAUDIT',
               32, 'CREATE DATABASE LINK',
               33, 'DROP DATABASE LINK',
               34, 'CREATE DATABASE',
               35, 'ALTER DATABASE',
               36, 'CREATE ROLLBACK SEGMENT',
               37, 'ALTER ROLLBACK SEGMENT',
               38, 'DROP ROLLBACK SEGMENT',
               39, 'CREATE TABLESPACE',
               40, 'ALTER TABLESPACE',
               41, 'DROP TABLESPACE',
               42, 'ALTER SESSION',
               43, 'ALTER USER',
               44, 'COMMIT',
               45, 'ROLLBACK',
               46, 'SAVEPOINT',
               47, 'PL/SQL EXECUTE',
               48, 'SET TRANSACTION', 
               49, 'ALTER SYSTEM SWITCH LOG',
               50, 'EXPLAIN',
               51, 'CREATE USER',
               52, 'CREATE ROLE',
               53, 'DROP USER',
               54, 'DROP ROLE',
               55, 'SET ROLE',
               56, 'CREATE SCHEMA',
               57, 'CREATE CONTROL FILE',
               58, 'ALTER TRACING',
               59, 'CREATE TRIGGER',
               60, 'ALTER TRIGGER',
               61, 'DROP TRIGGER',
               62, 'ANALYZE TABLE',
               63, 'ANALYZE INDEX',
               64, 'ANALYZE CLUSTER',
               65, 'CREATE PROFILE',
               67, 'DROP PROFILE',
               68, 'ALTER PROFILE',
               69, 'DROP PROCEDURE',
               70, 'ALTER RESOURCE COST',
               71, 'CREATE SNAPSHOT LOG',
               72, 'ALTER SNAPSHOT LOG',
               73, 'DROP SNAPSHOT LOG',
               74, 'CREATE SNAPSHOT',
               75, 'ALTER SNAPSHOT',
               76, 'DROP SNAPSHOT',
               79, 'ALTER ROLE',
               85, 'TRUNCATE TABLE',
               86, 'TRUNCATE CLUSTER',
               88, 'ALTER VIEW',
               91, 'CREATE FUNCTION',
               92, 'ALTER FUNCTION',
               93, 'DROP FUNCTION',
               94, 'CREATE PACKAGE',
               95, 'ALTER PACKAGE',
               96, 'DROP PACKAGE',
               97, 'CREATE PACKAGE BODY',
               98, 'ALTER PACKAGE BODY',
               99, 'DROP PACKAGE BODY',
         TO_CHAR(se.command) ) command,
       DECODE(lo.type,
         'MR', 'Media Recovery',
         'RT', 'Redo Thread',
         'UN', 'User Name',
         'TX', 'Transaction',
         'TM', 'DML',
         'UL', 'PL/SQL User Lock',
         'DX', 'Distributed Xaction',
         'CF', 'Control File',
         'IS', 'Instance State',
         'FS', 'File Set',
         'IR', 'Instance Recovery',
         'ST', 'Disk Space Transaction',
         'TS', 'Temp Segment',
         'IV', 'Library Cache Invalidation',
         'LS', 'Log Start or Switch',
         'RW', 'Row Wait',
         'SQ', 'Sequence Number',
         'TE', 'Extend Table',
         'TT', 'Temp Table',
         'JQ', 'Job Queue',
         lo.type) ltype,
       DECODE( lo.lmode, 
         0, 'NONE',           /* Mon Lock equivalent */
         1, 'Null Mode',      /* N */
         2, 'Row-S (SS)',     /* L */
         3, 'Row-X (SX)',     /* R */
         4, 'Share (S)',      /* S */
         5, 'S/Row-X (SSX)',  /* C */
         6, 'Excl (X)',       /* X */
         lo.lmode) lmode,
       DECODE( lo.request, 
         0, 'NONE',           /* Mon Lock equivalent */
         1, 'Null',           /* N */
         2, 'Row-S (SS)',     /* L */
         3, 'Row-X (SX)',     /* R */
         4, 'Share (S)',      /* S */
         5, 'S/Row-X (SSX)',  /* C */
         6, 'Excl (X)',       /* X */
         TO_CHAR(lo.request)) request,
       lo.ctime ctime,
       DECODE(lo.block,
         0, 'No Block',
         1, 'Blocking',
         2, 'Global',
         TO_CHAR(lo.block)) blkothr,
       'SYS' owner,
       ro.name image
  FROM v$lock lo,
       v$session se,
       v$transaction tr,
       v$rollname ro
 WHERE se.sid = lo.sid
   AND se.taddr = tr.addr(+)
   AND tr.xidusn = ro.usn(+)
 ORDER BY sid;

------------------------------------------------------------------
-- best sql query to get session info and wait on

set pagesize 100 linesize 32000
col username       format a12
col sid            format 9999
col state          format a25
col event          format a50
col wait_time      format 99999999
col command        format a8
col kill           format a15
select  sys_context('USERENV','DB_NAME')database_name,
    ''''||s.sid ||','|| s.serial#||',@'||s.inst_id ||'''' sess_info, s.schemaname,s.username,  se.state,
	 s.sql_id, 
     a.object, a.type,
	decode(s.command,0,'UNKNOWN',
	1,'CREATE TABLE',
	2,'INSERT',
	3,'SELECT',
	4,'CREATE CLUSTER',
	5,'ALTER CLUSTER',
	6,'UPDATE',
	7,'DELETE',
	8,'DROP CLUSTER',
	9,'CREATE INDEX',
	10,'DROP INDEX',
	11,'ALTER INDEX',
	12,'DROP TABLE',
	13,'CREATE SEQUENCE',
	14,'ALTER SEQUENCE',
	15,'ALTER TABLE',
	16,'DROP SEQUENCE',
	17,'GRANT OBJECT',
	18,'REVOKE OBJECT',
	19,'CREATE SYNONYM',
	20,'DROP SYNONYM',
	21,'CREATE VIEW',
	22,'DROP VIEW',
	23,'VALIDATE INDEX',
	24,'CREATE PROCEDURE',
	25,'ALTER PROCEDURE',
	26,'LOCK',
	27,'NO-OP',
	28,'RENAME',
	29,'COMMENT',
	30,'AUDIT OBJECT',
	31,'NOAUDIT OBJECT',
	32,'CREATE DATABASE LINK',
	33,'DROP DATABASE LINK',
	34,'CREATE DATABASE',
	35,'ALTER DATABASE',
	36,'CREATE ROLLBACK SEG',
	37,'ALTER ROLLBACK SEG',
	38,'DROP ROLLBACK SEG',
	39,'CREATE TABLESPACE',
	40,'ALTER TABLESPACE',
	41,'DROP TABLESPACE',
	42,'ALTER SESSION',
	43,'ALTER USER',
	44,'COMMIT',
	45,'ROLLBACK',
	46,'SAVEPOINT',
	47,'PL/SQL EXECUTE',
	48,'SET TRANSACTION',
	49,'ALTER SYSTEM',
	50,'EXPLAIN',
	51,'CREATE USER',
	52,'CREATE ROLE',
	53,'DROP USER',
	54,'DROP ROLE',
	55,'SET ROLE',
	56,'CREATE SCHEMA',
	57,'CREATE CONTROL FILE',
	59,'CREATE TRIGGER',
	60,'ALTER TRIGGER',
	61,'DROP TRIGGER',
	62,'ANALYZE TABLE',
	63,'ANALYZE INDEX',
	64,'ANALYZE CLUSTER',
	65,'CREATE PROFILE',
	66,'DROP PROFILE',
	67,'ALTER PROFILE',
	68,'DROP PROCEDURE',
	70,'ALTER RESOURCE COST',
	71,'CREATE MATERIALIZED VIEW LOG',
	72,'ALTER MATERIALIZED VIEW LOG',
	73,'DROP MATERIALIZED VIEW LOG',
	74,'CREATE MATERIALIZED VIEW',
	75,'ALTER MATERIALIZED VIEW',
	76,'DROP MATERIALIZED VIEW',
	77,'CREATE TYPE',
	78,'DROP TYPE',
	79,'ALTER ROLE',
	80,'ALTER TYPE',
	81,'CREATE TYPE BODY',
	82,'ALTER TYPE BODY',
	83,'DROP TYPE BODY',
	84,'DROP LIBRARY',
	85,'TRUNCATE TABLE',
	86,'TRUNCATE CLUSTER',
	88,'ALTER VIEW',
	91,'CREATE FUNCTION',
	92,'ALTER FUNCTION',
	93,'DROP FUNCTION',
	94,'CREATE PACKAGE',
	95,'ALTER PACKAGE',
	96,'DROP PACKAGE',
	97,'CREATE PACKAGE BODY',
	98,'ALTER PACKAGE BODY',
	99,'DROP PACKAGE BODY',
	100,'LOGON',
	101,'LOGOFF',
	102,'LOGOFF BY CLEANUP',
	103,'SESSION REC',
	104,'SYSTEM AUDIT',
	105,'SYSTEM NOAUDIT',
	106,'AUDIT DEFAULT',
	107,'NOAUDIT DEFAULT',
	108,'SYSTEM GRANT',
	109,'SYSTEM REVOKE',
	110,'CREATE PUBLIC SYNONYM',
	111,'DROP PUBLIC SYNONYM',
	112,'CREATE PUBLIC DATABASE LINK',
	113,'DROP PUBLIC DATABASE LINK',
	114,'GRANT ROLE',
	115,'REVOKE ROLE',
	116,'EXECUTE PROCEDURE',
	117,'USER COMMENT',
	118,'ENABLE TRIGGER',
	119,'DISABLE TRIGGER',
	120,'ENABLE ALL TRIGGERS',
	121,'DISABLE ALL TRIGGERS',
	122,'NETWORK ERROR',
	123,'EXECUTE TYPE',
	128,'FLASHBACK',
	129,'CREATE SESSION',
	130,'ALTER MINING MODEL',
	131,'SELECT MINING MODEL',
	133,'CREATE MINING MODEL',
	134,'ALTER PUBLIC SYNONYM',
	135,'DIRECTORY EXECUTE',
	136,'SQL*LOADER DIRECT PATH LOAD',
	137,'DATAPUMP DIRECT PATH UNLOAD',
	157,'CREATE DIRECTORY',
	158,'DROP DIRECTORY',
	159,'CREATE LIBRARY',
	160,'CREATE JAVA',
	161,'ALTER JAVA',
	162,'DROP JAVA',
	163,'CREATE OPERATOR',
	164,'CREATE INDEXTYPE',
	165,'DROP INDEXTYPE',
	166,'ALTER INDEXTYPE',
	167,'DROP OPERATOR',
	168,'ASSOCIATE STATISTICS',
	169,'DISASSOCIATE STATISTICS',
	170,'CALL METHOD',
	171,'CREATE SUMMARY',
	172,'ALTER SUMMARY',
	173,'DROP SUMMARY',
	174,'CREATE DIMENSION',
	175,'ALTER DIMENSION',
	176,'DROP DIMENSION',
	177,'CREATE CONTEXT',
	178,'DROP CONTEXT',
	179,'ALTER OUTLINE',
	180,'CREATE OUTLINE',
	181,'DROP OUTLINE',
	182,'UPDATE INDEXES',
	183,'ALTER OPERATOR',
	192,'ALTER SYNONYM',
	197,'PURGE USER_RECYCLEBIN',
	198,'PURGE DBA_RECYCLEBIN',
	199,'PURGE TABLESPACE',
	200,'PURGE TABLE',
	201,'PURGE INDEX',
	202,'UNDROP OBJECT',
	204,'FLASHBACK DATABASE',
	205,'FLASHBACK TABLE',
	206,'CREATE RESTORE POINT',
	207,'DROP RESTORE POINT',
	208,'PROXY AUTHENTICATION ONLY',
	209,'DECLARE REWRITE EQUIVALENCE',
	210,'ALTER REWRITE EQUIVALENCE',
	211,'DROP REWRITE EQUIVALENCE',
	212,'CREATE EDITION',
	213,'ALTER EDITION',
	214,'DROP EDITION',
	215,'DROP ASSEMBLY',
	216,'CREATE ASSEMBLY',
	217,'ALTER ASSEMBLY',
	218,'CREATE FLASHBACK ARCHIVE',
	219,'ALTER FLASHBACK ARCHIVE',
	220,'DROP FLASHBACK ARCHIVE',
	225,'ALTER DATABASE LINK',
	305,'ALTER PUBLIC DATABASE LINK') command,
	s.status,
     se.wait_time,
     se.seconds_in_wait,
     se.event,
     s.blocking_session,
	s.blocking_session_status,
	'select * from table(dbms_xplan.display_cursor('||''''||s.sql_id ||''''||',null,''ADVANCED OUTLINE ALLSTATS LAST +PEEKED_BINDS''));'  for_plan 
 from gv$session s, gv$session_wait se, gv$access a
where 1=1  
  and s.sid=se.sid
  and s.sid=a.sid
  and s.inst_id=se.inst_id
-- and se.event not like 'SQL*Net%'
  and se.event not like '%rdbms%'
  and s.username is not null
--  and s.schemaname='MIS'
--  and a.object='CODS_CLAIM_WIP'
  and SQL_ID is not null 
order by se.wait_time;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Session process info
3
col kill       for a15
col evnt   for a30
col usr    for a10
col osuser for a14
col mach   for a8
col prog   for a20
col sid    for 999
select ''''||a.sid ||','|| a.serial#||',@'||a.inst_id ||'''' kill,osuser,substr(a.username,1,10) usr,substr(a.program,1,20) prog,to_char(logon_time,'dd/mm hh24:mm:ss') logon,sql_id,prev_sql_id,substr(event,1,30) evnt,pga_alloc_mem pga
	,decode(a.command,0,'UNKNOWN',
	1,'CREATE TABLE',
	2,'INSERT',
	3,'SELECT',
	4,'CREATE CLUSTER',
	5,'ALTER CLUSTER',
	6,'UPDATE',
	7,'DELETE',
	8,'DROP CLUSTER',
	9,'CREATE INDEX',
	10,'DROP INDEX',
	11,'ALTER INDEX',
	12,'DROP TABLE',
	13,'CREATE SEQUENCE',
	14,'ALTER SEQUENCE',
	15,'ALTER TABLE',
	16,'DROP SEQUENCE',
	17,'GRANT OBJECT',
	18,'REVOKE OBJECT',
	19,'CREATE SYNONYM',
	20,'DROP SYNONYM',
	21,'CREATE VIEW',
	22,'DROP VIEW',
	23,'VALIDATE INDEX',
	24,'CREATE PROCEDURE',
	25,'ALTER PROCEDURE',
	26,'LOCK',
	27,'NO-OP',
	28,'RENAME',
	29,'COMMENT',
	30,'AUDIT OBJECT',
	31,'NOAUDIT OBJECT',
	32,'CREATE DATABASE LINK',
	33,'DROP DATABASE LINK',
	34,'CREATE DATABASE',
	35,'ALTER DATABASE',
	36,'CREATE ROLLBACK SEG',
	37,'ALTER ROLLBACK SEG',
	38,'DROP ROLLBACK SEG',
	39,'CREATE TABLESPACE',
	40,'ALTER TABLESPACE',
	41,'DROP TABLESPACE',
	42,'ALTER SESSION',
	43,'ALTER USER',
	44,'COMMIT',
	45,'ROLLBACK',
	46,'SAVEPOINT',
	47,'PL/SQL EXECUTE',
	48,'SET TRANSACTION',
	49,'ALTER SYSTEM',
	50,'EXPLAIN',
	51,'CREATE USER',
	52,'CREATE ROLE',
	53,'DROP USER',
	54,'DROP ROLE',
	55,'SET ROLE',
	56,'CREATE SCHEMA',
	57,'CREATE CONTROL FILE',
	59,'CREATE TRIGGER',
	60,'ALTER TRIGGER',
	61,'DROP TRIGGER',
	62,'ANALYZE TABLE',
	63,'ANALYZE INDEX',
	64,'ANALYZE CLUSTER',
	65,'CREATE PROFILE',
	66,'DROP PROFILE',
	67,'ALTER PROFILE',
	68,'DROP PROCEDURE',
	70,'ALTER RESOURCE COST',
	71,'CREATE MATERIALIZED VIEW LOG',
	72,'ALTER MATERIALIZED VIEW LOG',
	73,'DROP MATERIALIZED VIEW LOG',
	74,'CREATE MATERIALIZED VIEW',
	75,'ALTER MATERIALIZED VIEW',
	76,'DROP MATERIALIZED VIEW',
	77,'CREATE TYPE',
	78,'DROP TYPE',
	79,'ALTER ROLE',
	80,'ALTER TYPE',
	81,'CREATE TYPE BODY',
	82,'ALTER TYPE BODY',
	83,'DROP TYPE BODY',
	84,'DROP LIBRARY',
	85,'TRUNCATE TABLE',
	86,'TRUNCATE CLUSTER',
	88,'ALTER VIEW',
	91,'CREATE FUNCTION',
	92,'ALTER FUNCTION',
	93,'DROP FUNCTION',
	94,'CREATE PACKAGE',
	95,'ALTER PACKAGE',
	96,'DROP PACKAGE',
	97,'CREATE PACKAGE BODY',
	98,'ALTER PACKAGE BODY',
	99,'DROP PACKAGE BODY',
	100,'LOGON',
	101,'LOGOFF',
	102,'LOGOFF BY CLEANUP',
	103,'SESSION REC',
	104,'SYSTEM AUDIT',
	105,'SYSTEM NOAUDIT',
	106,'AUDIT DEFAULT',
	107,'NOAUDIT DEFAULT',
	108,'SYSTEM GRANT',
	109,'SYSTEM REVOKE',
	110,'CREATE PUBLIC SYNONYM',
	111,'DROP PUBLIC SYNONYM',
	112,'CREATE PUBLIC DATABASE LINK',
	113,'DROP PUBLIC DATABASE LINK',
	114,'GRANT ROLE',
	115,'REVOKE ROLE',
	116,'EXECUTE PROCEDURE',
	117,'USER COMMENT',
	118,'ENABLE TRIGGER',
	119,'DISABLE TRIGGER',
	120,'ENABLE ALL TRIGGERS',
	121,'DISABLE ALL TRIGGERS',
	122,'NETWORK ERROR',
	123,'EXECUTE TYPE',
	128,'FLASHBACK',
	129,'CREATE SESSION',
	130,'ALTER MINING MODEL',
	131,'SELECT MINING MODEL',
	133,'CREATE MINING MODEL',
	134,'ALTER PUBLIC SYNONYM',
	135,'DIRECTORY EXECUTE',
	136,'SQL*LOADER DIRECT PATH LOAD',
	137,'DATAPUMP DIRECT PATH UNLOAD',
	157,'CREATE DIRECTORY',
	158,'DROP DIRECTORY',
	159,'CREATE LIBRARY',
	160,'CREATE JAVA',
	161,'ALTER JAVA',
	162,'DROP JAVA',
	163,'CREATE OPERATOR',
	164,'CREATE INDEXTYPE',
	165,'DROP INDEXTYPE',
	166,'ALTER INDEXTYPE',
	167,'DROP OPERATOR',
	168,'ASSOCIATE STATISTICS',
	169,'DISASSOCIATE STATISTICS',
	170,'CALL METHOD',
	171,'CREATE SUMMARY',
	172,'ALTER SUMMARY',
	173,'DROP SUMMARY',
	174,'CREATE DIMENSION',
	175,'ALTER DIMENSION',
	176,'DROP DIMENSION',
	177,'CREATE CONTEXT',
	178,'DROP CONTEXT',
	179,'ALTER OUTLINE',
	180,'CREATE OUTLINE',
	181,'DROP OUTLINE',
	182,'UPDATE INDEXES',
	183,'ALTER OPERATOR',
	192,'ALTER SYNONYM',
	197,'PURGE USER_RECYCLEBIN',
	198,'PURGE DBA_RECYCLEBIN',
	199,'PURGE TABLESPACE',
	200,'PURGE TABLE',
	201,'PURGE INDEX',
	202,'UNDROP OBJECT',
	204,'FLASHBACK DATABASE',
	205,'FLASHBACK TABLE',
	206,'CREATE RESTORE POINT',
	207,'DROP RESTORE POINT',
	208,'PROXY AUTHENTICATION ONLY',
	209,'DECLARE REWRITE EQUIVALENCE',
	210,'ALTER REWRITE EQUIVALENCE',
	211,'DROP REWRITE EQUIVALENCE',
	212,'CREATE EDITION',
	213,'ALTER EDITION',
	214,'DROP EDITION',
	215,'DROP ASSEMBLY',
	216,'CREATE ASSEMBLY',
	217,'ALTER ASSEMBLY',
	218,'CREATE FLASHBACK ARCHIVE',
	219,'ALTER FLASHBACK ARCHIVE',
	220,'DROP FLASHBACK ARCHIVE',
	225,'ALTER DATABASE LINK',
	305,'ALTER PUBLIC DATABASE LINK') command
from gv$session a,gv$process b 
where a.paddr=b.addr 
and a.inst_id=b.inst_id
and b.username is not null 
order by 9 desc ;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Sequence alteration
3

SELECT 'alter sequence '||SEQUENCE_OWNER||'.'||SEQUENCE_NAME||' increment by '||decode(diff_number,0,(to_number(TW_Seq_LastNumber+100)),(to_number(diff_number+100)))||';'||CHR(10)||
       'select '||SEQUENCE_OWNER||'.'||SEQUENCE_NAME||'.nextval from dual;' ||CHR(10)||
       'alter sequence '||SEQUENCE_OWNER||'.'||SEQUENCE_NAME||' increment by 2;'||CHR(10)||
       'select '||SEQUENCE_OWNER||'.'||SEQUENCE_NAME||'.nextval from dual;' oops
FROM (
     SELECT tw.SEQUENCE_OWNER,
            TW.SEQUENCE_NAME,
            TW.LAST_NUMBER TW_Seq_LastNumber,
            TE.LAST_NUMBER TE_SEQ_LastNumber,
            TE.LAST_NUMBER - TW.LAST_NUMBER diff_number,
            TW.CACHE_SIZE            
       FROM dba_sequences TW, dba_sequences@brptp TE
      WHERE  TW.SEQUENCE_OWNER IN ('BO')
            AND TW.SEQUENCE_OWNER = TE.SEQUENCE_OWNER
            AND TW.SEQUENCE_NAME = TE.SEQUENCE_NAME
--            AND TE.LAST_NUMBER > TW.LAST_NUMBER
   ORDER BY 5 DESC)
--  where sequence_name in 
-- and sequence_owner='BO'

SELECT 'alter sequence '||SEQUENCE_OWNER||'.'||SEQUENCE_NAME||' increment by '||to_number(diff_number+100)||';'||CHR(10)||
       'select '||SEQUENCE_OWNER||'.'||SEQUENCE_NAME||'.nextval from dual;' ||CHR(10)||
       'alter sequence '||SEQUENCE_OWNER||'.'||SEQUENCE_NAME||' increment by 2;'||CHR(10)||
       'select '||SEQUENCE_OWNER||'.'||SEQUENCE_NAME||'.nextval from dual;' oops
FROM (
     SELECT tw.SEQUENCE_OWNER,
            TW.SEQUENCE_NAME,
            TW.LAST_NUMBER TW_Seq_LastNumber,
            TE.LAST_NUMBER TE_SEQ_LastNumber,
            TE.LAST_NUMBER - TW.LAST_NUMBER diff_number,
            TW.CACHE_SIZE            
       FROM dba_sequences TW, dba_sequences@brptp TE
      WHERE     TW.SEQUENCE_OWNER IN ('BO')
            AND TW.SEQUENCE_OWNER = TE.SEQUENCE_OWNER
            AND TW.SEQUENCE_NAME = TE.SEQUENCE_NAME
--            AND TE.LAST_NUMBER > TW.LAST_NUMBER
   ORDER BY 5 DESC)
  where sequence_name in ('BO_TERRITORY_CD_ID_SEQ','GL_BI_PD_ID_SEQ','GL_CLASS_CD_ID','GL_CLASS_CD_ID_SEQ','LAYOUT_LOSS_ID_SEQ',
'LAYOUT_PREM_ID_SEQ','MP_CLASS_CD_ID_SEQ','NON_REPORTABLE_ID_SEQ','OPERAND_ID_SEQ','RECORD_ID_SEQ',
'TYPE_OF_POLICY_ID_SEQ','TYPE_OF_POLICY_LKU_ID_SEQ')


select sequence_owner,sequence_name,last_number
from dba_Sequences@brptp
where sequence_name in 
	('CORRECTION_RULE_TRACKING','DCI_CA_FACT_DATA','DCI_CA_YEAR_DIM','DCI_CA_SUBLINE_DIM','DCI_CA_STATE_TERR_DIM','DCI_CA_COVERAGE_DIM',
	'DCI_CA_CLASS_DIM','HOLDBACK_STATUS_LKU_BO','MI_HIST_CORR_RULE_TRACKING','MA_HIST_CORR_RULE_TRACKING','IM_HIST_CORR_RULE_TRACKING',
	'GL_HIST_CORR_RULE_TRACKING','COMFAL_HIST_CORR_RULE_TRACKING','CA_HIST_CORR_RULE_TRACKING','BO_HIST_CORR_RULE_TRACKING',
	'DCI_GL_FACT_DATA','DCI_GL_YEAR_DIM','DCI_GL_SUBLINE_DIM','DCI_GL_STATE_TERR_DIM','DCI_GL_COVERAGE_DIM','DCI_GL_CLASS_DIM',
	'CNA_CA_CURRENT_FACT','CNA_CA_YEARLY_FACT','HISTORY_MASTER_LOSS_FACT','HISTORY_MASTER_PREM_FACT','SU_HIST_CORR_RULE_TRACKING',
	'MATV_5QTR_COMFAL_CORR_TRKING','MATV_5QTR_CA_CORR_TRKING','MATV_5QTR_BO_CORR_TRKING','MATV_5QTR_HIST_IM_LOSS',
	'MATV_5QTR_HIST_MA_PREM','MATV_5QTR_HIST_MA_LOSS','MATV_5QTR_HIST_CA_LOSS','MATV_5QTR_HIST_GL_PREM',
	'MATV_5QTR_HIST_GL_LOSS','MATV_5QTR_HIST_BO_PREM','MATV_5QTR_HIST_BO_LOSS','MATV_5QTR_HIST_CA_PREM',
	'MATV_5QTR_HIST_COMFAL_PREM','MATV_5QTR_HIST_COMFAL_LOSS','MATV_5QTR_SU_CORR_TRKING','MATV_5QTR_MA_CORR_TRKING',
	'MATV_5QTR_IM_CORR_TRKING','MATV_5QTR_GL_CORR_TRKING','MATV_5QTR_HIST_IM_PREM','CNA_GL_CURRENT_FACT','CNA_GL_YEARLY_FACT',
	'FILING_STATUS_LKU_BO','FILING_SUMMARY_BO','HOLDBACK_SUMMARY_BO','MASTER_PREM_FACT','MASTER_LOSS_FACT','FBMT_SUMMARY_BO',
	'FBMT_STATUS_LKU_BO','NB_HIST_CORR_RULE_TRACKING','MATV_5QTR_HIST_NB_LOSS','MATV_5QTR_HIST_NB_PREM','MATV_5QTR_NB_CORR_TRKING')
 and sequence_owner='BO'
minus
select sequence_owner,sequence_name
from dba_sequences
where sequence_name in
	('CORRECTION_RULE_TRACKING','DCI_CA_FACT_DATA','DCI_CA_YEAR_DIM','DCI_CA_SUBLINE_DIM','DCI_CA_STATE_TERR_DIM','DCI_CA_COVERAGE_DIM',
	'DCI_CA_CLASS_DIM','HOLDBACK_STATUS_LKU_BO','MI_HIST_CORR_RULE_TRACKING','MA_HIST_CORR_RULE_TRACKING','IM_HIST_CORR_RULE_TRACKING',
	'GL_HIST_CORR_RULE_TRACKING','COMFAL_HIST_CORR_RULE_TRACKING','CA_HIST_CORR_RULE_TRACKING','BO_HIST_CORR_RULE_TRACKING',
	'DCI_GL_FACT_DATA','DCI_GL_YEAR_DIM','DCI_GL_SUBLINE_DIM','DCI_GL_STATE_TERR_DIM','DCI_GL_COVERAGE_DIM','DCI_GL_CLASS_DIM',
	'CNA_CA_CURRENT_FACT','CNA_CA_YEARLY_FACT','HISTORY_MASTER_LOSS_FACT','HISTORY_MASTER_PREM_FACT','SU_HIST_CORR_RULE_TRACKING',
	'MATV_5QTR_COMFAL_CORR_TRKING','MATV_5QTR_CA_CORR_TRKING','MATV_5QTR_BO_CORR_TRKING','MATV_5QTR_HIST_IM_LOSS',
	'MATV_5QTR_HIST_MA_PREM','MATV_5QTR_HIST_MA_LOSS','MATV_5QTR_HIST_CA_LOSS','MATV_5QTR_HIST_GL_PREM',
	'MATV_5QTR_HIST_GL_LOSS','MATV_5QTR_HIST_BO_PREM','MATV_5QTR_HIST_BO_LOSS','MATV_5QTR_HIST_CA_PREM',
	'MATV_5QTR_HIST_COMFAL_PREM','MATV_5QTR_HIST_COMFAL_LOSS','MATV_5QTR_SU_CORR_TRKING','MATV_5QTR_MA_CORR_TRKING',
	'MATV_5QTR_IM_CORR_TRKING','MATV_5QTR_GL_CORR_TRKING','MATV_5QTR_HIST_IM_PREM','CNA_GL_CURRENT_FACT','CNA_GL_YEARLY_FACT',
	'FILING_STATUS_LKU_BO','FILING_SUMMARY_BO','HOLDBACK_SUMMARY_BO','MASTER_PREM_FACT','MASTER_LOSS_FACT','FBMT_SUMMARY_BO',
	'FBMT_STATUS_LKU_BO','NB_HIST_CORR_RULE_TRACKING','MATV_5QTR_HIST_NB_LOSS','MATV_5QTR_HIST_NB_PREM','MATV_5QTR_NB_CORR_TRKING')
 and sequence_owner='BO'
 
 
select * from dba_Sequences where sequence_name='BO_TERRITORY_CD_ID_SEQ'

<end node> 5P9i0s8y19Z
dt=Text
<node>
how much % sql query 
3
-- to check where the expdp - data pump workers are running 
select * from gv$session where regexp_like(module,'*data*','i');

col username format a10
col OPNAME format a30
col SOFAR format 999999999
col 'WorkDone%' format 999.99
col Start_time format a20
col "End_At" for a20
select sl.inst_id, sl.sid, sl.serial#, sl.username, sl.opname,s.module,TOTALWORK, 
       ROUND(sl.sofar/sl.totalwork * 100, 2) "WorkDone%",    
       sl.target_desc, to_char(sl.start_time,'mm/dd/yyyy hh24:mi:ss')start_time,
       to_char(sl.last_update_time,'mm/dd/yyyy hh24:mi:ss')last_update_time,
       to_char(sysdate + TIME_REMAINING/3600/24,'DD-MON-YY hh24:mi:ss') "End_At",
       sl.message
from gv$session_longops sl, gv$session s
where sl.sid = s.sid
  and sl.serial# = s.serial#
--  and sl.opname='MRLNRF_MERWHP_02092020'
--and s.module like 'Data%'
;
======================================================================================

select sl.inst_id, sl.sid, sl.serial#, sl.username, sl.opname,s.module,TOTALWORK, 
        ROUND(sl.sofar/sl.totalwork * 100, 2) "WorkDone%",    
        sl.target_desc, to_char(sl.start_time,'mm/dd/yyyy hh24:mi:ss')start_time,
        to_char(sl.last_update_time,'mm/dd/yyyy hh24:mi:ss')last_update_time,
        to_char(sysdate + TIME_REMAINING/3600/24,'DD-MON-YY hh24:mi:ss') "End_At",
        sl.message
from gv$session_longops sl, gv$session s
where sl.sid = s.sid
  and sl.serial# = s.serial#
--  and sl.opname='MRLNRF_MERWHP_02092020'
order by to_char(sl.start_time,'mm/dd/yyyy hh24:mi:ss') asc;
======================================================================================

--- The query will give the percentage completion and sql query on which it's running 
select sl.inst_id, sl.sid, sl.serial#, sl.username, sl.opname, sl.target,
       sl.sql_id, ROUND(sl.sofar/sl.totalwork * 100)||'%' WorkDone,
       to_char(sl.start_time,'mm/dd/yyyy hh24:mi:ss')start_time,
       to_char(sysdate + TIME_REMAINING/3600/24,'mm/dd/yyyy hh24:mi:ss') End_At,
       dbms_xplan.format_time_S(time_remaining) Time_Remaining,
       s.module, sl.message, 
       (select substr(sql_text,1,70) from gv$sqlarea sa where s.sql_id = sa.sql_id and sa.inst_id=s.inst_id)sql_query
from gv$session_longops sl, gv$session s
where sl.sid = s.sid
  and sl.serial# = s.serial#
  and sl.sql_id=s.sql_id and s.sql_id='9qcaxd4b8rh2r'
  and sl.sofar <> 0 and sl.totalwork <> 0 
  and ROUND(sl.sofar/sl.totalwork * 100, 2) <>100
order by sl.username,sl.opname asc
;

======================================================================================

-- check the progress of stats collections
select inst_id,sid,serial#,username,sql_id,round(sofar/totalwork *100,2) WorkDone,
    units,target_desc,to_char(start_time,'mm/dd/yyyy hh24:mi:ss')start_time,
    to_char(last_update_time,'mm/dd/yyyy hh24:mi:ss')last_update_time,
    dbms_xplan.format_time_S(time_remaining) Time_Remaining,
    message,sql_plan_operation,sql_plan_options
from gv$session_longops
where opname like '%Gather%' 
  and sofar<>0 and totalwork<>0 
  and round(sofar/totalwork * 100,2) <> 100
;
======================================================================================

-- check if backgroud session is present for export/import jobs
select inst_id, sid,serial#,process,sql_id,schemaname,
    username,osuser,status,action job_name,machine,program,
    module,to_char(sql_exec_start,'mm/dd/yyyy hh24:mi:ss')sql_started
from gv$session 
where schemaname = 'SYS' 
  and type <> 'BACKGROUND'
 --and not regexp_like(program,'rman*','i')
 --and regexp_like(action,'sys_export*','i') 
  --and module = 'Data Pump Master'
  and status = 'ACTIVE';
======================================================================================

--- Below Queries will help to know the precentage completion of export/import
SELECT x.job_name,b.state,b.job_mode,b.DEGREE
, x.owner_name, P.totalwork, P.sofar
, ROUND((P.sofar/P.totalwork)*100,2) done
, P.time_remaining
FROM dba_datapump_jobs b
LEFT JOIN dba_datapump_sessions x ON (x.job_name = b.job_name)
LEFT JOIN v$session y ON (y.saddr = x.saddr)
LEFT JOIN v$sql z ON (y.sql_id = z.sql_id)
LEFT JOIN v$session_longops P ON (P.sql_id = y.sql_id)
WHERE y.module='Data Pump Worker'
AND P.time_remaining > 0; 
======================================================================================

col username format a10
 col OPNAME format a30
 col SOFAR format 999999999
 col 'WorkDone%' format 999.99
 col Start_time format a20
 col "End_At" for a20
select SID, username, OPNAME, SOFAR,
	TOTALWORK, SOFAR/TOTALWORK*100 "WorkDone%",
	to_char(START_TIME,'DD-MON-YY hh24:mi:ss') "start_time",
	to_char(sysdate + TIME_REMAINING/3600/24,'DD-MON-YY hh24:mi:ss') "End_At",message,
     sql_id
  from gv$session_longops
 where sofar!=TOTALWORK
   and totalwork!=0
--   and OPNAME like 'RMAN%'
 order by 1;


col target for a20
col username for a30
col MESSAGE for a30
col ELAPSED_SECONDS heading 'ELAPSED|SECONDS'
col PERCENT_COMPLETED heading 'PERCENT|COMPLETED'
col LAST_UPDATE_TIME heading 'LastUpdate|Time'
SELECT  sid, serial#, username, target, sofar, totalwork,
     to_char(start_time,'mm/dd/yyyy hh24:mi:ss')start_time,
     to_char(last_update_time,'mm/dd/yyyy hh24:mi:ss')last_update_time,
     ROUND(sofar/totalwork*100,2)  percent_completed, 
     elapsed_seconds,
     message,
     sql_id
FROM gv$session_longops 
WHERE sofar <> totalwork 
ORDER BY target, SID;


SELECT ROUND(sofar/totalwork*100,2) Completed, 
     sid,serial#, opname, target, sofar, totalwork,units
     start_time, last_update_time,time_remaining, elapsed_seconds,
     message, sql_id
FROM gv$session_longops 
WHERE sofar <> totalwork 
ORDER BY target, SID;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Session Consumers
3
---- long running session more then 4 hours
 select inst_id, sid,serial#,username,status,schemaname,machine,program,
        module,trunc(last_Call_et/3600,2)"LAST_CALL_IN_HR",sql_id,
        to_char(logon_time,'mm/dd/yyyy hh24:mi:ss')logon_time
 from gv$session 
 where status='INACTIVE'
  -- and last_call_et > 5 * 60
   and last_call_et >= 14400
order by trunc(last_Call_et/3600,2) asc ;

-- Most active SQL in previous hour.
SELECT sql_id,COUNT(*),ROUND(COUNT(*)/SUM(COUNT(*)) OVER(), 2) PCTLOAD
  FROM gv$active_session_history
 WHERE sample_time > SYSDATE - 1/24
   AND session_type = 'BACKGROUND'
 GROUP BY sql_id
 ORDER BY COUNT(*) DESC;


SELECT sql_id,COUNT(*),ROUND(COUNT(*)/SUM(COUNT(*)) OVER(), 2) PCTLOAD
  FROM gv$active_session_history
 WHERE sample_time > SYSDATE - 1/24
   AND session_type = 'FOREGROUND'
 GROUP BY sql_id
 ORDER BY COUNT(*) DESC;

-- Top 10 CPU consumers in last 60 minutes
select * from
(
	select session_id, session_serial#, count(*)
	  from v$active_session_history
	 where session_state= 'ON CPU'
	   and sample_time > sysdate - interval '60' minute
	 group by session_id, session_serial#
	 order by count(*) desc
)
where rownum <= 10;

-- Top 10 waiting sessions in last 60 minutes
select * from
(
	select session_id, session_serial#,count(*)
	  from v$active_session_history
	 where session_state='WAITING'
	   and sample_time >  sysdate - interval '60' minute
	 group by session_id, session_tab
	 order by count(*) desc
)
where rownum <= 10;

<end node> 5P9i0s8y19Z
dt=Text
<node>
duplicate data
3
No Title 

how does one eliminate duplicates rows from a table?

-- deleting duplicate records.
delete  sushil a WHERE rowid < (SELECT max(rowid) FROM sushil 
								WHERE name=a.name 
								GROUP BY name HAVING count (*)>1)

Choose one of the following queries to identify or remove duplicate rows from 
a table leaving only unique records in the table:
Method 1: 

     DELETE FROM table_name A WHERE ROWID > (
     SELECT min(rowid) FROM table_name B
     WHERE A.key_values = B.key_values);

Method 2: 
    create table table_name2 as select distinct * from table_name1;
    drop table_name1;
    rename table_name2 to table_name1;
    -- Remember to recreate all indexes, constraints, triggers, etc on table... 

Method 3: (thanks to Dennis Gurnick) 
    delete from my_table t1
    where  exists (select 'x' from my_table t2
                    where t2.key_value1 = t1.key_value1
                      and t2.key_value2 = t1.key_value2
                      and t2.rowid      > t1.rowid);

Note 1: One can eliminate N^2 unnecessary operations by creating an index on the 
        joined fields in the inner loop (no need to loop through the entire table on each 
        pass by a record). This will speed-up the deletion process. 
        
Note 2: If you are comparing NOT-NULL columns, use the NVL function. Remember that 
        NULL is not equal to NULL. This should not be a problem as all key columns should be 
        NOT NULL by definition. 


SELECT TASK_ID, DEVICE_ID FROM TRANSACTION
GROUP BY TASK_ID, DEVICE_ID
HAVING COUNT(*) > 1


-- delete 
SELECT * FROM columnlayout
WHERE ROWID IN (
      SELECT "ROWID"
      FROM (
            SELECT RANK() OVER(PARTITION BY USERNAME ORDER BY ROWID) RANK_N, ROWID AS "ROWID"
            FROM columnlayout
            WHERE USERNAME IN (
                  SELECT USERNAME FROM columnlayout
                  GROUP BY USERNAME
                  HAVING COUNT(*) > 1
            )
      )
      WHERE RANK_N > 1
); 

<end node> 5P9i0s8y19Z
dt=Text
<node>
check session
3
select sid,serial#,username,schemaname,status,osuser,process,machine
 from gv$session where sql_id='1bdmq58z699q0';

 select sid,serial#,username,schemaname,status,osuser,process,machine
 from gv$session 
 where sql_id='9g4ct3csdu181';
 
 
  select s.inst_id, s.sid, s.serial#, s.schemaname, 
    s.sql_id, s.machine, s.status,
	substr(s.username,1,18) username,
	substr(s.program,1,15) program,
	decode(s.command, 
			0, 'No Command',
			1, 'Create Table',
			2, 'Insert',
			3, 'Select',
			6, 'Update',
			7, 'Delete',
			9, 'Create Index',
			15, 'Alter Table',
			21, 'Create View',
			23, 'Validate Index',
			35, 'Alter Database',
			39, 'Create Tablespace',
			41, 'Drop Tablespace',
			40, 'Alter Tablespace',
			53, 'Drop User',
			62, 'Analyze Table',
			63, 'Analyze Index', s.command||': Other') command,
        to_char(s.prev_exec_start,'mm/dd/yyyy hh24:mi:ss') prev_exec_start
   from
   	  gv$session s, v$process p, v$transaction t,
   	  v$rollstat r, v$rollname n
   where s.paddr = p.addr 
     and s.taddr = t.addr (+)
     and t.xidusn = r.usn (+)
     and r.usn = n.usn (+)
     and s.sql_id in ('42s9qxfkdw2gb','g083w5r4dxpr3')
   order by to_char(s.prev_exec_start,'mm/dd/yyyy hh24:mi:ss') asc;

<end node> 5P9i0s8y19Z
dt=Text
<node>
sql*plus cmd
3
--- Computing the same type of summary value on different columns
compute sum of salary comission_pct on report
-- to print the total of salaries and commissions for all sales people, first enter the following COMPUTE command

-- clear computes

<end node> 5P9i0s8y19Z
dt=Text
<node>
script 2 generate indxs
3
SELECT 'CREATE UNIQUE INDEX '||owner||'.'||constraint_name||' ON '||owner||'.'||table_name||' ('||wm_concat(column_name)||')'||' tablespace INDEX_3;' "Unique_PrimaryKey_Cons_Index"
FROM 
(
    SELECT dcc.owner, dcc.constraint_name, dcc.table_name, DC.CONSTRAINT_TYPE, dcc.column_name, dcc.position 
    FROM dba_segments ds, dba_constraints dc, dba_cons_columns dcc
    WHERE ds.owner = dc.owner
      AND dc.owner = dcc.owner
      AND ds.segment_name = dc.constraint_name
      AND dc.constraint_name = dcc.constraint_name
      AND ds.tablespace_name='INDEX_2'
      AND ds.segment_type='INDEX'   
      AND dc.constraint_type IN ('P','U')
    ORDER BY dcc.owner, dcc.constraint_name, dcc.table_name, dcc.position  ASC 
)
GROUP BY owner, constraint_name, table_name, constraint_type

-- create script for primary key constraints
SELECT 'ALTER TABLE '||owner||'.'||table_name||' ADD (CONSTRAINT '||constraint_name||' PRIMARY KEY ('||wm_concat(column_name)||')'||' USING INDEX '||owner||'.'||constraint_name||');' "PrimaryKey_Cons"
FROM 
(
    SELECT dcc.owner, dcc.constraint_name, dcc.table_name, DC.CONSTRAINT_TYPE, dcc.column_name, dcc.position 
    FROM dba_segments ds, dba_constraints dc, dba_cons_columns dcc
    WHERE ds.owner = dc.owner
      AND dc.owner = dcc.owner
      AND ds.segment_name = dc.constraint_name
      AND dc.constraint_name = dcc.constraint_name
      AND ds.tablespace_name='INDEX_2'
      AND ds.segment_type='INDEX'   
      AND dc.constraint_type='P'
    ORDER BY dcc.owner, dcc.constraint_name, dcc.table_name, dcc.position  ASC 
)
GROUP BY owner, constraint_name, table_name, constraint_type

--- create script of unique and non-unique indexes
SELECT
    CASE 
        WHEN uniqueness = 'UNIQUE' THEN 'CREATE UNIQUE INDEX '||table_owner||'.'||index_name||' ON '||table_owner||'.'||table_name||' ('||wm_concat(column_name)||') TABLESPACE INDEX_3;' 
        WHEN uniqueness = 'NONUNIQUE' THEN 'CREATE INDEX '||table_owner||'.'||index_name||' ON '||table_owner||'.'||table_name||' ('||wm_concat(column_name)||') TABLESPACE INDEX_3;' 
        ELSE NULL
    END "Unique_NonUnique_Index"   
FROM 
(
    SELECT dic.table_owner, dic.index_owner, dic.index_name, dic.table_name,di.uniqueness, dic.column_name, dic.column_position
    FROM dba_indexes di, dba_ind_columns dic
    WHERE di.owner=dic.index_owner
      AND di.index_name = dic.index_name
       AND di.tablespace_name='INDEX_2'
      AND NOT EXISTS (SELECT 1 FROM dba_constraints dc 
      		       WHERE dc.owner=di.owner 
      		         AND dc.constraint_name = di.index_name 
      		         AND dc.constraint_type IN ('P','U'))
    ORDER BY dic.table_name, dic.column_position ASC
)
GROUP BY table_owner, index_name, table_name, uniqueness

<end node> 5P9i0s8y19Z
dt=Text
<node>
DBMS_METADATA
3

=====================================================================================

Note:- If required, can get the DDL of a tablespace as below.

set pagesize 0
SET LONG 9999999999
SELECT DBMS_METADATA.GET_DDL('TABLESPACE','&TABLESPACE_NAME') FROM DUAL;
=====================================================================================

select wm_concat(granted_Role)  from dba_role_privs where grantee='KJMORR'

=====================================================================================

Note:- If required, can get the DDL of Object Types Like ....
-- INDEX, TABLESPACE, DATABASE LINK, SEQUENCE, VIEW, TABLE, USER, PROCEDURE, TRIGGER ETC...

set pagesize 0
SET LONG 9999999999
SELECT DBMS_METADATA.GET_DDL('TABLESPACE','&TABLESPACE_NAME') FROM DUAL;

SELECT DBMS_METADATA.GET_DEPENDENT_DDL('INDEX', BASE_TABLE_NAME) FROM DUAL;

SELECT DBMS_METADATA.GET_DEPENDENT_DDL('SEQUENCE', BASE_OBJECT_NAME) FROM DUAL;

SELECT DBMS_METADATA.GET_DDL('SEQUENCE','SEQ_SOYBEAN_HEDGING','AGCC') FROM DUAL;

-- Re-Creating the database link
SELECT dbms_metadata.get_ddl('DB_LINK','TEST_LINK','OLD_USER') stmt FROM 

--Generating create scripts through dbms_metadata package
--Execute the following to get the create script of existing database objects
 
SQL>set lines 120
SQL>set pages 99999
SQL>set long 1000000
SQL> SELECT DBMS_METADATA.GET_DDL('<object_type','<object_name>','<object owner>') FROM DUAL;
For example
 
--Following example to get table structure of EMP OF SCOTT SCHEMA
SQL> SELECT DBMS_METADATA.GET_DDL('TABLE','EMP','SCOTT') FROM DUAL;
 
--Following example to get index structure of PK_EMP OF SCOTT SCHEMA
SQL> SELECT DBMS_METADATA.GET_DDL('INDEX','PK_EMP_INDX','SCOTT') FROM DUAL;

--Following example to get index structure of PK_EMP OF SCOTT SCHEMA
SQL> SELECT DBMS_METADATA.GET_DDL('CONSTRAINT','PK_EMP','SCOTT') FROM DUAL;
 
--Following example to get Package Specification  EMP_PKG OF SCOTT SCHEMA
SQL> SELECT DBMS_METADATA.GET_DDL('PACKAGE','EMP_PKG','SCOTT') FROM DUAL;
 
--Following example to get Package Body   EMP_PKG OF SCOTT SCHEMA
SQL> SELECT DBMS_METADATA.GET_DDL('PACKAGE_BODY','EMP_PKG','SCOTT') FROM DUAL;
 
--Also we could get ddl for tablespace
SQL>  SELECT DBMS_METADATA.GET_DDL('TABLESPACE','USERS') FROM dual;
 
--To get the defination of the foreign key constraints.
SQL> SELECT DBMS_METADATA.GET_DEPENDENT_DDL('REF_CONSTRAINT','<table_name>','<schema>') from dual;
 
--To get the System privileges grants for a schema.
SQL> SELECT DBMS_METADATA.GET_GRANTED_DDL('SYSTEM_GRANT','<schema>') from dual;
 
--To get the Role grant for a schema,
SQL> SELECT DBMS_METADATA.GET_GRANTED_DDL('ROLE_GRANT','<schema>') from dual;
 
--To get the object grants for a schema 
SQL> SELECT DBMS_METADATA.GET_GRANTED_DDL('OBJECT_GRANT','<schema>') from dual;
 
--Following query to get the create scripts of all  tables of  a particular schema
SQL>spool tables.sql
SQL>select 'select dbms_metadata.get_ddl(''TABLE'', '''||TABLE_NAME||''',''<schema>'') 
from dual;' FROM DBA_TABLES
/

=====================================================================================

-- Below script will generate the ddl for all mentioned object types and object name or object owners
select owner, db_link, dbms_metadata.get_ddl('DB_LINK',db.db_link,db.owner) 
from dba_db_links db 
where upper(dbms_metadata.get_ddl('DB_LINK',db.db_link,db.owner)) like '%DESCRIPTION%' 
and upper(dbms_metadata.get_ddl('DB_LINK',db.db_link,db.owner)) not like '%SCAN%' ;

sqlplus<<EOF
set long 100000
set head off
set echo off
set pagesize 0
set verify off
set feedback off
spool schema.out

select dbms_metadata.get_ddl(object_type, object_name, owner)
from
(
    --Convert DBA_OBJECTS.OBJECT_TYPE to DBMS_METADATA object type:
    select
        owner,
        --Java object names may need to be converted with DBMS_JAVA.LONGNAME.
        --That code is not included since many database don't have Java installed.
        object_name,
        decode(object_type,
            'DATABASE LINK',      'DB_LINK',
            'JOB',                'PROCOBJ',
            'RULE SET',           'PROCOBJ',
            'RULE',               'PROCOBJ',
            'EVALUATION CONTEXT', 'PROCOBJ',
            'PACKAGE',            'PACKAGE_SPEC',
            'PACKAGE BODY',       'PACKAGE_BODY',
            'TYPE',               'TYPE_SPEC',
            'TYPE BODY',          'TYPE_BODY',
            'MATERIALIZED VIEW',  'MATERIALIZED_VIEW',
            'QUEUE',              'AQ_QUEUE',
            'JAVA CLASS',         'JAVA_CLASS',
            'JAVA TYPE',          'JAVA_TYPE',
            'JAVA SOURCE',        'JAVA_SOURCE',
            'JAVA RESOURCE',      'JAVA_RESOURCE',
            object_type
        ) object_type
    from dba_objects 
    where owner in ('OWNER1')
        --These objects are included with other object types.
        and object_type not in ('INDEX PARTITION','INDEX SUBPARTITION',
           'LOB','LOB PARTITION','TABLE PARTITION','TABLE SUBPARTITION')
        --Ignore system-generated types that support collection processing.
        and not (object_type = 'TYPE' and object_name like 'SYS_PLSQL_%')
        --Exclude nested tables, their DDL is part of their parent table.
        and (owner, object_name) not in (select owner, table_name from dba_nested_tables)
        --Exlclude overflow segments, their DDL is part of their parent table.
        and (owner, object_name) not in (select owner, table_name from dba_tables where iot_type = 'IOT_OVERFLOW')
)
order by owner, object_type, object_name;

spool off
quit
EOF

cat schema.out|sed 's/OWNER1/MYOWNER/g'>schema.out.change.sql

or 

-- even the below query will be usefull for the generating the ddl code
SELECT OBJECT_TYPE, OBJECT_NAME,
	  DBMS_METADATA.GET_DDL(OBJECT_TYPE, OBJECT_NAME, OWNER)
  FROM ALL_OBJECTS 
  WHERE (OWNER = 'XYZ') 
    AND OBJECT_TYPE NOT IN('LOB','MATERIALIZED VIEW', 'TABLE PARTITION') 
  ORDER BY OBJECT_TYPE, OBJECT_NAME;


-- clone the user to user
SELECT DBMS_METADATA.GET_DDL('USER', 'DBA_BATCH') || '/' DDL FROM DBA_USERS
UNION ALL
SELECT DBMS_METADATA.GET_GRANTED_DDL('ROLE_GRANT', 'DBA_BATCH') || '/' DDL FROM 
   DBA_USERS
UNION ALL
SELECT DBMS_METADATA.GET_GRANTED_DDL('SYSTEM_GRANT', 'DBA_BATCH') || '/' DDL FROM DBA_USERS
UNION ALL
SELECT DBMS_METADATA.GET_GRANTED_DDL('OBJECT_GRANT', 'DBA_BATCH') || '/' DDL FROM DBA_USERS;


select wm_concat(granted_Role)  from dba_role_privs where grantee='KJMORR'

--- User creation:
select dbms_metadata.get_ddl( 'USER', 'PHIL' ) from dual;

--- Default role:
select dbms_metadata.get_granted_ddl( 'DEFAULT_ROLE', 'AJBERE' ) from dual;

--- System grants:
select dbms_metadata.get_granted_ddl( 'SYSTEM_GRANT', 'PHIL' ) from  dual;

--- Object grants:
select dbms_metadata.get_granted_ddl( 'OBJECT_GRANT', 'PHIL' ) from dual;

--- Role grants:
select dbms_metadata.get_granted_ddl( 'ROLE_GRANT', 'PHIL' ) from dual;

select dbms_metadata.get_granted_ddl('ROLE_GRANT','JKBOGE') from dual

--- Quotas:
select dbms_metadata.get_granted_ddl( 'TABLESPACE_QUOTA', 'PHIL' ) from dual;

--- If any of the above have no output, you'll get an exception that looks something like this:
SQL> select dbms_metadata.get_granted_ddl( 'TABLESPACE_QUOTA', 'PHIL' ) from dual;
ERROR:
ORA-31608: specified object of type TABLESPACE_QUOTA not found
ORA-06512: at "SYS.DBMS_METADATA", line 4018
ORA-06512: at "SYS.DBMS_METADATA", line 5991
ORA-06512: at line 1

no rows selected

SQL>

================================================================================
-- get the procedure code from particular schema
select DBMS_METADATA.GET_DDL('PROCEDURE',u.object_name)
from DBA_objects u
where object_type = 'PROCEDURE'
   and u.owner='SYSTEM'
   and u.object_name='MAILSERVER_ACL'


-- get all the procedure code from the connected schema
select DBMS_METADATA.GET_DDL('PROCEDURE',u.object_name)
from user_objects u
where object_type = 'PROCEDURE';


-- get table structure of table of particular schema
select DBMS_METADATA.GET_DDL('TABLE',u.object_name)
from dba_objects u
where object_type = 'TABLE' 
  and object_name='BILLING_CLIENT_DATA' 
  AND OWNER='SYSTEM'


-- get the privileges given to rahulc schema
select DBMS_METADATA.GET_GRANTED_DDL('SYSTEM_GRANT','RAHULC') from dual;


-- get the object privileges which are given to transnox_iox schema
select DBMS_METADATA.GET_GRANTED_DDL('OBJECT_GRANT','TRANSNOX_IOX') from dual;

================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
regular Expression sqls
3
**************************************** Oracle Regular Expressions **************************************** 
-- if you search for content where the second character is L,D or S, you can do it with:

select ename
from emp
where ename like '_L%'
or ename like '_D%' 
or ename like '_S%'; 

-- But with REGEXP_LIKE it is like this:

select ename
from emp
where regexp_like(ename,'^.[LDS]');

REGEXP_REPLACE (NVL (rcs.Consumer_Zip_Code, ' '),'[[:alnum:]]','')
                           
-- sreach the object_name which are having any number starting 0 to 9 at last 
regexp_like(object_name, '[0-9]$','i')

-- Object_name starting with W or O
regexp_like(object_name, '^[WO]','i')

-- search all those table_name which are starting with sn_temp and sc_temp
regexp_like(table_name,'^SN_TEMP|SC_TEMP','i')
OR
regexp_like(table_name,'^(SN|SC)_TEMP','i')
OR
REGEXP_LIKE(object_name,'S._TEMP[[:digit:]]','i') --- use it 

-- searching for all-numeric data. The caret (^) START and dollar 
-- ($) END denotes of the line, respectively. 
-- The plus (+) after the digit class represents one or more occurrences.
REGEXP_LIKE(x, '^[0-9]+$');

--The following query returns the first and last names for those employees with a 
--first name of Steven or Stephen (where first_name begins with Ste and ends with en and 
--in between is either v or ph)
SELECT first_name, last_name
FROM employees
WHERE REGEXP_LIKE (first_name, '^Ste(v|ph)en$');

--Using the Regexp_like operator to identify sales people whose last names begin with a "W" and end with an "N"
Regexp_like (last_name, '^W.*N$');

--Using the Regexp_like operator to identify sales people whose last names begin with a "W" or "V" and end with an "N"
Regexp_like (last_name, '^(W|V).*N$');

--Using the Regexp_like operator to identify sales people with an "FF", "FL", "LF", or "LL" in their last name
Regexp_like (last_name, '.*(F|L){2}.*');

--Using the Regexp_like operator to identify sales people with five consecutive digits in the address
Regexp_like (address, '[[:digit:]]{5}')

--Using the Regexp_like operator and Character classes to identify two digit address numbers
Regexp_like (address, '^[[:digit:]][[:digit:]][[:space:]]');

--Using the range (-) symbol to identify sales people whose names begin with characters between K and R
--A hyphen (-) is used in the character list to indicate a range of values.
Regexp_like (last_name, '^[K-R]');

--Using the Negate carot to identify addresses that do not begin with alphabetic characters
--Carots (^) placed inside a character list are not anchor symbols.  They are the negate symbol.
Regexp_like (address, '^[^[:alpha:]]{4}');

-- will return those object_name which will not have any number in the name of the objects
not REGEXP_LIKE(object_name,'[[:digit:]]','i')


-- This query uses the regular expression metacharacter period (.), which matches any character. The expression does not
-- look for three periods followed by a dash followed by four periods. It looks for any three characters, followed by a dash,
-- followed by any four characters.
SELECT park_name
FROM park
WHERE REGEXP_LIKE(description, '...-....');


-- some more (Class Operators) Regular Expressions hints
[:digit:]   Any digit
[:alpha:]   Any upper or lower case letter
[:lower:]   Any lower case letter
[:upper:]   Any upper case letter
[:alnum:]   Any upper or lower case letter or number
[:xdigit:]  Any hex digit
[:blank:]   Space or Tab
[:space:]   Space, tab, return, line feed, form feed
[:cntrl:]   Control Character, non printing
[:print:]   Printable character including a space
[:graph:]   Printable characters, excluding space.
[:punct:]   Punctuation character, not a control character or alphanumeric
 

 /*
Regular Expression Patterns.

Regular Expressions have a formal definition as part of the POSIX standard.  Different symbols define how a pattern is described.  Let’s start with the basic symbols.

Characters and Numbers represent themselves.  If you are searching for ‘abc’ then the matching pattern is abc.  

Period (.) represents any single character or number.  The pattern ‘b.e’ will match bee, bye, b3e but not bei, or b55e.  Likewise the pattern ‘..-..=…’  matches any 
two characters, followed by a dash, followed by any two characters, followed by an equal sign, followed by any three characters.

Star (*) represent zero or more characters.  The pattern ‘b.*e will match bee, bye, beee, bzyxe and be.  The pattern ‘..-..=.*’ can end with zero or more characters after the equal sign. 

Plus (+) represents one or more characters.  This pattern is the same a ‘.*’ except that there must be one character.  Using the pattern ‘b.+e’ the string “be” will not match.

Question Mark (?) represents zero or one character.  The pattern ‘..-..=.?’ can only end with one character or no character after the equal sign.

If I wanted to match a US telephone number, I could use the pattern ‘…-…-….’.  This pattern will match any three characters, followed by a dash, followed by 3 more characters, followed by 
a dash and four final characters.  So the string “123-456-7891” will match this pattern.  Well so will “abc-def-ghij”.  So this simple patter will match a lot of strings that are not phone numbers.  
We will improve on this pattern in a moment.

Brackets are used to define numbers of characters.  

{count}  defines an exact number of characters.  The pattern a{3) defines exactly three character ‘a’.  Used with the period, the {count} defines the number of characters.  The phone number
example could be written as the pattern ‘.{3}-.{3}-.{4}’.  

Note:  When used with many applications, the bracket already has a meaning and to use it in a expression is must be escaped, normally with a slash.  ‘.\{3\}-\{3\}-\{4\}’  In this example the slash ‘\’ simply escapes the bracket.  With Oracle, this is not necessary.

{min,max} defines a minimum and maximum number of characters.  The pattern ‘.{2,8}’ will match any 2 or more characters, up to 8 characters.

{min,} defines the minimum or more number of characters.  The pattern ‘sto{1,}p’ will match any string that has ‘st’ followed by one or more ‘o’, followed by a ‘p’.  This includes stop, stoop, stooooop, but not stp or stoip.

Square Brackets are used to define a subset of the expression.  Any one character in the bracket will match the pattern.  If I want only a number character then I could use a pattern like ‘[0123456789]’.  
 The phone number pattern could be written as: 

‘[0123456789]{3}-[0123456789]{3}-[0123456789]{4}’  

With this pattern, I have excluded all the letters from matching strings.  A range of characters can also be defined in square brackets.  This is easier to type and read.  The range is defined using the 
dash between the min and max. The phone example now becomes:

‘[0-9]{3}-[0-9]{3}-[0-9]{4}’

Ranges of letters can also be defined.  The pattern ‘st[aeiou][A-Za-z]’ matches any string with the characters ‘st’ followed by a vowel, followed by any character, upper or lower case.  
This pattern matches stop, stay, staY, stud.  The pattern ‘abc[1-9]’ matches abc1, abc2, abc3,…

The caret [^] in square brackets matches any character except those following the caret.  The pattern ‘st[^o]p will match step, strp, but not stop.

So far, all the patterns match is the pattern is found anywhere in the line of text.  Use the caret and dollar sign to define patterns that match the start or end of a string.

^ defines that start of a string or column 1 of the string.

$ defines the end of a string or the last column.  This does not included carriage returns and line feeds.

The pattern ‘^St[a-z]*’ matches a string that starts with ‘St’ followed by zero or more lower case letters.  The pattern ‘stop$’ only matches “stop” if it is the last word on the line.

| or vertical line defines the Boolean OR.  The patter ‘[1-9]|[a-z]’ matched any number or lower case letter.  The pattern ‘stop|step’ matches the strings stop or step.

\ or backward slash is the escape character.   This is use to tell the parser that the character following it is to be taken literally.  In the note earlier, it was pointed out that
 some characters have special meaning in some applications and must be escaped to tell the application to use that literal character.  Another reason to escape a character is when you want 
 to actually use the character in your matching pattern.  For example, if you want to match a number that has two decimal places you could use the pattern:

‘[0-9]+.[0-9]{2}’

This example looks right but will not match the pattern that we are looking for.  The period we use to represent the decimal place, will actually match any character.  We must tell 
the expression parser that we want the character period and we do that by escaping the period character.

‘[0-9]+\.[0-9]{2}’

Now the pattern will match one or more digits followed by a period and exactly two digits.

Class Operators

Class operators are used as an alternative way to define classes of characters.  They are defined in the format [: class :].

-- some more Regular Expressions hints
[:digit:]   Any digit
[:alpha:]   Any upper or lower case letter
[:lower:]   Any lower case letter
[:upper:]   Any upper case letter
[:alnum:]   Any upper or lower case letter or number
[:xdigit:]  Any hex digit
[:blank:]   Space or Tab
[:space:]   Space, tab, return, line feed, form feed
[:cntrl:]   Control Character, non printing
[:print:]   Printable character including a space
[:graph:]   Printable characters, excluding space.
[:punct:]   Punctuation character, not a control character or alphanume

Again, these class operators represent other characters.  The phone number example can be rewritten using class operators.

‘[:digit:]{3}-[:digit:]{3}-[:digit:]{4}’

Being Greedy
Regular expressions are greedy.  By this we mean that the expression will match the largest string it can.  Think of it as the expression parser takes the entire sting and 
compares it to the pattern.  The parser then gives back characters until it finds that the string has no match or if finds the match.

Lets use a string ‘0123423434’

If my pattern is ‘.*4’  (zero of more characters followed by the digit 4).

The first match will be the entire sting.

Expression Grouping
Expression Grouping allows part of the pattern to be grouped.  This is also called tagging or referencing.  You group an expression by surrounding it with parens.  There can be only 9 
groups in a pattern.  Below is an example that contains two groups.

‘([a-z]+) ([a-z]+)’

This pattern matches two lower case words.  Using a string defined as ‘fast stop’, the first group would contain ‘fast’ and the second group ‘stop’.  The groups are 
referenced by a backward slash and the group number.  ‘\1’ references ‘fast’ while ‘\2’ reference ‘stop’.  Thus \2 \1 results in ‘stop fast’.

Oracle and Regular Expressions
The Oracle 10g database provides four functions to implement Regular Expressions.  The Java Virtual Machine in the database also implements the Java support for Regular Expression.  
The four functions can be used in SQL statements or PL/SQL.  They operate on the database character datatypes to include VARCHAR2, CHAR, CLOB, NVARCHAR2, NCHAR, and NCLOB.  The four functions are:

REGEXP_LIKE       Returns true is the pattern is matched, otherwise false.
REGEXP_INSTR      Returns the position of the start  or end of the matching string.  Returns zero if the pattern does not match.
REGEXP_REPLACE    Returns a string where each matching string is replaced with the text specified.
REGEXP_SUBSTR     Returns the matching string, or NULL if no match is found.

Let’s look at each of the functions and how to put them to use.
 

REGEXP_LIKE
Syntax:  regexp_like(source, pattern(, options));

The source is a text literal, variable or column.  The pattern is the expression you are looking for.  The options define how the matching will take place.  The options are:

i = case insensitive

c = case sensitive

n = the period will match a new line character

m = allows the ^ and $ to match the beginning and end of lines contained in the source.  Normally these characters would match the beginning and end of the source.  This is for multi-line sources.

This function can be used anywhere a Boolean result is acceptable. 

begin
  n_phone_number varchar2(20);
  …
begin
  …
  if (regexp_like(n_phone_number, .*[567]$)) then …
  end if;
  …
end;
If the phone number ends in either 5,6 or 7, the return it true and the THEN clause is executed.

In a SQL statement, this function can only be used in the WHERE or HAVING clause.

select
   …
   phone
from
  …
where regexp_like(phone, .*[567]$);
 

The REGEXP_LIKE function can also be used in check constraints.

 

REGEXP_REPLACE
Syntax:  regexp_replace( source, pattern, replace string, position, occurrence, options)

The source can be a string literal, variable, or column.  The pattern is the expression to be replaced.  The replace string is the text that will replace the matching patterns.  
The optional position defines the location to begin searching the source string.  This defaults to 1.  The optional occurrence defines the occurrence of the pattern that you want replaced.  
This defaults to 0 (all occurrences).  Setting this to a positive number will result in only that occurrence being replaced.  The matching options are the same.

select
  regexp_replace('We are driving south by south east',
                 'south', 'north')
from dual;
 

We are driving north by north east

REGEXP_INSTR
Syntax:  regexp_instr(source, pattern, position, occurrence, begin_end, options)

The source can be a string literal, variable, or column.  The pattern is the expression to be replaced.  The optional position is the location to begin the search and defaults to 1.  
The occurrence defines the occurrence you are looking for.  The begin_end defines whether you want the position of the beginning of the occurrence or the position of the end of the occurrence.  
This defaults to 0 which is the beginning of the occurrence.  Use 1 to get the end position.  The matching options are the same.

select
  regexp_instr('We are driving south by south east', 'south')
from dual;
 
16
select
  regexp_instr('We are driving south by south east', 'south', 1, 2, 1)
from dual;
 
30
 

REGEXP_SUBSTR
Syntax:  regexp_substr(source, pattern, position, occurrence, options)

The source can be a string literal, variable, or column.  
The pattern is the expression to be replaced.  
The optional position is the location to begin the search and defaults to 1.  
The optional occurrence defines the occurrence you are looking for.  
The matching options are the same.

select
  regexp_substr('We are driving south by south east', 'south')
from dual;
 
south 
 
*/




---- More Specific on RegExp..

/*

Anchoring Characters are metacharacters that 
affect the position of the search.
----------------------------------------------------
Character Class      Description
^      Anchor the expression to the start of a line
$      Anchor the expression to the end of a line
 
 
 
Equivalence Classes      
----------------------------------------------------
Character Class      Description
= =      Oracle supports the equivalence classes through 
        the POSIX '[==]' syntax. A base letter and all of 
        its accented versions constitute an equivalence 
        class. For example, the equivalence class '[=a=]' 
        matches ä and â. The equivalence classes are valid 
        only inside the bracketed expression
 
 
Match Options determine if the target is treated checked for 
case-sensitivity and whether or not the target is evaluated 
line by line or as a continuous string. 
----------------------------------------------------
Character Class      Description
c      Case sensitive matching
i      Case insensitive matching
m      Treat source string as multi-line activating Anchor chars
n      Allow the period (.) to match any newline character
 
 
 
Posix Characters tend to look very ugly but have the advantage 
that also take into account the 'locale', that is, any variant 
of the local language/coding system.
----------------------------------------------------
Character Class      Description
[:digit:]      Only the digits 0 to 9
[:alnum:]      Any alphanumeric character 0 to 9 OR A to Z or a to z.
[:alpha:]      Any alpha character A to Z or a to z.
[:blank:]      Space and TAB characters only.
[:xdigit:]     Hexadecimal notation 0-9, A-F, a-f.
[:punct:]      Punctuation symbols 
                --------------------------------
                % . , " ' ? ! : # $ & ( ) * ;
                + - / < > = @ [ ] \ ^ _ { } | ~
                --------------------------------
[:print:]      Any printable character.
[:space:]      Any whitespace characters (space, tab, NL, FF, VT, CR). 
                Many system abbreviate as \s.
[:graph:]      Exclude whitespace (SPACE, TAB). Many system abbreviate as \W.
[:upper:]      Any alpha character A to Z.
[:lower:]      Any alpha character a to z.
[:cntrl:]      Control Characters NL CR LF TAB VT FF NUL SOH STX 
                EXT EOT ENQ ACK SO SI DLE DC1 DC2 DC3 DC4 NAK SYN 
                ETB CAN EM SUB ESC IS1 IS2 IS3 IS4 DEL.
 
 
Quantifier Characters control the number of times a character 
or string is found in a search.
----------------------------------------------------
Character Class      Description
*      Match 0 or more times
?      Match 0 or 1 time
+      Match 1 or more times
{m}      Match exactly m times
{m,}      Match at least m times
{m, n}      Match at least m times but no more than n times
\n      Cause the previous expression to be repeated n times
 
 
 
Alternative Matching And Grouping Characters      
----------------------------------------------------
Character Class      Description
|      Separates alternates, often used with grouping 
        operator ()
 
( )      Groups subexpression into a unit for alternations, for 
        quantifiers, or for backreferencing 
 
[char]      Indicates a character list; most metacharacters inside a
        character list are understood as literals, with the 
        exception of character classes, and the ^ 
        and - metacharacters
 
 
////////////////////////////////////////////////////
Regex Cheat Sheet (non-posix)
////////////////////////////////////////////////////
 
 
Modifiers: 
i   case-insensitive pattern matching. 
 
g   global replace, or replace all 
 
m   Treat string as multiple lines. That is, 
    change ``^'' and ``$'' from matching at only 
    the very start or end of the string to the 
    start or end of any line anywhere within the string 
 
s   Treat string as single line. That is, change ``.'' to 
    match any character whatsoever, even a newline, which 
    it normally would not match. 
 
x   Extend your pattern's legibility by permitting 
    whitespace and comments.
 
 
Special Characters:
The following should be escaped if you are trying to 
match that character:
 
 \  ^  .  $  |  (  )  [  ]
 *  +  ?  {  }  ,
 
 
Special Character Definitions:
    \   Quote the next metacharacter
    ^   Match the beginning of the line
    .   Match any character (except newline)
    $   Match the end of the line (or before newline at the end)
    |   Alternation
    ()  Grouping
    []  Character class
    *      Match 0 or more times
    +      Match 1 or more times
    ?      Match 1 or 0 times
    {n}    Match exactly n times
    {n,}   Match at least n times
    {n,m}  Match at least n but not more than m times
 
More Special Characters: 
    \t          tab                   (HT, TAB)
    \n          newline               (LF, NL)
    \r          return                (CR)
    \f          form feed             (FF)
    \a          alarm (bell)          (BEL)
    \e          escape (think troff)  (ESC)
    \033        octal char (think of a PDP-11)
    \x1B        hex char
    \c[         control char
    \l          lowercase next char (think vi)
    \u          uppercase next char (think vi)
    \L          lowercase till \E (think vi)
    \U          uppercase till \E (think vi)
    \E          end case modification (think vi)
    \Q          quote (disable) pattern metacharacters till \E
 
Even More Special Characters:
    \w  Match a "word" character (alphanumeric plus "_")
    \W  Match a non-word character
    \s  Match a whitespace character
    \S  Match a non-whitespace character
    \d  Match a digit character
    \D  Match a non-digit character
    \b  Match a word boundary
    \B  Match a non-(word boundary)
    \A  Match only at beginning of string
    \Z  Match only at end of string, or before newline at the end
    \z  Match only at end of string
    \G  Match only where previous m//g left off (works only with /g)
 

*/

-- This is telling Oracle to start at the punct and include all characters until u reach a comma (include the comma as well).
SELECT regexp_substr( 'Employee Name and Age: Adam, Dana 28', '[:punct:][^,]+,' ) "REGEXP_SUBSTR"
FROM dual;

-- What if you want to find the number in the string?
SELECT regexp_substr( 'Employee Name and Age: Adam, Dana 28', '[[:digit:]]+' ) "REGEXP_SUBSTR"
FROM dual;


-- Tells oracle to start the string at the '-' character.  [^-] tells oracle to continue until it finds another '-' character.  
SELECT regexp_substr( '655-236-4567', '-[^-]+' ) "REGEXP_SUBSTR"
FROM dual;

-- Note that if you add an extra '-' at the end of the regular expression you will get the trailing '-' as part of the returned string:
SELECT regexp_substr( '655-236-4567', '-[^-]+-' ) "REGEXP_SUBSTR"
FROM dual;


Out put of REGEXP_SUBSTR
-236-

-- find the last '.' in the statment and returns all the characters followed by it.
-- so if there is value 'xyz.qos.jopuyt.sql' then it will return 'sql'
select REGEXP_SUBSTR(file_name, '[^.]+.$') from dual;


The basic regular expressions that for regexp_replace()

1- To remove duplicate white space and all carriage returns and linefeeds (this flattens the query into one line):

   regexp_replace(sql_text, '[[:space:]]+',' ' )
   
2- To transform all numeric literals into “:NUM”. The premise is that all numeric literals must be preceded by either one of 
"(=+, -" Otherwise, it is considered to be an identifier or a string literal:

   regexp_replace('([(=<>+, -])[0-9]+.?[0-9]*','1:NUM')
   
   
3- To transform all string literals into “‘:STR’”. For example, the string “select ‘abc’ from dual” would be translated into 
“select ‘:STR’ from dual” :

   regexp_replace('''(.)*?''',''':STR''' )
   
The final Oracle function call looks like this (three embedded regexp_replace):

   regexp_replace(
   regexp_replace(
   regexp_replace(sql_text, '[[:space:]]+',' ' ),
                  '([(=<>+, -])[0-9]+.?[0-9]*','1:NUM'),
                  '''(.)*?''',''':STR''' )
=============================================================================================

-- Stringtokenizer
-- getting the values from values option in insert statement
replace(replace(replace(substr(v_Sql_String, instr(v_Sql_String,') values(')+9,length(v_Sql_String)),')',''),'''',''),' , ',',')
=============================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
SQL to check Sequencetial read
3
-- Gives the information about sequencetial read and session connected from how many Hrs
SELECT A.SID,
        B.SCHEMANAME,
        B.username,
        B.OSUSER,
        b.machine,
        A.event,
        A.time_waited,
        A.time_waited / c.sum_time_waited * 100 pct_wait_time,
        ROUND((SYSDATE - b.logon_time) * 24) hours_connected
FROM v$session_event A, v$session b,
    (SELECT SID, SUM(time_waited) sum_time_waited
     FROM v$session_event
     WHERE event NOT IN ('Null event',
     			 'client message',
                         'KXFX: Execution Message Dequeue - Slave',
                         'PX Deq: Execution Msg',
                         'KXFQ: kxfqdeq - normal deqeue',
                         'PX Deq: Table Q Normal',
                         'Wait for credit - send blocked',
                         'PX Deq Credit: send blkd',
                         'Wait for credit - need buffer to send',
                         'PX Deq Credit: need buffer',
                         'Wait for credit - free buffer',
                         'PX Deq Credit: free buffer',
                         'parallel query dequeue wait',
                         'PX Deque wait',
                         'Parallel Query Idle Wait - Slaves',
                         'PX Idle Wait',
                         'slave wait',
                         'dispatcher timer',
                         'virtual circuit status',
                         'pipe get',
                         'rdbms ipc message',
                         'rdbms ipc reply',
                         'pmon timer',
                         'smon timer',
                         'PL/SQL lock timer',
                         'SQL*Net message from client',
                         'WMON goes to sleep')
            HAVING SUM(time_waited) > 0
            GROUP BY SID)c
WHERE A.SID = b.SID
  AND A.SID = c.SID
  AND A.time_waited > 0
  AND A.event = 'db file sequential read' 
  AND B.osuser<>'oracle'
  and B.username<>'GGATE'
  AND B.USERNAME NOT LIKE 'TRANSIT%'
--  AND A.SID='1151'
ORDER BY hours_connected DESC, pct_wait_time;

<end node> 5P9i0s8y19Z
dt=Text
<node>
regexp search
3
-- if you search for content where the second character is L,D or S, you can do it with:

select ename
from emp
where ename like '_L%'
or ename like '_D%' 
or ename like '_S%'; 

-- But with REGEXP_LIKE it is like this:

select ename
from emp
where regexp_like(ename,'^.[LDS]');

REGEXP_REPLACE (NVL (rcs.Consumer_Zip_Code, ' '),'[[:alnum:]]','')
                           
-- sreach the object_name which are having any number starting 0 to 9 at last 
regexp_like(object_name, '[0-9]$','i')

-- Object_name starting with W or O
regexp_like(object_name, '^[WO]','i')

-- search all those table_name which are starting with sn_temp and sc_temp
regexp_like(table_name,'^SN_TEMP|SC_TEMP','i')
OR
regexp_like(table_name,'^(SN|SC)_TEMP','i')
OR
REGEXP_LIKE(object_name,'S._TEMP[[:digit:]]','i') --- use it 

-- searching for all-numeric data. The caret (^) START and dollar 
-- ($) END denotes of the line, respectively. 
-- The plus (+) after the digit class represents one or more occurrences.
REGEXP_LIKE(x, '^[0-9]+$');

--The following query returns the first and last names for those employees with a 
--first name of Steven or Stephen (where first_name begins with Ste and ends with en and 
--in between is either v or ph)
SELECT first_name, last_name
FROM employees
WHERE REGEXP_LIKE (first_name, '^Ste(v|ph)en$');

--Using the Regexp_like operator to identify sales people whose last names begin with a "W" and end with an "N"
Regexp_like (last_name, '^W.*N$');

--Using the Regexp_like operator to identify sales people whose last names begin with a "W" or "V" and end with an "N"
Regexp_like (last_name, '^(W|V).*N$');

--Using the Regexp_like operator to identify sales people with an "FF", "FL", "LF", or "LL" in their last name
Regexp_like (last_name, '.*(F|L){2}.*');

--Using the Regexp_like operator to identify sales people with five consecutive digits in the address
Regexp_like (address, '[[:digit:]]{5}')

--Using the Regexp_like operator and Character classes to identify two digit address numbers
Regexp_like (address, '^[[:digit:]][[:digit:]][[:space:]]');

--Using the range (-) symbol to identify sales people whose names begin with characters between K and R
--A hyphen (-) is used in the character list to indicate a range of values.
Regexp_like (last_name, '^[K-R]');

--Using the Negate carot to identify addresses that do not begin with alphabetic characters
--Carots (^) placed inside a character list are not anchor symbols.  They are the negate symbol.
Regexp_like (address, '^[^[:alpha:]]{4}');

-- will return those object_name which will not have any number in the name of the objects
not REGEXP_LIKE(object_name,'[[:digit:]]','i')


-- This query uses the regular expression metacharacter period (.), which matches any character. The expression does not
-- look for three periods followed by a dash followed by four periods. It looks for any three characters, followed by a dash,
-- followed by any four characters.
SELECT park_name
FROM park
WHERE REGEXP_LIKE(description, '...-....');


-- some more (Class Operators) Regular Expressions hints
[:digit:]   Any digit
[:alpha:]   Any upper or lower case letter
[:lower:]   Any lower case letter
[:upper:]   Any upper case letter
[:alnum:]   Any upper or lower case letter or number
[:xdigit:]  Any hex digit
[:blank:]   Space or Tab
[:space:]   Space, tab, return, line feed, form feed
[:cntrl:]   Control Character, non printing
[:print:]   Printable character including a space
[:graph:]   Printable characters, excluding space.
[:punct:]   Punctuation character, not a control character or alphanumeric
 

 /*
Regular Expression Patterns.

Regular Expressions have a formal definition as part of the POSIX standard.  Different symbols define how a pattern is described.  Let’s start with the basic symbols.

Characters and Numbers represent themselves.  If you are searching for ‘abc’ then the matching pattern is abc.  

Period (.) represents any single character or number.  The pattern ‘b.e’ will match bee, bye, b3e but not bei, or b55e.  Likewise the pattern ‘..-..=…’  matches any 
two characters, followed by a dash, followed by any two characters, followed by an equal sign, followed by any three characters.

Star (*) represent zero or more characters.  The pattern ‘b.*e will match bee, bye, beee, bzyxe and be.  The pattern ‘..-..=.*’ can end with zero or more characters after the equal sign. 

Plus (+) represents one or more characters.  This pattern is the same a ‘.*’ except that there must be one character.  Using the pattern ‘b.+e’ the string “be” will not match.

Question Mark (?) represents zero or one character.  The pattern ‘..-..=.?’ can only end with one character or no character after the equal sign.

If I wanted to match a US telephone number, I could use the pattern ‘…-…-….’.  This pattern will match any three characters, followed by a dash, followed by 3 more characters, followed by 
a dash and four final characters.  So the string “123-456-7891” will match this pattern.  Well so will “abc-def-ghij”.  So this simple patter will match a lot of strings that are not phone numbers.  
We will improve on this pattern in a moment.

Brackets are used to define numbers of characters.  

{count}  defines an exact number of characters.  The pattern a{3) defines exactly three character ‘a’.  Used with the period, the {count} defines the number of characters.  The phone number
example could be written as the pattern ‘.{3}-.{3}-.{4}’.  

Note:  When used with many applications, the bracket already has a meaning and to use it in a expression is must be escaped, normally with a slash.  ‘.\{3\}-\{3\}-\{4\}’  In this example the slash ‘\’ simply escapes the bracket.  With Oracle, this is not necessary.

{min,max} defines a minimum and maximum number of characters.  The pattern ‘.{2,8}’ will match any 2 or more characters, up to 8 characters.

{min,} defines the minimum or more number of characters.  The pattern ‘sto{1,}p’ will match any string that has ‘st’ followed by one or more ‘o’, followed by a ‘p’.  This includes stop, stoop, stooooop, but not stp or stoip.

Square Brackets are used to define a subset of the expression.  Any one character in the bracket will match the pattern.  If I want only a number character then I could use a pattern like ‘[0123456789]’.  
 The phone number pattern could be written as: 

‘[0123456789]{3}-[0123456789]{3}-[0123456789]{4}’  

With this pattern, I have excluded all the letters from matching strings.  A range of characters can also be defined in square brackets.  This is easier to type and read.  The range is defined using the 
dash between the min and max. The phone example now becomes:

‘[0-9]{3}-[0-9]{3}-[0-9]{4}’

Ranges of letters can also be defined.  The pattern ‘st[aeiou][A-Za-z]’ matches any string with the characters ‘st’ followed by a vowel, followed by any character, upper or lower case.  
This pattern matches stop, stay, staY, stud.  The pattern ‘abc[1-9]’ matches abc1, abc2, abc3,…

The caret [^] in square brackets matches any character except those following the caret.  The pattern ‘st[^o]p will match step, strp, but not stop.

So far, all the patterns match is the pattern is found anywhere in the line of text.  Use the caret and dollar sign to define patterns that match the start or end of a string.

^ defines that start of a string or column 1 of the string.

$ defines the end of a string or the last column.  This does not included carriage returns and line feeds.

The pattern ‘^St[a-z]*’ matches a string that starts with ‘St’ followed by zero or more lower case letters.  The pattern ‘stop$’ only matches “stop” if it is the last word on the line.

| or vertical line defines the Boolean OR.  The patter ‘[1-9]|[a-z]’ matched any number or lower case letter.  The pattern ‘stop|step’ matches the strings stop or step.

\ or backward slash is the escape character.   This is use to tell the parser that the character following it is to be taken literally.  In the note earlier, it was pointed out that
 some characters have special meaning in some applications and must be escaped to tell the application to use that literal character.  Another reason to escape a character is when you want 
 to actually use the character in your matching pattern.  For example, if you want to match a number that has two decimal places you could use the pattern:

‘[0-9]+.[0-9]{2}’

This example looks right but will not match the pattern that we are looking for.  The period we use to represent the decimal place, will actually match any character.  We must tell 
the expression parser that we want the character period and we do that by escaping the period character.

‘[0-9]+\.[0-9]{2}’

Now the pattern will match one or more digits followed by a period and exactly two digits.

Class Operators

Class operators are used as an alternative way to define classes of characters.  They are defined in the format [: class :].

-- some more Regular Expressions hints
[:digit:]   Any digit
[:alpha:]   Any upper or lower case letter
[:lower:]   Any lower case letter
[:upper:]   Any upper case letter
[:alnum:]   Any upper or lower case letter or number
[:xdigit:]  Any hex digit
[:blank:]   Space or Tab
[:space:]   Space, tab, return, line feed, form feed
[:cntrl:]   Control Character, non printing
[:print:]   Printable character including a space
[:graph:]   Printable characters, excluding space.
[:punct:]   Punctuation character, not a control character or alphanume

Again, these class operators represent other characters.  The phone number example can be rewritten using class operators.

‘[:digit:]{3}-[:digit:]{3}-[:digit:]{4}’

Being Greedy
Regular expressions are greedy.  By this we mean that the expression will match the largest string it can.  Think of it as the expression parser takes the entire sting and 
compares it to the pattern.  The parser then gives back characters until it finds that the string has no match or if finds the match.

Lets use a string ‘0123423434’

If my pattern is ‘.*4’  (zero of more characters followed by the digit 4).

The first match will be the entire sting.

Expression Grouping
Expression Grouping allows part of the pattern to be grouped.  This is also called tagging or referencing.  You group an expression by surrounding it with parens.  There can be only 9 
groups in a pattern.  Below is an example that contains two groups.

‘([a-z]+) ([a-z]+)’

This pattern matches two lower case words.  Using a string defined as ‘fast stop’, the first group would contain ‘fast’ and the second group ‘stop’.  The groups are 
referenced by a backward slash and the group number.  ‘\1’ references ‘fast’ while ‘\2’ reference ‘stop’.  Thus \2 \1 results in ‘stop fast’.

Oracle and Regular Expressions
The Oracle 10g database provides four functions to implement Regular Expressions.  The Java Virtual Machine in the database also implements the Java support for Regular Expression.  
The four functions can be used in SQL statements or PL/SQL.  They operate on the database character datatypes to include VARCHAR2, CHAR, CLOB, NVARCHAR2, NCHAR, and NCLOB.  The four functions are:

REGEXP_LIKE       Returns true is the pattern is matched, otherwise false.
REGEXP_INSTR      Returns the position of the start  or end of the matching string.  Returns zero if the pattern does not match.
REGEXP_REPLACE    Returns a string where each matching string is replaced with the text specified.
REGEXP_SUBSTR     Returns the matching string, or NULL if no match is found.

Let’s look at each of the functions and how to put them to use.
 

REGEXP_LIKE
Syntax:  regexp_like(source, pattern(, options));

The source is a text literal, variable or column.  The pattern is the expression you are looking for.  The options define how the matching will take place.  The options are:

i = case insensitive

c = case sensitive

n = the period will match a new line character

m = allows the ^ and $ to match the beginning and end of lines contained in the source.  Normally these characters would match the beginning and end of the source.  This is for multi-line sources.

This function can be used anywhere a Boolean result is acceptable. 

begin
  n_phone_number varchar2(20);
  …
begin
  …
  if (regexp_like(n_phone_number, .*[567]$)) then …
  end if;
  …
end;
If the phone number ends in either 5,6 or 7, the return it true and the THEN clause is executed.

In a SQL statement, this function can only be used in the WHERE or HAVING clause.

select
   …
   phone
from
  …
where regexp_like(phone, .*[567]$);
 

The REGEXP_LIKE function can also be used in check constraints.

 

REGEXP_REPLACE
Syntax:  regexp_replace( source, pattern, replace string, position, occurrence, options)

The source can be a string literal, variable, or column.  The pattern is the expression to be replaced.  The replace string is the text that will replace the matching patterns.  
The optional position defines the location to begin searching the source string.  This defaults to 1.  The optional occurrence defines the occurrence of the pattern that you want replaced.  
This defaults to 0 (all occurrences).  Setting this to a positive number will result in only that occurrence being replaced.  The matching options are the same.

select
  regexp_replace('We are driving south by south east',
                 'south', 'north')
from dual;
 

We are driving north by north east

REGEXP_INSTR
Syntax:  regexp_instr(source, pattern, position, occurrence, begin_end, options)

The source can be a string literal, variable, or column.  The pattern is the expression to be replaced.  The optional position is the location to begin the search and defaults to 1.  
The occurrence defines the occurrence you are looking for.  The begin_end defines whether you want the position of the beginning of the occurrence or the position of the end of the occurrence.  
This defaults to 0 which is the beginning of the occurrence.  Use 1 to get the end position.  The matching options are the same.

select
  regexp_instr('We are driving south by south east', 'south')
from dual;
 
16
select
  regexp_instr('We are driving south by south east', 'south', 1, 2, 1)
from dual;
 
30
 

REGEXP_SUBSTR
Syntax:  regexp_substr(source, pattern, position, occurrence, options)

The source can be a string literal, variable, or column.  
The pattern is the expression to be replaced.  
The optional position is the location to begin the search and defaults to 1.  
The optional occurrence defines the occurrence you are looking for.  
The matching options are the same.

select
  regexp_substr('We are driving south by south east', 'south')
from dual;
 
south 
 
*/




---- More Specific on RegExp..

/*

Anchoring Characters are metacharacters that 
affect the position of the search.
----------------------------------------------------
Character Class      Description
^      Anchor the expression to the start of a line
$      Anchor the expression to the end of a line
 
 
 
Equivalence Classes      
----------------------------------------------------
Character Class      Description
= =      Oracle supports the equivalence classes through 
        the POSIX '[==]' syntax. A base letter and all of 
        its accented versions constitute an equivalence 
        class. For example, the equivalence class '[=a=]' 
        matches ä and â. The equivalence classes are valid 
        only inside the bracketed expression
 
 
Match Options determine if the target is treated checked for 
case-sensitivity and whether or not the target is evaluated 
line by line or as a continuous string. 
----------------------------------------------------
Character Class      Description
c      Case sensitive matching
i      Case insensitive matching
m      Treat source string as multi-line activating Anchor chars
n      Allow the period (.) to match any newline character
 
 
 
Posix Characters tend to look very ugly but have the advantage 
that also take into account the 'locale', that is, any variant 
of the local language/coding system.
----------------------------------------------------
Character Class      Description
[:digit:]      Only the digits 0 to 9
[:alnum:]      Any alphanumeric character 0 to 9 OR A to Z or a to z.
[:alpha:]      Any alpha character A to Z or a to z.
[:blank:]      Space and TAB characters only.
[:xdigit:]     Hexadecimal notation 0-9, A-F, a-f.
[:punct:]      Punctuation symbols 
                --------------------------------
                % . , " ' ? ! : # $ & ( ) * ;
                + - / < > = @ [ ] \ ^ _ { } | ~
                --------------------------------
[:print:]      Any printable character.
[:space:]      Any whitespace characters (space, tab, NL, FF, VT, CR). 
                Many system abbreviate as \s.
[:graph:]      Exclude whitespace (SPACE, TAB). Many system abbreviate as \W.
[:upper:]      Any alpha character A to Z.
[:lower:]      Any alpha character a to z.
[:cntrl:]      Control Characters NL CR LF TAB VT FF NUL SOH STX 
                EXT EOT ENQ ACK SO SI DLE DC1 DC2 DC3 DC4 NAK SYN 
                ETB CAN EM SUB ESC IS1 IS2 IS3 IS4 DEL.
 
 
Quantifier Characters control the number of times a character 
or string is found in a search.
----------------------------------------------------
Character Class      Description
*      Match 0 or more times
?      Match 0 or 1 time
+      Match 1 or more times
{m}      Match exactly m times
{m,}      Match at least m times
{m, n}      Match at least m times but no more than n times
\n      Cause the previous expression to be repeated n times
 
 
 
Alternative Matching And Grouping Characters      
----------------------------------------------------
Character Class      Description
|      Separates alternates, often used with grouping 
        operator ()
 
( )      Groups subexpression into a unit for alternations, for 
        quantifiers, or for backreferencing 
 
[char]      Indicates a character list; most metacharacters inside a
        character list are understood as literals, with the 
        exception of character classes, and the ^ 
        and - metacharacters
 
 
////////////////////////////////////////////////////
Regex Cheat Sheet (non-posix)
////////////////////////////////////////////////////
 
 
Modifiers: 
i   case-insensitive pattern matching. 
 
g   global replace, or replace all 
 
m   Treat string as multiple lines. That is, 
    change ``^'' and ``$'' from matching at only 
    the very start or end of the string to the 
    start or end of any line anywhere within the string 
 
s   Treat string as single line. That is, change ``.'' to 
    match any character whatsoever, even a newline, which 
    it normally would not match. 
 
x   Extend your pattern's legibility by permitting 
    whitespace and comments.
 
 
Special Characters:
The following should be escaped if you are trying to 
match that character:
 
 \  ^  .  $  |  (  )  [  ]
 *  +  ?  {  }  ,
 
 
Special Character Definitions:
    \   Quote the next metacharacter
    ^   Match the beginning of the line
    .   Match any character (except newline)
    $   Match the end of the line (or before newline at the end)
    |   Alternation
    ()  Grouping
    []  Character class
    *      Match 0 or more times
    +      Match 1 or more times
    ?      Match 1 or 0 times
    {n}    Match exactly n times
    {n,}   Match at least n times
    {n,m}  Match at least n but not more than m times
 
More Special Characters: 
    \t          tab                   (HT, TAB)
    \n          newline               (LF, NL)
    \r          return                (CR)
    \f          form feed             (FF)
    \a          alarm (bell)          (BEL)
    \e          escape (think troff)  (ESC)
    \033        octal char (think of a PDP-11)
    \x1B        hex char
    \c[         control char
    \l          lowercase next char (think vi)
    \u          uppercase next char (think vi)
    \L          lowercase till \E (think vi)
    \U          uppercase till \E (think vi)
    \E          end case modification (think vi)
    \Q          quote (disable) pattern metacharacters till \E
 
Even More Special Characters:
    \w  Match a "word" character (alphanumeric plus "_")
    \W  Match a non-word character
    \s  Match a whitespace character
    \S  Match a non-whitespace character
    \d  Match a digit character
    \D  Match a non-digit character
    \b  Match a word boundary
    \B  Match a non-(word boundary)
    \A  Match only at beginning of string
    \Z  Match only at end of string, or before newline at the end
    \z  Match only at end of string
    \G  Match only where previous m//g left off (works only with /g)
 

*/

-- This is telling Oracle to start at the punct and include all characters until u reach a comma (include the comma as well).
SELECT regexp_substr( 'Employee Name and Age: Adam, Dana 28', '[:punct:][^,]+,' ) "REGEXP_SUBSTR"
FROM dual;

-- What if you want to find the number in the string?
SELECT regexp_substr( 'Employee Name and Age: Adam, Dana 28', '[[:digit:]]+' ) "REGEXP_SUBSTR"
FROM dual;


-- Tells oracle to start the string at the '-' character.  [^-] tells oracle to continue until it finds another '-' character.  
SELECT regexp_substr( '655-236-4567', '-[^-]+' ) "REGEXP_SUBSTR"
FROM dual;

-- Note that if you add an extra '-' at the end of the regular expression you will get the trailing '-' as part of the returned string:
SELECT regexp_substr( '655-236-4567', '-[^-]+-' ) "REGEXP_SUBSTR"
FROM dual;


Out put of REGEXP_SUBSTR
-236-

-- find the last '.' in the statment and returns all the characters followed by it.
-- so if there is value 'xyz.qos.jopuyt.sql' then it will return 'sql'
select REGEXP_SUBSTR(file_name, '[^.]+.$') from dual;


The basic regular expressions that for regexp_replace()

1- To remove duplicate white space and all carriage returns and linefeeds (this flattens the query into one line):

   regexp_replace(sql_text, '[[:space:]]+',' ' )
   
2- To transform all numeric literals into “:NUM”. The premise is that all numeric literals must be preceded by either one of 
"(=+, -" Otherwise, it is considered to be an identifier or a string literal:

   regexp_replace('([(=<>+, -])[0-9]+.?[0-9]*','1:NUM')
   
   
3- To transform all string literals into “‘:STR’”. For example, the string “select ‘abc’ from dual” would be translated into 
“select ‘:STR’ from dual” :

   regexp_replace('''(.)*?''',''':STR''' )
   
The final Oracle function call looks like this (three embedded regexp_replace):

   regexp_replace(
   regexp_replace(
   regexp_replace(sql_text, '[[:space:]]+',' ' ),
                  '([(=<>+, -])[0-9]+.?[0-9]*','1:NUM'),
                  '''(.)*?''',''':STR''' )



select ename
from emp
where ename like '_L%'
or ename like '_D%' 
or ename like '_S%'; 

-- But with REGEXP_LIKE it is like this:

select ename
from emp
where regexp_like(ename,'^.[LDS]');

REGEXP_REPLACE (NVL (rcs.Consumer_Zip_Code, ' '),'[[:alnum:]]','')

-- sreach the object_name which are having any number starting 0 to 9 at last 
regexp_like(object_name, '[0-9]$','i')

-- Object_name starting with W or O
regexp_like(object_name, '^[WO]','i')

-- search all those table_name which are starting with sn_temp and sc_temp
regexp_like(table_name,'^SN_TEMP|SC_TEMP','i')
OR
regexp_like(table_name,'^(SN|SC)_TEMP','i')
OR
REGEXP_LIKE(object_name,'S._TEMP[[:digit:]]','i') --- use it 

-- searching for all-numeric data. The caret (^) START and dollar 
-- ($) END denotes of the line, respectively. 
-- The plus (+) after the digit class represents one or more occurrences.
REGEXP_LIKE(x, '^[0-9]+$');

--The following query returns the first and last names for those employees with a 
--first name of Steven or Stephen (where first_name begins with Ste and ends with en and 
--in between is either v or ph)
SELECT first_name, last_name
FROM employees
WHERE REGEXP_LIKE (first_name, '^Ste(v|ph)en$');

--Using the Regexp_like operator to identify sales people whose last names begin with a "W" and end with an "N"
Regexp_like (last_name, '^W.*N$');

--Using the Regexp_like operator to identify sales people whose last names begin with a "W" or "V" and end with an "N"
Regexp_like (last_name, '^(W|V).*N$');

--Using the Regexp_like operator to identify sales people with an "FF", "FL", "LF", or "LL" in their last name
Regexp_like (last_name, '.*(F|L){2}.*');

--Using the Regexp_like operator to identify sales people with five consecutive digits in the address
Regexp_like (address, '[[:digit:]]{5}')

--Using the Regexp_like operator and Character classes to identify two digit address numbers
Regexp_like (address, '^[[:digit:]][[:digit:]][[:space:]]');

--Using the range (-) symbol to identify sales people whose names begin with characters between K and R
--A hyphen (-) is used in the character list to indicate a range of values.
Regexp_like (last_name, '^[K-R]');

--Using the Negate carot to identify addresses that do not begin with alphabetic characters
--Carots (^) placed inside a character list are not anchor symbols.  They are the negate symbol.
Regexp_like (address, '^[^[:alpha:]]{4}');

-- will return those object_name which will not have any number in the name of the objects
not REGEXP_LIKE(object_name,'[[:digit:]]','i')


-- This query uses the regular expression metacharacter period (.), which matches any character. The expression does not
-- look for three periods followed by a dash followed by four periods. It looks for any three characters, followed by a dash,
-- followed by any four characters.
SELECT park_name
FROM park
WHERE REGEXP_LIKE(description, '...-....');


-- some more (Class Operators) Regular Expressions hints
[:digit:]   Any digit
[:alpha:]   Any upper or lower case letter
[:lower:]   Any lower case letter
[:upper:]   Any upper case letter
[:alnum:]   Any upper or lower case letter or number
[:xdigit:]  Any hex digit
[:blank:]   Space or Tab
[:space:]   Space, tab, return, line feed, form feed
[:cntrl:]   Control Character, non printing
[:print:]   Printable character including a space
[:graph:]   Printable characters, excluding space.
[:punct:]   Punctuation character, not a control character or alphanumeric
 

 /*
Regular Expression Patterns.

Regular Expressions have a formal definition as part of the POSIX standard.  Different symbols define how a pattern is described.  Let’s start with the basic symbols.

Characters and Numbers represent themselves.  If you are searching for ‘abc’ then the matching pattern is abc.  

Period (.) represents any single character or number.  The pattern ‘b.e’ will match bee, bye, b3e but not bei, or b55e.  Likewise the pattern ‘..-..=…’  matches any 
two characters, followed by a dash, followed by any two characters, followed by an equal sign, followed by any three characters.

Star (*) represent zero or more characters.  The pattern ‘b.*e will match bee, bye, beee, bzyxe and be.  The pattern ‘..-..=.*’ can end with zero or more characters after the equal sign. 

Plus (+) represents one or more characters.  This pattern is the same a ‘.*’ except that there must be one character.  Using the pattern ‘b.+e’ the string “be” will not match.

Question Mark (?) represents zero or one character.  The pattern ‘..-..=.?’ can only end with one character or no character after the equal sign.

If I wanted to match a US telephone number, I could use the pattern ‘…-…-….’.  This pattern will match any three characters, followed by a dash, followed by 3 more characters, followed by 
a dash and four final characters.  So the string “123-456-7891” will match this pattern.  Well so will “abc-def-ghij”.  So this simple patter will match a lot of strings that are not phone numbers.  
We will improve on this pattern in a moment.

Brackets are used to define numbers of characters.  

{count}  defines an exact number of characters.  The pattern a{3) defines exactly three character ‘a’.  Used with the period, the {count} defines the number of characters.  The phone number
example could be written as the pattern ‘.{3}-.{3}-.{4}’.  

Note:  When used with many applications, the bracket already has a meaning and to use it in a expression is must be escaped, normally with a slash.  ‘.\{3\}-\{3\}-\{4\}’  In this example the slash ‘\’ simply escapes the bracket.  With Oracle, this is not necessary.

{min,max} defines a minimum and maximum number of characters.  The pattern ‘.{2,8}’ will match any 2 or more characters, up to 8 characters.

{min,} defines the minimum or more number of characters.  The pattern ‘sto{1,}p’ will match any string that has ‘st’ followed by one or more ‘o’, followed by a ‘p’.  This includes stop, stoop, stooooop, but not stp or stoip.

Square Brackets are used to define a subset of the expression.  Any one character in the bracket will match the pattern.  If I want only a number character then I could use a pattern like ‘[0123456789]’.  
 The phone number pattern could be written as: 

‘[0123456789]{3}-[0123456789]{3}-[0123456789]{4}’  

With this pattern, I have excluded all the letters from matching strings.  A range of characters can also be defined in square brackets.  This is easier to type and read.  The range is defined using the 
dash between the min and max. The phone example now becomes:

‘[0-9]{3}-[0-9]{3}-[0-9]{4}’

Ranges of letters can also be defined.  The pattern ‘st[aeiou][A-Za-z]’ matches any string with the characters ‘st’ followed by a vowel, followed by any character, upper or lower case.  
This pattern matches stop, stay, staY, stud.  The pattern ‘abc[1-9]’ matches abc1, abc2, abc3,…

The caret [^] in square brackets matches any character except those following the caret.  The pattern ‘st[^o]p will match step, strp, but not stop.

So far, all the patterns match is the pattern is found anywhere in the line of text.  Use the caret and dollar sign to define patterns that match the start or end of a string.

^ defines that start of a string or column 1 of the string.

$ defines the end of a string or the last column.  This does not included carriage returns and line feeds.

The pattern ‘^St[a-z]*’ matches a string that starts with ‘St’ followed by zero or more lower case letters.  The pattern ‘stop$’ only matches “stop” if it is the last word on the line.

| or vertical line defines the Boolean OR.  The patter ‘[1-9]|[a-z]’ matched any number or lower case letter.  The pattern ‘stop|step’ matches the strings stop or step.

\ or backward slash is the escape character.   This is use to tell the parser that the character following it is to be taken literally.  In the note earlier, it was pointed out that
 some characters have special meaning in some applications and must be escaped to tell the application to use that literal character.  Another reason to escape a character is when you want 
 to actually use the character in your matching pattern.  For example, if you want to match a number that has two decimal places you could use the pattern:

‘[0-9]+.[0-9]{2}’

This example looks right but will not match the pattern that we are looking for.  The period we use to represent the decimal place, will actually match any character.  We must tell 
the expression parser that we want the character period and we do that by escaping the period character.

‘[0-9]+\.[0-9]{2}’

Now the pattern will match one or more digits followed by a period and exactly two digits.

Class Operators

Class operators are used as an alternative way to define classes of characters.  They are defined in the format [: class :].

-- some more Regular Expressions hints
[:digit:]   Any digit
[:alpha:]   Any upper or lower case letter
[:lower:]   Any lower case letter
[:upper:]   Any upper case letter
[:alnum:]   Any upper or lower case letter or number
[:xdigit:]  Any hex digit
[:blank:]   Space or Tab
[:space:]   Space, tab, return, line feed, form feed
[:cntrl:]   Control Character, non printing
[:print:]   Printable character including a space
[:graph:]   Printable characters, excluding space.
[:punct:]   Punctuation character, not a control character or alphanume

Again, these class operators represent other characters.  The phone number example can be rewritten using class operators.

‘[:digit:]{3}-[:digit:]{3}-[:digit:]{4}’

Being Greedy
Regular expressions are greedy.  By this we mean that the expression will match the largest string it can.  Think of it as the expression parser takes the entire sting and 
compares it to the pattern.  The parser then gives back characters until it finds that the string has no match or if finds the match.

Lets use a string ‘0123423434’

If my pattern is ‘.*4’  (zero of more characters followed by the digit 4).

The first match will be the entire sting.

Expression Grouping
Expression Grouping allows part of the pattern to be grouped.  This is also called tagging or referencing.  You group an expression by surrounding it with parens.  There can be only 9 
groups in a pattern.  Below is an example that contains two groups.

‘([a-z]+) ([a-z]+)’

This pattern matches two lower case words.  Using a string defined as ‘fast stop’, the first group would contain ‘fast’ and the second group ‘stop’.  The groups are 
referenced by a backward slash and the group number.  ‘\1’ references ‘fast’ while ‘\2’ reference ‘stop’.  Thus \2 \1 results in ‘stop fast’.

Oracle and Regular Expressions
The Oracle 10g database provides four functions to implement Regular Expressions.  The Java Virtual Machine in the database also implements the Java support for Regular Expression.  
The four functions can be used in SQL statements or PL/SQL.  They operate on the database character datatypes to include VARCHAR2, CHAR, CLOB, NVARCHAR2, NCHAR, and NCLOB.  The four functions are:

REGEXP_LIKE       Returns true is the pattern is matched, otherwise false.
REGEXP_INSTR      Returns the position of the start  or end of the matching string.  Returns zero if the pattern does not match.
REGEXP_REPLACE    Returns a string where each matching string is replaced with the text specified.
REGEXP_SUBSTR     Returns the matching string, or NULL if no match is found.

Let’s look at each of the functions and how to put them to use.
 

REGEXP_LIKE
Syntax:  regexp_like(source, pattern(, options));

The source is a text literal, variable or column.  The pattern is the expression you are looking for.  The options define how the matching will take place.  The options are:

i = case insensitive

c = case sensitive

n = the period will match a new line character

m = allows the ^ and $ to match the beginning and end of lines contained in the source.  Normally these characters would match the beginning and end of the source.  This is for multi-line sources.

This function can be used anywhere a Boolean result is acceptable. 

begin
  n_phone_number varchar2(20);
  …
begin
  …
  if (regexp_like(n_phone_number, .*[567]$)) then …
  end if;
  …
end;
If the phone number ends in either 5,6 or 7, the return it true and the THEN clause is executed.

In a SQL statement, this function can only be used in the WHERE or HAVING clause.

select
   …
   phone
from
  …
where regexp_like(phone, .*[567]$);
 

The REGEXP_LIKE function can also be used in check constraints.

 

REGEXP_REPLACE
Syntax:  regexp_replace( source, pattern, replace string, position, occurrence, options)

The source can be a string literal, variable, or column.  The pattern is the expression to be replaced.  The replace string is the text that will replace the matching patterns.  
The optional position defines the location to begin searching the source string.  This defaults to 1.  The optional occurrence defines the occurrence of the pattern that you want replaced.  
This defaults to 0 (all occurrences).  Setting this to a positive number will result in only that occurrence being replaced.  The matching options are the same.

select
  regexp_replace('We are driving south by south east',
                 'south', 'north')
from dual;
 

We are driving north by north east

REGEXP_INSTR
Syntax:  regexp_instr(source, pattern, position, occurrence, begin_end, options)

The source can be a string literal, variable, or column.  The pattern is the expression to be replaced.  The optional position is the location to begin the search and defaults to 1.  
The occurrence defines the occurrence you are looking for.  The begin_end defines whether you want the position of the beginning of the occurrence or the position of the end of the occurrence.  
This defaults to 0 which is the beginning of the occurrence.  Use 1 to get the end position.  The matching options are the same.

select
  regexp_instr('We are driving south by south east', 'south')
from dual;
 
16
select
  regexp_instr('We are driving south by south east', 'south', 1, 2, 1)
from dual;
 
30
 

REGEXP_SUBSTR
Syntax:  regexp_substr(source, pattern, position, occurrence, options)

The source can be a string literal, variable, or column.  
The pattern is the expression to be replaced.  
The optional position is the location to begin the search and defaults to 1.  
The optional occurrence defines the occurrence you are looking for.  
The matching options are the same.

select
  regexp_substr('We are driving south by south east', 'south')
from dual;
 
south 
 
*/




---- More Specific on RegExp..

/*

Anchoring Characters are metacharacters that 
affect the position of the search.
----------------------------------------------------
Character Class      Description
^      Anchor the expression to the start of a line
$      Anchor the expression to the end of a line
 
 
 
Equivalence Classes      
----------------------------------------------------
Character Class      Description
= =      Oracle supports the equivalence classes through 
        the POSIX '[==]' syntax. A base letter and all of 
        its accented versions constitute an equivalence 
        class. For example, the equivalence class '[=a=]' 
        matches ä and â. The equivalence classes are valid 
        only inside the bracketed expression
 
 
Match Options determine if the target is treated checked for 
case-sensitivity and whether or not the target is evaluated 
line by line or as a continuous string. 
----------------------------------------------------
Character Class      Description
c      Case sensitive matching
i      Case insensitive matching
m      Treat source string as multi-line activating Anchor chars
n      Allow the period (.) to match any newline character
 
 
 
Posix Characters tend to look very ugly but have the advantage 
that also take into account the 'locale', that is, any variant 
of the local language/coding system.
----------------------------------------------------
Character Class      Description
[:digit:]      Only the digits 0 to 9
[:alnum:]      Any alphanumeric character 0 to 9 OR A to Z or a to z.
[:alpha:]      Any alpha character A to Z or a to z.
[:blank:]      Space and TAB characters only.
[:xdigit:]     Hexadecimal notation 0-9, A-F, a-f.
[:punct:]      Punctuation symbols 
                --------------------------------
                % . , " ' ? ! : # $ & ( ) * ;
                + - / < > = @ [ ] \ ^ _ { } | ~
                --------------------------------
[:print:]      Any printable character.
[:space:]      Any whitespace characters (space, tab, NL, FF, VT, CR). 
                Many system abbreviate as \s.
[:graph:]      Exclude whitespace (SPACE, TAB). Many system abbreviate as \W.
[:upper:]      Any alpha character A to Z.
[:lower:]      Any alpha character a to z.
[:cntrl:]      Control Characters NL CR LF TAB VT FF NUL SOH STX 
                EXT EOT ENQ ACK SO SI DLE DC1 DC2 DC3 DC4 NAK SYN 
                ETB CAN EM SUB ESC IS1 IS2 IS3 IS4 DEL.
 
 
Quantifier Characters control the number of times a character 
or string is found in a search.
----------------------------------------------------
Character Class      Description
*      Match 0 or more times
?      Match 0 or 1 time
+      Match 1 or more times
{m}      Match exactly m times
{m,}      Match at least m times
{m, n}      Match at least m times but no more than n times
\n      Cause the previous expression to be repeated n times
 
 
 
Alternative Matching And Grouping Characters      
----------------------------------------------------
Character Class      Description
|      Separates alternates, often used with grouping 
        operator ()
 
( )      Groups subexpression into a unit for alternations, for 
        quantifiers, or for backreferencing 
 
[char]      Indicates a character list; most metacharacters inside a
        character list are understood as literals, with the 
        exception of character classes, and the ^ 
        and - metacharacters
 
 
////////////////////////////////////////////////////
Regex Cheat Sheet (non-posix)
////////////////////////////////////////////////////
 
 
Modifiers: 
i   case-insensitive pattern matching. 
 
g   global replace, or replace all 
 
m   Treat string as multiple lines. That is, 
    change ``^'' and ``$'' from matching at only 
    the very start or end of the string to the 
    start or end of any line anywhere within the string 
 
s   Treat string as single line. That is, change ``.'' to 
    match any character whatsoever, even a newline, which 
    it normally would not match. 
 
x   Extend your pattern's legibility by permitting 
    whitespace and comments.
 
 
Special Characters:
The following should be escaped if you are trying to 
match that character:
 
 \  ^  .  $  |  (  )  [  ]
 *  +  ?  {  }  ,
 
 
Special Character Definitions:
    \   Quote the next metacharacter
    ^   Match the beginning of the line
    .   Match any character (except newline)
    $   Match the end of the line (or before newline at the end)
    |   Alternation
    ()  Grouping
    []  Character class
    *      Match 0 or more times
    +      Match 1 or more times
    ?      Match 1 or 0 times
    {n}    Match exactly n times
    {n,}   Match at least n times
    {n,m}  Match at least n but not more than m times
 
More Special Characters: 
    \t          tab                   (HT, TAB)
    \n          newline               (LF, NL)
    \r          return                (CR)
    \f          form feed             (FF)
    \a          alarm (bell)          (BEL)
    \e          escape (think troff)  (ESC)
    \033        octal char (think of a PDP-11)
    \x1B        hex char
    \c[         control char
    \l          lowercase next char (think vi)
    \u          uppercase next char (think vi)
    \L          lowercase till \E (think vi)
    \U          uppercase till \E (think vi)
    \E          end case modification (think vi)
    \Q          quote (disable) pattern metacharacters till \E
 
Even More Special Characters:
    \w  Match a "word" character (alphanumeric plus "_")
    \W  Match a non-word character
    \s  Match a whitespace character
    \S  Match a non-whitespace character
    \d  Match a digit character
    \D  Match a non-digit character
    \b  Match a word boundary
    \B  Match a non-(word boundary)
    \A  Match only at beginning of string
    \Z  Match only at end of string, or before newline at the end
    \z  Match only at end of string
    \G  Match only where previous m//g left off (works only with /g)
 

*/

-- This is telling Oracle to start at the punct and include all characters until u reach a comma (include the comma as well).
SELECT regexp_substr( 'Employee Name and Age: Adam, Dana 28', '[:punct:][^,]+,' ) "REGEXP_SUBSTR"
FROM dual;

-- What if you want to find the number in the string?
SELECT regexp_substr( 'Employee Name and Age: Adam, Dana 28', '[[:digit:]]+' ) "REGEXP_SUBSTR"
FROM dual;


-- Tells oracle to start the string at the '-' character.  [^-] tells oracle to continue until it finds another '-' character.  
SELECT regexp_substr( '655-236-4567', '-[^-]+' ) "REGEXP_SUBSTR"
FROM dual;

-- Note that if you add an extra '-' at the end of the regular expression you will get the trailing '-' as part of the returned string:
SELECT regexp_substr( '655-236-4567', '-[^-]+-' ) "REGEXP_SUBSTR"
FROM dual;


Out put of REGEXP_SUBSTR
-236-

-- find the last '.' in the statment and returns all the characters followed by it.
-- so if there is value 'xyz.qos.jopuyt.sql' then it will return 'sql'
select REGEXP_SUBSTR(file_name, '[^.]+.$') from dual;


The basic regular expressions that for regexp_replace()

1- To remove duplicate white space and all carriage returns and linefeeds (this flattens the query into one line):

   regexp_replace(sql_text, '[[:space:]]+',' ' )
   
2- To transform all numeric literals into “:NUM”. The premise is that all numeric literals must be preceded by either one of 
"(=+, -" Otherwise, it is considered to be an identifier or a string literal:

   regexp_replace('([(=<>+, -])[0-9]+.?[0-9]*','1:NUM')
   
   
3- To transform all string literals into “‘:STR’”. For example, the string “select ‘abc’ from dual” would be translated into 
“select ‘:STR’ from dual” :

   regexp_replace('''(.)*?''',''':STR''' )
   
The final Oracle function call looks like this (three embedded regexp_replace):

   regexp_replace(
   regexp_replace(
   regexp_replace(sql_text, '[[:space:]]+',' ' ),
                  '([(=<>+, -])[0-9]+.?[0-9]*','1:NUM'),
                  '''(.)*?''',''':STR''' )


-- ATOS world

-- Example of regexp_replace 
SELECT userid, country, Department, emailname, employer
FROM lp_baseinfo lb
WHERE EXISTS 
    (
        SELECT 1 
        FROM (
               SELECT UNIQUE du.username
                 FROM (
                        SELECT REGEXP_REPLACE(REGEXP_REPLACE(du.username,'[0-9]'),'P_|_NA|_P|_AP') username
                        FROM dba_users@rprd1 du
                        WHERE  PROFILE  IN ('STD_INTERACTIVE_USER_90DAYS','STD_INTERACTIVE_USER_60DAYS')
                      ) du
                ORDER BY du.username ASC
             )iner
        WHERE iner.username = lb.userid
    )


-- Extracting letter and number sequences from a string 
with strings as ( 
  select 'ABC123' str from dual union all 
  select 'A1B2C3' str from dual union all 
  select '123ABC' str from dual union all 
  select '1A2B3C' str from dual 
) 
  select regexp_substr(str, '[0-9]'), /* Returns the first number */  
         regexp_substr(str, '[0-9].*'), /* Returns the first number and the rest of the string */  
         regexp_substr(str, '[A-Z][0-9]') /* Returns the first letter with a following number */  
  from   strings

-- Format of string is Route (departure & desitination airports) / departure date (ddmmyyyy) / Passenger name 
with strings as ( 
  select 'LHRJFK/010315/SAXONMR' str from dual union all 
  select 'CDGLAX/050515/SMITHMRS' str from dual union all 
  select 'LAXCDG/220515/SMITHMRS' str from dual union all 
  select 'SFOJFK/010615/JONESMISS' str from dual 
) 
  select regexp_substr(str, '[A-Z]{6}'), /* Returns the first string of 6 characters */  
         regexp_substr(str, '[0-9]+'), /* Returns the first matching numbers */  
         regexp_substr(str, '[A-Z].*$'), /* Returns the first letter followed by all other characters */  
         regexp_substr(str, '/[A-Z].*$') /* Returns / followed by a letter then all other characters */  
  from   strings

-- Format of string is Route (departure & desitination airports) / departure date (ddmmyyyy) / Passenger name 
with strings as ( 
  select 'LHRJFK/010315/SAXONMR' str from dual union all 
  select 'CDGLAX/050515/SMITHMRS' str from dual union all 
  select 'LAXCDG/220515/SMITHMRS' str from dual union all 
  select 'SFOJFK/010615/JONESMISS' str from dual 
) 
  select regexp_substr(str, '[A-Z]{6}') first_6_letters, /* Returns the first string of 6 characters */  
         regexp_substr(str, '[0-9]+') first_matching_numbers, /* Returns the first matching numbers */  
         regexp_substr(str, '[A-Z].*$') first_letter_then_all, /* Returns the first letter followed by all other characters */  
         regexp_substr(str, '/[A-Z].*$') first_slash_w_letter_after /* Returns / followed by a letter then all other characters */  
  from   strings
  
-- If we wanted to find the third word in the string, we could modify our function as follows:
SELECT REGEXP_SUBSTR ('TechOnTheNet is a great resource', '(\S*)(\s)', 1, 3)
FROM dual;

Result: 'a '

-- If we wanted to find the second word in the string, we could modify our function as follows:
SELECT REGEXP_SUBSTR ('TechOnTheNet is a great resource', '(\S*)(\s)', 1, 2)
FROM dual;

Result: 'is '

<end node> 5P9i0s8y19Z
dt=Text
<node>
sys_context
3

select 
   SYS_CONTEXT('USERENV','TERMINAL') terminal,
   SYS_CONTEXT('USERENV','LANGUAGE') language,
   SYS_CONTEXT('USERENV','SESSIONID') sessionid,
   SYS_CONTEXT('USERENV','INSTANCE') instance,
   SYS_CONTEXT('USERENV','ENTRYID') entryid,
   SYS_CONTEXT('USERENV','ISDBA') isdba,
   SYS_CONTEXT('USERENV','NLS_TERRITORY') nls_territory,
   SYS_CONTEXT('USERENV','NLS_CURRENCY') nls_currency,
   SYS_CONTEXT('USERENV','NLS_CALENDAR') nls_calendar,
   SYS_CONTEXT('USERENV','NLS_DATE_FORMAT') nls_date_format,
   SYS_CONTEXT('USERENV','NLS_DATE_LANGUAGE') nls_date_language,
   SYS_CONTEXT('USERENV','NLS_SORT') nls_sort,
   SYS_CONTEXT('USERENV','CURlRID') session_userid,
   SYS_CONTEXT('USERENV','PROXY_USER') proxy_user,
   SYS_CONTEXT('USERENV','PROXY_USERID') proxy_userid,
   SYS_CONTEXT('USERENV','DB_DOMAIN') db_domain,
   SYS_CONTEXT('USERENV','DB_NAME') db_name,
   SYS_CONTEXT('USERENV','HOST') host,
   SYS_CONTEXT('USERENV','OS_USER') os_user,
   SYS_CONTEXT('USERENV','EXTERNAL_NAME') external_name,
   SYS_CONTEXT('USERENV','IP_ADDRESS') ip_address,
   SYS_CONTEXT('USERENV','NETWORK_PROTOCOL') network_protocol,
   SYS_CONTEXT('USERENV','BG_JOB_ID') bg_job_id,
   SYS_CONTEXT('USERENV','FG_JOB_ID') fg_job_id,
   SYS_CONTEXT('USERENV','AUTHENTICATION_TYPE')authentication_type,
   SYS_CONTEXT('USERENV','AUTHENTICATION_DATA')authentication_data,
--   CURRENT_SQLn attributes return subsequent 4K-byte increments, where n can be an integer from 1 to 7, inclusive. 
--   CURRENT_SQL1 returns bytes 4K to 8K; CURRENT_SQL2 returns bytes 8K to 12K, and so forth. You can specify these 
--   attributes only inside the event handler for the fine-grained auditing feature.
   SYS_CONTEXT('USERENV','CURRENT_SQL') current_sql,
   SYS_CONTEXT('USERENV','CLIENT_IDENTIFIER') client_identifier,
   SYS_CONTEXT('USERENV','GLOBAL_CONTEXT_MEMORY') global_context_memory,
   sys_context('USERENV', 'ACTION') Action_Taken,
   sys_context('USERENV', 'CLIENT_INFO')CLIENT_INFO,
   sys_context('USERENV', 'MODULE')program,
   sys_context('USERENV', 'SERVER_HOST') server_host,
   sys_context('USERENV', 'SERVICE_NAME')service_name
from dual;

-- link for sys_context
http://www.psoug.org/reference/sys_context.html

<end node> 5P9i0s8y19Z
dt=Text
<node>
Unix-Linux Scripts
2
-- AIX (Size check)
df -g | sed 's/%//g'| awk '$5 >= 75 { print }' | head -4

-- move files
ls -larts *.arc |head -n 3 |awk '{print $10}'|xargs -I {} mv {} /shared/arch672/

export NOW=$(date +"%F_%H%M%S") 

--- To get the list months wish
ls -larts *.dmp |grep  "Feb\|Mar\|Apr"|

-- list last 10 updated/modified files
ls -lt |head -10

-- search out top 10 largest file/directories in linux
du -a | sort -n -r | head -n 10


---- Linux Date Formating
#monday
date -dmonday +%Y%m%d

#last monday
date -dlast-monday +%Y%m%d

#next monday
date -dnext-monday +%Y%m%d

#two mondays from now
date -d'monday+14 days' +%Y%m%d

#two mondays ago
date -d'monday-14 days' +%Y%m%d

#although, if you fancy yourself an Abraham Lincolin
date -d'monday-fortnight ago' +%Y%m%d #2 weeks ago
date -d'monday+fortnight' +%Y%m%d #2 weeks from now

#Monday Next Year
date -d'52+monday' +%Y%m%d

#However, Monday Last Year
date -d'52-monday' +%Y%m%d  #DOES NOT  WORK

-- you can try a day other than monday and format this differently.
-- if a range is what your after you may need to do a few things
#Tuesday to Sunday
#since today is monday, i will use Tuesday

echo `date -dtuesday +%Y%m%d-``date -dnext-sunday +%Y%m%d`
 
-- curl command 
/usr/local/bin/curl -v -O -u $USERNAME:$PASSWORD sftp://$SERVERNAME/~/prod/smsnox/$FILENAME


sch1h904>cat expdp_JDE8_schemas.sh
export NOW=$(date +"%F_%H%M%S")
export ORACLE_SID=JDEPROD
export ORAENV_ASK=NO
. oraenv

echo "ORACLE HOME is: "$ORACLE_HOME
mv /cloudfs/DBA/scripts/JDE82_schemas_exp_*.* /cloudfs/DBA/scripts/old_dump

$ORACLE_HOME/bin/expdp \'/ as sysdba\' \
schemas=JDE,PRODDTA,PRODCTL,PD920 \
directory=DATA_PUMP_DIR \
CONTENT=METADATA_ONLY \
dumpfile=JDE82_schemas_exp_$NOW.dmp \
logfile=JDE82_schemas_exp_$NOW.log

mv /u01/app/oracle/admin/JDEPROD/dpdump/JDE82_schemas_exp_$NOW.* /cloudfs/DBA/scripts 
 

Now the final shell script which will call the dbnodes.txt and script.sql to loop the above sql commands
through all databases. The shell script is called dbloop.sh
#!/bin/bash
cat dbnodes.txt | while read line
do
sqlplus -s user/user123@$line @/u03/scripts/script.sql
done
=============================================================================================

--- check the perticular DB processes
ps -ef |grep oraclerstg4e |grep -e "LOCAL=NO"
ps -ef |grep oracleecm2fn5p2 |grep -e "LOCAL=NO" |wc -l
ps -ef |grep oracleecm2fn5p2 |grep -e "LOCAL=NO" |awk '{print $2}'|head -n 100
ps -ef |grep oraclerstg4e |grep -e "LOCAL=NO" |awk '{print $2}'|head -n 100 |xargs kill -9
=============================================================================================

-- Shell Script to Run a SQLPLUS against all databases running on a server...
#!/usr/bin/bash
#---------------------------------------------------------------------------
# Script Name : alldatafiles.sh
# Description : Provides list of all datafiles for each running database on
#               on a machine
#---------------------------------------------------------------------------
 
ORATAB=/etc/oratab
echo "INSTANCE_NAME, FILE_NAME"
 
# Step through running instances
ps -ef | grep ora_smon_ | grep -v grep | cut -b61-70 | while read LINE
do
    # Assign the ORACLE_SID
    ORACLE_SID=$LINE
    export ORACLE_SID
 
    #Find ORACLE_HOME info for current instance
    ORATABLINE=`grep $LINE $ORATAB`
    ORACLE_HOME=`echo $ORATABLINE | cut -f2 -d:`
    export ORACLE_HOME
    LD_LIBRARY_PATH=$ORACLE_HOME/lib:/usr/lib
    export LD_LIBRARY_PATH
 
    # Put $ORACLE_HOME/bin into PATH and export.
    PATH=$ORACLE_HOME/bin:/bin:/usr/bin:/etc ; export PATH
 
    # Get SGA
    sqlplus -s "/ as sysdba" &LT;&LT;EOF
    SET HEADING OFF
    SET FEEDBACK OFF
    SET LINESIZE 3800
    SET TRIMSPOOL ON
    SET TERMOUT OFF
    SET SPACE 0
    SET PAGESIZE 0
    select (select instance_name from v\$instance) as DB_NAME,
           file_name
      from dba_data_files
     order by 2;
EOF
 
done

<end node> 5P9i0s8y19Z
dt=Text
<node>
Unix-Linux cmd
3
-- Execute the script without redirection
nohup sh custom-script.sh &

nohup sh custom-script.sh > custom-out.log &
===========================================================================

--command finds the unique key values in a file
cat gcatest.log|awk -F ' ' {'print $3'}|uniq|sort|uniq

--- will delete the first thousand 
ls -ltrh|head -n 1000|awk '{print $9}'|xargs rm -f
===========================================================================
-- last 10 files
ls -larts |tail -10

-- vi option for replace in front of script
:%s/^/ mv /g 

-- vi option for replace at the end of the script
:%s/$/ \/moneris5\/old_archive\/coms /g

:%s/$/ \/ora10\/old_archive /g

-- checking the multiple disk space on linux
#!/bin/bash
for ID in `df -h | grep -v none | grep -v Filesystem | grep -v "/" | grep -v -w "home"| awk '{if ($5 > "80%") print $1 " " $5}' | sed 's/ /=/g'`
do
        echo $ID | sed 's/=/ /g'
        excecute the script
done

-- checking the /home partition disk space on linux
VAL=`df -h | grep "/ora4" | awk '{print $5}'`

if [ $VAL > 80 ]
then
	execute script
else
	:
fi

-- last 2 weeks files
find transnox/wucc/exp*.dmp -mtime -14 -print

-- exclude files which are modified last 2 weeks back... and take all files 
find transnox/wucc/exp*.dmp ! -mtime -14 -ls

-- find the files which are not modified in 14 days and which are created in last 26 days
find ../../transnox/centennial/exp*.dmp ! -mtime +26 ! -mtime -14 -ls

-- one day prevoius file sreaching
find /ora3/oracle/oradata/coms/archive -type f -mtime +0 -exec ls -l {} \;


-- sreaching for the days given 
ls -ltrh |grep "Jul  5"

-- remove the files up till date like Mar 12
ls -ltr | grep "Mar 12" | awk '{print $9}'  | xargs rm -f

===========================================================================

-- replace the string in big files without opening the files
grep -rl US7ASCII test.log |xargs sed -i -e 's/US7ASCII/US7ASCII1267892345/g'
===========================================================================

--- scp command help
expect -c "
# exp_internal 1 # uncomment for debugging
spawn  scp -q qcp_xtns.dmp oracle@logarchive.ifxlv.com:/archive/bkups/dumps/transmoneris
expect { 
		"*password:*" { send oracle@7534\r\n; interact } 
		eof { exit }
	}
exit
"
===========================================================================

vi /home/oracle/CRISTAL/CTASK0083223/kinjal_abc_06042017.sh

#!/bin/sh
export ORACLE_HOME=
export ORACLE_SID=

PATH=$PATH:$HOME/bin:$ORACLE_HOME/bin
export PATH

sqlplus -s "/as sysdba" << eof
@/home/oracle/CRISTAL/CTASK0083223/Script_rattrapage_14500_affaire_3221.sql
commit;
spool off
exit
eof
exit
===========================================================================

-- shell script to run some oracle .sql scripts
sqlplus -s / as sysdba << eof
spool /home/oracle/mergecustcode_logs_16Jul2014.log
alter session set current_schema=MERGECUSTCODE;
DECLARE 
  O_OUTPUTSTATUS NUMBER;
  O_OUTPUTMESSAGE VARCHAR2(32767);
BEGIN 
  O_OUTPUTSTATUS := NULL;
  O_OUTPUTMESSAGE := NULL;
  MERGECUSTCODE.P0 ( O_OUTPUTSTATUS, O_OUTPUTMESSAGE );
  DBMS_OUTPUT.PUT_LINE('O_OUTPUTSTATUS = ' || TO_CHAR(O_OUTPUTSTATUS));
  DBMS_OUTPUT.PUT_LINE('O_OUTPUTMESSAGE = ' || O_OUTPUTMESSAGE);
  DBMS_OUTPUT.PUT_LINE('');
  COMMIT; 
END;
/
commit;
show errors;
spool off
eof
===========================================================================

-- script to transfer the files on remote server
-- below script take the username/password from the script
#! /bin/bash
# This script transfers the tar file to backup server of LV 10.75.245.50

echo "Backup Started `date`"

echo "Transferring Daily_Backup_Files to backup server 10.75.245.50"
#cd /snox6/prod_bck/tarlocation
cd /snox6/prod_bck/bck_scripts
#/home/oracle/prod_bck/capitaloneT2

/usr/bin/expect <<SCRIPT_END
set timeout -1
spawn sftp oracle@10.75.15.50
expect "password:"
send "oracle\r"
expect "sftp> "
send "cd /snox6/prod_bck/bck_scripts\r"
expect "sftp> "
send "put *.txt /home/oracle/prod_bck/capitaloneT2\r"
expect "sftp> "
send "exit\r"
SCRIPT_END

echo "Backup Completed `date`"

exit 0

#EOF
===========================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
Shell Scripting
3
-- This script will create folder on local disk, copy archivelogs of yesterday to this 
-- folder and compress folder with zip

#!/bin/bash

. /home/oracle/.bash_profile

cd /home/oracle/backup/rman/archivelogs/

mkdir `date -d "1 day ago" "+%Y_%m_%d"`

. /home/oracle/grid_env

for i in $(asmcmd ls +FRA/TESTDB/ARCHIVELOG/`date -d "1 day ago" "+%Y_%m_%d"`);
	do asmcmd cp +FRA/TESTDB/ARCHIVELOG/`date -d "1 day ago" "+%Y_%m_%d"`/$i /home/oracle/backup/rman/archivelogs/`date -d "1 day ago" "+%Y_%m_%d"`;
done

zip -r `date -d "1 day ago" "+%Y_%m_%d"`.zip `date -d "1 day ago" "+%Y_%m_%d"`

rm -r `date -d "1 day ago" "+%Y_%m_%d"`

================================================================================================
-- backup script scheduled for NYBC DB server

#!/bin/sh

export HOST=`hostname`
export ORACLE_HOME=/u01/app/oracle/product/rac/11.2.0.4
PATH=$PATH:$HOME/bin:$ORACLE_HOME/bin
export PATH

export ORACLE_SID=EP2MPRD2

export BKUP_DATE=`date +%d_%m_%Y_%H%M`
export BKUP_DIR_PATH=/u02/bkup_EP2MPRD2_DB
export BKUP_DUMPFILE=expdp_bkup_${ORACLE_SID}_${BKUP_DATE}
export BKUP_LOGFILE=logfs_expdp_bkup_${ORACLE_SID}_${BKUP_DATE}

export BKUP_DIR_NAME=EXP_FULL_EP2MPRD2
export TAR_ZIP_BKUP_FILES=${BKUP_DUMPFILE}

# do cd to backup directory
cd ${BKUP_DIR_PATH}

# start full backup of EP2MPRD2 database
expdp \'/as sysdba\' DUMPFILE=${BKUP_DUMPFILE}.dmp LOGFILE=${BKUP_LOGFILE}.log directory=${BKUP_DIR_NAME} full=Y compression=all content=all

# compress the backup dump and log files using tar.gz command 
tar -cvzf ${TAR_ZIP_BKUP_FILES}.tar.gz ${BKUP_DUMPFILE} ${BKUP_LOGFILE}

# delete the 3 days older .tar.gz file to save the space
find ${TAR_ZIP_BKUP_FILES}.tar.gz -type f -mtime +3 -exec rm {} \;

# echo Backup Completed

# modify the script if the you see the ORA- errors in export backup .log file and 
# send a mail to DLINO-NAIMO-ORACLE-SUPPORT.it-solutions@atos.net group
# echo "this is the body of the email" | mail -s "testing mail" rahul.chaudhari@atos.net

=============================================================================================

->cat /depot/oracle/temp/create_new_DBA_users_multi_atatime_all_DBs.ksh
#!/bin/ksh
username="${1}"
DBA_passwd="${2}"
new_userlist="${3}"
new_user_pass="${4}"
ALL_DATABASES=`ps -ef|grep ora_smon_ |grep -v grep|awk -F"_" '{print $3 " " $4}'|sort`
for DB in $ALL_DATABASES
do
   unset  TWO_TASK
   export ORACLE_SID=$DB
   export ORACLE_HOME=`grep "^${DB}:" /etc/oratab|cut -d: -f2 -s`
   export PATH=$ORACLE_HOME/bin:$PATH
        export v_Date=`date '+%Y%m%d%H%M%S'`
        echo "---> Database $ORACLE_SID, using home $ORACLE_HOME"
        #set -x
        for usrlst in `echo ${new_userlist} | awk -F"," '{for(i=1;i<=NF;i++) print x=$i}'`
        do
          sqlplus -s "/as sysdba" <<ENDofSQL
set echo on
create user ${usrlst} identified by "${new_user_pass}"
default tablespace users
temporary tablespace temp profile DPROFILE;
grant create session,dba to $usrlst;
set echo off
ENDofSQL
done | tee /depot/oracle/temp/tmp_logs/create_new_user_${ORACLE_SID}_${v_Date}.log
done

<end node> 5P9i0s8y19Z
dt=Text
<node>
shell e.g
3
/*
    This example is a simple representative sequence of commands that can be used to read user 
   input for various purposes
*/

doContinue=n
echo -n "Do you really want to continue? (y/n) " 
read doContinue

if [ "$doContinue" != "y" ]; then
      echo "Quitting..."
      exit
fi

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
 /*
     It is imperative that only users with the correct permissions and environment run a given 
   script. A useful check in a script tests the user who is attempting to run the script. If 
   you enclose a command within back-quote (‘) characters, the results of the command can be returned 
   to the script. The following example retrieves the currently logged-on user, by using whoami, 
   and displays the date, by using the date command later in the script. 
*/	

echo "You are logged in as ‘whoami‘";

if [ ‘whoami‘ != "oracle" ]; then
  echo "Must be logged on as oracle to run this script."
  exit
fi

echo "Running script at ‘date‘"

-----------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------
 /*
     search_log.sh. A variety of logs are generated by Oracle products, and you might be interested 
   in monitoring them. The database alert log contains messages that are critical to database operations. 
   Log files are also generated when products are installed or deinstalled and when patches are applied. 
   The following script iterates over a file passed to it as an argument. If any lines are found that 
   contain ORA-, an e-mail message is sent to a designated recipient. 
*/
	
#!/bin/bash
rm -rf alert.err

cat ora_err.log | grep "ORA-" > alert.err

COUNT=`cat alert.err | wc -l`

if [ "$COUNT" == "0" ]
then
        echo " No Errors"
else
  mail -s " Errors" rahulc@infonox.com < alert.err
        echo " Erros"
fi

<end node> 5P9i0s8y19Z
dt=Text
<node>
usefull cmds
3

-- Below command can be used to copy past 3 days files to a destination folder. 
-- * run the command from the file location.
find . -type f -mtime -3 | awk -F / '{print "cp  "$2 " /tmp/test/"}' | sh –x

<end node> 5P9i0s8y19Z
dt=Text
<node>
shell oracle
3

vi /csapps/oracle/fresh_expdp.sh
#!/bin/bash

echo "Preparing export for"$1

export ORAENV_ASK=YES
. oraenv <<EOF
$1
EOF

sqlplus "/ as sysdba" <<EOF


select name from v\$database;
create or replace directory fresh_bkp as '/new_expdp006/DONOT_DELETE_RESTORED/$1';
select * from dba_directories;

exit
EOF

nohup expdp \"/ as sysdba\" dumpfile=fresh_bkp:expdp_$1_%U.dmp logfile=fresh_bkp:$1_19dec2019_exp.log compression=all parallel=6 full=y flashback_time=\"TO_TIMESTAMP \(TO_CHAR \(SYSDATE, \'YYYY-MM-
DD HH24:MI:SS\'\), \'YYYY-MM-DD HH24:MI:SS\'\)\"  &

:wq

/csapps/oracle/fresh_expdp.sh <database_name> -- for which export has to be run
-------------------------------------------------------------------

-- col fname for a70
-- select tsname, fname from sys.sysfiles;

--- create database and start importing 
->cat /csapps/oracle/create_testdb.sh
!#/usr/bin/bash

echo "Preparing for:"$1
export ORAENV_ASK=YES
. oraenv <<EOF
$1
EOF
cp $ORACLE_HOME/dbs/spfile$1.ora $ORACLE_HOME/dbs/spfile$1.ora_bak
sqlplus "/ as sysdba" <<EOF

select name from v\$database;

create pfile='/tmp/init$1.ora' from spfile;

exit
EOF
ls -l /tmp/init$1.ora
#echo "changing initfile to test"
#sed "s/${1}/test/gpw output" /tmp/init$1.ora > /tmp/init.ora
#mv /tmp/init.ora /tmp/init$1.ora
echo $?

cat /tmp/init$1.ora

sqlplus "/ as sysdba" <<EOF

create spfile='+DATA2/$1/spfile$1.ora' from pfile='/tmp/init$1.ora';
shut immediate;
EOF

cp $ORACLE_HOME/dbs/init$1.ora $ORACLE_HOME/dbs/init$1.ora_bak

sed 's/DATA/DATA2/g' $ORACLE_HOME/dbs/init$1.ora_bak > $ORACLE_HOME/dbs/init$1.ora

sqlplus "/ as sysdba" <<EOF

startup nomount;
set echo on;
sho parameter spfile;
alter system set control_files='+FRA','+FRA2' scope=spfile;
alter system set db_create_file_dest='+DATA2';
alter system set audit_file_dest='/csapps/oracle/admin/$1/adump' scope=spfile;
alter system set undo_tablespace='UNDOTBS1' scope=spfile;
shut immediate;
startup nomount;
sho parameter spfile;
sho parameter control;
sho parameter audit_file_dest;
sho parameter undo_tablespace;
sho parameter db_create_file_dest;
exit
EOF
rman cmdfile=/csapps/oracle/rman_clone.cmd using ${1} <<EOF
EOF
sqlplus "/ as sysdba" <<EOF
set serveroutput on;
set feedback on;
select name,open_mode from v\$database;
create or replace directory fresh_bkp as '/new_expdp006/DONOT_DELETE_RESTORED/$1';
select * from dba_directories;
begin

for df in (select name from v\$datafile)
loop

execute immediate 'alter database datafile '''||df.name||''' autoextend on maxsize 20G';

end loop;
end;
/


begin

for df in (select name from v\$tempfile)
loop

execute immediate 'alter database tempfile '''||df.name||''' autoextend on maxsize 20G';

end loop;
end;
/
exit
EOF

nohup impdp \"/ as sysdba\" dumpfile=fresh_bkp:expdp_$1_%U.dmp logfile=fresh_bkp:$1_21dec2019_imp.log parallel=6 full=y remap_datafile='+DATA':'+DATA2' table_exists_action=replace &

cd /new_expdp006/DONOT_DELETE_RESTORED/$1



sch1h673:oracle:trece:/new_expdp006/DONOT_DELETE_RESTORED/trece
->

-- RMAN script
-> cat /csapps/oracle/rman_clone.cmd

---create auxiliary/duplicate database from backup
>newsid trece -- . oraenv

--- connect directlry to duplicate database using auxiliary keyword
>rman auxiliary /

run{
allocate auxiliary channel c1 device type disk;
allocate auxiliary channel c2 device type disk;
allocate auxiliary channel c3 device type disk;
allocate auxiliary channel c4 device type disk;
set newname for database to '+DATA2';
duplicate database to trece backup location '/new_expdp006/sample';
}

<end node> 5P9i0s8y19Z
dt=Text
<node>
DB Commissions
3
cat /etc/oratab |grep -e "efiler" |sed 's/^/#/g' | sed 's/$/ \#DB decommissioned with Ticket No:RITM0532743/g'

vi /etc/oratab |grep -e "infotr" |sed 's/^/#/g' | sed 's/$/ \#DB decommissioned with Ticket No:RITM0532743/g'


cat /etc/oratab |grep -e "efiler" |sed 's/^/#/g' | sed 's/$/ \#DB decommissioned with Ticket No:RITM0532743/g' /etc/oratab


sed 's/efiler/#efiler/g' | sed 's/$/ \#DB decommissioned with Ticket No:RITM0532743/g' /etc/oratab

<end node> 5P9i0s8y19Z
dt=Text
<node>
Linux Date Format
3
---- Linux Date Formating
#monday
date -dmonday +%Y%m%d

#last monday
date -dlast-monday +%Y%m%d

#next monday
date -dnext-monday +%Y%m%d

#two mondays from now
date -d'monday+14 days' +%Y%m%d

#two mondays ago
date -d'monday-14 days' +%Y%m%d

#although, if you fancy yourself an Abraham Lincolin
date -d'monday-fortnight ago' +%Y%m%d #2 weeks ago
date -d'monday+fortnight' +%Y%m%d #2 weeks from now

#Monday Next Year
date -d'52+monday' +%Y%m%d

#However, Monday Last Year
date -d'52-monday' +%Y%m%d  #DOES NOT  WORK

-- you can try a day other than monday and format this differently.
-- if a range is what your after you may need to do a few things
#Tuesday to Sunday
#since today is monday, i will use Tuesday

echo `date -dtuesday +%Y%m%d-``date -dnext-sunday +%Y%m%d`
 
-- curl command 
/usr/local/bin/curl -v -O -u $USERNAME:$PASSWORD sftp://$SERVERNAME/~/prod/smsnox/$FILENAME


DEST_DIR="/home/sites/transgca/File_Transfer/zipfiles"
mkdir -p $DEST_DIR
cd $DEST_DIR

echo " " > .tmpfile
FILENAME="`date  +%Y%m%d`_TS.ZIP"
#FILENAME=20101122_TS.ZIP
FILENAME1="`date +%Y%m%d`.TS"
#FILENAME1=20100429.TS
echo $FILENAME

#username=transgca
USERNAME="ndmjobs"
#password=es0s_DpL
PASSWORD='NdmJ0b$@Tempe'
SERVERNAME="transuploader.ifxtempe.com"

FILENAME2="download_success_mail.txt"
echo "" > $FILENAME2 

curl -u ftpuser:ftppass -T myfile.txt ftp://ftp.testserver.com  




---- deleting one day older file

#!/bin/bash

# User specific environment and startup programs
ORACLE_BASE=/ora1/oracle/
ORACLE_HOME=/ora1/oracle/product/11.1.0/db_1
export ORACLE_BASE
export ORACLE_HOME
export ORACLE_SID=aqprod
PATH=$ORACLE_HOME/bin:/usr/bin:/bin:/usr/bin/X11:/usr/local/bin:/sbin:
PATH=$PATH:$HOME/bin
export PATH


# checking the /archive disk partition space where archive files are getting create
VAL=`df -h | grep "/archive" | awk '{print $5}'|sed 's/%//g'`

if [ "$VAL" -gt "65" ]
then
    echo "Disk value $VAL"
    echo "Disk space above 65%"

    cd /archive/oracle/aqprod/archive

    find *.dbf -type f -mtime +1 -exec ls -l {} \; > temp_file.sh

    for fn in `cat temp_file.sh |awk '{print $9}'`
    do
       echo "$fn"
       # deleting non tar files
       rm -f $fn
    done

    rm -f temp_file.sh
else
    echo "$VAL"
    echo "Disk space is below 65%"
fi

<end node> 5P9i0s8y19Z
dt=Text
<node>
remove space file Name
3

# mv “file with space.mp3? file_with_space.mp3

Now, the next command assumes that you have thousands of hundred of thousands MP3 files with spaces between 
its filenames. And you want to remove space character and replace them with underscores. Just make sure you are currently 
inside the working folder of these MP3 files and issue

# for files in *.mp3; do mv “$files” `echo $files | tr ‘ ‘ ‘_’`; done

Wonderful linux.

How to convert lower case filenames to uppercase filenames of hundred thousand files in one shot?

# for files in *.mp3; do mv “$files” `echo $files | tr ‘[:lower:]‘ ‘[:upper:]‘`; done

You can replace *.mp3 with any other filename identifier or file glob.

<end node> 5P9i0s8y19Z
dt=Text
<node>
DG and StandBy DBs
2

-- check the max sequence number on both primary and standby DB
select max(sequence#)  from v$archived_log;

select max(sequence#) from gv$archived_log where applied='YES'

--  if the result of this query is greater than 0, than the Data Guard is in use
SELECT COUNT(*) 
FROM v$archive_dest 
WHERE status = 'VALID' 
  AND target = 'STANDBY';

SELECT NAME,VERSION,CURRENTLY_USED,FEATURE_INFO
FROM DBA_FEATURE_USAGE_STATISTICS
WHERE NAME = 'Data Guard'

oracle> dgmgrl /
DGMGRL for Linux: Version 11.2.0.2.0 - 64bit Production

Copyright (c) 2000, 2009, Oracle. All rights reserved.

Welcome to DGMGRL, type "help" for information.
Connected.

DGMGRL> show configuration verbose;
Error:
ORA-16525: the Data Guard broker is not yet available

Configuration details cannot be determined by DGMGRL
DGMGRL>

<end node> 5P9i0s8y19Z
dt=Text
<node>
DG & StdBy
3
-- All required command for Standby and DG
https://valehagayev.wordpress.com/category/high-availability/

-- Standby Issues check

-- Query the below sql to validate the archive dest on both 

SELECT DEST_NAME,STATUS,DESTINATION FROM V$ARCHIVE_DEST WHERE DESTINATION IS NOT NULL;

PRIMARY
---------
DEST_NAME STATUS DESTINATION
---------------------------------------- --------- ------------------------------
LOG_ARCHIVE_DEST_1 VALID USE_DB_RECOVERY_FILE_DEST
LOG_ARCHIVE_DEST_2 ERROR amppdrp


STANDBY
--------
DEST_NAME STATUS DESTINATION
---------------------------------------- --------- ------------------------------
LOG_ARCHIVE_DEST_1 VALID USE_DB_RECOVERY_FILE_DEST
LOG_ARCHIVE_DEST_2 VALID USE_DB_RECOVERY_FILE_DEST


on PRIMARY
==========
SYS@ampp1> show parameter LOG_ARCHIVE_DEST_2

NAME TYPE VALUE
------------------------------------ ----------- ------------------------------
log_archive_dest_2 string service="amppdrp" LGWR ASYNC N
                                                 OAFFIRM delay=0 optional compr
                                                 ession=enable max_failure=6 ma
                                                 x_connections=10 reopen=300 db
                                                 _unique_name="amppdrp" net_tim
                                                 eout=30 valid_for=(all_logfile
                                                 s,primary_role)



alter system set log_archive_dest_state_2=ENABLE scope=both sid='*';


-- now run the query it will be in valid state 

-- check the DG broker state

show configuration verbose

-- check the primary and standby seq. difference
-- run the query on standby to check the difference
SELECT ARCH.THREAD# "Thread", ARCH.SEQUENCE# "Last Sequence Received",
    APPL.SEQUENCE# "Last Sequence Applied", (ARCH.SEQUENCE# - APPL.SEQUENCE#) "Difference"
FROM (SELECT THREAD# ,SEQUENCE#
      FROM V$ARCHIVED_LOG
      WHERE (THREAD#,FIRST_TIME ) IN (SELECT THREAD#,MAX(FIRST_TIME)
                                        FROM V$ARCHIVED_LOG
                                        GROUP BY THREAD#)) ARCH,
      (SELECT THREAD# ,SEQUENCE#
       FROM V$LOG_HISTORY
       WHERE (THREAD#,FIRST_TIME ) IN (SELECT THREAD#,MAX(FIRST_TIME)
                                          FROM V$LOG_HISTORY
                                          GROUP BY THREAD#)) APPL
WHERE ARCH.THREAD# = APPL.THREAD#
ORDER BY 1;

-- If we want to review all the property values of standby then we can use "verbose" 
-- command associated with show database.
-- http://phxcharger.blogspot.in/2014/03/ora-16857-standby-disconnected-from.html

DGMGRL> show configuration -- and take the DBName to check all configuration property
DGMGRL> show database verbose <<DBName>>

DGMGRL>EDIT DATABASE amppdrp SET PROPERTY TransportDisconnectedThreshold='300';

-- some more information to check for the errors on dgmgrl

1.) SQL> SELECT status, error FROM V$ARCHIVE_DEST_STATUS  WHERE STATUS <> 'DEFERRED' AND STATUS <> 'INACTIVE';

2.) SQL> SELECT THREAD#, MAX(SEQUENCE#) AS "LAST_APPLIED_LOG" FROM V$LOG_HISTORY GROUP BY THREAD#;

3.) SQL> select name, value from v$dataguard_Stats;

4.) SQL> SELECT status, error

5.) SQL> SELECT status, error

SQL> select severity,error_code,message from v$dataguard_status where dest_id=2;


6.) SQL> select inst_id, process, status, thread#, sequence#, block#, blocks 
		 from gv$managed_standby where process in ('RFS','LNS','MRP0');

   INST_ID PROCESS   STATUS          THREAD#  SEQUENCE#     BLOCK#     BLOCKS

---------- --------- ------------ ---------- ---------- ---------- ----------

         1 MRP0      WAIT_FOR_GAP          1       1983          0          0

         1 RFS       IDLE                  0          0          0          0

         1 RFS       IDLE                  0          0          0          0

         1 RFS       IDLE                  0          0          0          0


-- On Primary DB

-- steps 2) check the last log sequence number (archive log) details on both Primary and StandBy DB's
SQL> select sequence#, first_time,next_time,applied from v$archived_log order by sequence#;

-- On StandBy DB
SQL> select sequence#, first_time,next_time,applied from v$archived_log order by sequence#;

-- On both the database the max sequence# number should be matching

-- ===============================================================================================

-- http://www.datadisk.co.uk/html_docs/oracle_dg/

-- http://www.datadisk.co.uk/html_docs/oracle_dg/active_dg.htm

-- Read-only Standby
The downside is that once the standby database has been open in read-only mode it is no 
longer applying redo from the primary and thus becomes out of sync, here are the steps to open 
in read-only and to put it back in to recovery mode

-- open in read-only mode	
alter database recover managed standby database cancel;
alter database open;

-- return to recovery mode	
shutdown immediate;
startup mount; 
alter database recover managed standby database disconnect from session;

-- enable real-time apply of redo	
alter database recover managed standby database using current logfile disconnect;
-- ===============================================================================================

-- Snapshot Standby

The difference between a read-only standby and a snapshot standby is that the snapshot standby 
is fully up dateable. It was possible in Oracle 10g to open a standby database as read-write 
but as from version 11g you now have the snapshot feature. This new feature makes it simpler 
to make the standby read-write and to revert to back again with the use of the Broker, also it 
is advised to use the flashback database feature as it makes life a whole lot simpler.

-- snapshot standby	
DGMGRL> convert database 'prod1dr' to snapshot standby;
DGMGRL> show configuration;

## Check that redo is still being sent to the standby
select status, sequence#, block# from v$managed_standby;

## you can double check some tables make sure that you are protected

-- revert back	
DGMGRL> convert database 'prod1dr' to physical standby;
DGMGRL> show configuration;

## shutdown the physical database and restart it mount mode
As you can see the broker makes light work of this.
-- ===============================================================================================


-- To enable Active data guard you can either use SQL Plus or the Broker

-- Enable Active Data Guard using SQL Plus	
## First stop the redo and open the database as read-only
sql> recover managed standby database cancel;
sql> alter database open read only; 

## Restart the redo
sql> recover managed standby database disconnect using current logfile;

-- Enable Active Data Guard using the Broker	
## First stop the redo
DGMGRL> edit database prod1dr set state='apply=off';

## Open the database as read-only
sql> alter database open read only;

## Restart the redo
DGMGRL> edit database prod1dr set state='apply=on';
-- ===============================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
Multiple StdBy DB
3
-- Multiple Standby Databases Dataguard Oracle
-- https://easyoradba.com/2012/12/04/multiple-standby-databases-dataguard-oracle/


We will create 2 standby databases from a single RAC primary database. 11gR2 allows upto 30 standby databases.  The most important part is to consider the dataguard parameters, the rest is a normal dataguard creation. The important parameters are as below :

db_file_name_convert

log_archive_config

log_archive_dest_1

log_archive_dest_2

log_archive_dest_3

LOG_ARCHIVE_DEST_STATE_1

LOG_ARCHIVE_DEST_STATE_2

LOG_ARCHIVE_DEST_STATE_3

log_file_name_convert

remote_login_passwordfile

STANDBY_FILE_MANAGEMENT

fal_client

fal_server

sec_case_sensitive_logon    (if on 11gR2)
All database are running on Grid + ASM 11.2.0.3.4 with RAC primary and RAC standby’s. Please note the procedure is identical to a single instance setup. In Rac the only special thing you do is register the standby database and instances to the OCR via srvctl command.

We all call our primary database SWX and our PHYSICAL STANDBY databases as SWXSTANDBY, SWXSTANDYBY2. We will use RMAN Duplicate Active Standby database feature of 11gR2. If your standby databases are in different data centesr and the bandwidht isn’t suffcient you can use the tradionatl RMAN  duplicate command.

1. Create tnsnames.ora entry on Primary database. Use RDBMS owner for the tnsnames.ora not Grid infrastructure owner

SWX =
(DESCRIPTION =
(ADDRESS = (PROTOCOL = TCP)(HOST = *.*.*.213)(PORT = 1521))
(CONNECT_DATA =
(SERVER = DEDICATED)
(SERVICE_NAME = swx1)(UR=A)
)
)

SWXSTANDBY =
(DESCRIPTION =
(ADDRESS = (PROTOCOL = TCP)(HOST = *.*.*.219)(PORT = 1521))
(CONNECT_DATA =
(SERVER = DEDICATED)
(SERVICE_NAME = swxstandby)(UR=A)
)
)

SWXSTANDBY2 =
(DESCRIPTION =
(ADDRESS = (PROTOCOL = TCP)(HOST =  *.*.*.224)(PORT = 1521))
(CONNECT_DATA =
(SERVER = DEDICATED)
(SERVICE_NAME = swxstandby2)(UR=A)
)

2. Add an SID entry on the listener.ora as Grid infrastructure user

SID_LIST_EASYORADBA_LISTENER=(SID_LIST=(SID_DESC=(SID_NAME=swx1)(GLOBAL_DBNAME=swx)(ORACLE_HOME=/grid/app/11.2.0/grid/)))

3. Create a pfile and the below datagaurd parameters to the pfile

#########################STANDBY PARAMETERS########################
*.DB_UNIQUE_NAME=’swx’
*.db_file_name_convert=’+DATA/SWXSTANDBY2/’,’+DATA/SWXSTANDBY/’,’+DATA/SWX/’,’+FRA/SWXSTANDBY2/’,’+FRA/SWXSTANDBY/’,’+FRA/SWX/’
*.log_archive_config=’dg_config=(swxstandby2,swxstandby,swx)’
*.log_archive_dest_1=’LOCATION=+FRA valid_for=(ALL_LOGFILES,ALL_ROLES) db_unique_name=swx’
*.log_archive_dest_2=’service=swxstandby LGWR ASYNC valid_for=(ONLINE_LOGFILE,PRIMARY_ROLE) db_unique_name=swxstandby’
*.log_archive_dest_3=’service=swxstandby2 LGWR ASYNC valid_for=(ONLINE_LOGFILE,PRIMARY_ROLE) db_unique_name=swxstandby2'
*.LOG_ARCHIVE_DEST_STATE_1=’ENABLE’
*.LOG_ARCHIVE_DEST_STATE_2=’ENABLE’
*.LOG_ARCHIVE_DEST_STATE_3=’ENABLE’
*.LOG_ARCHIVE_FORMAT=’log%t_%s_%r.arc’
*.log_file_name_convert=’+DATA/SWXSTANDBY2/’,’+DATA/SWXSTANDBY/’,’+DATA/SWX/’,’+FRA/SWXSTANDBY2/’,’+FRA/SWXSTANDBY/’,’+FRA/SWX/’
*.remote_login_passwordfile=’exclusive’
*.STANDBY_FILE_MANAGEMENT=’AUTO’
*.fal_client=’SWX’
*.fal_server=’SWXSTANDBY2',’SWXSTANDBY’
*.sec_case_sensitive_logon=FALSE
########################################

4. Restart the database with the new pfile and create spfile from it and bounce the database again

5. Login to the First DR database server as Oracle user and create tnsnames.ora entry

SWX =
(DESCRIPTION =
(ADDRESS = (PROTOCOL = TCP)(HOST = *.*.*.213)(PORT = 1521))
(CONNECT_DATA =
(SERVER = DEDICATED)
(SERVICE_NAME = swx)(UR=A)
)
)

SWXSTANDBY =
(DESCRIPTION =
(ADDRESS_LIST =
(ADDRESS = (PROTOCOL = TCP)(HOST = *.*.*.218)(PORT = 1521))
)
(CONNECT_DATA =
(SERVICE_NAME = swxstandby)(UR=A)
)
)

SWXSTANDBY2 =
(DESCRIPTION =
(ADDRESS_LIST =
(ADDRESS = (PROTOCOL = TCP)(HOST = *.*.*.224)(PORT = 1521))
)
(CONNECT_DATA =
(SERVICE_NAME = swxstandby2)(UR=A)
)
)

6. Add SID listener entry in listener.ora file as Grid infrastructure user.

SID_LIST_EASYORADBA_LISTENER=(SID_LIST=(SID_DESC=(SID_NAME=swx1)(GLOBAL_DBNAME=swx)(ORACLE_HOME=/grid/app/11.2.0/grid)))

7. Create a pfile with the dataguard parameters from the pfile created before on primary and add below parameters.

#########################STANDBY DATABASE PARAMETERS########################
*.DB_UNIQUE_NAME=’SWXSTANDBY’
*.db_file_name_convert=’+DATA/SWX/’,’+DATA/SWXSTANDBY/’,’+DATA/SWXSTANDBY2/’,’+FRA/SWX/’,’+FRA/SWXSTANDBY/’,’+FRA/SWXSTANDBY2/’
*.log_archive_config=’dg_config=(swxstandby2,swxstandby,swx)’
*.log_archive_dest_1=’LOCATION=+FRA valid_for=(ALL_LOGFILES,ALL_ROLES) db_unique_name=swxstandby’
*.log_archive_dest_2=’service=swx LGWR ASYNC valid_for=(ONLINE_LOGFILE,PRIMARY_ROLE) db_unique_name=swx’
*.log_archive_dest_3=’service=swxstandby2 LGWR ASYNC valid_for=(ONLINE_LOGFILE,PRIMARY_ROLE) db_unique_name=swxstandby2'
*.LOG_ARCHIVE_DEST_STATE_1=’ENABLE’
*.LOG_ARCHIVE_DEST_STATE_2=’ENABLE’
*.LOG_ARCHIVE_DEST_STATE_3=’ENABLE’
*.LOG_ARCHIVE_FORMAT=’log%t_%s_%r.arc’
*.log_file_name_convert=’+DATA/SWX/’,’+DATA/SWXSTANDBY/’,’+DATA/SWXSTANDBY2/’,’+FRA/SWX/’,’+FRA/SWXSTANDBY/’,’+FRA/SWXSTANDBY2/’
*.remote_login_passwordfile=’exclusive’
*.STANDBY_FILE_MANAGEMENT=’AUTO’
*.fal_client=’SWXSTANDBY’
*.fal_server=’SWX’,’SWXSTANDBY2'
*.sec_case_sensitive_logon=FALSE
########################################

8. Start the database with the pfile and create spfile from it

9. Clone the database from RMAN using active option

rman target sys/***@swx auxiliary sys/***@swxstandby

RMAN> duplicate target database for standby from active database nofilenamecheck dorecover;

10. Register the database and instance with srvctl command

srvctl add database -d SWXSTANDBY -o /oracle/app/oracle/product/11.2.0/dbhome_1 -c RAC -r PHYSICAL_STANDBY -a DATA,FRA
srvctl add instance -d SWXSTANDBY -i swx1 -n csftest-2
srvctl stop database -d SWXSTANDBY
sqlplus “/as sysdba”
srvctl start database -d swxstandby
srvctl modify database -d swxstandby -s mount
srvctl config database -d swxstandby

## TO ACTIVATE ACTIVE STANDBY DATABASE ###
srvctl start database -d swxstandby -o open

11. Login to the Second DR database server as Oracle user and create tnsnames.ora entry

SWX =
(DESCRIPTION =
(ADDRESS = (PROTOCOL = TCP)(HOST = *.*.*.213)(PORT = 1521))
(CONNECT_DATA =
(SERVER = DEDICATED)
(SERVICE_NAME = swx)(UR=A)
)
)

SWXSTANDBY2 =
(DESCRIPTION =
(ADDRESS = (PROTOCOL = TCP)(HOST = *.*.*.15)(PORT = 1521))
(CONNECT_DATA =
(SERVER = DEDICATED)
(SERVICE_NAME = SWXSTANDBY2)(UR=A)
)
)

SWXSTANDBY =
(DESCRIPTION =
(ADDRESS = (PROTOCOL = TCP)(HOST = *.*.*.218)(PORT = 1521))
(CONNECT_DATA =
(SERVER = DEDICATED)
(SERVICE_NAME = SWXSTANDBY)(UR=A)
)
)

12. Create a listener.ora entry as grid user

SID_LIST_EASYORADBA_LISTENER=(SID_LIST=(SID_DESC=(SID_NAME=swx1)(GLOBAL_DBNAME=swx)(ORACLE_HOME=/grid/app/11.2.0/grid)))

13. Create a pfile with the dataguard parameters from the pfile created before on primary and add below parameters.

#########################STANDBY DATABASE PARAMETERS########################
*.DB_UNIQUE_NAME=’SWXSTANDBY2'
*.db_file_name_convert=’+DATA/SWX/’,’+DATA/SWXSTANDBY/’,’+DATA/SWXSTANDBY2/’,’+FRA/SWX/’,’+FRA/SWXSTANDBY/’,’+FRA/SWXSTANDBY2/’
*.log_archive_config=’dg_config=(swxstandby2,swxstandby,swx)’
*.log_archive_dest_1=’LOCATION=+FRA valid_for=(ALL_LOGFILES,ALL_ROLES) db_unique_name=swxstandby2'
*.log_archive_dest_2=’service=swx LGWR ASYNC valid_for=(ONLINE_LOGFILE,PRIMARY_ROLE) db_unique_name=swx’
*.log_archive_dest_3=’service=swxstandby LGWR ASYNC valid_for=(ONLINE_LOGFILE,PRIMARY_ROLE) db_unique_name=swxstandby’
*.LOG_ARCHIVE_DEST_STATE_1=’ENABLE’
*.LOG_ARCHIVE_DEST_STATE_2=’ENABLE’
*.LOG_ARCHIVE_DEST_STATE_3=’ENABLE’
*.LOG_ARCHIVE_FORMAT=’log%t_%s_%r.arc’
*.log_file_name_convert=’+DATA/SWX/’,’+DATA/SWXSTANDBY/’,’+DATA/SWXSTANDBY2/’,’+FRA/SWX/’,’+FRA/SWXSTANDBY/’,’+FRA/SWXSTANDBY2/’
*.remote_login_passwordfile=’exclusive’
*.STANDBY_FILE_MANAGEMENT=’AUTO’
*.fal_client=’SWXSTANDBY2'
*.fal_server=’SWX’,’SWXSTANDBY’
*.sec_case_sensitive_logon=FALSE
########################################

14. Start the database with the pfile and create spfile from it

15. Clone the database from RMAN using active option

rman target sys/***@swx auxiliary sys/***@swxstandby

RMAN> duplicate target database for standby from active database nofilenamecheck dorecover;

16. Register the database and instance with srvctl command

srvctl add database -d swxstandby2 -o /oracle/app/oracle/product/11.2.0/dbhome_1 -c RAC -r PHYSICAL_STANDBY -n swx -a DATA,FRA
srvctl add instance -d swxstandby2 -i swx1 -n suncsftst

Now that we  have  a fully functional RAC PRIMARY with 2 PHYSICAL STANDBYs now let us consider the 2 most important things in Dataguard: Switchover and Failover

————–

Switchover

—————-

No extra steps are necessary when performing a switchover. All bystander physical
standby databases automatically apply redo data received from the new primary
database.

————–

Failover

—————-

The steps for performing a failover to a physical standby database depend on the
Redo Apply progress of the new primary database and any bystander physical
standby databases at the time of the failover.
• If the new primary database has applied more redo than all of the bystander
physical standby databases, no additional steps are required. Only the original
primary database needs to be reinstated, using the steps documented in Oracle
Data Guard Concepts and Administration[5], Section 12.4.1 “Flashing Back a Failed
Primary Database into a Physical Standby Database.”.
• If any bystander physical standby database has applied more redo than the new
primary database, then perform the following steps to reinstate the bystander
physical standby

SQL*Plus Physical/Physical Failover with Physical Bystander Ahead

1. Determine STANDBY_BECAME_PRIMARY_SCN from the new
primary.
SQL> select STANDBY_BECAME_PRIMARY_SCN from
v$database;
2. On the bystander physical standby, flash back to
STANDBY_BECAME_PRIMARY_SCN from the new primary
database.
SQL> flashback database to scn
<STANDBY_BECAME_PRIMARY_SCN>;
3. On the bystander physical standby, delete divergent archived redo logs
created at the time of, or after, the failover.
RMAN> delete archivelog from scn
<STANDBY_BECAME_PRIMARY_SCN>;
4. On the new primary database, enable the redo transport destination
for this bystander physical standby and archive the current redo log.
SQL> alter system set
log_archive_destination_2=enable;
SQL> alter system archive log current;
5. After the logs have been received by the bystander physical standby,
start Redo Apply on the bystander physical standby.

SQL> alter database recover managed standby
database using current logfile through all
switchover disconnect;
The bystander standby database is now reinstated.

For more information refer to this excellent Oracle document.

http://www.oracle.com/technetwork/database/features/availability/maa10gr2multiplestandbybp-1-131937.pdf

Interesting Case-Study on Multiple Standby Databases. Apparently Apple uses it for one of their Large databases.

http://www.oracle.com/technetwork/database/features/availability/311400-134359.pdf

<end node> 5P9i0s8y19Z
dt=Text
<node>
Patch Pri and StdBy DB
3

-- Applying PSU Patch in a Dataguard (Physical Standby) environment

-- Good URL
https://shivanandarao-oracle.com/2012/09/20/applying-psu-patch-in-a-dataguard-physical-standby-environment/

-- Can Refere it also
http://dbaclass.com/article/how-to-apply-psu-patch-on-standby-database/

-- Another one to refere
https://arvindasdba.wordpress.com/2014/07/14/applying-cpu-patch-in-a-dataguard-physical-standby-environment/

-- ===============================================================================================
-- Applying PSU Patch in a dataguard (Physical Standby) environment

-- Process
-- 1 Check the database_role for both dbs
PRIMARY> select database_role from v$database;
 
DATABASE_ROLE
----------------
PRIMARY
 
STANDBY>  select database_role from v$database;
 
SDATABASE_ROLE
----------------
PHYSICAL STANDBY

-- 2 Run below in primary to check log gap between primary and standby ( it should be zero)
PRIMARY >select LOG_ARCHIVED-LOG_APPLIED "LOG_GAP" from
(SELECT MAX(SEQUENCE#) LOG_ARCHIVED
FROM V$ARCHIVED_LOG WHERE DEST_ID=1 AND ARCHIVED='YES'),
(SELECT MAX(SEQUENCE#) LOG_APPLIED
FROM V$ARCHIVED_LOG WHERE DEST_ID=2 AND APPLIED='YES');

-- 3 DISABLE SHIPPING ON PRIMARY
PRIMARY> alter system set log_archive_dest_state_2=defer;

-- 4 CANCEL THE RECOVERY ON STANDBY
STANDBY> alter database recover managed standby database cancel;

-- 5 Shutdown the listener and database in standby:
STANDBY > shutdown immediate;

STANDBY > ps -ef |grep tns

-- take the listener name of standby database, if the name is coming LISTENER_STBY
STANDBY$ lsnrctl stop LISTENER_STBY

-- Go to the patch location in standby and unzip it.
-- check the full process to apply the patch
-- http://dbaclass.com/article/how-to-apply-psu-patch-on-standby-database/

-- Now ask to OS team to apply the patch 
-- Or DBA team to apply the patch
-- Now apply the patch(on standby)

***************************************************************************************

-- How to start the standby DB again

-- 6 start the standby database in mount state and start the listener
STANDBY$ sqlplus "/as sysdba"

STANDBY> startup mount
 
STANDBY$ lsnrctl start LISTENER_STBY

***************************************************************************************

-- 7 Now shutdown the database and listener on PRIMARY
PRIMARY$ sqlplus "/as sysdba"

PRIMARY> shutdown immediate;

PRIMARY$ ps -ef|grep tns

PRIMARY$ lsnrctl stop LISTENER_PROD

-- Apply the OS/Oracle Patch on PRIMARY, Once done then start the DB and listener

-- 8 Now start up open the database and listener.
PRIMARY$ sqlplus "/as sysdba"
 
PRIMARY > startup open

PRIMARY$ lsnrctl start LISTENER_PROD

-- 8 Enable archive shipping on PRIMARY
PRIMARY> alter system set log_archive_dest_state_2=enable;

***************************************************************************************

-- 9 Start the recovery(MRP) on standby:
STANDBY> select PROCESS,CLIENT_PROCESS,THREAD#,SEQUENCE#,BLOCK# from v$managed_standby where process = 'MRP0' or client_process='LGWR';
PROCESS   CLIENT_P    THREAD#  SEQUENCE#     BLOCK#
--------- -------- ---------- ---------- ----------
RFS       LGWR              1      37628       1358       

--- start the recovery process(MRP) on standby DB 
STANDBY> alter database recover managed standby database disconnect from session;

-- if there is any error "ORA-01153 an incompatible media recovery" then 
STANDBY> alter database recover managed standby database cancel;
STANDBY> alter database recover managed standby database disconnect from session;

-- if this is oracle patch apply then run catbundle.sql script on primary DB
-- Run the catbundle.sql script from PRIMARY
-- and Check the registry history in primary( this patch should be listed there)

-- if you see this in standby DB
Warning: ORA-16826: apply service state is inconsistent with the DelayMins property

/*
DGMGRL> show configuration verbose

Configuration - ankeny

  Protection Mode: MaxPerformance
  Databases:
    ampp    - Primary database
    amppdrp - Physical standby database
      Warning: ORA-16826: apply service state is inconsistent with the DelayMins property

*/

-- to fix the above execute the below command on standby DB

SQL> alter database recover managed standby database cancel;
SQL> alter database recover managed standby database using current logfile disconnect; 


-- ===============================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
DG cmds & SQLs
3
-- Data Guard and StandBy database 
-- http://www.datadisk.co.uk/html_docs/oracle_dg/cheatsheet.htm
-- https://valehagayev.wordpress.com/2016/07/09/dataguard-commands-and-sql-scripts/

-- Information on Redo Data
-- Note: this indirectly shows how much redo data could be lost if the primary db crashes
select * from v$dataguard_stats;

-- Background processes
select process, client_process, thread#, sequence#, status from v$managed_standby;

## primary (example) 

PROCESS   CLIENT_P THREAD#    SEQUENCE#  STATUS
--------- -------- ---------- ---------- ------------
ARCH      ARCH     1          58         CLOSING
ARCH      ARCH     0          0          CONNECTED
ARCH      ARCH     1          59         CLOSING
ARCH      ARCH     1          56         CLOSING
LNS       LNS      1          60         WRITING
LNS       LNS      1          60         WRITING

## physical standby (example) 

PROCESS   CLIENT_P THREAD#    SEQUENCE#  STATUS
--------- -------- ---------- ---------- ------------
ARCH      ARCH     0          0          CONNECTED
ARCH      ARCH     1          55         CLOSING
ARCH      ARCH     0          0          CONNECTED
ARCH      ARCH     1          59         CLOSING
RFS       N/A      0          0          IDLE
RFS       UNKNOWN  0          0          IDLE
RFS       UNKNOWN  0          0          IDLE
RFS       LGWR     1          60         IDLE
MRP0      N/A      1          60         APPLYING_LOG

## Logical standby (example) 

PROCESS   CLIENT_P THREAD#    SEQUENCE#  STATUS
--------- -------- ---------- ---------- ------------
ARCH      ARCH     1          55         CLOSING
ARCH      ARCH     1          10         CLOSING
ARCH      ARCH     0          0          CONNECTED
ARCH      ARCH     0          0          CONNECTED
RFS       UNKNOWN  0          0          IDLE
RFS       LGWR     1          60         IDLE
RFS       UNKNOWN  0          0          IDLE
RFS       UNKNOWN  0          0          IDLE
============================================================================================


-- To start redo apply in foreground:
SQL> ALTER DATABASE RECOVER MANAGED STANDBY DATABASE;

-- To stop redo apply process on the Standby database (to stop MRP):
SQL> ALTER DATABASE RECOVER MANAGED STANDBY DATABASE CANCEL;

-- To start real-time redo apply:
SQL> ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION;

-- To start redo apply in background:
SQL> ALTER DATABASE RECOVER MANAGED STANDBY DATABASE DISCONNECT FROM SESSION;
or
SQL> RECOVER MANAGED STANDBY DATABASE DISCONNECT;

-- To check redo apply  and Media recovery service status:
SQL> SELECT PROCESS,STATUS, THREAD#,SEQUENCE#, BLOCK#, BLOCKS FROM V$MANAGED_STANDBY ;

-- If managed standby recovery is not running or not started with real-time apply, 
-- restart managed recovery with real-time apply enabled:
SQL> ALTER DATABASE RECOVER MANAGED STANDBY DATABASE CANCEL;
SQL> ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT;

-- To gather Data Guard configuration information(standby)
SQL> SELECT DATABASE_ROLE,OPEN_MODE, PROTECTION_MODE FROM V$DATABASE 

DATABASE_ROLE OPEN_MODE PROTECTION_MODE
---------------- -------------------- --------------------
PHYSICAL STANDBY MOUNTED MAXIMUM PERFORMANCE

SQL> SELECT RECOVERY_MODE FROM V$ARCHIVE_DEST_STATUS WHERE RECOVERY_MODE!='IDLE';

RECOVERY_MODE
-----------------------
MANAGED REAL TIME APPLY

-- To calculate the Redo bytes per second
SQL> SELECT SUM (BLOCKS * BLOCK_SIZE) / 1024 / 1024 / 60 / 60 / 30 REDO_MB_PER_SEC
 FROM GV$ARCHIVED_LOG
 WHERE FIRST_TIME BETWEEN TO_DATE ('01.05.2016', 'DD.MM.YYYY')
 AND TO_DATE ('01.06.2016', 'DD.MM.YYYY')

-- To check status of Data Guard synchronization(standby):
SQL> SELECT NAME, VALUE FROM V$DATAGUARD_STATS;

NAME VALUE
--------------------- -------------------------------
transport lag          +00 00:00:00
apply lag              +00 00:00:00
apply finish time      +00 00:00:00.000
estimated startup time 32

-- To verify there is no log file gap between the primary and the standby database:
SQL> SELECT STATUS, GAP_STATUS FROM V$ARCHIVE_DEST_STATUS WHERE DEST_ID = 3;

STATUS GAP_STATUS
--------- ------------------------
VALID NO GAP
 

-- To verify that the primary database can be switched to the standby role:

-- A value of TO STANDBY or SESSIONS ACTIVE indicates that the primary database can be 
-- switched to the standby role. If neither of these values is returned, a switchover 
-- is not possible because redo transport is either misconfigured or is not functioning properly.
SQL> SELECT SWITCHOVER_STATUS FROM V$DATABASE; 

SWITCHOVER_STATUS
--------------------
TO STANDBY
To convert the primary database into a physical standby :

-- Before switchover the current control file is backed up to the current SQL session trace 
-- file and it possible to reconstruct a current control file, if necessary.
SQL> ALTER DATABASE COMMIT TO SWITCHOVER TO PHYSICAL STANDBY WITH SESSION SHUTDOWN;


-- To verify Managed Recovery is running on the standby :
SQL> SELECT PROCESS FROM V$MANAGED_STANDBY WHERE PROCESS LIKE 'MRP%'; 

PROCESS
---------
MRP0

-- To show information about the protection mode, the protection level, the role 
-- of the database, and switchover status:

SQL> SELECT DATABASE_ROLE, DB_UNIQUE_NAME INSTANCE, OPEN_MODE, PROTECTION_MODE, PROTECTION_LEVEL, SWITCHOVER_STATUS FROM V$DATABASE;

DATABASE_ROLE     INSTANCE    OPEN_MODE    PROTECTION_MODE     PROTECTION_LEVEL     SWITCHOVER_STATUS
---------------- ---------- ------------ -------------------- -------------------- -------------------- --------------------
PRIMARY           TESTCDB    READ WRITE    MAXIMUM PERFORMANCE MAXIMUM PERFORMANCE   TO STANDBY

-- On the standby database, query the V$ARCHIVED_LOG view to identify existing files 
-- in the archived redo log.

SQL> SELECT SEQUENCE#, FIRST_TIME, NEXT_TIME FROM V$ARCHIVED_LOG ORDER BY SEQUENCE#;
Or
SQL> SELECT THREAD#, MAX(SEQUENCE#) AS "LAST_APPLIED_LOG" FROM V$LOG_HISTORY GROUP BY THREAD#;

-- On the standby database, query the V$ARCHIVED_LOG view to verify the archived redo 
-- log files were applied.
SELECT SEQUENCE#,APPLIED FROM V$ARCHIVED_LOG ORDER BY SEQUENCE#;
 

--To determine which log files were not received by the standby site.
SQL> SELECT LOCAL.THREAD#, LOCAL.SEQUENCE#
FROM (SELECT THREAD#, SEQUENCE#
FROM V$ARCHIVED_LOG
WHERE DEST_ID = 1) LOCAL
WHERE LOCAL.SEQUENCE# NOT IN (SELECT SEQUENCE#
FROM V$ARCHIVED_LOG
WHERE DEST_ID = 2 AND THREAD# = LOCAL.THREAD#);
 

-- Archivelog difference: Run this on the primary database. (not for real-time apply):
-- Good query to check the difference between the primary and standby DBs
SQL> ALTER SESSION SET NLS_DATE_FORMAT = 'DD-MON-YYYY HH24:MI:SS';
SQL> 
SELECT A.THREAD#,
 	B.LAST_SEQ,
 	A.APPLIED_SEQ,
 	A.LAST_APP_TIMESTAMP,
	 B.LAST_SEQ - A.APPLIED_SEQ ARC_DIFF
 FROM ( SELECT THREAD#,
 		MAX (SEQUENCE#) APPLIED_SEQ,
		MAX (NEXT_TIME) LAST_APP_TIMESTAMP
 	     FROM GV$ARCHIVED_LOG
 	    WHERE APPLIED = 'YES'
 	    GROUP BY THREAD#) A,
 	 ( SELECT THREAD#, MAX (SEQUENCE#) LAST_SEQ
 		FROM GV$ARCHIVED_LOG
 	    GROUP BY THREAD#) B
 WHERE A.THREAD# = B.THREAD#;

 THREAD#   LAST_SEQ    APPLIED_SEQ  LAST_APP_TIMESTAMP   ARC_DIFF
---------- ---------- -----------   --------------------- ----------
 1         21282      21281         09-IYUL-2016 12:06:5     1
 2         23747      23746         09-IYUL-2016 12:16:13    1

2 rows selected.

 
-- To check archive log apply  on primary database:
SQL> SET LINESIZE 150
SET PAGESIZE 999
COL NAME FORMAT A65
COL DEST_TYPE FORMAT A10
COL ARCHIVED FORMAT A10
COL APPLIED FORMAT A10

SELECT SEQUENCE#,NAME,DEST_ID ,
	CASE 
	  WHEN STANDBY_DEST = 'YES'
	  THEN 'Standby' 
	ELSE 
	  'Local' 
	END AS DEST_TYPE ,
	ARCHIVED ,
	APPLIED
 FROM V$ARCHIVED_LOG
WHERE SEQUENCE# > (SELECT MAX (SEQUENCE#)
			  	FROM V$ARCHIVED_LOG
				WHERE STANDBY_DEST = 'YES' 
  				  AND APPLIED = 'YES')
ORDER BY SEQUENCE# , DEST_ID ;


 SEQUENCE#  NAME                                                          DEST_ID  DEST_TYPE  ARCHIVED APPLIED
---------- -------------------------------------------------------------- -------  ---------- -------- --------
 23748      +FRA/TESTCDB/ARCHIVELOG/2016_07_09/thread_2_seq_23748.10041.9   1      Local        YES       NO
 23748      +DATA/TESTCDB/ARCHIVELOG/2016_07_09/thread_2_seq_23748.10062.   2      Local        YES       NO
 23748      TESTSTB                                                         3      Standby      YES       NO

3 rows selected.

 
========================================================================================
--* DG BROKER COMMANDS

-- How to configure Data Guard broker:

-- 1.Start the DMON process on both the primary and standby databases:
SQL> ALTER SYSTEM SET DG_BROKER_START=TRUE SCOPE=BOTH;


-- 2.Set the log_archive_dest_2 settings from both the Primary and Standby databases
-- to be nothing , then try to create the broker configuration (it will automatically 
-- set the log_archive_dest_n when you'll add a database to the configuration)
SQL> ALTER SYSTEM SET LOG_ARCHIVE_DEST_2='';

-- Connect DGMGRL on the primary DB and create the configuration 
[oracle@primary ~]$ dgmgrl

DGMGRL> connect sys/test
Connected as SYSDG.

DGMGRL> CREATE CONFIGURATION 'TEST' AS PRIMARY DATABASE IS 'DB12C' CONNECT IDENTIFIER IS DB12C;

-- Next add a standby database to the Data Guard broker configuration:
DGMGRL> ADD DATABASE 'db12c_stby' AS CONNECT IDENTIFIER IS 'db12c_stby';

-- Enable dataguard broker configuration 
DGMGRL> enable configuration;

DGMGRL> show configuration;


-- To remove DG broker configuration:
DGMGRL> remove configuration;

-- Rename the database name in the Data Guard broker as follows:
DGMGRL> edit database 'db12c_stby' rename to 'STBY';

-- To turn off redo transport to all remote destinations on the primary database:
 DGMGRL> edit database 'DB12C' SET STATE="LOG-TRANSPORT-OFF";

-- To stop and start redo transport services to specific standby databases:
DGMGRL> edit database 'db12c_stby' SET PROPERTY 'LogShipping'='OFF';

DGMGRL> SHOW DATABASE 'db12c_stby' 'LogShipping';

DGMGRL> edit database 'db12c_stby' SET PROPERTY 'LogShipping'='ON';

-- To change the state of the standby database to read-only and back APPLY-ON:
DGMGRL> EDIT DATABASE 'db12c' SET STATE='READ-ONLY';

DGMGRL> show database db12c

-- To change back:
DGMGRL> shutdown 
DGMGRL> startup mount;
DGMGRL> show database db12c

DGMGRL> EDIT DATABASE DB12C SET STATE = APPLY-ON;

DGMGRL> show database db12c
========================================================================================
 

 


-- LOGICAL STANDBY COMMANDS

-- To Restart SQL apply on logical standby
SQL> ALTER DATABASE START LOGICAL STANDBY APPLY IMMEDIATE;

-- To Stop SQL apply on logical standby
SQL> ALTER DATABASE STOP LOGICAL STANDBY APPLY;

-- Run the following SQL against the logical standby to start real-time SQL 
-- apply if the SQL apply failed with an error, and you are 100% certain that 
-- the transaction is safe to skip
SQL> ALTER DATABASE START LOGICAL STANDBY APPLY IMMEDIATE SKIP FAILED TRANSACTION;

-- To see unsupported tables for logical standby:
SQL> SELECT * FROM DBA_LOGSTDBY_UNSUPPORTED_TABLE ORDER BY OWNER, TABLE_NAME;

-- To know which archive log sequences are at what stage for logical standby?
SQL> SELECT 'RESTART' "TYPE",
 P.RESTART_SCN "SCN",
 TO_CHAR (P.RESTART_TIME, 'yyyy/mm/dd hh24:mi:ss') "TIME",
 L.SEQUENCE# "SEQ#"
 FROM V$LOGSTDBY_PROGRESS P, DBA_LOGSTDBY_LOG L
 WHERE P.RESTART_SCN >= L.FIRST_CHANGE# AND P.RESTART_SCN < L.NEXT_CHANGE#
UNION
SELECT 'RESTART',
 P.RESTART_SCN,
 TO_CHAR (P.RESTART_TIME, 'yyyy/mm/dd hh24:mi:ss'),
 L.SEQUENCE#
 FROM V$LOGSTDBY_PROGRESS P, V$STANDBY_LOG L
 WHERE P.RESTART_SCN >= L.FIRST_CHANGE# AND P.LATEST_SCN <= L.LAST_CHANGE#
UNION
SELECT 'APPLIED',
 P.APPLIED_SCN,
 TO_CHAR (P.APPLIED_TIME, 'yyyy/mm/dd hh24:mi:ss'),
 L.SEQUENCE#
 FROM V$LOGSTDBY_PROGRESS P, DBA_LOGSTDBY_LOG L
 WHERE P.APPLIED_SCN >= L.FIRST_CHANGE# AND P.APPLIED_SCN < L.NEXT_CHANGE#
UNION
SELECT 'APPLIED',
 P.APPLIED_SCN,
 TO_CHAR (P.APPLIED_TIME, 'yyyy/mm/dd hh24:mi:ss'),
 L.SEQUENCE#
 FROM V$LOGSTDBY_PROGRESS P, V$STANDBY_LOG L
 WHERE P.APPLIED_SCN >= L.FIRST_CHANGE# AND P.LATEST_SCN <= L.LAST_CHANGE#
UNION
SELECT 'MINING',
 P.MINING_SCN,
 TO_CHAR (P.MINING_TIME, 'yyyy/mm/dd hh24:mi:ss'),
 L.SEQUENCE#
 FROM V$LOGSTDBY_PROGRESS P, DBA_LOGSTDBY_LOG L
 WHERE P.MINING_SCN >= L.FIRST_CHANGE# AND P.MINING_SCN < L.NEXT_CHANGE#
UNION
SELECT 'MINING',
 P.MINING_SCN,
 TO_CHAR (P.MINING_TIME, 'yyyy/mm/dd hh24:mi:ss'),
 L.SEQUENCE#
 FROM V$LOGSTDBY_PROGRESS P, V$STANDBY_LOG L
 WHERE P.MINING_SCN >= L.FIRST_CHANGE# AND P.LATEST_SCN <= L.LAST_CHANGE#
UNION
SELECT 'SHIPPED',
 P.LATEST_SCN,
 TO_CHAR (P.LATEST_TIME, 'yyyy/mm/dd hh24:mi:ss'),
 L.SEQUENCE#
 FROM V$LOGSTDBY_PROGRESS P, DBA_LOGSTDBY_LOG L
 WHERE P.LATEST_SCN >= L.FIRST_CHANGE# AND P.LATEST_SCN < L.NEXT_CHANGE#
UNION
SELECT 'SHIPPED',
 P.LATEST_SCN,
 TO_CHAR (P.LATEST_TIME, 'yyyy/mm/dd hh24:mi:ss'),
 L.SEQUENCE#
 FROM V$LOGSTDBY_PROGRESS P, V$STANDBY_LOG L
 WHERE P.LATEST_SCN >= L.FIRST_CHANGE# AND P.LATEST_SCN <= L.LAST_CHANGE#;

-- To know is the SQL Apply up to date
SQL> SELECT TO_CHAR(LATEST_TIME,'yyyy/mm/dd hh24:mi:ss') "LATEST_TIME", 
TO_CHAR(APPLIED_TIME,'yyyy/mm/dd hh24:mi:ss') "APPLIED_TIME", 
APPLIED_SCN, LATEST_SCN 
FROM V$LOGSTDBY_PROGRESS;

-- To know is the Logical standby applying changes? Run the following SQL against the Logical standby database:
SQL> SELECT REALTIME_APPLY, STATE FROM V$LOGSTDBY_STATE;

-- If the value of STATE is “NULL” or “SQL APPLY NOT ON” then the Sql Apply is not running.
-- The value of REALTIME_APPLY should be Y to allow for real time apply from the standby 
-- redo logs. To know what major Sql Apply events have occurred, run the following 
-- SQL against the Logical standby database:
SQL> SELECT TO_CHAR (EVENT_TIME, 'YYYY/MM/DD HH24:MI:SS') "EVENT_TIME",
STATUS, EVENT
FROM DBA_LOGSTDBY_EVENTS
ORDER BY EVENT_TIME;

-- To know what major Dataguard events have occurred, run the following SQL against 
-- the Logical standby database:
SQL> SELECT TO_CHAR (TIMESTAMP, 'yyyy/mm/dd hh24:mi:ss') "TIME",
ERROR_CODE "ERROR", DEST_ID "DEST", MESSAGE
FROM V$DATAGUARD_STATUS
WHERE timestamp > TRUNC (SYSDATE + 6 / 24)
ORDER BY timestamp DESC;

-- To know where are the archive logs going and are there any achieving issues, 
-- run the following SQL against either the logical standby or primary database:
SQL> SELECT DEST_ID "DID",
STATUS, DESTINATION, ARCHIVER, VALID_NOW, VALID_TYPE, VALID_ROLE, ERROR
FROM V$ARCHIVE_DEST
WHERE STATUS <> 'INACTIVE';

<end node> 5P9i0s8y19Z
dt=Text
<node>
DGMGRL Commands
3
-- Summary of DGMGRL Commands with Example

-- Command	Effect
-- ADD DATABASE	Adds a new standby database profile to the existing broker configuration 
DGMGRL> ADD DATABASE 'secondary' AS CONNECT IDENTIFIER IS secondary MAINTAINED AS PHYSICAL;

-- CONNECT	Connects to the specified database using the specified username. 
DGMGRL> connect sys/manager@primary
Connected.

-- CREATE CONFIGURATION	Creates a broker configuration and creates and adds a primary 
-- database profile to the configuration. 
DGMGRL> CREATE CONFIGURATION 'sample' AS PRIMARY DATABASE IS 'primary' CONNECT IDENTIFIER IS primary;
Configuration “sample” created with primary database “primary”

-- DISABLE CONFIGURATION	Disables broker management of a configuration so that the configuration 
-- and all of its databases are no longer managed by the broker. 
DGMGRL> disable configuration;
Disabled.

-- DISABLE DATABASE	Disables broker management of the named standby database. 
DGMGRL> disable database secondary;
Disabled.

-- EDIT CONFIGURATION (Protection Mode)	Changes the current protection mode setting for 
-- the broker configuration 
DGMGRL> EDIT CONFIGURATION SET PROTECTION MODE AS  MAXPerformance;
Succeeded.

DGMGRL> EDIT CONFIGURATION SET PROTECTION MODE AS  MAXPROTECTION;
Operation requires shutdown of instance “primary” on database “primary”
Shutting down instance “primary”…
Database closed.
Database dismounted.
ORACLE instance shut down.
Operation requires startup of instance “primary” on database “primary”
Starting instance “primary”…

-- EDIT DATABASE (Property)	Changes the value of a property for the named database 
DGMGRL> EDIT DATABASE 'primary' SET PROPERTY 'ArchiveLagTarget'=200;
Property “ArchiveLagTarget” updated

DGMGRL> EDIT DATABASE 'primary' SET PROPERTY 'StandbyArchiveLocation'='C:\app\patilsa\product\11.2.0\dbhome_1\oradata';
Property “StandbyArchiveLocation” updated

-- EDIT DATABASE (Rename)	Changes the name used by the broker to refer to the specified 
-- database. This command can only be done when broker management of the database that you 
-- are renaming is disabled. 
DGMGRL> EDIT DATABASE 'secondary' RENAME TO 'standby';
Error: ORA-16602: database must be disabled to perform this operation
Failed.

DGMGRL> disable database secondary;
Disabled.

DGMGRL> EDIT DATABASE 'secondary' RENAME TO 'standby';
Succeeded.

-- EDIT DATABASE (State)	Changes the state of the specified database.The state in 
-- which you want the database to be running. The possible states are:
-- ONLINE
-- LOG-TRANSPORT-OFF (primary database only)
-- LOG-APPLY-OFF (standby database only)
-- READ-ONLY (physical standby database only)
-- OFFLINE 
DGMGRL> EDIT DATABASE 'secondary' SET STATE='READ-ONLY';
Succeeded.

DGMGRL> EDIT DATABASE 'secondary' SET STATE='OFFLINE';
Operation requires shutdown of instance “secondary” on database “secondary”
Shutting down instance “secondary”…
Database closed.
Database dismounted.
ORACLE instance shut down.

DGMGRL> EDIT DATABASE 'secondary' SET STATE='ONLINE';
Error: ORA-16525: the Data Guard broker is not yet available
– Make sure Standby Database is started and mounted.

DGMGRL> EDIT DATABASE 'secondary' SET STATE='ONLINE';
Succeeded.

-- EDIT INSTANCE (AUTO PFILE) Sets the name of the initialization parameter file for 
-- the specified instance. 
DGMGRL> EDIT INSTANCE 'secondary' ON DATABASE 'secondary' SET AUTO PFILE='initsecondary.ora';
Instance “secondary” updated

-- EDIT INSTANCE (Property)	Changes the value of a property for the specified instance. 
DGMGRL> EDIT instance 'primary' on DATABASE 'primary' SET PROPERTY 'StandbyArchiveLocation'='C:\app\patilsa\product\11.2.0\dbhome_1\oradata';
Property “StandbyArchiveLocation” updated

-- ENABLE CONFIGURATION	Enables broker management of the broker configuration and all 
-- of its databases.
DGMGRL> enable configuration;
Enabled.

-- ENABLE DATABASE	Enables broker management of the specified database. 
DGMGRL> enable database 'secondary';
Enabled.

-- EXIT	Exits the Data Guard command-line interface.
-- FAILOVER	Performs a database failover operation in which the standby database, to which the CLI 
-- is currently connected, fails over to the role of primary database.

-- HELP	Displays online help for the Data Guard command-line interface. 
-- add            Adds a standby database to the broker configuration
-- connect        Connects to an Oracle database instance
-- convert        Converts a database from one type to another
-- create         Creates a broker configuration
-- disable        Disables a configuration, a database, or fast-start failover
-- edit           Edits a configuration, database, or instance
-- enable         Enables a configuration, a database, or fast-start failover
-- exit           Exits the program
-- failover       Changes a standby database to be the primary database
-- help           Displays description and syntax for a command
-- quit           Exits the program
-- reinstate      Changes a database marked for reinstatement into a viable standby
-- rem            Comment to be ignored by DGMGRL
-- remove         Removes a configuration, database, or instance
-- show           Displays information about a configuration, database, or instance
-- shutdown       Shuts down a currently running Oracle database instance
-- start          Starts the fast-start failover observer
-- startup        Starts an Oracle database instance
-- stop           Stops the fast-start failover observer
-- switchover     Switches roles between a primary and standby database
-- Use "help <command>" to see syntax for individual commands
-- QUIT	Quits the Data Guard command-line interface.

-- REMOVE CONFIGURATION	Removes the broker configuration including all of its database profiles 
-- from the broker configuration file.
-- REMOVE DATABASE	Removes the specified standby database profile from the broker configuration. 
DGMGRL> remove database secondary;
Removed database “secondary” from the configuration

-- REMOVE INSTANCE	Removes knowledge of an instance from an existing database profile in the 
-- broker configuration.
-- SHOW CONFIGURATION	Displays information about the broker configuration. 
DGMGRL> SHOW CONFIGURATION
Configuration – sample
Protection Mode: MaxPerformance
Databases:
primary   – Primary database
Warning: ORA-16789: standby redo logs not configured
secondary – Physical standby database
Fast-Start Failover: DISABLED
Configuration Status:
WARNING

-- SHOW DATABASE	Displays information about the specified database. 
DGMGRL> show database secondary;
Database – secondary
Role:            PRIMARY
Intended State:  TRANSPORT-ON
Instance(s):
secondary
Database Status:
SUCCESS

-- SHOW INSTANCE :Displays information about the specified instance. 
DGMGRL> show instance primary;
Instance 'primary' of database 'primary'
Host Name: sagar-pc
Instance Status:
SUCCESS

DGMGRL> show instance secondary;
Instance 'secondary' of database 'secondary'
Host Name: sagar-pc
Instance Status:
SUCCESS

-- SHUTDOWN	Shuts down a currently running Oracle database. 
DGMGRL> connect sys/manager@primary
Connected.
DGMGRL> shutdown abort;
ORACLE instance shut down.

-- STARTUP	Starts an Oracle instance with the same options as SQL*Plus, including mounting 
-- and opening a database. 
DGMGRL> connect sys/manager@primary
Connected.
DGMGRL> startup;
ORACLE instance started.
Database mounted.
Database opened.

-- SWITCHOVER	Performs a switchover operation in which the current primary database becomes a 
-- standby database, and the specified standby database becomes the primary database. 
DGMGRL> switchover to secondary;
Performing switchover NOW, please wait…
New primary database “secondary” is opening…
Operation requires shutdown of instance “primary” on database “primary”
Shutting down instance “primary”…
ORA-01109: database not open
Database dismounted.
ORACLE instance shut down.
Operation requires startup of instance “primary” on database “primary”
Starting instance “primary”…
Unable to connect to database
ORA-12514: TNS:listener does not currently know of service requested in connectdescriptor Failed. (IGNORE TNS error)
Warning: You are no longer connected to ORACLE.
Please complete the following steps to finish switchover:
start up and mount instance “primary” of database “primary”

-- The following commands are available: 
-- add            Adds a standby database to the broker configuration
-- connect        Connects to an Oracle database instance
-- convert        Converts a database from one type to another
-- create         Creates a broker configuration
-- disable        Disables a configuration, a database, or fast-start failover
-- edit           Edits a configuration, database, or instance
-- enable         Enables a configuration, a database, or fast-start failover
-- exit           Exits the program
-- failover       Changes a standby database to be the primary database
-- help           Displays description and syntax for a command
-- quit           Exits the program
-- reinstate      Changes a database marked for reinstatement into a viable standby

-- rem            Comment to be ignored by DGMGRL
-- remove         Removes a configuration, database, or instance
-- show           Displays information about a configuration, database, or instance

-- shutdown       Shuts down a currently running Oracle database instance
-- start          Starts the fast-start failover observer
-- startup        Starts an Oracle database instance
-- stop           Stops the fast-start failover observer
-- switchover     Switches roles between a primary and standby database

-- Use “help <command>” to see syntax for individual commands

<end node> 5P9i0s8y19Z
dt=Text
<node>
StandBy RMAN restore
3

-- if there are some archive log missing in standby and it's stuck for missing then
-- we can recover it from primary dbs backup, execute the below script in primary DB
RUN { 
ALLOCATE CHANNEL ch00 TYPE 'SBT_TAPE'; ALLOCATE CHANNEL ch01 TYPE 'SBT_TAPE';
ALLOCATE CHANNEL ch02 TYPE 'SBT_TAPE'; ALLOCATE CHANNEL ch03 TYPE 'SBT_TAPE';
RESTORE ARCHIVELOG FROM SEQUENCE 9523 until sequence 9719 thread=1;
} 


-- in standby DB just check the sequence are getting applied or not
SELECT A.THREAD#,
     B.LAST_SEQ,
     A.APPLIED_SEQ,
     A.LAST_APP_TIMESTAMP,
     B.LAST_SEQ - A.APPLIED_SEQ ARC_DIFF
 FROM ( SELECT THREAD#,
         MAX (SEQUENCE#) APPLIED_SEQ,
        MAX (NEXT_TIME) LAST_APP_TIMESTAMP
          FROM GV$ARCHIVED_LOG
         WHERE APPLIED = 'YES'
         GROUP BY THREAD#) A,
      ( SELECT THREAD#, MAX (SEQUENCE#) LAST_SEQ
         FROM GV$ARCHIVED_LOG
         GROUP BY THREAD#) B
 WHERE A.THREAD# = B.THREAD#;

<end node> 5P9i0s8y19Z
dt=Text
<node>
SYS pass change in pri-stndby
3


--  changing the SYS password in a Data Guard environment

-- Stop redo transport from the primary database to the standby database. We can execute the 
-- DEFER command to defer the log destination with the ALTER SYSTEM statement:

SQL> ALTER SYSTEM SET LOG_ARCHIVE_DEST_STATE_2 = 'DEFER';

-- If the Data Guard broker is being used, we can use the following statement:

dgmgrl \

DGMGRL> EDIT DATABASE TURKEY_UN SET STATE = 'LOG-TRANSPORT-OFF';


-- Change the SYS user's password in the primary database:

SQL> ALTER USER SYS IDENTIFIED BY newpassword;

-- Copy the primary database's password file to the standby site:
$ cd $ORACLE_HOME/dbs
$ scp orapwTURKEY standbyhost:/u01/app/oracle/product/11.2.0/ dbhome_1/dbs/orapwINDIAPS

-- Try logging into the standby database from the standby server using the new SYS password:

sqlplus sys/newpassword as sysdba 

<end node> 5P9i0s8y19Z
dt=Text
<node>
Convert phy stdby to snapshot stdBy
3
-- Convert physical standby to snapshot standby: We will now convert the physical standby database to snapshot standby

On standby:
===========
-- check the below sql query in both Phyical and standby DB, Before converting standby DB into snapshot
-- 
SQL> select thread#,max(sequence#) from v$archived_log group by thread#;
 
THREAD# MAX(SEQUENCE#)
 ---------- --------------
 1            206

SQL> select process,status,sequence# from v$managed_standby;

PROCESS   STATUS        SEQUENCE#
 --------- ------------ ----------
 ARCH      CLOSING               1
 ARCH      CONNECTED             0
 ARCH      CONNECTED             0
 ARCH      CONNECTED             0
 RFS       IDLE                  0
 RFS       IDLE                209
 RFS       IDLE                  0
 
7 rows selected.

SQL> alter database recover managed standby database cancel;

-- make sure the database is mounted
SQL> select name, open_mode from v$database;

SQL> alter database convert to snapshot standby;

-- open the DB
SQL> alter database open;

SQL> select name, open_mode, database_role from v$database;

-- Verifying snapshot standby: 
-- Now you must be able to read-write on snapshot standby. Meanwhile, we can even check the standby alert log. 
-- The archives received from primary are not applied on standby. We can even check that there is a guaranteed 
-- restore point has been created. So that when you convert snapshot back to physical standby, it will be used. 

-- NOTE: for this snapshot standby, you do not need Flashback enabled at database level
On standby:
===========
SQL> select name, guarantee_flashback_database from v$restore_point;

SQL> create table student(sno number(2), s_name varchar2(10));
SQL> insert into student values(1,'RAM');
SQL> insert into student values (2,'Max');
SQL> commit;

SQL> select * from student;

-- Revert back snapshot standby to physical standby: 
-- Once application testing is done, you can revert back snapshot standby 
-- to same point when it was converted from physical standby to snapshot standby

On standby:
===========
SQL> select name, open_mode, database_role from v$database;
SQL> shut immediate;
SQL> startup mount;
SQL> alter database convert to physical standby;
SQL> shutdown immediate
SQL> startup mount;
SQL> alter database recover managed standby database disconnect;
SQL> select * from student;


============================================================================================================

-- if you want to enable falshback for snapshot stdby DB then follow the below steps

-- Convert Physical Standby To Snapshot Standby Database
SQL@STANDBY> select open_mode from v$database;

OPEN_MODE
--------------------
READ ONLY WITH APPLY

SYS@STANDBY> select database_role from v$database;

DATABASE_ROLE
----------------
PHYSICAL STANDBY

--Cancel the recovery process:
SYS@STANDBY> alter database recover managed standby database cancel;

Database altered.

--Enable flashback mode:
SYS@STANDBY> shut immediate
SYS@STANDBY> startup mount;

SYS@TESTER1 SQL> alter database flashback on;
alter database flashback on
*
ERROR at line 1:
ORA-38706: Cannot turn on FLASHBACK DATABASE logging.
ORA-38709: Recovery Area is not enabled.
Elapsed: 00:00:01.49

SYS@TESTER1 SQL> show parameter db_recovery_file_dest

NAME TYPE VALUE
------------------------------------ ----------- ------------------------------
db_recovery_file_dest string
db_recovery_file_dest_size big integer 0


SYS@TESTER1 SQL> alter system set db_recovery_file_dest_size=1g;
SYS@TESTER1 SQL> alter system set db_recovery_file_dest='/u03/testdb/TESTER1';

System altered.

SYS@TESTER1 SQL> show parameter db_recovery_file_dest

NAME TYPE VALUE
------------------------------------ ----------- ------------------------------
db_recovery_file_dest string /u03/testdb/TESTER1
db_recovery_file_dest_size big integer 1G

SYS@TESTER1 SQL> alter database flashback on;

Database altered.

SYS@TESTER1 SQL> select flashback_on from v$database;

FLASHBACK_ON
------------------
YES

-- Now the below command will convert it to snapshot standby
SYS@TESTER1 SQL> select status from v$instance;

STATUS
------------
MOUNTED

SYS@TESTER1 SQL> alter database convert to snapshot standby;

SYS@TESTER1 SQL> alter database open;

SYS@TESTER1 SQL> select database_role from v$database;

DATABASE_ROLE
----------------
SNAPSHOT STANDBY

SYS@TESTER1 SQL> select open_mode from v$database;

OPEN_MODE
--------------------
READ WRITE

SQL> select NAME,GUARANTEE_FLASHBACK_DATABASE from v$restore_point;

NAME GUA
---------------------------------------- ---
SNAPSHOT_STANDBY_REQUIRED_10/03/2012 06: YES 13:19

--Let’s do some DML changes in this snapshot standby
SYS@TESTER1 SQL> alter table mahendra add (b VARCHAR2(10));

Table altered.

SYS@TESTER1 SQL> insert into mahendra values('mahi','notu');

1 row created.

SYS@TESTER1 SQL> commit;

Commit complete.

SYS@TESTER1 SQL> select * from mahendra;
-- We can see we are able to do write operation on snapshot database also.
--------------------------------------------------------------------------------------------

-- ** Let convert it again to physical standby again.
SYS@TESTER1 SQL> shut immediate;

SYS@TESTER1 SQL> startup mount

SYS@TESTER1 SQL> select FLASHBACK_ON from v$database;

FLASHBACK_ON
------------------
YES

SYS@TESTER1 SQL> alter database convert to physical standby;

Database altered.

SYS@TESTER1 SQL> select database_role from v$database;
select database_role from v$database
*
ERROR at line 1:
ORA-01507: database not mounted

SYS@TESTER1 SQL> select status from v$instance;

STATUS
------------
STARTED

SYS@TESTER1 SQL> shut immediate
SYS@TESTER1 SQL> startup

SYS@TESTER1 SQL>alter database recover managed standby database using current logfile disconnect;

SYS@TESTER1 SQL> select open_mode from v$database;

OPEN_MODE
--------------------
READ ONLY

SYS@TESTER1 SQL> select database_role from v$database;

DATABASE_ROLE
----------------
PHYSICAL STANDBY

--Let’s check whether DML changes we did previously has been reverted or not.
SYS@TSTER1 SQL> desc mahendra

Name Null? Type
----------------------------------------- -------- ----------------------------
A VARCHAR2(10)

SYS@TESTER1 SQL> select *from mahendra;

no rows selected

<end node> 5P9i0s8y19Z
dt=Text
<node>
DG errors howto
3
-- Error: ORA-16810: multiple errors or warnings detected for the database - Fix
Monitoring a Data Guard Configuration:

-- The scenario in this section demonstrates how to use the SHOW command and monitorable database 
-- properties to identify and resolve a failure situation.

-- Step 1   Check the configuration status.
-- The status of the broker configuration is an aggregated status of all databases and instances 
-- in the broker configuration. You can check the configuration status first to determine whether 
-- or not any further action needs to be taken. If the configuration status is SUCCESS, everything in 
-- the broker configuration is working fine. However, if you see the following error, it means something is 
-- wrong in the configuration:

DGMGRL> SHOW CONFIGURATION;
Configuration
 Name:                DRSolution
 Enabled:             NO
 Protection Mode:     MaxPerformance
 Fast-Start Failover: DISABLED
 Databases:
    SALESPRD    - Primary database
    SALESDR     - Physical standby database

Current status for "DRSolution":
Warning: ORA-16607: one or more databases have failed

-- In this case, you need to continue on to Step 2 to determine the actual failure.

-- Step 2   Check the database status.
-- To identify which database has the failure, you need to go through all of the databases in the 
-- configuration one by one. In this example, the error happens to be on the primary database SALESPRD:

DGMGRL> SHOW DATABASE 'SALESPRD';

The command returns the following output:
Database
  Name:            SALESPRD
  Role:            PRIMARY
  Enabled:         YES
  Intended State:  TRANSPORT-ON
  Instance(s):
    sales1

Current status for "SALESPRD":
Error: ORA-16810: multiple errors or warnings detected for the database

-- Step 3   Check the StatusReport monitorable database property.
-- When you see message ORA-16810, you can use the StatusReport monitorable database property to identify each 
-- of the errors or warnings:

DGMGRL> SHOW DATABASE 'SALESPRD' 'StatusReport';
STATUS REPORT
       INSTANCE_NAME   SEVERITY ERROR_TEXT
              sales1      ERROR ORA-16737: the redo transport service for
standby " SALESDR" has an error
             sales1    WARNING ORA-16714: the value of property
LogArchiveTrace is inconsistent with the database setting
             sales1    WARNING ORA-16715: redo transport-related property
ReopenSecs of standby database " SALESDR" is inconsistent

-- Step 4   Check the LogXptStatus monitorable database property.
-- You see error ORA-16737 in the previous status report in Step 3. To identify the exact log transport 
-- error, you can use LogXptStatus monitorable database property:

DGMGRL> SHOW DATABASE 'SALESPRD' 'LogXptStatus';
LOG TRANSPORT STATUS
PRIMARY_INSTANCE_NAME STANDBY_DATABASE_NAME               STATUS
              sales1              SALESDR ORA-12541: TNS:no listener

-- Now you know the exact reason why redo transport services failed. To fix this error, start the 
-- listener for the physical standby database  SALESDR.

-- Step 5   Check the InconsistentProperties monitorable database property.
-- You also see warning ORA-16714 reported in Step 3. To identify the inconsistent values for property 
-- LogArchiveTrace, you can use the InconsistentProperties monitorable database property:

DGMGRL> SHOW DATABASE 'SALESPRD' 'InconsistentProperties';

INCONSISTENT PROPERTIES
   INSTANCE_NAME   PROPERTY_NAME    MEMORY_VALUE    SPFILE_VALUE    BROKER_VALUE
          sales1   LogArchiveTrace           255            0            0

-- It seems that the current database memory value (255) is different from both the server 
-- parameter file (SPFILE) value (0) and Data Guard broker's property value (0). If you decide 
-- the database memory value is correct, you can update Data Guard broker's property value using the following command:

DGMGRL> EDIT DATABASE 'SALESPRD' SET PROPERTY 'LogArchiveTrace'=255;
Property "LogArchiveTrace" updated

-- In the previous command, Data Guard broker also updates the spfile value for you so that 
-- value for LogArchiveTrace is kept consistent.

-- Step 6   Check the InconsistentLogXptProps monitorable database property.
-- Another warning you see in the status report returned in Step 3 is ORA-16715. To identify the 
-- inconsistent values for the redo transport configurable database property, ReopenSecs, you can use the 
-- InconsistentLogXptProps monitorable database property.

DGMGRL> SHOW DATABASE 'SALESPRD' 'InconsistentLogXptProps';

INCONSISTENT LOG TRANSPORT PROPERTIES
   INSTANCE_NAME    STANDBY_NAME   PROPERTY_NAME    MEMORY_VALUE    BROKER_VALUE
          sales1         SALESDR      ReopenSecs             600             300

-- The current database memory value (600) is different from the Data Guard broker's property value (300). 
-- If you think the broker's property value is correct, you can fix the inconsistency by re-editing the property 
-- of the standby database with the same value, as shown in the following example:

DGMGRL> EDIT DATABASE 'SALESDR' SET PROPERTY 'ReopenSecs'=300;
Property "ReopenSecs" updated

-- You can also reenable the standby database or reset the primary database state to TRANSPORT-ON to fix the 
-- inconsistency, but re-editing the property is the simplest.

<end node> 5P9i0s8y19Z
dt=Text
<node>
DG Cmd2
3
$ dgmgrl [-silent | -echo] [username/password[@connect_identifier] [dgmgrl_command]]
$ dgmgrl  /
$ dgmgrl sys/pwd
$ dgmgrl sys/pwd@oltp
$ dgmgrl sys/test@dgprimary "show database 'prod'"
$ dgmgrl -logfile observer.log / "stop observer"
$ dgmgrl -silent sys/test@dgprimary "show configuration verbose"
$ dgmgrl  / "show configuration verbose"

-- ADD - Adds a standby database to the broker configuration.
-- DGMGRL> ADD DATABASE db_name [AS CONNECT IDENTIFIER IS conn_identifier] [MAINTAINED AS {PHYSICAL|LOGICAL}];
DGMGRL> ADD DATABASE 'testdb' AS CONNECT IDENTIFIER IS testdb MAINTAINED AS PHYSICAL;
DGMGRL> ADD DATABASE 'logdb' AS CONNECT IDENTIFIER IS logdb MAINTAINED AS LOGICAL;
DGMGRL> ADD DATABASE 'devdb' AS CONNECT IDENTIFIER IS devdb.foo.com;

-- CONNECT - Connects to an Oracle database instance.
-- DGMGRL> CONNECT username/password[@connect_identifier]
DGMGRL> CONNECT /
DGMGRL> CONNECT sys;
DGMGRL> CONNECT sys@test;
DGMGRL> CONNECT sys/pwd;
DGMGRL> CONNECT sys/pwd@dwh;
DGMGRL> CONNECT /@dwh;
$dgmgrl connect sys

-- CONVERT - Converts a database from one type to another (from Oracle 11g).
-- DGMGRL> CONVERT DATABASE database_name TO {SNAPSHOT STANDBY|PHYSICAL STANDBY};
DGMGRL> CONVERT DATABASE 'devdb' to SNAPSHOT STANDBY;
DGMGRL> CONVERT DATABASE 'devdb' to PHYSICAL STANDBY;

-- CREATE - Creates a broker configuration.
-- DGMGRL> CREATE CONFIGURATION config_name AS PRIMARY DATABASE IS db_name CONNECT IDENTIFIER IS conn_ident;
DGMGRL> CREATE CONFIGURATION 'dg' AS PRIMARY DATABASE IS 'prod' CONNECT IDENTIFIER IS prod.foo.com;
DGMGRL> CREATE CONFIGURATION 'dg_test' AS PRIMARY DATABASE IS 'test' CONNECT IDENTIFIER IS test;

-- DISABLE - Disables a configuration, a database, or fast-start failover (FSFO).
DGMGRL> DISABLE CONFIGURATION;
DGMGRL> DISABLE CONFIGURATION;

-- DGMGRL> DISABLE DATABASE database_name;
DGMGRL> DISABLE DATABASE 'devdb';

-- DGMGRL> DISABLE FAST_START FAILOVER [FORCE | CONDITION condition];
DGMGRL> DISABLE FAST_START FAILOVER;
DGMGRL> DISABLE FAST_START FAILOVER FORCE;
DGMGRL> DISABLE FAST_START FAILOVER CONDITION '1578';

-- EDIT - Edits a configuration, database, or instance.
-- DGMGRL> EDIT CONFIGURATION SET PROTECTION MODE AS {MaxProtection|MaxAvailability|MaxPerformance};
DGMGRL> EDIT CONFIGURATION SET PROTECTION MODE AS MAXPROTECTION;
DGMGRL> EDIT CONFIGURATION SET PROTECTION MODE AS MAXAVAILABILITY;
DGMGRL> EDIT CONFIGURATION SET PROTECTION MODE AS MAXPERFORMANCE;

-- DGMGRL> EDIT CONFIGURATION SET PROPERTY property_name = value;
DGMGRL> EDIT CONFIGURATION SET PROPERTY FastStartFailoverThreshold = 45;
DGMGRL> EDIT CONFIGURATION SET PROPERTY FastStartFailoverAutoReinstate = FALSE;
DGMGRL> EDIT CONFIGURATION SET PROPERTY FastStartFailoverAutoReinstate = TRUE;
DGMGRL> EDIT CONFIGURATION SET PROPERTY BYSTANDERSFOLLOWROLECHANGE= 'NONE';

-- DGMGRL> EDIT DATABASE database_name SET PROPERTY property_name = value;
DGMGRL> EDIT DATABASE devdb SET PROPERTY 'LogArchiveFormat'='log_%t_%s_%r_%d.arc';
DGMGRL> EDIT DATABASE prodb SET PROPERTY LogXptMode=SYNC;
DGMGRL> EDIT DATABASE prodb SET PROPERTY LogXptMode=ASYNC;
DGMGRL> EDIT DATABASE prodb SET PROPERTY LogXptMode=ARCH;
DGMGRL> EDIT DATABASE devdb SET PROPERTY LogShipping=OFF;
DGMGRL> EDIT DATABASE devdb SET PROPERTY LogShipping=ON;
DGMGRL> EDIT DATABASE prodb SET PROPERTY LogArchiveTrace=8;
DGMGRL> EDIT DATABASE prodb SET PROPERTY NetTimeout=60;
DGMGRL> EDIT DATABASE devdb SET PROPERTY 'ReopenSecs'=300;
DGMGRL> EDIT DATABASE prodb SET PROPERTY ArchiveLagTarget=1200;
DGMGRL> EDIT DATABASE prodb SET PROPERTY FastStartFailoverTarget='standby_name';
DGMGRL> EDIT DATABASE devdb SET PROPERTY 'StandbyArchiveLocation'='/oradata/archive/';
DGMGRL> EDIT DATABASE devdb SET PROPERTY 'DbFileNameConvert' = '/u01/od01/datafile/, /oradisk/od01/datafile/';
DGMGRL> EDIT DATABASE testdb SET PROPERTY DelayMins='720';
DGMGRL> EDIT DATABASE prodb SET PROPERTY RedoCompression ='ENABLE'
DGMGRL> EDIT DATABASE prodb SET PROPERTY RedoCompression ='DISABLE'
DGMGRL> EDIT DATABASE testdb SET PROPERTY LogArchiveMinSucceedDest =1

-- DGMGRL> EDIT DATABASE database_name RENAME TO new database_name;
DGMGRL> EDIT DATABASE 'devdbb' RENAME TO 'devdb';

-- DGMGRL> EDIT DATABASE database_name SET STATE = state [WITH APPLY INSTANCE = instance_name];
DGMGRL> EDIT DATABASE devdb SET STATE='READ-ONLY';
DGMGRL> EDIT DATABASE devdb SET STATE='OFFLINE';
DGMGRL> EDIT DATABASE devdb SET STATE='APPLY-OFF';
DGMGRL> EDIT DATABASE devdb SET STATE='APPLY-ON';
DGMGRL> EDIT DATABASE devdb SET STATE='TRANSPORT-OFF';
DGMGRL> EDIT DATABASE devdb SET STATE='TRANSPORT-ON';
DGMGRL> EDIT DATABASE prodb SET STATE='LOG-TRANSPORT-OFF';
DGMGRL> EDIT DATABASE devdb SET STATE='ONLINE' WITH APPLY INSTANCE=devdb2;

-- DGMGRL> EDIT INSTANCE instance_name [ON DATABASE database_name] SET AUTO PFILE [={init_file_path|OFF}];
DGMGRL> EDIT INSTANCE 'devdb1' ON DATABASE 'devdb' SET AUTO PFILE='initdevdb1.ora';

-- DGMGRL> EDIT INSTANCE instance_name [ON DATABASE database_name] SET PROPERTY property_name = value;
DGMGRL> EDIT INSTANCE * ON DATABASE database_name SET PROPERTY property_name = value;
DGMGRL> EDIT INSTANCE 'proddb' ON DATABASE 'proddb' SET PROPERTY 'StandbyArchiveLocation'='/oradata/arch/';

-- ENABLE - Enables a configuration, a database, or fast-start failover (FSFO).
DGMGRL> ENABLE CONFIGURATION;
DGMGRL> ENABLE CONFIGURATION;

-- DGMGRL> ENABLE DATABASE database_name;
DGMGRL> ENABLE DATABASE 'devdb';

-- DGMGRL> ENABLE FAST_START FAILOVER [CONDITION condition];
DGMGRL> ENABLE FAST_START FAILOVER;
DGMGRL> ENABLE FAST_START FAILOVER CONDITION '1578';
DGMGRL> ENABLE FAST_START FAILOVER CONDITION "Stuck Archiver";
DGMGRL> ENABLE FAST_START FAILOVER CONDITION 'Corrupted Controlfile';
DGMGRL> ENABLE FAST_START FAILOVER CONDITION 'Corrupted Dictionary';
DGMGRL> ENABLE FAST_START FAILOVER CONDITION 'Inaccessible Logfile';

-- EXIT - Exits the program.
DGMGRL> EXIT;

-- FAILOVER - Changes a standby database to be the primary database.
-- DGMGRL> FAILOVER TO standby_database_name [IMMEDIATE]
DGMGRL> FAILOVER TO "testdb";
DGMGRL> FAILOVER TO "snapdb" IMMEDIATE;

-- HELP - Displays description and syntax for a command.
-- DGMGRL> HELP [command];
DGMGRL> HELP REINSTATE
DGMGRL> HELP EDIT

-- QUIT - Exits the program.
DGMGRL> QUIT;

-- REINSTATE - Changes a database marked for reinstatement into a viable standby.
DGMGRL> REINSTATE DATABASE database_name;
DGMGRL> REINSTATE DATABASE prim1;

-- REM - Comment to be ignored by DGMGRL.
DGMGRL> REM [comment];

-- REMOVE - Removes a configuration, Oracle database, or instance.
-- DGMGRL> REMOVE CONFIGURATION [PRESERVE DESTINATIONS];
DGMGRL> REMOVE CONFIGURATION;
DGMGRL> REMOVE CONFIGURATION PRESERVE DESTINATIONS;


-- DGMGRL> REMOVE DATABASE database_name [PRESERVE DESTINATIONS];
DGMGRL> REMOVE DATABASE devdb;
DGMGRL> REMOVE DATABASE standby PRESERVE DESTINATIONS;

-- DGMGRL> REMOVE INSTANCE instance_name [ON DATABASE database_name];
DGMGRL> REMOVE INSTANCE inst1 ON DATABASE racdb;

-- SHOW - Displays information about a configuration, database, instance or FSFO.
-- DGMGRL> SHOW CONFIGURATION [VERBOSE];
DGMGRL> SHOW CONFIGURATION;
DGMGRL> SHOW CONFIGURATION VERBOSE;


-- DGMGRL> SHOW DATABASE [VERBOSE] db_name [property_name];
DGMGRL> SHOW DATABASE 'devdb';
DGMGRL> SHOW DATABASE VERBOSE 'test';
DGMGRL> SHOW DATABASE 'dwhdb' 'StatusReport';
DGMGRL> SHOW DATABASE 'proddb' 'LogXptStatus';
DGMGRL> SHOW DATABASE 'proddb' 'InconsistentProperties';
DGMGRL> SHOW DATABASE 'proddb' 'InconsistentLogXptProps';
DGMGRL> SHOW DATABASE 'testdb' 'ArchiveLagTarget';
DGMGRL> SHOW DATABASE 'testdb' 'LogShipping';
DGMGRL> SHOW DATABASE 'testdb' 'PreferredApplyInstance';
DGMGRL> SHOW DATABASE 'proddb' 'StatusReport';
DGMGRL> SHOW DATABASE 'testdb' 'RecvQEntries';
DGMGRL> SHOW DATABASE 'proddb' 'SendQEntries';

-- DGMGRL> SHOW INSTANCE [VERBOSE] instance_name [property_name] [ON DATABASE db_name];
DGMGRL> SHOW INSTANCE inst1;
DGMGRL> SHOW INSTANCE VERBOSE inst3;
DGMGRL> SHOW INSTANCE testdb 'TopWaitEvents';

DGMGRL> SHOW FAST_START FAILOVER;
DGMGRL> SHOW FAST_START FAILOVER;

-- From 18c Oracle Database, SHOW ALL command shows the values of DGMGRL command line utility properties.
DGMGRL> SHOW ALL;
   debug ON
   echo OFF
   time OFF
   observerconfigfile = observer.ora

-- SHUTDOWN - Shuts down a currently running Oracle instance.
-- DGMGRL> SHUTDOWN [NORMAL | IMMEDIATE | ABORT];
DGMGRL> SHUTDOWN;
DGMGRL> SHUTDOWN NORMAL;
DGMGRL> SHUT IMMEDIATE;
DGMGRL> SHUT ABORT;

-- SQL - Executes a SQL statement
DGMGRL> SQL "sql_statement";

-- START - Starts the fast-start failover(FSFO) observer.
DGMGRL> START OBSERVER [FILE=observer_configuration_file];
DGMGRL> START OBSERVER;

-- STARTUP - Starts an Oracle database instance.
DGMGRL> STARTUP [RESTRICT] [FORCE] [PFILE=filespec]
-- [NOMOUNT  |  MOUNT | OPEN [READ ONLY|READ WRITE]];
DGMGRL> STARTUP;
DGMGRL> STARTUP NOMOUNT;
DGMGRL> STARTUP MOUNT;
DGMGRL> STARTUP OPEN;
DGMGRL> STARTUP FORCE;
DGMGRL> STARTUP FORCE RESTRICT NOMOUNT;
DGMGRL> STARTUP PFILE=initdwh.ora NOMOUNT;

-- STOP - Stops the fast-start failover(FSFO) observer.
DGMGRL> STOP OBSERVER;

-- SWITCHOVER - Switches roles between a primary and standby database.
-- DGMGRL> SWITCHOVER TO standby_database_name;
DGMGRL> SWITCHOVER TO "standby";


-- VALIDATE - command to checks whether the database is ready for a role transition or not.
DGMGRL> VALIDATE DATABASE ...;    -- From Oracle Database 12c


-- From Oracle Database 18c,
DGMGRL> VALIDATE DATABASE standby-database-name SPFILE;

-- DGMGRL> VALIDATE NETWORK CONFIGURATION FOR { ALL | member name };
DGMGRL> VALIDATE NETWORK CONFIGURATION FOR stdby;

-- DGMGRL> VALIDATE STATIC CONNECT IDENTIFIER FOR { ALL | database name };
DGMGRL> VALIDATE STATIC CONNECT IDENTIFIER FOR stdby;


$BDUMP/drc*.log
$ORACLE_HOME/rdbms/log/drc*.log

alter system set dg_broker_start=false;
alter system set dg_broker_start=false sid='*';
alter system set dg_broker_start=FALSE SCOPE=spfile SID='*';
alter system set dg_broker_start=true;
alter system set dg_broker_start=true sid='*';
alter system set dg_broker_start=TRUE SCOPE=spfile SID='*';

alter system set dg_broker_config_file1='/u01/dg_broker_config_files/dr1TESTP.dat' sid='*';
alter system set dg_broker_config_file2='/u01/dg_broker_config_files/dr2TESTP.dat' sid='*';

<end node> 5P9i0s8y19Z
dt=Text
<node>
OEM Commands
2

emctl commands
EMCTL:   -- Enterprise Manager Control, in Oracle


EMCTL @ normal (Oracle Management) Agent
emctl start agent
./emctl start agent
emctl stop agent
./emctl stop agent
emctl status agent
Download Pdf Article Registers Agents Alia Amphenol Connectors Ati display drivers

emctl status agent -secure [-omsurl http://oms-hostname:oms-unsecure-port/em/*]
./emctl status agent
./emctl status agent cpu -depth 10

emctl upload agent
./emctl upload agent
emctl reload agent
emctl reload agent dynamicproperties [Target_name:Target_Type]....
./emctl reload agent
./emctl reload agent dynamicproperties

emctl clearstate agent
./emctl clearstate agent
emctl config agent options_options
emctl config agent updateTZ
emctl config agent getTZ
emctl config agent credentials [Target_name[:Target_Type]]
./emctl config agent listtargets
emctl resetTZ agent
emctl relocate_target agent target_name target_type [name1=value1]* [-force]

emctl getversion
emctl getversion agent
emctl dumpstate agent component_name . . .
emctl gensudoprops
emctl clearsudoprops
emctl switchOMS repos_Url
emctl verifykey
emctl verifykey

emctl start blackout Blackout_name [-nodeLevel] [Target_name[:Target_Type]].... [-d Duration_in_days] [-nowait]
./emctl start blackout blk
./emctl start blackout blk -nodeLevel
./emctl start blackout blk -nodeLevel -d 3:00
emctl stop blackout Blackout_name [-nowait]
./emctl stop blackout blk
emctl status blackout [Target_name[:Target_Type]]....
./emctl status blackout

emctl getemhome
emctl ilint
emctl annotateconfigfiles agent [template_files_dir config_files_dir]
emctl start subagent
emctl stop subagent
emctl status subagent

emctl secure agent [registration password] [-emdWalletSrcUrl url]
emctl secure agent -emdWalletSrcUrl  https://example.com:4900/empbs/upload
emctl unsecure agent
emctl secure add_trust_cert -trust_certs_loc loc
emctl secure add_trust_cert_to_jks [-password password -trust_certs_loc loc -alias alias]

emctl start dbconsole
emctl stop dbconsole
emctl status dbconsole

emctl secure dbconsole
emctl secure status dbconsole
emctl secure dbconsole -sysman_pwd sysman_password [-passwd_file passwordfile_location] [-host hostname] [-sid service_name] [-reset]
 [-secure_port secure_port] [-root_dc root_dc] [-root_country root_country] [-root_state root_state] [-root_loc root_loc] 
 [-root_org root_org] [-root_unit root_unit] [-root_email root_email]
emctl unsecure dbconsole
emctl setpasswd dbconsole

emctl config emkey -emkeyfile emkey.ora_path [-force] [-sysman_pwd sysman_password]
emctl config emkey -emkey [-emkeyfile emkey.ora_path] [-force] [-sysman_pwd sysman_password]
emctl config emkey -repos [-emkeyfile emkey.ora_path] [-force] [-sysman_pwd sysman_password]
emctl config emkey -remove_from_repos [-sysman_pwd sysman_password]
emctl config emkey -copy_to_repos [-sysman_pwd sysman_password]
emctl status emkey [-sysman_pwd sysman_password]
emctl status emkey

emctl upgrade -cluster

EMCTL @ (Oracle Management) Agent on OMS server


emctl start | getversion oms    -- OMS -> Oracle Management Server
./emctl start oms
./emctl start oms -all

emctl stop oms [-all] [-force] 
./emctl stop oms
./emctl stop oms -all
./emctl stop oms -all -force

emctl status oms
emctl status oms -details
./emctl status oms
emctl status oms -details

emctl config oms sso -host ssoHost -port ssoPort -sid ssoSid -pass ssoPassword -das dasURL -u user
       emctl config oms loader -shared -dir [-sysman_pwd ]
       emctl config oms -list_repos_details
       emctl config oms -store_repos_details (-repos_host -repos_port -repos_sid | -repos_conndesc ) -repos_user [-repos_pwd ] [-no_check_db]
             Connect descriptor should be enclosed in quotes. eg: '""' or "''"
       emctl config oms -change_repos_pwd [-change_in_db] [-old_pwd ] [-new_pwd ] [-use_sys_pwd [-sys_pwd ]] 
           -change_in_db This option will change in repository too. If not specified, only Credential Store will be updated
       emctl config oms -change_repos_pwd
       emctl config oms -change_view_user_pwd [-sysman_pwd ] [-user_pwd ] [-auto_generate]
           -auto_generate This option will generate random password.
       emctl getmessagedetails oms -id=[EM-]#####
emctl pingOMS

Register Targettype Usage : 
emctl register oms targettype [-o ] [ ] OR 
emctl register oms targettype [-o ] [ ] 

The provided must be the xml file name with the absolute path and not with relative path.
The will be prompted if not provided on the command line.
-o option generates the SQL file into the and does not register the target type into the repository. Hence repository details and -o option are exclusive and cannot be passed simultaneously.
should have file extension as '.sql'.
EM Key Commands Usage : 
emctl status emkey [-sysman_pwd ]
emctl config emkey -copy_to_credstore [-sysman_pwd ]
emctl config emkey -copy_to_repos [-sysman_pwd ]
emctl config emkey -remove_from_repos [-sysman_pwd ]
emctl config emkey -copy_to_file_from_credstore -admin_host -admin_port -admin_user [-admin_pwd ] [-repos_pwd ] -emkey_file
emctl config emkey -copy_to_file_from_repos (-repos_host -repos_port -repos_sid | -repos_conndesc ) -repos_user [-repos_pwd ] [-admin_pwd ] -emkey_file
emctl config emkey -copy_to_credstore_from_file -admin_host -admin_port -admin_user [-admin_pwd ] [-repos_pwd ] -emkey_file
emctl config emkey -copy_to_repos_from_file (-repos_host -repos_port -repos_sid | -repos_conndesc ) -repos_user [-repos_pwd ] [-admin_pwd ] -emkey_file

Secure OMS Usage : 
emctl secure oms [-sysman_pwd ] [-reg_pwd ]
[-host ] [-slb_port ] [-slb_console_port ]
[-reset] [-console] [-lock] [-lock_console] [-secure_port ] [-upload_http_port ]
[-root_dc ] [-root_country ] [-root_email ]
[-root_state ] [-root_loc ] [-root_org ] [-root_unit ]
[-wallet -trust_certs_loc ] [-wallet_pwd ]
[-key_strength ] [-cert_validity ] [-protocol ]
Valid values for are the allowed values for Apache's SSLProtocol directive
emctl secure oms -host oemoms
emctl secure setpwd [authpasswd] [newpasswd]
emctl secure setpwd
emctl secure setpwd pwd newpwd
emctl secure sync
emctl secure lock [-sysman_pwd ] [-console] [-upload]
emctl secure lock -console
emctl secure unlock [-sysman_pwd ] [-console] [-upload]
emctl secure unlock -console
emctl secure console -wallet [-wallet_pwd ]
emctl secure create_admin_creds_wallet [-admin_pwd ] [-nodemgr_pwd ]

Dump Usage : 
emctl dump omsthread 
emctl dump [-log] repos OR 
emctl dump [-log] repos  

EM Connector Commands Usage : 
emctl register_connector connector [-dd ] [-repos_pwd ]
-dd Connector Deployment Descriptor File(full path)
-repos_pwd Enterprise Manager Root (SYSMAN) Password

emctl register_template connector [-t
-t Template(full path)
-repos_pwd Enterprise Manager Root (SYSMAN) Password
-ctname Connector Type Name
-cname Connector Name
-iname Template Internal Name
-tname Template Name Displayed
-ttype Template Type
1 - inbound transformation
2 - outbound transformation
3 - XML outbound transformation
-d Description

emctl extract_jar connector [-jar ] [-cname ]
-jar Connector Jar File(full path)
-cname Connector Name

HAConfig Commands Usage: 

emctl exportconfig oms [-sysman_pwd ] 
      [-dir ]     Specify directory to store backup file 
      [-oms_only]             Specify OMS-only backup on Admin Server host 
      [-keep_host]            Specify to backup hostname if no slb defined 
                              (Use this option only if recovery will be done on machine that responds to this hostname)
emctl exportconfig oms -dir  
emctl importconfig oms [-sysman_pwd ] [-reg_pwd ] 
      -file     Required backup file to import from 
      [-no_resecure]          Specify not to resecure oms after import (default is to resecure after import) 
emctl config emrep [-sysman_pwd ] 
      [-agent ]    Specify new destination agent for emrep target 
      [-conn_desc []] 
                              Update Connect Descriptor with value if specified, else from value stored in emoms.properties 
emctl config repos [-sysman_pwd ] 
      [-agent ]    Specify new destination agent for repository target 
      [-host ]      Specify new hostname for repository target 
      [-oh ] Specify new OracleHome for repository target 
      [-conn_desc []] 
                              Update Connect Descriptor with value if specified, else from value stored in emoms.properties 
emctl enroll oms [-as_host ] Specify admin server to enroll the oms 
                 [-as_port ] Specify admin server secure port 
                 [-as_pwd ] Specify admin server password 
                 [-nm_pwd ] Specify nodemanager password 

Following Commands Valid on NT Only: 
emctl create service [-user ] [-pwd ] -name     Name of service to be created 
emctl delete service -name     Name of service to be deleted 

Emctl Resync Commands Usage:
       emctl resync repos (-full|-agentlist "agent names") [-name "resync name"] [-sysman_pwd "sysman password"]
       emctl abortresync repos (-full|-agentlist "agent names") -name "resync name" [-sysman_pwd "sysman password"]
       emctl statusresync repos -name "resync name"

Emctl Configuration management Commands Usage:
       emctl get property [-sysman_pwd "sysman password"] -name
emctl get property -name oracle.sysman.core.notification.short_format_length
emctl get property -name admin_groups_height_limit
       emctl set property [-sysman_pwd "sysman password"] -name -value [-module (default emoms)]
       emctl set property [-sysman_pwd "sysman password"] -file [-module (default emoms)]
./emctl set property -name "em.security.auth.autoprovisioning" -value "true"
emctl set property -name oracle.sysman.core.notification.os_cmd_timeout value 30
emctl set property -name oracle.sysman.core.notification.short_format -value both
       emctl delete property [-sysman_pwd "sysman password"] -name
       emctl list properties [-sysman_pwd "sysman password"] [-module ]

Partool Commands Usage : 

       emctl partool -parFile -force(optional)
       emctl partool -parFile -force(optional) -ssPasswd
       emctl partool -parDir



-force(optional)
       emctl partool export -guid -file -displayName -description -metadataOnly(optional)
       emctl partool check
       emctl partool help

  -repPasswd           Repository Password
  -force                           force the swlib entities to be created/reuploaded, if already present creates a new revision
  -check                           check if Software Library is configured
  -file                     PAR file
  -verbose                         verbose mode
  -help                            display this help message
  -displayName       PAR file name
  -parDir 


                    Directory where par files are located
  -metadataOnly                    flag for metadata-only exports
  -guid                     Procedure GUID to export. To export multiple procedures provide the GUIDs separated by "," 
  -parFile                   path of par file
  -description       PAR file description
  -ssPasswd   is optional. An Oracle Wallet is created with specified password to store the value of the secret property in the exported software library entity. User must use the same password while importing the PAR file in a new repository.

./emctl control agent runCollection :oracle_exadata_hc ExadataResults

emctl listplugins agent -type all

<end node> 5P9i0s8y19Z
dt=Text
<node>
OEM Config & Checks
3
Database BLACKOUT
OEM BLACKOUT
------------
 
OEM -> 
Targets -> 
enter the target dbhost name -> 
select blackout ->
enter blackout name -> 
select the reason -> 
select add(if required to add more) -> 
select all -> 
next -> 
select immediatetime from & select end time -> 
next

 To know the particular database is configured with OEM or not:
-------------------------------------------------------------
echo $AGENT_HOME
/u01/app/oracle/product/agent10g/

cd $AGENT_HOME/bin
./emctl config agent listtargets


To check the status of all the blackouts on a host:
--------------------------------------------------
./emctl status blackout


To set a blackout for all targets/databases on a host:
-----------------------------------------------------
emctl start blackout <Blackoutname> [-nodeLevel] [-d <Duration>]

"-nodeLevel" tells the agent to stop monitoring all targets on the server.
"-d Duration" allows you to set a duration in the format of [days] hh:mm. 

cd $AGENT_HOME/bin
./emctl start blackout alltargets_onserver –nodeLevel----->Blackout entire host indefinitely
<Perform Maintenance Tasks>

To stop blackout "alltargets_onserver" immediately:
--------------------------------------------------
cd $AGENT_HOME/bin
./emctl stop blackout alltargets_onserver


To set a blackout for a database on a host:
------------------------------------------
emctl start blackout <Blackoutname> [<Target_name>:<Target_Type>]…. [-d <Duration>]

"-nodeLevel" tells the agent to stop monitoring all targets on the server.
"-d Duration" allows you to set a duration in the format of [days] hh:mm. 

cd $AGENT_HOME/bin
./emctl start blackout Blackoutname database1 -d 6:00
<Perform Maintenance Tasks>

To stop blackout "Blackoutname" immediately:
-------------------------------------------
./emctl stop blackout Blackoutname

To get the help menu for emctl
------------------------------
emctl blackout


Examples:
--------
To start an immediate indefinite blackout called "Blackoutname" for all targets on the host:
./emctl start blackout Blackoutname -nodeLevel

To start an immediate blackout called "Blackoutname" for all targets on the host  for 6 hours: 
./emctl start blackout Blackoutname -nodeLevel -d 06:00

To start an immediate blackout called "Blackoutname" for database "database1" for 30 minutes:
./emctl start blackout Blackoutname database1 -d 30

To start an immediate blackout called "Blackoutname" for database "database2" for 6 hours:
./emctl start blackout Blackoutname database2 -d 6:00

To start an immediate blackout called "Blackoutname" for databases "database1","database2" and listener "listener1" which will last for 5 days 3 hours and 30 minutes. 
./emctl start blackout Blackoutname database1 database2 listener1:oracle_listener -d 5 03:30

<end node> 5P9i0s8y19Z
dt=Text
<node>
Montly Growth DB
3
SELECT Database,
	Month_Date,
	round(sum(decode(metric_column, 'spaceUsed', maximum))/1024, 3) Used_Size_GB,
	round(sum(decode(metric_column, 'spaceAllocated', maximum))/1024, 3) Allocated_Size_GB
FROM
(
	SELECT target_name Database, trunc(rollup_timestamp, 'MONTH') Month_Date,  metric_column, round(max(maximum),0) maximum
	FROM mgmt$metric_daily
WHERE 
	target_type in( 'oracle_database','rac_database')
	and metric_name = 'tbspAllocation'
	and metric_column in ('spaceAllocated', 'spaceUsed')
	and target_name in ('Your Target Name')
	GROUP BY target_name, key_value, trunc(rollup_timestamp, 'MONTH'), metric_column
)
GROUP BY Database, Month_Date
ORDER BY Database, Month_Date

<end node> 5P9i0s8y19Z
dt=Text
<node>
group run
3
emcli login -username=sysman
emcli execute_sql -sql="select count(*) from dba_users" -targets="sandbox_databases:group" 


emcli logout -username=sysman -password=Tsys123$
 emcli login -username=sysman -password=Tsys123
 
 
 -- Incase you have forgotten the sysman password
 
 1. Login to Cloud Control 12c database
 
 SQL> alter user sysman identified by abc123;
 
 2. Stop OMS
 
 $OMS_HOME/bin/emctl stop oms
 
 -- (DO not use -all postfix)
 
 3. Change password in Repository
 
$OMS_HOME/bin/emctl config oms -change_repos_pwd -use_sys_pwd -sys_pwd sys123 -new_pwd abc123
 
changing passwords in backend … 
Passwords changed in backend successfully.
Updating repository password in Credential Store…
Successfully updated Repository password in Credential Store.
Restart all the OMSs using ’emctl stop oms -all’ and ’emctl start oms’.
Successfully changed repository password.
 
 4. Stop and Start OMS completely
 
$OMS_HOME/bin/emctl stop oms -all
 
$OMS_HOME/bin/emctl start oms
 
emctl status oms -details
 
emcli sync

-- 

/opt/app/oracle/Agent/agent_inst/bin/./emctl stop agent 
/opt/app/oracle/Middleware/oms/bin/./emctl stop oms -all 

./emctl config oms -change_repos_pwd -use_sys_pwd -sys_pwd Tsys123 -new_pwd Tsys123

/opt/app/oracle/Middleware/oms/bin/./emctl start oms
/opt/app/oracle/Agent/agent_inst/bin/./emctl start agent 


#!/bin/bash

# User specific environment and startup programs
. ~/.bash_profile

#ecking the /data disk partition space where archive files are getting created
VAL=`df -h | grep "/ora4" | awk '{print $5}'|sed 's/%//g'`

if [ "$VAL" -gt "65" ]
then
    echo "Disk value $VAL"
    echo "Disk space above 60%"

    cd /ora4/oracle/aqprod/archive

    find *.dbf -type f -mtime +1 -exec ls -l {} \; > temp_file.sh

    for fn in `cat temp_file.sh |awk '{print $9}'`
     do
       echo "$fn"
       # deleting non tar files
       rm -f $fn
    done

    rm -f temp_file.sh
else
    echo "$VAL"
    echo "Disk space is below 60%"
fi

<end node> 5P9i0s8y19Z
dt=Text
<node>
EM Express Manager
3
-- Oracle Enterprise Manager Express enables you to perform administrative 
-- tasks such as managing user security and managing database memory and 
-- storage. You can also view performance and status information about your database.

SQL>select dbms_xdb_config.gethttpsport() from dual;

DBMS_XDB_CONFIG.GETHTTPSPORT()
------------------------------
                          5501
-- If the 5501 port is not present and it's like 0 then execute to get 5501 port
-- and check again using above sql query gethttpsport
--SQL>exec DBMS_XDB_CONFIG.SETHTTPSPORT(5501);

SQL> select dbms_xdb_config.gethttpport() from dual;

DBMS_XDB_CONFIG.GETHTTPPORT()
-----------------------------

SQL> exec dbms_xdb_config.sethttpport(5511);                          0
or
SQL> exec dbms_xdb_config.sethttpsport(7803);

PL/SQL procedure successfully completed.

SQL>  select dbms_xdb_config.gethttpport() from dual;

DBMS_XDB_CONFIG.GETHTTPPORT()
-----------------------------
                         5511

SQL> !hostname
mrlndrtdbadm01.cna.com

http://mrlnprddbadm02.cna.com
http://mrlndrtdbadm01.cna.com:5501/em

http://mrlnprddbadm01.cna.com:/em

-- To grant users read-only access so that they can view the UI but not make any changes, grant them the EM_EXPRESS_BASIC role as follows:
-- EM_EXPRESS_BASIC and the EM_EXPRESS_ALL
SQL> grant EM_EXPRESS_BASIC to <user>;


---- For Oracle 11g
SQL> select dbms_xdb.getHttpPort() from dual;

GETHTTPPORT
-----------
       8080

SQL> select dbms_xdb_config.getHttpsPort() from dual;

GETHTTPSPORT
------------
        5500

--------------------------------------------------------------------------------------------------------------------
-- Configuring the HTTPS Port for EM Express

Configure and start the Oracle Net Listener (the listener). You can use lsnrctl to start, stop, and view the status of the listener.
If the listener is running on a nonstandard port (for example, not 1521), then the init.ora file for the database you want to manage using EM Express 
must contain a local_listener entry so that the HTTPS port can register with the correct listener. The local_listener entry references a TNSNAMES entry
that points to the correct listener. For example:

local_listener=inst1

where inst1 is a TNSNAMES entry defined in tnsnames.ora that points to the listener. For example:

inst1= (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=host_name)(PORT=1234))
(CONNECT_DATA=(SERVICE_NAME=service_name)(SERVER=DEDICATED)))

In this example, 1234 is the nonstandard port on which the listener has been configured to listen.

Enable the TCP dispatcher by adding the following entry to the init.ora file for the database you want to manage using EM Express:
dispatchers="(PROTOCOL=TCP)(SERVICE=<sid>XDB)"

For example, if the database SID is ORCL, then the entry would be:

dispatchers="(PROTOCOL=TCP)(SERVICE=ORCLXDB)"

Restart the database so that the changes made in the init.ora file take effect.
Use the PL/SQL procedure DBMS_XDB_CONFIG.SETHTTPSPORT to set the HTTPS port for EM Express for the database to a port that is not 
in use. This will update the HTTPS port in the xdbconfig.xml file in the Oracle XML DB Repository. 
You must connect as SYS / AS SYSDBA to run the procedure.

For example, to set the HTTPS port for EM Express for a non-CDB:

SQL> exec DBMS_XDB_CONFIG.SETHTTPSPORT(5500);

To set the HTTPS port for EM Express for a multitenant container database (CDB), go to the root in the CDB and then use the PL/SQL procedure 
DBMS_XDB_CONFIG.SETHTTPSPORT in the CDB to set the HTTPS port for EM Express for the CDB to a port that is not in use. This will update the 
HTTPS port in the xdbconfig.xml file in the Oracle XML DB Repository. You must connect as SYS / AS SYSDBA to run the procedure. For example:

SQL> alter session set container=CDB$ROOT;
SQL> exec DBMS_XDB_CONFIG.SETHTTPSPORT(5501);

To set the HTTPS port for EM Express for a PDB, ensure that the PDB is open in read/write mode, and then use the PL/SQL procedure 
DBMS_XDB_CONFIG.SETHTTPSPORT in the PDB to set the HTTPS port for EM Express for the PDB to a port that is not in use. This will 
update the HTTPS port in the xdbconfig.xml file in the Oracle XML DB Repository. You must connect as SYS / AS SYSDBA to 
run the procedure. For example:

SQL> alter session set container=PDB1;
SQL> exec DBMS_XDB_CONFIG.SETHTTPSPORT(5502);

Use the following command to confirm that the port has registered with the listener:

$ lsnrctl status | grep -i 5502
(DESCRIPTION=(ADDRESS=(PROTOCOL=tcps)(HOST=hostname.example.com)(PORT=5502)
)(Security=(my_wallet_directory=/$ORACLE_BASE/admin/sid/xdb_wallet))
(Presentation=HTTP)(Session=RAW))

To access EM Express for a non-CDB, CDB, or PDB, enter a URL in the following format in a Web browser, specifying the EM Express port number 
for the non-CDB, CDB, or PDB you want to manage:

https://database-hostname:portnumber/em/

For example:

https://mydbhost.example.com:5500/em/

When prompted for your username and password, log in as a user with DBA privilege (such as SYS or SYSTEM).
--------------------------------------------------------------------------------------------------------------------





-- merwhr
https://10.28.39.120:5501/em/

<end node> 5P9i0s8y19Z
dt=Text
<node>
RAC Info
2

-- to enable/disable the mgmtdb
srvctl enable mgmtdb -node mrlndrtdbadm04

-- for relocating
srvctl relocate mgmtdb -n mrlndrtdbadm04

<end node> 5P9i0s8y19Z
dt=Text
<node>
ASM Disks
3
volinfo --all
volenable --all
voldisable --all

select free_mb/1024 FREE_GB,total_mb/1024 TOTAL_GB,name from v$asm_diskgroup;

--- ASM disk group size
set linesize 1000
break on report on disk_group_name skip 1
compute sum label "Grand Total: " of total_MB used_MB on report
SELECT
  name                                GROUP_NAME
, round ( total_mb)                   TOTAL_MB
, round ( (total_mb - free_mb) )      USED_MB
, round ( free_mb)                    FREE_MB
, ROUND((1- (free_mb / total_mb))*100,2  )  USED
, (100 - ROUND((1- (free_mb / total_mb))*100,2))  FREE
FROM v$asm_diskgroup
ORDER BY name
;

-- check the disk group
col dg_name heading "DG|Name" for a15
col dg_state heading "DG|State"
col dsk_no heading "DSK_No"
col MOUNT_STATUS heading "Mount|Status"
col HEADER_STATUS heading "Header|Status"
col MODE_STATUS heading "Mode|Status"
col path for a40 
select dg.name dg_name,  dg.state dg_state,  dg.type, 
	d.DISK_NUMBER dsk_no, d.MOUNT_STATUS, d.HEADER_STATUS, d.MODE_STATUS,
	d.STATE, d. PATH, d.FAILGROUP  
FROM V$ASM_DISK d,  v$asm_diskgroup dg
where dg.group_number(+)=d.group_number 
  and dg.name='DATA'
order by FAILGROUP asc;


col dg_name heading "DG|Name" for a15
col dg_state heading "DG|State"
col dsk_no heading "DSK_No"
col MOUNT_STATUS heading "Mount|Status"
col HEADER_STATUS heading "Header|Status"
col MODE_STATUS heading "Mode|Status"
col path for a40 
select dg.name dg_name,  dg.state dg_state,  dg.type, 
	d.DISK_NUMBER dsk_no, d.MOUNT_STATUS, d.HEADER_STATUS, d.MODE_STATUS,
	d.STATE, d. PATH, d.FAILGROUP  
FROM V$ASM_DISK d,  v$asm_diskgroup dg
where dg.group_number(+)=d.group_number 
  and d.MOUNT_STATUS='CLOSED'
  and d.HEADER_STATUS='FORMER'
order by FAILGROUP asc;



sqlplus "/as sysdba"

select name, header_status, path 
  from v$asm_disk 
 where regexp_like(name,'DATA','i') 
 order by 1;	


-- view diskgroup client. like which disk are assign to which DB
SELECT dg.name AS diskgroup, SUBSTR(c.instance_name,1,12) AS instance,
     SUBSTR(c.db_name,1,12) AS dbname, SUBSTR(c.SOFTWARE_VERSION,1,12) AS software,
     SUBSTR(c.COMPATIBLE_VERSION,1,12) AS compatible 
  FROM V$ASM_DISKGROUP dg, V$ASM_CLIENT c  
 WHERE dg.group_number = c.group_number; 


----------------------------------------------------
-- SQL Query to show asm disk utilization in mbs for all DBs and their assigned disks
col gname for a10
col dbname for a15
col FILE_TYPE for a30
SELECT
    gname,
    dbname,
    file_type,
    round(SUM(space) / 1024 / 1024) mb,
    round(SUM(space) / 1024 / 1024 / 1024) gb,
    COUNT(*) "#FILES"
FROM
    (
        SELECT
            gname,
            regexp_substr(full_alias_path, '[[:alnum:]_]*', 1, 4) dbname,
            file_type,
            space
        FROM
            (
                SELECT
                    concat('+' || gname, sys_connect_by_path(aname, '/')) full_alias_path,
                    system_created,
                    file_type,
                    space,
                    gname
                FROM
                    (
                        SELECT
                            b.name               gname,
                            a.parent_index       pindex,
                            a.name               aname,
                            a.reference_index    rindex,
                            a.system_created,
                            c.type               file_type,
                            c.space
                        FROM
                            v$asm_alias      a,
                            v$asm_diskgroup  b,
                            v$asm_file       c
                        WHERE a.group_number = b.group_number
                            AND a.group_number = c.group_number (+)
                            AND a.file_number = c.file_number (+)
                            AND a.file_incarnation = c.incarnation (+)
                    )
                START WITH ( mod(pindex, power(2, 24)) ) = 0
                  AND rindex IN (
                    SELECT a.reference_index
                    FROM v$asm_alias a, v$asm_diskgroup  b
                    WHERE a.group_number = b.group_number
                        AND mod(a.parent_index, power(2, 24)) = 0
                ) CONNECT BY
                    PRIOR rindex = pindex
            )
        WHERE NOT file_type IS NULL
          AND system_created = 'Y'
    )
where gname in ('FRA1')
-- and file_type='DATAFILE'
GROUP BY gname, dbname, file_type
ORDER BY gname,dbname,file_type;

----------------------------------------------------

--- add asm diskgroup disk
-- login by asm admin
sqlplus / as sysasm

-- add one by one disk by giving their path
alter diskgroup data
 add disk
	'/dev/asm-data-disk7' name DATA_0006,
	'/dev/asm-data-disk8' name DATA_0007;

alter diskgroup data 
 add disk 
	'/dev/oracleasm/disks/EMCPOWERHE' name data_0139,
	'/dev/oracleasm/disks/EMCPOWERHF' name data_0140,
	'/dev/oracleasm/disks/EMCPOWERHG' name data_0141,
	'/dev/oracleasm/disks/EMCPOWERHM' name data_0142,
	'/dev/oracleasm/disks/EMCPOWERHQ' name data_0143,
	'/dev/oracleasm/disks/EMCPOWERHO' name data_0144,
	'/dev/oracleasm/disks/EMCPOWERHL' name data_0145,
	'/dev/oracleasm/disks/EMCPOWERHN' name data_0146,
	'/dev/oracleasm/disks/EMCPOWERHP' name data_0147;

alter diskgroup data
 add disk
   '/dev/rhdiskpower8' name DATA_0041,
   '/dev/rhdiskpower9' name DATA_0042;

alter diskgroup data
 add disk
'/dev/oracleasm/disks/MPATHCH' name data_0026,
'/dev/oracleasm/disks/MPATHBP' name data_0027,
'/dev/oracleasm/disks/MPATHCD' name data_0028,
'/dev/oracleasm/disks/MPATHAP' name data_0029,
'/dev/oracleasm/disks/MPATHCJ' name data_0030,
'/dev/oracleasm/disks/MPATHCK' name data_0031,
'/dev/oracleasm/disks/MPATHCG' name data_0032,
'/dev/oracleasm/disks/MPATHCI' name data_0033,
'/dev/oracleasm/disks/MPATHCC' name data_0034,
'/dev/oracleasm/disks/MPATHCF' name data_0035,
'/dev/oracleasm/disks/MPATHCE' name data_0036

alter diskgroup PSJPCP_DATA add disk '/dev/rhdiskpower30' name PSJPCP_DATA_0080;

alter diskgroup data add disk '/dev/asm-data-disk8' name DATA_0007;

alter diskgroup D1_T1_A4 add disk 'ORCL:D1_T1_A4_0019' name D1_T1_A4_0019;

alter diskgroup data add disk '/dev/rhdiskpower5' name DATA_0069;

D1_T1_A4_0019

# This gives you latest logs in the end of the listing:
ASMCMD> ls -lat --reverse

col diskgroup for a10
col diskname for a12
col path for a20
select a.name DiskGroup,b.name DiskName, b.total_mb, b.free_mb,b.path, b.header_status
from v$asm_disk b, v$asm_diskgroup a 
where a.group_number (+) =b.group_number 
order by b.group_number,b.name;

SELECT name, free_mb, total_mb, free_mb/total_mb*100 as percentage 
     FROM v$asm_diskgroup;


set lines 200
col name for a50
SELECT NAME,
	ROUND(SPACE_LIMIT / 1048576/1024) SPACE_LIMIT_GB,
	ROUND(SPACE_USED / 1048576/1024) SPACE_USED_GB,
	ROUND(((SPACE_USED / 1048576) * 100) / (SPACE_LIMIT / 1048576), 2) PRC_USED
FROM V$RECOVERY_FILE_DEST;


--- check free space
select name,total_mb/1024 total_gb,free_mb/1024 free_gb, 
    round(free_mb/total_mb*100) "FREE%" 
from v$asm_diskgroup

-----------------------------------------------------------------------------

--- to get the RAC information
gpnptool get -o-

--- to check the asm disk or discover the asm disk
./kfod status=TRUE asm_diskstring='/dev/rhdiskpower*' disks=all dscvgroup=TRUE
-----------------------------------------------------------------------------
-- in usmdmp oracleasm ASMlib is used for adding the disk

oracleasm scandisks

oracleasm listdisks

--- Log into sqlplus /as sysdba and check if any disk is newly added and candidate disk
SELECT
 NVL(a.name, '[CANDIDATE]') disk_group_name
 , b.path disk_file_path
 , b.name disk_file_name
 , b.failgroup disk_file_fail_group
 FROM
 v$asm_diskgroup a RIGHT OUTER JOIN v$asm_disk b USING (group_number)
 ORDER BY a.name;

sqlplus "/as sysasm"

-- now add/present the newly added disk into database
alter diskgroup D1_T1_A4 ADD DISK 'ORCL:D1_T1_A4_0019' ;

OR

alter diskgroup D1_T1_A4 add disk 'ORCL:D1_T1_A4_0019' name D1_T1_A4_0019;

--- once again check if any disk is a candidate disk
SELECT
 NVL(a.name, '[CANDIDATE]') disk_group_name, b.path disk_file_path, b.name disk_file_name, b.failgroup disk_file_fail_group
FROM v$asm_diskgroup a 
	RIGHT OUTER JOIN v$asm_disk b USING (group_number)
ORDER BY a.name;


--- finally check if disk group size has increased
select name, TOTAL_MB/1024 total_gb,free_mb/1024 FREE_GB 
from v$asm_diskgroup;


-- Viewing Oracle ASM File Access Control information with V$ASM_FILE
SELECT dg.name AS diskgroup, a.name, f.permissions, f.user_number, u.os_name,
   f.usergroup_number, ug.name 
FROM V$ASM_DISKGROUP dg, V$ASM_USER u, V$ASM_USERGROUP ug, V$ASM_FILE f, V$ASM_ALIAS a 
WHERE dg.name = 'FRA' AND dg.group_number = u.group_number AND 
   u.group_number = ug.group_number AND ug.group_number = f.group_number AND 
   f.group_number = a.group_number AND 
   f.usergroup_number = ug.usergroup_number AND f.user_number = u.user_number AND 
   f.file_number = a.file_number;

-- Viewing File Access Control information with V$ASM_USERGROUP_MEMBER
SELECT dg.name AS diskgroup, um.group_number, um.member_number, u.os_name, 
     um.usergroup_number, ug.name FROM V$ASM_DISKGROUP dg, V$ASM_USER u, V$ASM_USERGROUP_MEMBER um, 
     V$ASM_USERGROUP ug WHERE dg.group_number = um.group_number AND 
     dg.group_number = ug.group_number AND dg.group_number = u.group_number AND dg.name = 'DATA' 
     AND um.member_number = u.user_number AND um.usergroup_number = ug.usergroup_number;

-- Viewing File Access Control information with V$ASM_USERGROU
SELECT dg.name AS diskgroup, ug.group_number, ug.owner_number, u.os_name,
     ug.usergroup_number, ug.name FROM V$ASM_DISKGROUP dg, V$ASM_USER u, V$ASM_USERGROUP ug 
     WHERE dg.group_number = ug.group_number -- AND dg.name = 'DATA' 
     AND ug.owner_number = u.user_number;

-- Viewing Oracle ASM File Access Control information with V$ASM_USER
SELECT dg.name AS diskgroup, u.group_number, u.user_number, u.os_id, u.os_name 
     FROM V$ASM_DISKGROUP dg, V$ASM_USER u 
     WHERE dg.group_number = u.group_number AND dg.name = 'DATA';	 

<end node> 5P9i0s8y19Z
dt=Text
<node>
RAC - Commands
3
-- Most Common RAC Commands Used

-- Shutdown and Start sequence of Oracle RAC 

-- STOP ORACLE RAC (11g)
1. emctl stop dbconsole
2. srvctl stop listener -n racnode1
3. srvctl stop database -d RACDB
4. srvctl stop asm -n racnode1 -f
5. srvctl stop asm -n racnode2 -f
6. srvctl stop nodeapps -n racnode1 -f
7. crsctl stop crs

-- START ORACLE RAC (11g)
1. crsctl start crs
2. crsctl start res ora.crsd -init
3. srvctl start nodeapps -n racnode1
4. srvctl start nodeapps -n racnode2
5. srvctl start asm -n racnode1
6. srvctl start asm -n racnode2
7. srvctl start database -d RACDB
8. srvctl start listener -n racnode1
9. emctl start dbconsole
 
srvctl relocate scan_listener -scannumber 3 -node lrau1p25

-- To start and stop oracle clusterware (run as the superuser) :
-- on local node
[root@node1 ~]# crsctl stop crs

[root@node1 ~]# crsctl start crs
 

-- To start and stop oracle cluster resources running on all nodes :
[root@node1 ~]#  crsctl stop cluster -all

[root@node1 ~]#  crsctl start cluster -all

OR

-- To start the Oracle Clusterware stack on two named servers run the following command as root
[root@node1 ~]# crsctl start cluster -n node1 node2
 

-- To check the current status of a cluster :
[oracle@node1~]$ crsctl check cluster
CRS-4537: Cluster Ready Services is online
CRS-4529: Cluster Synchronization Services is online
CRS-4533: Event Manager is online
 

-- To check the current status of CRS :
[oracle@node1 ~]$ crsctl check crs
CRS-4638: Oracle High Availability Services is online
CRS-4537: Cluster Ready Services is online
CRS-4529: Cluster Synchronization Services is online
CRS-4533: Event Manager is online
 

-- To display the status cluster resources :
[oracle@node1 ~]$ crsctl stat res -t
 

-- To check version of  Oracle Clusterware :
[oracle@node1 ~]$ crsctl query crs softwareversion
Oracle Clusterware version on node [node1] is [11.2.0.4.0]

[oracle@node1 ~]$ 
[oracle@node1 ~]$ crsctl query crs activeversion
Oracle Clusterware active version on the cluster is [11.2.0.4.0]

[oracle@node1 ~]$ crsctl query crs releaseversion
Oracle High Availability Services release version on the local node is [11.2.0.4.0]
 

-- To check current status of OHASD (Oracle High Availability Services) daemon :
[oracle@node1 ~]$ crsctl check has
CRS-4638: Oracle High Availability Services is onli
 

-- Forcefully deleting resource :
[oracle@node1 ~]$ crsctl delete resource testresource -f
 

-- Enabling and disabling CRS daemons (run as the superuser) :
[root@node1 ~]# crsctl enable crs
CRS-4622: Oracle High Availability Services autostart is enabled.

[root@node1 ~]# 
[root@node1 ~]# crsctl disable crs
CRS-4621: Oracle High Availability Services autostart is disabled.
 

-- To check the status of Oracle CRS :
[oracle@node1 ~]$ olsnodes
node1
node2
 

-- To print node name with node number :
[oracle@node1 ~]$ olsnodes -n
node1	1
node2	2
 

-- To print private interconnect address for the local node :
[oracle@node1 ~]$ olsnodes -l -p
node1	192.168.1.101
 

-- To print virtual IP address with node name :
[oracle@node1 ~]$ olsnodes -i
node1	node1-vip
node2	node2-vip

[oracle@node1 ~]$ olsnodes -i node1
node1	node1-vip
 

-- To print information for the local node :
[oracle@node1 ~]$ olsnodes -l
node1
pl
 

-- To print node status (active or inactive) :
[oracle@node1 ~]$ olsnodes -s
node1	Active
node2	Active

[oracle@node1 ~]$ olsnodes -l -s
node1	Active
 

-- To print node type (pinned or unpinned) :
[oracle@node1 ~]$ olsnodes -t
node1	Unpinned
node2	Unpinned
[oracle@node1 ~]$ olsnodes -l -t
node1	Unpinned
 

-- To print clusterware name :
[oracle@node1 ~]$ olsnodes -c
rac-scan
 

-- To display global public and global cluster_interconnect :
[oracle@node1 ~]$ oifcfg getif
eth0  192.168.100.0  global  public
eth1  192.168.1.0  global  cluster_interconnect
 

-- To display the database registered in the repository :
[oracle@gpp4 ~]$ srvctl config database
TESTRACDB
 

-- To display the configuration details of the database :
[oracle@TEST4 ~]$ srvctl config database -d TESTRACDB
Database unique name: TESTRACDB
Database name: TESTRACDB
Oracle home: /home/oracle/product/11.2.0/db_home1
Oracle user: oracle
Spfile: +DATA/TESTRACDB/spfileTESTRACDB.ora
Domain: 
Start options: open
Stop options: immediate
Database role: PRIMARY
Management policy: AUTOMATIC
Server pools: TESTRACDB
Database instances: TESTRACDB1,TESTRACDB2
Disk Groups: DATA,ARCH
Mount point paths: 
Services: SRV_TESTRACDB
Type: RAC
Database is administrator managed
 

-- To change  policy of database from automatic to manual :
[oracle@TEST4 ~]$ srvctl modify database -d TESTRACDB -y MANUAL
 

-- To change  the startup option of database from open to mount :
[oracle@TEST4 ~]$ srvctl modify database -d TESTDB -s mount
 

-- To start RAC listener :
[oracle@TEST4 ~]$ srvctl start listener
 

-- To display the status of the database :
[oracle@TEST4 ~]$ srvctl status database -d TESTRACDB
Instance TESTRACDB1 is running on node TEST4
Instance TESTRACDB2 is running on node TEST5
 

-- To display the status services running in the database :
[oracle@TEST4 ~]$ srvctl status service -d TESTRACDB
Service SRV_TESTRACDB is running on instance(s) TESTRACDB1,TESTRACDB2
 

-- To check nodeapps running on a node :
[oracle@TEST4 ~]$ srvctl status nodeapps
VIP TEST4-vip is enabled
VIP TEST4-vip is running on node: TEST4
VIP TEST5-vip is enabled
VIP TEST5-vip is running on node: TEST5
Network is enabled
Network is running on node: TEST4
Network is running on node: TEST5
GSD is enabled
GSD is not running on node: TEST4
GSD is not running on node: TEST5
ONS is enabled
ONS daemon is running on node: TEST4
ONS daemon is running on node: TEST5
 

 
[oracle@TEST4 ~]$  srvctl status nodeapps -n TEST4
VIP TEST4-vip is enabled
VIP TEST4-vip is running on node: TEST4
Network is enabled
Network is running on node: TEST4
GSD is enabled
GSD is not running on node: TEST4
ONS is enabled
ONS daemon is running on node: TEST4
 

-- To start or stop all instances associated with a database. This command also starts services and listeners on each node :
[oracle@TEST4 ~]$ srvctl start database -d TESTRACDB
 

-- To shut down instances and services (listeners not stopped):
[oracle@TEST4 ~]$ srvctl stop database -d TESTRACDB
 

-- You can use -o option to specify startup/shutdown options.
-- To shutdown immediate database – srvctl stop database -d TESTRACDB -o immediate
-- To startup force all instances – srvctl start database -d TESTRACDB -o force
-- To perform normal shutdown – srvctl stop database -d TESTRACDB -i instance racnode1

-- To start or stop the ASM instance on racnode01 cluster node :
[oracle@TEST4 ~]$ srvctl start asm -n racnode1
[oracle@TEST4 ~]$ srvctl stop asm -n racnode1
 

-- To display current configuration of the SCAN VIP’s :
[oracle@test4 ~]$ srvctl config scan
SCAN name: vmtestdb.exo.local, Network: 1/192.168.5.0/255.255.255.0/eth0
SCAN VIP name: scan1, IP: /vmtestdb.exo.local/192.168.5.100
SCAN VIP name: scan2, IP: /vmtestdb.exo.local/192.168.5.101
SCAN VIP name: scan3, IP: /vmtestdb.exo.local/192.168.5.102
 

-- Refreshing  SCAN VIP’s with new IP addresses from DNS :
[oracle@test4 ~]$ srvctl modify scan -n your-scan-name.example.com
 

-- To stop or start SCAN listener and the  SCAN VIP resources :
[oracle@test4 ~]$ srvctl stop scan_listener 
[oracle@test4 ~]$ srvctl start scan_listener 
[oracle@test4 ~]$ srvctl stop scan
[oracle@test4 ~]$ srvctl start scan
 

-- To display the status of SCAN VIP’s and SCAN listeners :
[oracle@test4 ~]$ srvctl status scan
SCAN VIP scan1 is enabled
SCAN VIP scan1 is running on node test4
SCAN VIP scan2 is enabled
SCAN VIP scan2 is running on node test5
SCAN VIP scan3 is enabled
SCAN VIP scan3 is running on node test5
 
 
[oracle@test4 ~]$ srvctl status scan_listener
SCAN Listener LISTENER_SCAN1 is enabled
SCAN listener LISTENER_SCAN1 is running on node test4
SCAN Listener LISTENER_SCAN2 is enabled
SCAN listener LISTENER_SCAN2 is running on node test5
SCAN Listener LISTENER_SCAN3 is enabled
SCAN listener LISTENER_SCAN3 is running on node test5
 

-- To add/remove/modify SCAN :
[oracle@test4 ~]$ srvctl add scan -n your-scan
[oracle@test4 ~]$ srvctl remove scan
[oracle@test4 ~]$ srvctl modify scan -n new-scan
 

-- To add/remove SCAN listener :
[oracle@test4 ~]$ srvctl add scan_listener
[oracle@test4 ~]$ srvctl remove scan_listener
 

-- To modify SCAN listener port :
srvctl modify scan_listener -p <port_number>
srvctl modify scan_listener -p <port_number>  (reflect changes to the current SCAN listener only)

-- To start the ASM instnace in mount state :
ASMCMD> startup --mount
 

-- To shut down ASM instance immediately(database instance must be shut down before the ASM instance is shut down) :
ASMCMD> shutdown --immediate
 

-- Use lsop command on ASMCMD to list ASM operations :
ASMCMD > lsop
 

-- To perform quick health check of OCR :
[oracle@test4 ~]$ ocrcheck
Status of Oracle Cluster Registry is as follows :
	 Version                  :          3
	 Total space (kbytes)     :     262120
	 Used space (kbytes)      :       3304
	 Available space (kbytes) :     258816
	 ID                       : 1555543155
	 Device/File Name         :      +DATA
                                    Device/File integrity check succeeded
	 Device/File Name         :       +OCR
                                    Device/File integrity check succeeded

                                    Device/File not configured

                                    Device/File not configured

                                    Device/File not configured

	 Cluster registry integrity check succeeded

	 Logical corruption check bypassed due to non-privileged user
 

-- To dump content of OCR file into an xml :
[oracle@test4 ~]$ ocrdump testdump.xml -xml
 

-- To add or relocate the OCR mirror file to the specified location :
[oracle@test4 ~]$ ocrconfig -replace ocrmirror ‘+TESTDG’
[oracle@test4 ~]$ ocrconfig -replace +CURRENTOCRDG -replacement +NEWOCRDG
 

-- To relocate existing OCR file :
[oracle@test4 ~]$ ocrconfig  -replce ocr ‘+TESTDG’
 

-- To add mirrod disk group for OCR :
[oracle@test4 ~]$ ocrconfig -add +TESTDG
 

-- To remove OCR mirror :
ocrconfig -delete +TESTDG
 

-- To remove the OCR or the OCR mirror :
[oracle@test4 ~]$ ocrconfig -replace ocr

[oracle@test4 ~]$ ocrconfig replace ocrmirror
 

-- To list ocrbackup list :
[oracle@test4 ~]$ ocrconfig -showbackup

test5     2016/04/16 17:30:29     /home/oracle/app/11.2.0/grid/cdata/vmtestdb/backup00.ocr

test5     2016/04/16 13:30:29     /home/oracle/app/11.2.0/grid/cdata/vmtestdb/backup01.ocr

test5     2016/04/16 09:30:28     /home/oracle/app/11.2.0/grid/cdata/vmtestdb/backup02.ocr

test5     2016/04/15 13:30:26     /home/oracle/app/11.2.0/grid/cdata/vmtestdb/day.ocr

test5     2016/04/08 09:30:03     /home/oracle/app/11.2.0/grid/cdata/vmtestdb/week.ocr
 

-- Performs OCR backup manually :
[root@testdb1 ~]# ocrconfig -manualbackup

testdb1     2016/04/16 17:31:42     /votedisk/backup_20160416_173142.ocr     0  
 

-- Changes OCR autobackup directory
[root@testdb1 ~]# ocrconfig -backuploc /backups/ocr
 

-- To verify the integrity of all the cluster nodes:
[oracle@node1]$ cluvfy comp ocr -n all -verbose
Verifying OCR integrity 
Checking OCR integrity...

Checking the absence of a non-clustered configuration...
All nodes free of non-clustered, local-only configurations

-- Checking daemon liveness...

Check: Liveness for "CRS daemon"
  Node Name                             Running?                
  ------------------------------------  ------------------------
  node2                                yes                     
  node1                                yes                     
Result: Liveness check passed for "CRS daemon"

Checking OCR config file "/etc/oracle/ocr.loc"...
OCR config file "/etc/oracle/ocr.loc" check successful

Disk group for ocr location "+DATA/testdb-scan/OCRFILE/registry.255.903592771" is available on all the nodes
Disk group for ocr location "+CRS/testdb-scan/OCRFILE/registry.255.903735431" is available on all the nodes
Disk group for ocr location "+MULTIPLEX/testdb-scan/OCRFILE/registry.255.903735561" is available on all the nodes

Checking OCR backup location "/bkpdisk"
OCR backup location "/bkpdisk" check passed
Checking OCR dump functionality
OCR dump check passed

NOTE: 
This check does not verify the integrity of the OCR contents. 
Execute 'ocrcheck' as a privileged user to verify the contents of OCR.
OCR integrity check passed
Verification of OCR integrity was successful. 

<end node> 5P9i0s8y19Z
dt=Text
<node>
ASM Question
3
--------------------------------------------------------------------------
							ORACLE ASM 
--------------------------------------------------------------------------

*. What is ASM?

	Automatic Storage Management (ASM) is an integrated, high-performance database file system and disk manager. ASM is based on the principle that the database should manage storage instead of requiring an administrator to do it. ASM eliminates the need for you to directly manage potentially thousands of Oracle database files.
	
	In Oracle Database 10g/11g there are two types of instances: database and ASM instances. The ASM instance, which is generally named +ASM, is started with the INSTANCE_TYPE=ASM init.ora parameter. This parameter, when set, signals the Oracle initialization routine to start an ASM instance and not a standard database instance. Unlike the standard database instance, the ASM instance contains no physical files; such as logfiles, controlfiles or datafiles, and only requires a few init.ora parameters for startup.
	
	Upon startup, an ASM instance will spawn all the basic background processes, plus some new ones that are specific to the operation of ASM. The STARTUP clauses for ASM instances are similar to those for database instances. For example, RESTRICT prevents database instances from connecting to this ASM instance. NOMOUNT starts up an ASM instance without mounting any disk group. MOUNT option simply mounts all defined diskgroups
	
	For RAC configurations, the ASM SID is +ASMx instance, where x represents the instance number.

*. What are the key benefits of ASM?

	ASM provides filesystem and volume manager capabilities built into the Oracle database kernel. Withthis capability, ASM simplifies storage management tasks, such as creating/laying out databases and disk space management. Since ASM allows disk management to be done using familiar create/alter/drop SQL statements, DBAs do not need to learn a new skill set or make crucial decisions on provisioning.

The following are some key benefits of ASM:

    1.ASM spreads I/O evenly across all available disk drives to prevent hot spots and maximize performance.
    2.ASM eliminates the need for over provisioning and maximizes storage resource utilization facilitating database consolidation.
    3.Inherent large file support.
    4.Performs automatic online redistribution after the incremental addition or removal of storage  capacity.
    5.Maintains redundant copies of data to provide high availability, or leverages 3rd party RAID functionality.
    6.Supports Oracle Database as well as Oracle Real Application Clusters (RAC).
    7.Capable of leveraging 3rd party multipathing technologies.
    8.For simplicity and easier migration to ASM, an Oracle database can contain ASM and non-ASM files.
    9.Any new files can be created as ASM files whilst existing files can also be migrated to ASM.
    10.RMAN commands enable non-ASM managed files to be relocated to an ASM disk group.
    11.Enterprise Manager Database Control or Grid Control can be used to manage ASM disk and file activities.

	

*. What are different types of redundancies in ASM & explain?

    Normal redundancy - : for 2-way mirroring, requiring two failure groups, when ASM allocates an extent for a normal 	redundancy file, ASM allocates a primary copy and a secondary copy. ASM chooses the disk on which to store the secondary copy in a different failure group other than the primary copy.
    High redundancy - for 3-way mirroring, requiring three failure groups, in this case the extent is mirrored across 3 disks.
    External redundancy - to not use ASM mirroring. This is used if you are using hardware mirroring or third party redundancy mechanism like RAID, Storage arrays.

*. How to find out the databases, which are using the ASM instance?
	ASMCMD> lsct
	SQL> select DB_NAME from V$ASM_CLIENT;

*. What is a diskgroup?

	A disk group consists of multiple disks and is the fundamental object that ASM manages. Each disk group contains the metadata that is required for the management of space in the disk group. The ASM instance manages the metadata about the files in a Disk Group in the same way that a file system manages metadata about its files. However, the vast majority of I/O operations do not pass through the ASM instance. In a moment we will look at how file
	I/O works with respect to the ASM instance.
	
*. What happens when an Oracle ASM diskgroup is created?
	When an ASM diskgroup is created, a hierarchialfilesystem structure is created.
	
*. What is an incarnation number?
	An incarnation number is a part of ASM filename syntax. It is derived from the timestamp. Once the file is created, its incarnation number doesnot change.



*. What is ASM striping ?
	ASM spreads data evenly across all disks in a disk group to optimize performance and utilization.    This even distribution of database files eliminates the need for regular monitoring and I/O performance tuning.
    To balance loads across all of the disks in a disk group
    To reduce I/O latency

*. What are different types of stripings in ASM & their differences?
	1.Fine Striping :- Fine striping writes 128 KB data to each ASM Disk in the diskgroup in a round robin fashion, 128 KB goes tothe first disk, then the next 128 KB, goes to the next disk, etc. According to manual, The fine-grained stripe size always equals 128 KB in any configuration; this provides lower I/O latency for small I/O operations.” Small I/O operations sure sounds like a good candidate for redo logs, control files etc. The size for coarse striping can be set using the "_asm_ausize parameter."
	
	2.Coarse-grained striping :-With coarse grained striping ASM writes data to each disk in the same round robin fashion, but writes chunks in the size of the ASM instance’s allocation unit (AU) size, default is 1MB. The size for fine grained striping can be set using the "_asm_stripesize" parameter.
	
*. We have a 16 TB database. I’m curious about the number of disk groups we should use; e.g. 1 large disk group, a couple of 	disk groups, or otherwise?

	For VLDBs you will probably end up with different storage tiers; e.g with some of our large customers they have Tier1 (RAID10 FC), Tier2 (RAID5 FC), Tier3 (SATA), etc. Each one of these is mapped to a diskgroup.
	
*. Can my RDBMS and ASM instances run different versions?

	Yes. ASM can be at a higher version or at lower version than its client databases. There’s two
	components of compatiblity:
	Software compatibility
	Diskgroup compatibility attributes:
	"compatible.asm"	---alter diskgroup dg2 set attribute 'compatible.asm'='11.1';
	"compatible.rdbms" ----alter diskgroup dg2 set attribute 'compatible.rdbms'='11.1';
	
*. Where do I run my database listener from; i.e., ASM HOME or DB HOME?

	It is recommended to run the listener from the ASM HOME. This is particularly important for RAC env, since the listener is a node-level resource. In this config, you can create additional [user] listeners from the database homes as needed.

*. How do I backup my ASM instance?
	Not applicable! ASM has no files to backup, as its does not contain controlfile,redo logs etc.

*. When should I use RMAN and when should I use ASMCMD copy?

    RMAN is the recommended and most complete and flexible method to backup and transport database files in ASM.
    ASMCMD copy is good for copying single files
    • Supports all Oracle file types
    • Can be used to instantiate a Data Guard environment
    • Does not update the controlfile
    • Does not create OMF files

*. I’m going to do add disks to my ASM diskgroup, how long will this rebalance take?

    Rebalance time is heavily driven by the three items:
    1) Amount of data currently in the diskgroup
    2) IO bandwidth available on the server
    3) ASM_POWER_LIMIT or Rebalance Power Level (GV$ASM_OPERATION;)

	ASM_POWER_LIMIT :  specifies the disk rebalancing speed of the ASM instance. The higher the limit, the faster rebalancing operation, but consume lot of CPU. Lower values will take longer, but consume fewer processing and I/O resources.
		• Background process "ARBx" performs the rebalance activity (where x is a number).
		• If the POWER clause of a rebalance operation is not specified, then the default power will be the value of 		   ASM_POWER_LIMIT.
		• The range of asm_power_limit is from 0 to 1024. Default is one.
		


*. We are migrating to a new storage array. How do I move my ASM database from storage A to storage B?
	Given that the new and old storage are both visible to ASM, simply add the new disks to the ASM disk group and drop the old disks. ASM rebalance will migrate data online. (NYBC)



*. How does ASM work with multipathing software?
	It works great! Multipathing software is at a layer lower than ASM, and thus is transparent.
	You may need to adjust ASM_DISKSTRING to specify only the path to the multipathing pseudo devices.

*. What are the file types that ASM support and keep in disk groups?

	Control files ,Flashback logs ,Data Pump dump sets ,Data files ,DB SPFILE ,Data Guard configuration ,Temporary data files ,RMAN backup sets ,Change tracking bitmaps ,Online redo logs ,RMAN data file copies ,OCR files ,Archive logs ,Transport data files ,ASM SPFILE.

	
*.  Below are the HEADER_STATUS in the v$ASM_DISK. I have taken below status from 11gR2.
·UNKNOWN 		- Automatic Storage Management disk header has not been read
·CANDIDATE 		- Disk is not part of a disk group and may be added to a disk group with the ALTER DISKGROUP statement
·INCOMPATIBLE	- Version number in the disk header is not compatible with the Automatic Storage Management software version.
·PROVISIONED 	- Disk is not part of a disk group and may be added to a disk group with the ALTER DISKGROUP statement. The 				 PROVISIONED header status is different from the CANDIDATE header status in that PROVISIONED implies that an 				  additional platform-specific action has been taken by an administrator to make the disk available for 				 Automatic Storage Management.
·MEMBER 		- Disk is a member of an existing disk group. No attempt should be made to add the disk to a different disk 				 group. The ALTER DISKGROUP statement will reject such an addition unless overridden with the FORCE option
·FORMER 		- Disk was once part of a disk group but has been dropped cleanly from the group. It may be added to a new 					disk group with the ALTER DISKGROUP statement.
·CONFLICT 		- Automatic Storage Management disk was not mounted due to a conflict
·FOREIGN 		- Disk contains data created by an Oracle product other than ASM. This includes datafiles, logfiles, and OCR 				  disks.

*. Whats is Kfed?
	kfed is a utility which can be used to view the ASM Disk information. Syntax for using it is
	kfed read devicename

*.  ASM Specific Init.ora Parameters
	.cluster_database= true
	.asm_diskstring = '/dev/sd*1'
	.instance_type=asm
	.shared_pool_size=100M
	.large_pool_size = 80M
	.db_cache_size=60M
	.asm_diskgroups = 'DATA','FRA'
	.processes=128	
		
*. ASM Instance Background Processes:
   ---------------------------------
	•ARBx (ASM) : Rebalance working process ARBn performs the actual rebalance data extent movements in an Automatic Storage Management instance. There can be many of these processes running at a time, named ARB0, ARB1, and so on.These processes are managed by the RBAL process. The number of ARBx processes invoked is directly influenced by the asm_power_limit parameter.

	•RBAL (Re-balancer)  : RBAL runs in both database and ASM instances. In the database instance, it does a global open of ASM disks. In an ASM instance, it also coordinates rebalance activity for disk groups.RBAL, which coordinates rebalance activities
	for disk resources controlled by ASM.

	Database Instance ASM Background Processes: 
	------------------------------------------
	In the database instances, there are three background process to support ASM, namely:

	•ASMB, : this process contact CSS using the group name and acquires the associated ASM connect string. The connect string is subsequently used to connect to the ASM instance.

	•RBAL, :which performs global opens on all disks in the disk group.A global open means that more than one database instance can be accessing the ASM disks at a time.

	.O00x, : a group slave processes, with a numeric sequence starting at 000. 
	

	PATCHING : (way of patching " best way use auto patch ")
		command  : $ORACLE_HOME/OPatch/./opatch auto  $DIR/$GRID_DB_PATCH -oh $ORACLE_HOME  -ocmrf $ORACLE_HOME/dbs/ocm.rsp 
		OCW 	 : primary patch for ASM
		ACFS 	 : seconday patch for ASM
		DB PSU 	 : optinal but manditory patch for asm 
		
REM VIEW            |ASM INSTANCE                                     |DB INSTANCE
REM ----------------------------------------------------------------------------------------------------------
REM V$ASM_DISKGROUP |Describes a disk group (number, name, size       |Contains one row for every open ASM
REM                 |related info, state, and redundancy type)        |disk in the DB instance.
REM V$ASM_CLIENT    |Identifies databases using disk groups           |Contains no rows.
REM                 |managed by the ASM instance.                     |
REM V$ASM_DISK      |Contains one row for every disk discovered       |Contains rows only for disks in the
REM                 |by the ASM instance, including disks that        |disk groups in use by that DB instance.
REM                 |are not part of any disk group.                  |
REM V$ASM_FILE      |Contains one row for every ASM file in every     |Contains rows only for files that are
REM                 |disk group mounted by the ASM instance.          |currently open in the DB instance.
REM V$ASM_TEMPLATE  |Contains one row for every template present in   |Contains no rows.
REM                 |every disk group mounted by the ASM instance.    |
REM V$ASM_ALIAS     |Contains one row for every alias present in      |Contains no rows.
REM                 |every disk group mounted by the ASM instance.    |
REM v$ASM_OPERATION |Contains one row for every active ASM long       |Contains no rows.
REM                 |running operation executing in the ASM instance. |

	
COMMANDS :

	/etc/init.d/oracleasm 
	start-----start asm instance 
	stop-----stop asm instance 
	restart---restart asm 
	configure--set configuration of asm ( -i)
	status----to check asm status
	enable----enable asm services 
	disable---disable asm services 
	listdisks--check the asm disks 
	deletedisk---delete disk from asm
	scandisks----scan disk from diskgreoup
	querydisk /dev/sdd1 ----check disk on which disk greoup
	createdisk VOL1 /dev/sdb1 ----create disk using file system 
	renamedisk /dev/sdb1 VOL1 ----rename disk 
	
	

	ADD -- 		srvctl add asm -n node_name -i +asm_instance_name -o oracle_home
	REMOVE--	srvctl remove asm -n node_name [-i +asm_instance_name]
	ENABLE --	srvctl enable asm -n node_name [-i ] +asm_instance_name
	DISABLE --	srvctl disable asm -n node_name [-i +asm_instance_name]
	START --	srvctl start asm -n node_name [-i +asm_instance_name] [-o start_options]
	STOP --		srvctl stop asm -n node_name [-i +asm_instance_name] [-o stop_options]
	CONFIG--	srvctl config asm -n node_name
	STATUS --	srvctl status asm -n node_name
	
	CHECK REBALABCE : v$asm_operation.
	CHECCK CLIENT 	: v$asm_clients or lsct
	CHECK SPACE 	: v$asm_disk, v$asm_diskgroup
	CHECK ALISE 	: v$asm_alias	(X$KFFXP)
	
	create diskgroup  : create diskgroup FRA1 external redundancy disk '/dev/vx/rdsk/oraASMdg/fra1'
						--ATTRIBUTE 'compatible.rdbms' = '11.1', 'compatible.asm' = '11.1';
	
	alter diskgroup 
		check: 		alter diskgroup FRA1  check all;
		mount:  	alter diskgroup FRA1 mount;
		add disk:	alter diskgroup FRA1 add disk '/dev/vx/rdsk/oraASMdg/fra2'; OR  '/dev/vx/rdsk/oraASMdg/fra*';
		remove disk:alter diskgroup FRA1 drop disk 'FRA1_0002';
		rebalance : alter diskgroup DATA1 rebalance power 10;

	drop diskgreoup: drop diskgroup DATA1 including contents;
	
	
	•copy command : 
		ASM to filesystem -->
		ASMCMD> cp dumpfile1.dmp dumpfile1.dmp dumpfile1.dmp /oracle/backup/testdb/expdp
				copying +FRA/TESTDB/EXPDP/dumpfile1.dmp -> /oracle/backup/testdb/expdp/dumpfile1.dmp
				copying +FRA/TESTDB/EXPDP/dumpfile2.dmp -> /oracle/backup/testdb/expdp/dumpfile2.dmp
				copying +FRA/TESTDB/EXPDP/dumpfile3.dmp -> /oracle/backup/testdb/expdp/dumpfile3.dmp	
		
		•File system to asm : -->
		ASMCMD> cp /oracle/backup/testdb/expdp/dumpfile1.dmp '+FRA/TESTDB/EXPDP/'
				copying /oracle/backup/testdb/expdp/dumpfile1.dmp -> +FRA/TESTDB/EXPDP/dumpfile1.dmp
		ASMCMD> cp /oracle/backup/testdb/expdp/dumpfile2.dmp '+FRA/TESTDB/EXPDP/'
				copying /oracle/backup/testdb/expdp/dumpfile2.dmp -> +FRA/TESTDB/EXPDP/dumpfile2.dmp
		ASMCMD> cp /oracle/backup/testdb/expdp/dumpfile3.dmp '+FRA/TESTDB/EXPDP/'
				copying /oracle/backup/testdb/expdp/dumpfile3.dmp -> +FRA/TESTDB/EXPDP/dumpfile3.dmp 
		ASMCMD> ls
				dumpfile1.dmp
				dumpfile2.dmp
				dumpfile3.dmp
		
		OR  
				set timing on
				BEGIN
				dbms_file_transfer.get_file('SOURCE_DUMP',
				'test.dmp',
				'SOURCEDB',
				'TARGET_DUMP',
				'test.dmp');
				END;
				/
				
		OR
		
		RMAN> copy datafile '/u01/oradata/racdb/trtst01.dbf' to '+DATADG';
		
		RMAN> COPY DATAFILE '+ASMDISK2/orcl/datafile/users.256.565313879' TO '+ASMDISK1';

	•If you have used RMAN (method 4 b) use the following option of RMAN 
		RMAN>
		run 
		{ 
		set newname for datafile '+ASMDISK2/orcl/datafile/users.256.565313879' 
		to '+ASMDISK1/orcl/datafile/users.259.565359071'; 
		switch datafile all; 
		} 
		
	•Delete the datafile from its original location.

		SQL> ALTER DISKGROUP ASMDISK2 DROP FILE users.256.565313879;
		or
		ASMCMD> rm -rf <filename>

<end node> 5P9i0s8y19Z
dt=Text
<node>
ASMCMD disk check
3
vi asmdu.sh

chmod 777 asmdu.sh

#!/bin/bash
#
# du of each subdirectory in a directory for ASM
#
D=$1

if [[ -z $D ]]
then
 echo "Please provide a directory !"
 exit 1
fi

(for DIR in `asmcmd ls ${D}`
 do
     echo ${DIR} `asmcmd du ${D}/${DIR} | tail -1`
 done) | awk -v D="$D" ' BEGIN {  printf("\n\t\t%40s\n\n", D " subdirectories size")           ;
                                  printf("%25s%16s%16s\n", "Subdir", "Used MB", "Mirror MB")   ;
                                  printf("%25s%16s%16s\n", "------", "-------", "---------")   ;}
                               {
                                  printf("%25s%16s%16s\n", $1, $2, $3)                         ;
                                  use += $2                                                    ;
                                  mir += $3                                                    ;
                               }
                         END   { printf("\n\n%25s%16s%16s\n", "------", "-------", "---------");
                                 printf("%25s%16s%16s\n\n", "Total", use, mir)                 ;} '

-- save the files

chmod 777 asmdu.sh


./asmdu.sh FRA2/ --- fra2  is the disk on which we have to calculate the disk size 

<end node> 5P9i0s8y19Z
dt=Text
<node>
asmcmd sql/cmds
3
--- sql query to check the asm disk level free space
--- run as grid user owner with 
sqlplus "/as sysasm"

select NAME,STATE,round(TOTAL_MB/1024)TOTAL_GB ,round(free_mb/1024) FREE_G, 
	round ((FREE_MB/TOTAL_MB)*100,2) PCT_FREE 
from v$asm_diskgroup; 

<end node> 5P9i0s8y19Z
dt=Text
<node>
relocate service
3
-- Relocating Service in Oracle RAC
http://oracle-help.com/oracle-rac/relocating-service-oracle-rac/ 
http://oracledbabhuvan.blogspot.com/2011/11/relocate-service-in-rac.html 
 


$srvctl relocate service -h

Temporarily relocates service from one node of the cluster to another.

Usage: srvctl relocate service -d <db_unique_name> -s <service_name> {-i <old_inst_name> -t <new_inst_name> | -c <current_node> -n <target_node>} [-f]
       Specify instances for an administrator-managed database, or nodes for a policy managed database
    -d <db_unique_name>      Unique name for the database
    -s <service>             Service name
    -i <old_inst>            Old instance name
    -t <new_inst>            New instance name
    -c <current_node>        Node name to relocate service from
    -n <target_node>         Node name to relocate service to
    -f                       Disconnect all sessions during stop or relocate service operations
    -h                       Print usage


-- In this article, we will see Relocation of Service from One Instance to another Instance.

-- I have service called myservice already running at orcl1 instance.

-- Let us check status of myservice

[oracle@rac1 ~]$ srvctl status service -d orcl -s myservice
Service myservice is running on instance(s) orcl1

[oracle@rac1 ~]$

[oracle@rac1 ~]$ srvctl status service -d orcl -s myservice
Service myservice is running on instance(s) orcl1

[oracle@rac1 ~]$


-- for e.g.. (Moving Monsanto service from usmgenp1 to usmgenp2)
-- usmgenp2 service was running on usmgenp1 node so relocated it
oracle@rac1 ~]$ srvctl relocate service -d usmgenp -s usmgenp2.monsanto.com -i usmgenp1 -t usmgenp2   

------------------------------------------------------------------------------------------
-- Now relocate service from orcl1 to orcl2

[oracle@rac1 ~]$ srvctl relocate service -d orcl -s myservice -i orcl1 -t orcl2
-i represents an old instance
-t represents a new instance

-- Now check the status of service.
[oracle@rac1 ~]$ srvctl status service -d orcl -s myservice
Service myservice is running on instance(s) orcl2

[oracle@rac1 ~]$

[oracle@rac1 ~]$ srvctl status service -d orcl -s myservice
Service myservice is running on instance(s) orcl2

[oracle@rac1 ~]$

-- We can see here service is relocated at an orcl2 instance and is running at instance orcl2.
------------------------------------------------------------------------------------------

<end node> 5P9i0s8y19Z
dt=Text
<node>
Add ASM DiskGroup 01 Manual
3

-- CREATE DISKGROUP MANUAL in 11gR2

-- In the document I am creating DISK and creating the DISKGROUP in the cluster environment 
-- using manual method.  I have a two node primary database & two node standby database.

-- We need to identify the raw disks which are candidates for the ASM storage. I have check 
-- in the primary & standby site

-- Below disk are free on both side (primary RAC DB & Standby RAC DB)
raw_vote_03    
raw_vote_04    
raw_vote_05    


-- CREATING ORACLEASM DISKS using 'oracleasm createdisk' command as root. This command will 
-- make the disks available to ASMLib. 
-- List the existing disks using the listdisks option to verify that ASMLib is aware of the 
-- marked new disks.


[root@bhuora01~]# oracleasm createdisk DG_TEST /dev/mapper/raw_vote_03
Writing disk header: done
Instantiating disk: done

[root@bhuora01]# oracleasm createdisk DG_TEST1 /dev/mapper/raw_vote_04
Writing disk header: done
Instantiating disk: done

[root@bhuora01]# oracleasm createdisk DG_TEST2 /dev/mapper/raw_vote_05
Writing disk header: done
Instantiating disk: done

-- VERIFYING ASK DISK LABEL BY PROVIDING DISK

[root@bhuora01 ~]# oracleasm querydisk /dev/mapper/raw_vote_03
Device "/dev/mapper/raw_vote_03" is marked an ASM disk with the label "DG_TEST"

[root@bhuora01 ~]# oracleasm querydisk /dev/mapper/raw_vote_04
Device "/dev/mapper/raw_vote_04" is marked an ASM disk with the label "DG_TEST1"

[root@bhuora01 ~]# oracleasm querydisk /dev/mapper/raw_vote_05
Device "/dev/mapper/raw_vote_05" is marked an ASM disk with the label "DG_TEST2"

-- VERIFYING DISK USING listdiks

[root@bhuora01 ~]# oracleasm listdisks
DG_TEST
DG_TEST1
DG_TEST2


[root@bhuora01 ~]# ls -alrt /dev/oracleasm/disks/DG*
total 0
drwxr-xr-x 4 root   root         0 Nov 22 13:14 ..
drwxr-xr-x 1 root   root         0 Nov 22 13:14 .
brw-rw---- 1 oracle asmdba 253, 26 Dec 13 15:36 DG_TEST
brw-rw---- 1 oracle asmdba 253, 27 Dec 13 15:36 DG_TEST1
brw-rw---- 1 oracle asmdba 253, 28 Dec 13 15:36 DG_TEST2


-- Make ASM disks available to other nodes in the cluster by running the scandisk 
-- command. This needs to be run on all other nodes.

[root@bhuora02 ~]# oracleasm scandisks
Reloading disk partitions: done
Cleaning any stale ASM disks...
Scanning system for ASM disks...
Instantiating disk "DG_TEST"
Instantiating disk "DG_TEST1"
Instantiating disk "DG_TEST2"
[root@bhuora02 ~]#

-- You can see from the scandisks commands, it display above 3 disks are creating newly 
-- on the first node

[root@bhuora02 ~]# ls -alrt /dev/oracleasm/disks/DG*
brw-rw---- 1 oracle asmdba 253, 36 Dec 13 15:40 /dev/oracleasm/disks/DG_TEST
brw-rw---- 1 oracle asmdba 253, 38 Dec 13 15:40 /dev/oracleasm/disks/DG_TEST1
brw-rw---- 1 oracle asmdba 253, 40 Dec 13 15:40 /dev/oracleasm/disks/DG_TEST2


-- Creating The Disk Group In Command Prompt

oracle +ASM1 bhuora02> sqlplus / as sysasm

SQL*Plus: Release 11.2.0.2.0 Production on Tue Dec 13 16:02:22 2011

Copyright (c) 1982, 2010, Oracle.  All rights reserved.


Connected to:
Oracle Database 11g Enterprise Edition Release 11.2.0.2.0 - 64bit Production
With the Real Application Clusters and Automatic Storage Management options

SQL> CREATE DISKGROUP TEST EXTERNAL REDUNDANCY
DISK '/dev/oracleasm/disks/DG_TEST',
'/dev/oracleasm/disks/DG_TEST1',
'/dev/oracleasm/disks/DG_TEST2' ATTRIBUTE 'au_size'='4M',
'compatible.asm' = '11.2.0.2.0',
'compatible.rdbms' = '11.2.0.2.0',
'compatible.advm' = '11.2.0.2.0';

Diskgroup created.


SQL> select * from v$asm_diskgroup where name='TEST';

GROUP_NUMBER NAME                           SECTOR_SIZE BLOCK_SIZE
------------ ------------------------------ ----------- ----------
ALLOCATION_UNIT_SIZE STATE       TYPE     TOTAL_MB    FREE_MB HOT_USED_MB
-------------------- ----------- ------ ---------- ---------- -----------
COLD_USED_MB REQUIRED_MIRROR_FREE_MB USABLE_FILE_MB OFFLINE_DISKS
------------ ----------------------- -------------- -------------
COMPATIBILITY
------------------------------------------------------------
DATABASE_COMPATIBILITY                                       V
------------------------------------------------------------ -
          32 TEST                                   512       4096
             4194304 MOUNTED     EXTERN       6144       6004           0
         140                       0           6004             0

GROUP_NUMBER NAME                           SECTOR_SIZE BLOCK_SIZE
------------ ------------------------------ ----------- ----------
ALLOCATION_UNIT_SIZE STATE       TYPE     TOTAL_MB    FREE_MB HOT_USED_MB
-------------------- ----------- ------ ---------- ---------- -----------
COLD_USED_MB REQUIRED_MIRROR_FREE_MB USABLE_FILE_MB OFFLINE_DISKS
------------ ----------------------- -------------- -------------
COMPATIBILITY
------------------------------------------------------------
DATABASE_COMPATIBILITY                                       V
------------------------------------------------------------ -
11.2.0.2.0
11.2.0.2.0                                                   N


-- ON NODE#2 if you run the same queries on the second node, it shows there is no disk 
-- group with the name. When I check further on the issue, I found that we need to manual 
-- mount in all the cluster nodes.

SQL> select * from v$asm_diskgroup where name='TEST';

GROUP_NUMBER NAME                           SECTOR_SIZE BLOCK_SIZE
------------ ------------------------------ ----------- ----------
ALLOCATION_UNIT_SIZE STATE       TYPE     TOTAL_MB    FREE_MB HOT_USED_MB
-------------------- ----------- ------ ---------- ---------- -----------
COLD_USED_MB REQUIRED_MIRROR_FREE_MB USABLE_FILE_MB OFFLINE_DISKS
------------ ----------------------- -------------- -------------
COMPATIBILITY
------------------------------------------------------------
DATABASE_COMPATIBILITY                                       V
------------------------------------------------------------ -
           0 TEST                                     0       4096
                   0 DISMOUNTED                  0          0           0
           0                       0              0             0

GROUP_NUMBER NAME                           SECTOR_SIZE BLOCK_SIZE
------------ ------------------------------ ----------- ----------
ALLOCATION_UNIT_SIZE STATE       TYPE     TOTAL_MB    FREE_MB HOT_USED_MB
-------------------- ----------- ------ ---------- ---------- -----------
COLD_USED_MB REQUIRED_MIRROR_FREE_MB USABLE_FILE_MB OFFLINE_DISKS
------------ ----------------------- -------------- -------------
COMPATIBILITY
------------------------------------------------------------
DATABASE_COMPATIBILITY                                       V
------------------------------------------------------------ -
0.0.0.0.0
0.0.0.0.0                                                    N

-- when i try to dismount disk group, i got an error saying that there is no disk available
--on the node

SQL> alter diskgroup test dismount;
alter diskgroup test dismount
*
ERROR at line 1:
ORA-15032: not all alterations performed
ORA-15001: diskgroup "TEST" does not exist or is not mounted

-- THEN MOUNT THE DISK GROUP

SQL> alter diskgroup test mount;

Diskgroup altered.

SQL> select * from v$asm_diskgroup where name='TEST';

GROUP_NUMBER NAME                           SECTOR_SIZE BLOCK_SIZE
------------ ------------------------------ ----------- ----------
ALLOCATION_UNIT_SIZE STATE       TYPE     TOTAL_MB    FREE_MB HOT_USED_MB
-------------------- ----------- ------ ---------- ---------- -----------
COLD_USED_MB REQUIRED_MIRROR_FREE_MB USABLE_FILE_MB OFFLINE_DISKS
------------ ----------------------- -------------- -------------
COMPATIBILITY
------------------------------------------------------------
DATABASE_COMPATIBILITY                                       V
------------------------------------------------------------ -
          32 TEST                                   512       4096
             4194304 MOUNTED     EXTERN       6144       6004           0
         140                       0           6004             0

GROUP_NUMBER NAME                           SECTOR_SIZE BLOCK_SIZE
------------ ------------------------------ ----------- ----------
ALLOCATION_UNIT_SIZE STATE       TYPE     TOTAL_MB    FREE_MB HOT_USED_MB
-------------------- ----------- ------ ---------- ---------- -----------
COLD_USED_MB REQUIRED_MIRROR_FREE_MB USABLE_FILE_MB OFFLINE_DISKS
------------ ----------------------- -------------- -------------
COMPATIBILITY
------------------------------------------------------------
DATABASE_COMPATIBILITY                                       V
------------------------------------------------------------ -
11.2.0.2.0
11.2.0.2.0                                                   N


SQL>

-- NOTE#
-- I have the DISK GROUP is automatically added in the cluster registry.

oracle +ASM1 bhuora02> crsctl stat res ora.TEST.dg -t
--------------------------------------------------------------------------------
NAME           TARGET  STATE        SERVER                   STATE_DETAILS     
----------------------------------------------------------------------------
Local Resources
----------------------------------------------------------------------------
ora.TEST.dg
               ONLINE  ONLINE       bhuora02                                
               ONLINE  ONLINE       bhuora01  

<end node> 5P9i0s8y19Z
dt=Text
<node>
Add ASM DiskGroup 02
3
Oracle CREATE ASM DISKGROUP manually in 11gR2/12C

Create ASM DiskGroup ....!!!!


Node 1

#ls -ltr  /dev/mapper/
lrwxrwxrwx 1 root root       8 Mar 29 10:01 ora_fra_0003p1 -> ../dm-29
lrwxrwxrwx 1 root root       8 Mar 29 10:01 ora_acfs_0001 -> ../dm-43

#oracleasm createdisk -v ORA_0001 /dev/mapper/ora_acfs_0001


# oracleasm listdisks
DATA_0000
FRA_0000
GRID_0000
ORA_0001  <<<<<< New disk 


ls -alrt /dev/oracleasm/disks/ORA*

scan and list 
# date ; hostname;  oracleasm scandisks ; for d in `oracleasm listdisks | sort`; do oracleasm querydisk -p $d; done

Node2
#oracleasm scandisks
Reloading disk partitions: done
Cleaning any stale ASM disks...
Cleaning disk "ORA_0001"
Scanning system for ASM disks...

#oracleasm listdisks
DATA_0000
FRA_0000
GRID_0000
ORA_0001  <<<<<< New disk 



Node3
#oracleasm scandisks
Reloading disk partitions: done
Cleaning any stale ASM disks...
Cleaning disk "ORA_0001"
Scanning system for ASM disks...

#oracleasm listdisks
DATA_0000
FRA_0000
GRID_0000
ORA_0001  <<<<<< New disk 




-- for  Candidate disk !!!


ASMCMD [+] > lsdsk --candidate -p
Group_Num  Disk_Num      Incarn  Mount_Stat  Header_Stat  Mode_Stat  State   Path



set echo off feedback 6 heading on linesize 200 pagesize 300 termout on timing off trimout  on trimspool on  verify  off
clear columns breaks computes
column disk_group_name        format a12           head 'disk group name'
column disk_file_path         format a45           head 'path'
column disk_file_name         format a12           head 'file name'
column disk_file_fail_group   format a12           head 'fail group'
column total_mb               format 999,999,999   head 'file size (mb)'
column used_mb                format 999,999,999   head 'used size (mb)'
column pct_used               format 999.99        head 'pct. used'
break on report on disk_group_name skip 1
compute sum label ""              of total_mb used_mb on disk_group_name
compute sum label "grand total: " of total_mb used_mb on report
SELECT
   NVL(a.name, '[CANDIDATE]')                       disk_group_name
 , b.path                                           disk_file_path
 , b.name                                           disk_file_name
 , b.failgroup                                      disk_file_fail_group
 , b.total_mb                                       total_mb
 , (b.total_mb - b.free_mb)                         used_mb
-- , ROUND((1- (b.free_mb / b.total_mb))*100, 2)    pct_used
FROM v$asm_diskgroup a ,v$asm_disk b 
where a.group_number (+) =b.group_number 
ORDER BY a.name;




Disk Group N Path                                          File Name    Fail Group   File Size (MB) Used Size (MB)
------------ --------------------------------------------- ------------ ------------ -------------- --------------
************
[candidate]  /dev/oracleasm/disks/ORA_0001                                                        0              0
************                                                                         -------------- --------------
                                                                                                  0              0


SQL> CREATE DISKGROUP ORAFS EXTERNAL REDUNDANCY disk '/dev/oracleasm/disks/ORA_0001';


Check the disk group ...

[grid]$ asmcmd -p
ASMCMD [+] > lsdg
State    Type    Rebal  Sector  Block       AU  Total_MB  Free_MB  Req_mir_free_MB  Usable_file_MB  Offline_disks  Voting_files  Name
MOUNTED  EXTERN  N         512   4096  1048576     51200    51150                0           51150              0             N  ORAFS/


ASMCMD [+] > ls -l +         <<<< for DiskGroup !!!

ASMCMD [+] > lsdsk -t -G DATA

Create_Date  Mount_Date  Repair_Timer  Path
01-FEB-18    01-FEB-18   0             ORCL:DATA0
01-FEB-18    01-FEB-18   0             ORCL:DATA1
01-FEB-18    01-FEB-18   0             ORCL:DATA2
01-FEB-18    01-FEB-18   0             ORCL:DATA3



set echo off feedback 6 heading on linesize 200 pagesize 300 termout on timing off trimout  on
set trimspool on  verify  off
clear columns breaks computes
column disk_group_name        format a12           head 'disk group name'
column disk_file_path         format a45           head 'path'
column disk_file_name         format a12           head 'file name'
column disk_file_fail_group   format a12           head 'fail group'
column total_mb               format 999,999,999   head 'file size (mb)'
column used_mb                format 999,999,999   head 'used size (mb)'
column pct_used               format 999.99        head 'pct. used'
break on report on disk_group_name skip 1
compute sum label ""              of total_mb used_mb on disk_group_name
compute sum label "grand total: " of total_mb used_mb on report
SELECT
   NVL(a.name, '[CANDIDATE]')                       disk_group_name
 , b.path                                           disk_file_path
 , b.name                                           disk_file_name
 , b.failgroup                                      disk_file_fail_group
 , b.total_mb                                       total_mb
 , (b.total_mb - b.free_mb)                         used_mb
 , ROUND((1- (b.free_mb / b.total_mb))*100, 2)      pct_used
FROM v$asm_diskgroup a ,v$asm_disk b 
where a.group_number (+) =b.group_number 
ORDER BY a.name;





*********************************************************************

Imp ......

On all the Nodes mount the DiskGroup !!!!!!!!!!!!!!!!!!!!!

SQL>  alter diskgroup ORAFS mount ;

Diskgroup altered.

ASMCMD [+] > lsdg -g     <<<<<<<< check for all node 
*********************************************************************


If Required .. 

sqlplus> alter diskgroup ORACFS set attribute 'compatible.asm'='11.2.0.0.0'; 



set linesize 200 
col compatibility          form a15
col database_compatibility form a25
col name                   form a20
select group_number, name, compatibility, database_compatibility from v$asm_diskgroup;



set linesize 200  pagesize 300
col value for a10
col name  for a50
select group_number, name, value from v$asm_attribute
where 1=1
and group_number=1
;

GROUP_NUMBER NAME                                               VALUE
------------ -------------------------------------------------- ----------
           1 idp.type                                           dynamic
           1 idp.boundary                                       auto
           1 disk_repair_time                                   3.6h




 asmcmd lsattr -G DATA -l
Name                     Value
access_control.enabled   FALSE
access_control.umask     066
au_size                  1048576
cell.smart_scan_capable  FALSE
compatible.asm           12.1.0.0.0
compatible.rdbms         10.1.0.0.0
content.check            FALSE
content.type             data
disk_repair_time         3.6h
failgroup_repair_time    24.0h
idp.boundary             auto
idp.type                 dynamic
phys_meta_replicated     true
sector_size              512
thin_provisioned         FALSE




[grid@rac01 ~]$ asmcmd -p

ASMCMD [+] > lsattr -G DATA -l
Name                     Value
access_control.enabled   FALSE
access_control.umask     066
au_size                  1048576
cell.smart_scan_capable  FALSE
compatible.asm           12.1.0.0.0
compatible.rdbms         10.1.0.0.0
content.check            FALSE
content.type             data
disk_repair_time         3.6h
failgroup_repair_time    24.0h
idp.boundary             auto
idp.type                 dynamic
phys_meta_replicated     true
sector_size              512

thin_provisioned         FALSE

<end node> 5P9i0s8y19Z
dt=Text
<node>
srvctl commands
3
SRVCTL is known as server control utility, which is used to add, remove,relocate and manage different crs services or components in RAC database.

-- 1. STOP DATABASE :
-- SYNTAX – srvctl stop database -d db_name [-o stop_options] where stop_options is normal/immediate(default)/transactional/abort
srvctl stop database -d PRODB -o normal
srvctl stop database -d PRODB -o immediate
srvctl stop database -d PRODB -o transactional
srvctl stop database -d PRODB -o abort

-- 2. START DATABASE
-- SYNTAX – srvctl start database -d db_name [-o start_options] where start_option is nomount/mount/open(default)
srvctl start database -d PRODB -o nomount
srvctl start database -d PRODB -o mount
srvctl start database -d PRODB -o open

-- 3. STOP AN INSTANCE
-- SYNTAX – srvctl stop instance -d db_unique_name [-i “instance_name_list”]} [-o stop_options] [-f]
srvctl stop instance -d PRODB -i PRODB1

-- 4. START AN INSTANCE
-- SYNTAX – srvctl start instance -d db_unique_name [-i “instance_name_list”} [-o start_options]
srvctl start instance -d PRODB -i PRODB1

-- 5. REMOVING DB FROM CRS:
-- SYNTAX – srvctl remove database -d db_unique_name [-f] [-y] [-v]
srvctl remove database -d PRODB -f -y

-- 6. ADDING DB IN CRS :
-- SYNTAX – srvctl add database -d db_unique_name -o ORACLE_HOME [-p spfile]
srvctl add database -d PRODB -o /u01/app/oracle/product/12.1.0.2/dbhome_1 -p +DATA/PRODDB/parameterfile/spfilePRODB.ora

-- 7. REMOVING AN INSTANCE FROM CRS:
-- SYNTAX – srvctl remove instance -d DB_UNIQUE_NAME -i INSTANCE_NAME
srvctl remove instance -d PRODB - I PRODB1 
 
-- 8.ADDING AN INSTANCE TO CRS:
-- SYNTAX – srvctl add instance –d db_unique_name –i inst_name -n node_name
srvctl add instance -d PRODB - i PRODB1 -n rachost1

-- 9. Enable/disable auto restart of the instance
srvctl enable instance -d DB_UNIQUE_NAME-i INSTANCE_NAME 
srvctl disable instance -d DB_UNIQUE_NAME-i INSTANCE_NAME 

-- 10. Enable/disable auto restart of the database
srvctl enable database -d DB_UNIQUE_NAME 
srvctl disable database -d DB_UNIQUE_NAME

-- 11. ADDING A SERVICE:
-- SYNTAX – srvctl add servicec -d {DB_NAME} -s {SERVICE_NAME} -r {“preferred_list”} -a {“available_list”} [-P {BASIC | NONE | PRECONNECT}]
srvctl add service -d PREDB -s PRDB_SRV -r "PREDB1,PREDB2" -a "PREDB2" -P BASIC 

-- 12.REMOVING A SERVICE:
-- SYNTAX – srvctl remove service -d {DB_NAME} -s {SERVICE_NAME}
srvctl remove service -d PREDB -s PRDB_SRV

-- 13. START A SERVICE
-- SYNTAX– srvctl start servicec -d {DB_NAME} -s {SERVICE_NAME}
srvctl start service -d PREDB -s PRDB_SRV 

-- 14. START A SERVICE
-- SYNTAX– srvctl stop servicec -d {DB_NAME} -s {SERVICE_NAME}
srvctl stop service -d PREDB -s PRDB_SRV

-- 15. RELOCATE A SERVICE
-- SYNTAX – srvctl relocate service -d {database_name} -s {service_name} -i {old_inst_name} -r {new_inst_name}
-- e.g..: (Relocating service PRDB_SRV from PREDB2 to PREDB1)
srvctl relocate service -d PREDB -s PRDB_SVC -i PREDB2 -t PREDB1 

-- 16. Check the status of service
-- SYNTAX – srvctl status service -d {database_name} -s {service_name}
srvctl status service -d PREDB -s PRDB_SVC

-- 17. Check the configuration of service
-- SYNTAX – srvctl config service -d {database_name} -s {service_name}
srvctl config service -d PREDB -s PRDB_SVC

-- 18. Check scan listener configuration
srvctl config scan_listener

-- 19. Modify scan_listener port:
-- srvctl modify scan_listener -p {new-SCAN-port} 
grid>srvctl modify scan_listener -p 1523 
grid>$GRID_HOME/bin/srvctl stop scan_listener
grid>$GRID_HOME/bin/srvctl start scan_listener
SQL> Alter system set remote_listener='orcl-scan.stc.com.sa:1523' scope=both sid='*';


-- 20. Manage MGMTDB in oracle 12c:
srvctl status mgmtdb

-- 21. stop and start MGMT db.
srvctl stop mgmtdb
srvctl start mgmtdb

-- 22. Enable trace for srvctl commands:
-- set this to enable trace at os 
SRVM_TRACE=true
export SRVM_TRACE
 
-- run any srvctl command
srvctl status database -d ORACL

-- 23. Set environment variables through srvctl.
-- setenv to set env variables.(ORCL is the db_unique_name)
srvctl setenv database -db ORCL -env "ORACLE_HOME=/oracle/app/oracle/product/12.1.0.2/dbhome_1"
srvctl setenv database -db ORCL -env "TNS_ADMIN=/oracle/app/oracle/product/12.1.0.2/dbhome_1/network/admin"
  
--getenv to view the env setting:
srvctl getenv database -db ORCL
 
ORCL:
ORACLE_HOME=/oracle/app/oracle/product/12.1.0.2/dbhome_1
TNS_ADMIN=/oracle/app/oracle/product/12.1.0.2/dbhome_1/network/admin


-- 24. Check status and config of ASM instance:
srvctl config asm
ASM home: 
Password file: +MGMT/orapwASM
ASM listener: LISTENER
 
 
srvctl status asm
ASM is running on ses11-4,ses11-5

-- 25. Stop and start services running from ORACLE_HOME
srvctl stop home -oraclehome /oracle/product/12.1.0.2/dbhome_1 -statefile /home/oracle/state.txt  -node dbhost-1
 
srvctl start home -oraclehome /oracle/product/12.1.0.2/dbhome_1 -statefile /home/oracle/state.txt  -node dbhost-1
 

-- 26. Create a TAF policy
srvctl add service -db ORCLDB -service TAF_ORCL -preferred ORCLDB1 -available ORCLDB2 -tafpolicy BASIC -failovertype SELECT
 
srvctl start service -db OMPREDB -service TAF_ORCL

<end node> 5P9i0s8y19Z
dt=Text
<node>
move spfile
3
No Title 

HOME / HOW TO, ORACLE RAC / HOW TO MOVE SPFILE FROM FILE SYSTEM TO ASM IN RAC
How To Move Spfile From File System To ASM In RAC
8950 views Less than a minute 1

Below are the steps for moving spfile from file system to ASM diskgroup in RAC.

database name – ORCL
instance_names – ORCL1,ORCL2
oracle DB nodes – dbhstorcl1, dbhstorcl2

1. Check current pfile location:

 
SQL> show parameter pfile
 
NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
spfile                               string      /oracle/app/oracle/product/dbs/temp_init.ora
 
2. Now required directory in ASM diskgroup(where pfile will be created)

 
export ORACLE_HOME=/crsapp/app/oracle/product/12.1.2.0/grid12c
export ORACLE_SID=+ASM1
export PATH=$ORACLE_HOME/bin:$PATH
 
asmcmd
ASMCMD>mkdir +DATA/PARAM
 
3. Create the spfile from pfile:

 
create spfile='+DATA/PARAM/spfileORCL.ora' from pfile='/oracle/app/oracle/product/dbs/temp_init.ora';
 
4. Update INIT FILE on each node (pointing to actual spfile path)


on node 1(dbhstorcl1)

 
cd $ORACLE_HOME/dbs
 
cat initORCL1.ora
SPFILE='+DATA/PARAM/spfileORCL.ora'
 
on node 2(dbhstorcl2)

 
cd $ORACLE_HOME/dbs
 
cat initORCL2.ora
SPFILE='+DATA/PARAM/spfileORCL.ora'
 
5. update database config

srvctl modify database -d racdb1 -p +DATA/PARAM/spfileORCL.ora
 
srvctl config database -d B2CPRE | grep Spfile
Spfile: +CRMDB01/paramfile/spfileB2CPRE.ora
 
6. Restart the databas 

<end node> 5P9i0s8y19Z
dt=Text
<node>
Delete Node
3
-- check the configured instance for the database
select inst_id, instance_name, status, to_char(startup_time, 'DD-MON-YYYY HH24:MI:SS') as "START_TIME"
from gv$instance 
order by inst_id;

# Public IPs
10.100.224.193  loadrpdbnode1.tsysacquiring.org loadrpdbnode1
10.100.224.194  loadrpdbnode2.tsysacquiring.org loadrpdbnode2
10.100.224.195  loadrpdbnode3.tsysacquiring.org loadrpdbnode3

# Private IPs
10.100.226.91    loadrpdbnode1-priv.tsysacquiring.org loadrpdbnode1-priv
10.100.226.92    loadrpdbnode2-priv.tsysacquiring.org loadrpdbnode2-priv
10.100.226.93    loadrpdbnode3-priv.tsysacquiring.org loadrpdbnode3-priv

# Virtual IPs
10.100.224.196  loadrpdbnode1-vip.tsysacquiring.org loadrpdbnode1-vip
10.100.224.197  loadrpdbnode2-vip.tsysacquiring.org loadrpdbnode2-vip
10.100.224.198  loadrpdbnode3-vip.tsysacquiring.org loadrpdbnode3-vip


cluvfy stage -pre crsinst -n loadrpdbnode1,loadrpdbnode2,loadrpdbnode3 -fixup -verbose


-- There where no service created/configured for rptDCE instance, so delete directly
dbca -silent -deleteInstance -nodeList loadrpdbnode1 -gdbName rptDCE -instanceName rptDCE1 -sysDBAUserName sys -sysDBAPassword Tsys$1234


Step 1: -- check if any services are present for the removing Node1 or deleting database instance

-- As there where services configured for txnDCE database instance, so they were needt modify
-- below steps are taking care of it

-- Stop the service running
srvctl stop service -d txnDCE -s transittxn

-- remove the required service from required instance, the instance which needs to be deleted
srvctl remove service -d txnDCE -s transittxn -i txnDCE1

-- add the service for other instance to point
srvctl add service -d txnDCE -s transittxn -r txnDCE2,txnDCE3 -P BASIC

-- configure the service
srvctl config service -d txnDCE -s transittxn

-- modify the service
srvctl modify service -d txnDCE -s transittxn -e select -m BASIC -z 180 -w 5 -j LONG -q TRUE

-- start the service
srvctl start service -d txnDCE -s transittxn

step 2: -- start vncserver
-- on linux window
vncserver :1

login to vncserver to port :1

step 3: -- remove database instance using dbca (GUI)
on vncserver window
open the terminal window
dbca
|
|>> 
	|NEXT Button
	|
	|>> Click on "Instance Management"
	 	 |NEXT Button
	 	 |
	 	 |>> click on "Delete an Instance"
	 	 	 | NEXT Button
	 	 	 |
	 	 	 |>> select Instance that you want to delete, By specifing a sysdba provileged user name and password
	 	 	 	 |NEXT Button
	 	 	 	 |
	 	 	 	 |>> select the node and instance name you would like to delete
	 	 	 	 |NEXT Button
	 	 	 	 |>> Finish -- It will start deleting the instance from the said node

Step 4: -- check in the database, if the instance has been clearly removed

export ORACLE_SID=txnDCE2

and also on 

export ORACLE_SID=rptDCE2


sqlplus / as sysdba
-- check the configured instance by the below sql query
select inst_id, instance_name, status, to_char(startup_time, 'DD-MON-YYYY HH24:MI:SS') as "START_TIME"
from gv$instance 
order by inst_id;


step 5: -- check the configuration of database, those should not list the name of deleted Node
srvctl config database -d txnDCE -v
srvctl config database -d rptDCE -v


Step 6: -- check if the redo log thread, redolog members and undo tablespace are present for removing Node, if so then remove the records for them from database
select thread# from v$thread where upper(instance) = upper('txnDCE1');
select group# from v$log where thread# = 3;
select member from v$logfile where group# in (5,6);

alter database disable thread 3;

alter database drop logfile group 5;

alter database drop logfile group 6;

drop tablespace UNDOTBS1 including contents and datafiles;

alter system reset undo_tablespace scope=spfile sid = 'txnDCE1';

alter system reset instance_number scope=spfile sid = 'txnDCE1';


Step 7: -- Remove the listener if configured for removing Node
-- check the listener
srvctl config listener -a

-- if any listener is configured then remove it
srvctl disable listener -l listener_scan1 -n loadrpdbnode1

srvctl stop listener -n loadrpdbnode1

Step 8: -- stop vip services
srvctl stop  vip -i loadrpdbnode1

srvctl stop vip -i loadrpdbnode1-vip -f
srvctl remove vip -i loadrpdbnode1-vip -f

-- Command of Step 1 thru Step 8 are been executed on other Node which is part of Cluster. This can be execute on same node if your cluster software is not having any issues and which is up and running..

Step 9: -- Update the oracle inventory, for Node being removed
-- as the oracle software owner..

-- On a node to be removed login as oracle user and run the following command from $ORACLE_HOME/oui/bin.
cd $ORACLE_HOME/oui/bin

-- Make sure to specify the -local flag as to not update the inventory on all nodes in the cluster.
./runInstaller -updateNodeList ORACLE_HOME=$ORACLE_HOME "CLUSTER_NODES={loadrpdbnode1}" -local


Step 10: -- deinstall ORACLE_HOME and GRID_HOME software from removing Node by using -local keyword

-- Run deinstall with option -local from $ORACLE_HOME/deinstall from the node to be removed (loadrpdbnode1) in order to remove the RDBMS binaries.

-- Make sure to specify the -local flag as to not remove more than just the local node's software. 
-- If -local is not specified then deinstall would apply to the entire cluster.
/opt/app/oracle/product/11.2.0/db_4/deinstall/./deinstall -local


Step 11: -- Update Oracle Inventory on all other Remaining Nodes which are still part of cluster
-- connect to the working node of the cluster

cd $ORACLE_HOME/oui/bin

-- run the command for those remaining node
./runInstaller -updateNodeList ORACLE_HOME=$ORACLE_HOME "CLUSTER_NODES={loadrpdbnode2,loadrpdbnode3}"


Step 12: -- Remove Node from clusterware (GRID Software). Most of the commands will be execute from root access
-- login to root user
export GRID_HOME=/opt/app/11.2.0/grid4/bin

-- Run the following command as root to determine whether the node you want to delete is active and whether it is pinned.
$GRID_HOME/olsnodes -s -t

-- If the node being removed is already unpinned then you do not need to run the "crsctl unpin css" command below and can proceed to the next step.

-- If the node being removed is pinned with a fixed node number, then run the crsctl unpin css command as 
-- root from a node that is to remain a member of the Oracle RAC in order to unpin the node and expire the CSS lease on the node you are deleting.

$GRID_HOME/crsctl unpin css -n loadrpdbnode1

Step 13: -- Disable Oracle Clusterware

-- Next, disable the Oracle Clusterware applications and daemons running on the node to be deleted from the cluster. 
-- Run the rootcrs.pl script as root from the $GRID_HOME/crs/install directory on the node to be deleted.

/opt/app/11.2.0/grid4/crs/install/./rootcrs.pl -deconfig -force

Step 14: -- Delete Node from Clusterware Configuration
-- From a node that is to remain a member of the Oracle RAC Clusterware, run the following command from the $GRID_HOME/bin directory 
-- as root to update the Clusterware configuration to delete the node from the cluster.
 /opt/app/11.2.0/grid4/bin/crsctl delete node -n loadrpdbnode1
 
 /opt/app/11.2.0/grid4/bin/olsnodes -t -s
 
 Step 15: -- Update GRID Inventory from Node Being Removed
 
  -- Execute on the node being removed to update the inventory, run as the oracle GRID Infrastructure owner
  -- Make sure to specify the -local flag as to not update the inventory on all nodes in the cluster.
 /opt/app/11.2.0/grid4/oui/bin/./runInstaller -updateNodeList ORACLE_HOME=/opt/app/11.2.0/grid4 "CLUSTER_NODES={loadrpdbnode1}" CRS=TRUE -local
 
 
 Step 16: -- De-install Oracle Grid Infrastructure Software
 -- When using a non-shared Grid home, run deinstall as the Grid Infrastructure software owner (Oracle) from the node to be removed 
 -- in order to delete the Oracle Grid Infrastructure software.
  
 /opt/app/11.2.0/grid4/deinstall/./deinstall -local
 
-- NOTE: the above command will asked to run some commands so check that one..
 
 
 
 Step 17: -- Remove specified files as root:

-- This has to run on the removing Node
rm -rf /etc/oraInst.loc
rm -rf /opt/ORCLfmap
rm -rf /opt/app/11.2.0/grid4
rm -rf /opt/app/oracle/product/11.2.0/db_4

Step 18: -- Verify Cluster Configuration
-- Run the following CVU command to verify that the specified node has been successfully deleted from the cluster.
cluvfy stage -post nodedel -n loadrpdbnode1 -verbose

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN scripts
2
-- oem 12c
select DATABASE_NAME, host, status, to_char(start_time,'yyyy-mm-dd hh24:mi') start_time,
       to_char(end_time,'yyyy-mm-dd hh24:mi') end_time, input_type, output_device_type
from mgmt$ha_backup where status !='COMPLETED'  or end_time < sysdate - 7 and  database_name not in ('fspfp','RSMTRP','corefp','SIEP','ltcmip','BOXITLSP','spinp','edvp','cedrp','siep','SPINP','CEDRP','INMLP','WBIP')  
order by start_time


rman target /
crosscheck archivelog all;
delete expired archivelog all;
crosscheck backup;


---create auxiliary/duplicate database from backup
>newsid trece -- . oraenv

--- connect directlry to duplicate database using auxiliary keyword
>rman auxiliary /

run{
allocate auxiliary channel c1 device type disk;
allocate auxiliary channel c2 device type disk;
allocate auxiliary channel c3 device type disk;
allocate auxiliary channel c4 device type disk;
set newname for database to '+DATA2';
duplicate database to trece backup location '/new_expdp006/sample';
}

--- cloning the the DB from source to target using backup location
1) copy the full rman backups of soruce DB to target DB server
2) on Target DB Server
  a) create spfile from pfile
sqlplus "/as sysdba"
sqlplus>create spfile from pfile='?/dbs/initcnac5c.ora';
sqlplus>shutdown immediate

sqlplus "/as sysdba"
sqlplus>startup nomount;

rman auxiliary /

run{
allocate auxiliary channel c1 device type disk;
allocate auxiliary channel c2 device type disk;
allocate auxiliary channel c3 device type disk;
allocate auxiliary channel c4 device type disk;
duplicate database to cnac5c backup location '/depot/oracle/cnacp'
nofilenamecheck;
}

rman target /

RMAN> sql 'alter database datafile 566 offline';

RMAN> copy datafile 566 to '/shared/data901/pctrap/pc_op_0185.dbf';

RMAN> switch datafile 566 to copy;
RMAN> recover datafile 566;

RMAN> sql 'alter database datafile 566 online'; 

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN SQLs
3
-- catalog updation timestamp
SELECT dbms_registry.time_stamp('CATALOG') AS timestamp FROM DUAL

--- resend 5 backups
col TIME_TAKEN_DISPLAY heading "Time_Taken|Display" for a15
col start_time heading "Start|Time" for a19
col end_time heading "End|Time"for a19
col status for a12
select SESSION_KEY, SESSION_STAMP, INPUT_TYPE, STATUS,
   to_char(START_TIME,'dd-mm-yyyy:hh24:mi:Ss') start_time,
   to_char(END_TIME,'dd-mm-yyyy:hh24:mi:Ss') end_time,
   time_taken_display, OUTPUT_BYTES/1024/1024 siz_in_MB
from V$RMAN_BACKUP_JOB_DETAILS
where START_TIME >=sysdate-10
order by session_key;


--- How to Determine RMAN backup size
SELECT TO_CHAR(completion_time, 'YYYY-MON-DD') completion_time, 
  type, round(sum(bytes)/1048576) MB, 
  round(sum(elapsed_seconds)/60) min
 FROM
   (
     SELECT CASE  WHEN s.backup_type='L' THEN 'ARCHIVELOG'  
	             WHEN s.controlfile_included='YES' THEN 'CONTROLFILE'  
                  WHEN s.backup_type='D' AND s.incremental_level=0 THEN 'LEVEL0'  
                  WHEN s.backup_type='I' AND s.incremental_level=1 THEN 'LEVEL1'
		    END type, TRUNC(s.completion_time) completion_time, 
			p.bytes, s.elapsed_seconds
	   FROM v$backup_piece p, v$backup_set s
	  WHERE p.status='A' AND p.recid=s.recid
	 UNION ALL
	 SELECT 'DATAFILECOPY' type, TRUNC(completion_time), output_bytes, 0 elapsed_seconds 
	   FROM v$backup_copy_details
	)
GROUP BY TO_CHAR(completion_time, 'YYYY-MON-DD'), type
ORDER BY 1 ASC,2,3;

-- SQL Query to check size of recovery desk
set pages 9999 lines 300
col name format a40
select name,
	to_char(space_limit, '999,999,999,999') as space_limit,
	to_char(space_limit - space_used + space_reclaimable,
	'999,999,999,999') as space_available,
	round((space_used - space_reclaimable)/space_limit * 100, 1) as pct_full
from v$recovery_file_dest;

set echo on timing on
set lines 140

col username format a10
col OPNAME format a30
col SOFAR format 999999999
col 'WorkDone%' format 999.99
col Start_time format a20

select SID, username, OPNAME, SOFAR, 
	TOTALWORK, SOFAR/TOTALWORK*100 "WorkDone%",
	to_char(START_TIME,'DD-MON-YY hh24:mi:ss') "start_time",
	to_char(sysdate + TIME_REMAINING/3600/24,'DD-MON-YY hh24:mi:ss') "End_At"
from v$session_longops
where sofar!=TOTALWORK 
  and totalwork!=0
  and OPNAME like 'RMAN%'
order by 1;

SELECT SID, SERIAL#, CONTEXT, SOFAR, TOTALWORK, 
ROUND (SOFAR/TOTALWORK*100, 2) "% COMPLETE"
FROM V$SESSION_LONGOPS
WHERE OPNAME LIKE 'RMAN%' AND OPNAME NOT LIKE '%aggregate%'
AND TOTALWORK! = 0 AND SOFAR <> TOTALWORK; 


newsid ecfp
while true
do
sqlplus -s / as sysdba << EOF
Set lines 1000
Col context for A30
SELECT decode(context,1,'This Task:',2,'Agregate:','Total Backup:') Context, sofar, totalwork, round(sofar/totalwork*100,2) "% Complete" FROM gv\$session_longops WHERE opname LIKE 'RMAN%' AND opname LIKE '%aggregate%' AND totalwork != 0 AND sofar <> totalwork UNION SELECT decode(context,1,s.client_info,2,'Agregate:','Total Backup:') Context, sofar, totalwork, round (sofar/totalwork*100,2) "% Complete" FROM GV\$SESSION_LONGOPS SL,GV\$SESSION S WHERE OPNAME LIKE 'RMAN%' AND OPNAME NOT LIKE '%aggregate%' AND TOTALWORK! = 0 AND SOFAR <> TOTALWORK and SL.sid=s.sid and s.CLIENT_INFO like 'rman channel=%';
exit;
EOF
sleep 10
done


SELECT decode(context,1,'This Task:',2,'Agregate:','Total Backup:') Context, sofar, totalwork, round(sofar/totalwork*100,2) "% Complete" 
  FROM gv$session_longops 
 WHERE opname LIKE 'RMAN%' 
   AND opname LIKE '%aggregate%' 
   AND totalwork != 0 
   AND sofar <> totalwork 
 UNION 
SELECT decode(context,1,s.client_info,2,'Agregate:','Total Backup:') Context, sofar, totalwork, round (sofar/totalwork*100,2) "% Complete" 
  FROM GV$SESSION_LONGOPS SL,GV$SESSION S 
 WHERE OPNAME LIKE 'RMAN%' 
   AND OPNAME NOT LIKE '%aggregate%' 
   AND TOTALWORK! = 0 
   AND SOFAR <> TOTALWORK 
   and SL.sid=s.sid 
   AND s.CLIENT_INFO like 'rman channel=%';
===================================================================================
-- pages 300
set lines 3200  
col TIME_TAKEN_DISPLAY for a10
col start_time for a25
col status for a40
col input_type for a20
col end_time for a20
col INPUT_TYPE for a15
col status for a22

select SESSION_KEY, SESSION_STAMP, INPUT_TYPE, STATUS,
   to_char(START_TIME,'dd-mm-yyyy:hh24:mi:Ss') start_time,
   to_char(END_TIME,'dd-mm-yyyy:hh24:mi:Ss') end_time,
   time_taken_display, OUTPUT_BYTES/1024/1024 "size in MB" 
from V$RMAN_BACKUP_JOB_DETAILS
order by session_key;

--find Errors in backup using id and stamp 
set lines 200 
set pages 1000 
select output 
from GV$RMAN_OUTPUT 
where session_recid =1077
and session_stamp =946252862 
order by recid; 
======================================================================================

-- check the rman backup is running , status of rman backup
select SESSION_KEY, INPUT_TYPE, STATUS, 
	to_char(START_TIME,'mm/dd/yy hh24:mi') start_time,
	to_char(END_TIME,'mm/dd/yy hh24:mi')end_time, elapsed_seconds/3600 hrs
from V$RMAN_BACKUP_JOB_DETAILS oter
where START_TIME = (select max(start_time) from v$RMAN_BACKUP_JOB_DETAILS iner where iner.start_time = oter.start_time)-1
order by session_key;

select i.instance_name,i.host_name,r.INPUT_TYPE, 
to_char(r.START_TIME,'dd-mm-yyyy:hh24:mi:Ss') start_time,r.STATUS 
from V$INSTANCE i,V$RMAN_BACKUP_JOB_DETAILS r 
WHERE start_time >= sysdate-1
order by r.session_key; 


set lines 2200
set pages 1000
col cf for 9,999
col df for 9,999
col elapsed_seconds heading "ELAPSED|SECONDS"
col i0 for 9,999
col i1 for 9,999
col l for 9,999
col output_mbytes for 9,999,999 heading "OUTPUT|MBYTES"
col session_recid for 999999 heading "SESSION|RECID"
col session_stamp for 99999999999 heading "SESSION|STAMP"
col status for a10 trunc
col time_taken_display for a10 heading "TIME|TAKEN"
col output_instance for 9999 heading "OUT|INST"
select
  j.session_recid, j.session_stamp,
  to_char(j.start_time, 'yyyy-mm-dd hh24:mi:ss') start_time,
  to_char(j.end_time, 'yyyy-mm-dd hh24:mi:ss') end_time,
  (j.output_bytes/1024/1024) output_mbytes, j.status, j.input_type,
  decode(to_char(j.start_time, 'd'), 1, 'Sunday', 2, 'Monday',
                                     3, 'Tuesday', 4, 'Wednesday',
                                     5, 'Thursday', 6, 'Friday',
                                     7, 'Saturday') dow,
  j.elapsed_seconds, j.time_taken_display,
  x.cf, x.df, x.i0, x.i1, x.l,
  ro.inst_id output_instance
from V$RMAN_BACKUP_JOB_DETAILS j
  left outer join (select
                     d.session_recid, d.session_stamp,
                     sum(case when d.controlfile_included = 'YES' then d.pieces else 0 end) CF,
                     sum(case when d.controlfile_included = 'NO'
                               and d.backup_type||d.incremental_level = 'D' then d.pieces else 0 end) DF,
                     sum(case when d.backup_type||d.incremental_level = 'D0' then d.pieces else 0 end) I0,
                     sum(case when d.backup_type||d.incremental_level = 'I1' then d.pieces else 0 end) I1,
                     sum(case when d.backup_type = 'L' then d.pieces else 0 end) L
                   from
                     V$BACKUP_SET_DETAILS d
                     join V$BACKUP_SET s on s.set_stamp = d.set_stamp and s.set_count = d.set_count
                   where s.input_file_scan_only = 'NO'
                   group by d.session_recid, d.session_stamp) x
    on x.session_recid = j.session_recid and x.session_stamp = j.session_stamp
  left outer join (select o.session_recid, o.session_stamp, min(inst_id) inst_id
                   from GV$RMAN_OUTPUT o
                   group by o.session_recid, o.session_stamp)
    ro on ro.session_recid = j.session_recid and ro.session_stamp = j.session_stamp
where j.start_time > trunc(sysdate)-10
order by j.start_time;

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN change DBID/NID
3
-- Changing DB ID for the Oracle Database

-- When you clone the database, the DB ID remains same as like the source database, 
-- if you need to change to the different DB ID, then this note will be useful. This is 
-- very much useful as in the case of working with RMAN.

-- The DBID is an unique identifier for a database. You should only change the DBID of a database 
-- when really needed since a new DBID,

-- 1. invalidates previously taken backups and backup information
-- 2. invalidates previously generated archivelogs
-- 3. resets the log sequence to 1

-- The DBID is used in RMAN's recovery catalog. Also you cannot recover archived redo logs when 
-- there is a DBID mismatch. Changing the database DB_NAME has less consequences with respect
-- to database backup and recovery.

-- Follow the below steps to change the DB ID in Oracle10g and Oracle11g databases:

-- 1. Identify the DBID of the database

SQL> select dbid from v$database;

DBID

———-

1272957858

-- 2. Shutdown the database in normal mode

SQL> shutdown immediate

Database closed.
Database dismounted.
ORACLE instance shut down.

-- 3. Start the database to mount phase

SQL> startup mount

ORACLE instance started.
Total System Global Area    150667264 bytes
Fixed Size                    1335080 bytes
Variable Size                92274904 bytes
Database Buffers             50331648 bytes
Redo Buffers                  6725632 bytes

Database mounted.

SQL> exit

Disconnected from Oracle Database 11g Enterprise Edition Release 11.2.0.1.0 – Production

With the Partitioning, OLAP, Data Mining and Real Application Testing options

-- 4. In the Terminal Window, execute the nid command

[oracle@apps ~]$ which nid

/u01/app/oracle/product/11.2.0/dbhome_1/bin/nid

[oracle@apps ~]$ nid target=/

DBNEWID: Release 11.2.0.1.0 – Production on Fri Mar 25 16:32:17 2011
Copyright (c) 1982, 2009, Oracle and/or its affiliates. All rights reserved.
Connected to database RC (DBID=1272957858)
Connected to server version 11.2.0
Control Files in database:
/u01/app/oracle/oradata/rc/control01.ctl
/u01/app/oracle/oradata/rc/control02.ctl

Change database ID of database RC? (Y/[N]) => Y

Proceeding with operation
Changing database ID from 1272957858 to 2943969233
Control File /u01/app/oracle/oradata/rc/control01.ctl – modified
Control File /u01/app/oracle/oradata/rc/control02.ctl – modified
Datafile /u01/app/oracle/oradata/rc/system01.db – dbid changed
Datafile /u01/app/oracle/oradata/rc/sysaux01.db – dbid changed
Datafile /u01/app/oracle/oradata/rc/undotbs01.db – dbid changed
Datafile /u01/app/oracle/oradata/rc/def_perm01.db – dbid changed
Control File /u01/app/oracle/oradata/rc/control01.ctl – dbid changed
Control File /u01/app/oracle/oradata/rc/control02.ctl – dbid changed

Instance shut down

Database ID for database RC changed to 2943969233.

All previous backups and archived redo logs for this database are unusable.

Database has been shutdown, open database with RESETLOGS option.

Succesfully changed database ID.

DBNEWID – Completed succesfully.

-- 5. Bounce back the database to mount phase

[oracle@apps ~]$ sqlplus / as sysdba

SQL*Plus: Release 11.2.0.1.0 Production on Fri Mar 25 16:33:14 2011
Copyright (c) 1982, 2009, Oracle. All rights reserved.
Connected to an idle instance.

SQL> startup mount

ORACLE instance started.
Total System Global Area    150667264 bytes
Fixed Size                    1335080 bytes
Variable Size                92274904 bytes
Database Buffers             50331648 bytes
Redo Buffers                  6725632 bytes

Database mounted.

-- 6. Open the database with resetlog option

SQL> alter database open resetlogs ;

Database altered.

SQL>

-- 7. Identify the new changed DBID

SQL> select dbid from v$database;

DBID

———-

2943969233


=====================================================================================

-- Another Methode for using RMAN




------Change the DBID using below command for FOCUSDEV
1)	Shutdown database and then startup mount database FOCUSDEV.
2)	Run command nid TARGET=/
3)  shut immediate;  
3)	startup mount;
4)	ALTER DATABASE OPEN RESETLOGS;

-----Register FOCUSDEV database in Recover catalog database :-

 19.a) rman rcvcat rman_fga/******@aorman11
 19.b) register database;

 ======================================================================================================
 
Changing DBID with NID

oracle@fgsdcrfocdb01:/appl/oracle[FOCUSDEV]>sqlplus "/as sysdba"

SQL*Plus: Release 10.2.0.4.0 - Production on Tue Jan 9 11:43:41 2018

Copyright (c) 1982, 2007, Oracle.  All Rights Reserved.


Connected to:
Oracle Database 10g Enterprise Edition Release 10.2.0.4.0 - 64bit Production
With the Partitioning option

SQL> select name, open_mode from v$database;

NAME      OPEN_MODE
--------- ----------
FOCUSDEV  READ WRITE

SQL> exit
Disconnected from Oracle Database 10g Enterprise Edition Release 10.2.0.4.0 - 64bit Production
With the Partitioning option


oracle@fgsdcrfocdb01:/appl/oracle[FOCUSDEV]>sqlplus "/as sysdba"

SQL*Plus: Release 10.2.0.4.0 - Production on Tue Jan 9 11:49:18 2018

Copyright (c) 1982, 2007, Oracle.  All Rights Reserved.


Connected to:
Oracle Database 10g Enterprise Edition Release 10.2.0.4.0 - 64bit Production
With the Partitioning option

SQL> select name, open_mode from v$database;

NAME      OPEN_MODE
--------- ----------
FOCUSDEV  READ WRITE

SQL> shut immediate;
Database closed.
Database dismounted.
ORACLE instance shut down.
SQL> startup mount
ORACLE instance started.

Total System Global Area 1048576000 bytes
Fixed Size                  2089176 bytes
Variable Size             255856424 bytes
Database Buffers          780140544 bytes
Redo Buffers               10489856 bytes
Database mounted.
SQL>
SQL> exit
Disconnected from Oracle Database 10g Enterprise Edition Release 10.2.0.4.0 - 64bit Production
With the Partitioning option
oracle@fgsdcrfocdb01:/appl/oracle[FOCUSDEV]>nid TARGET=/

DBNEWID: Release 10.2.0.4.0 - Production on Tue Jan 9 11:51:56 2018

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

Connected to database FOCUSDEV (DBID=4167916323)

Connected to server version 10.2.0

Control Files in database:
    /appl/oracle/FOCUSDEV/control/control1/control01.ctl
    /appl/oracle/FOCUSDEV/control/control2/control02.ctl
    /appl/oracle/FOCUSDEV/control/control3/control03.ctl

Change database ID of database FOCUSDEV? (Y/[N]) => Y

Proceeding with operation
Changing database ID from 4167916323 to 175736797
    Control File /appl/oracle/FOCUSDEV/control/control1/control01.ctl - modified
    Control File /appl/oracle/FOCUSDEV/control/control2/control02.ctl - modified
    Control File /appl/oracle/FOCUSDEV/control/control3/control03.ctl - modified
    Datafile /appl/oracle/FOCUSDEV/system1/SYSTEM_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/undo/undo2/UNDOTBS_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/system1/SYSAUX_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/USERS_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/FOCUS_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/FOCUS_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/FOCUS_03.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/FOCUS_04.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/AQ_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/FOCUS_05.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/FOCUS_06.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/FOCUS_07.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/FOCUSTMP_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/lucheng.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data4/dbadmin_data.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/FOCUS_08.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/mobile01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/ora_FOCUSDEV_JBM_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data5/ora_FOCUSDEV_tools_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/dbadmin_data01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data1/ora_FOCUSDEV_FOCUS_GPSC_DATA_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data4/ora_FOCUSDEV_FOCUS_LOB_DATA_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index1/ora_FOCUSDEV_FOCUS_GPSC_IDX_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index2/ora_FOCUSDEV_FOCUS_LRG_IDX_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_MED_DATA_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data4/ora_FOCUSDEV_FOCUS_SML_DATA_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index3/ora_FOCUSDEV_FOCUS_SML_IDX_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index2/ora_FOCUSDEV_FOCUS_MED_IDX_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data1/ora_FOCUSDEV_FOCUS_GPSC_DATA_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data1/ora_FOCUSDEV_FOCUS_GPSC_DATA_03.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data1/ora_FOCUSDEV_FOCUS_GPSC_DATA_04.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data1/ora_FOCUSDEV_FOCUS_GPSC_DATA_05.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data4/ora_FOCUSDEV_FOCUS_LOB_DATA_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index1/ora_FOCUSDEV_FOCUS_GPSC_IDX_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index1/ora_FOCUSDEV_FOCUS_GPSC_IDX_03.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index1/ora_FOCUSDEV_FOCUS_GPSC_IDX_04.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index1/ora_FOCUSDEV_FOCUS_GPSC_IDX_05.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index1/ora_FOCUSDEV_FOCUS_GPSC_IDX_06.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index1/ora_FOCUSDEV_FOCUS_GPSC_IDX_07.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index2/ora_FOCUSDEV_FOCUS_LRG_IDX_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index2/ora_FOCUSDEV_FOCUS_LRG_IDX_03.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index2/ora_FOCUSDEV_FOCUS_LRG_IDX_04.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index2/ora_FOCUSDEV_FOCUS_LRG_IDX_05.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index2/ora_FOCUSDEV_FOCUS_LRG_IDX_06.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index2/ora_FOCUSDEV_FOCUS_LRG_IDX_07.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index2/ora_FOCUSDEV_FOCUS_LRG_IDX_08.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index2/ora_FOCUSDEV_FOCUS_LRG_IDX_09.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index2/ora_FOCUSDEV_FOCUS_LRG_IDX_10.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index1/ora_FOCUSDEV_FOCUS_LRG_IDX_11.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index1/ora_FOCUSDEV_FOCUS_LRG_IDX_12.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index1/ora_FOCUSDEV_FOCUS_LRG_IDX_13.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index1/ora_FOCUSDEV_FOCUS_LRG_IDX_14.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_MED_DATA_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_MED_DATA_03.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_MED_DATA_04.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_MED_DATA_05.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_MED_DATA_06.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_03.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_04.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_05.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_06.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_07.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_08.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_09.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_10.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_11.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_12.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_13.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_14.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_15.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_16.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_17.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_18.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_19.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_20.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_21.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_22.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data2/ora_FOCUSDEV_FOCUS_LRG_DATA_23.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_LRG_DATA_24.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_LRG_DATA_25.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_LRG_DATA_26.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_LRG_DATA_27.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_LRG_DATA_28.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index2/ora_FOCUSDEV_FOCUS_MED_IDX_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index3/ora_FOCUSDEV_FOCUS_MED_IDX_03.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index3/ora_FOCUSDEV_FOCUS_SML_IDX_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data4/ora_FOCUSDEV_FOCUS_SML_DATA_03.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data4/ora_FOCUSDEV_FOCUS_SML_DATA_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_LRG_DATA_29.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data3/ora_FOCUSDEV_FOCUS_LRG_DATA_30.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data4/ora_FOCUSDEV_FOCUS_LRG_DATA_31.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data1/ora_FOCUSDEV_FOCUS_GPSC_DATA_06.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data4/ora_FOCUSDEV_FOCUS_LRG_DATA_32.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/data4/ora_FOCUSDEV_FOCUS_LRG_DATA_33.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index3/ora_FOCUSDEV_FOCUS_TEST_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/index3/ora_FOCUSDEV_FOCUS_TEST_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/temp2/USER_TEMP_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/temp2/TEMP_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/temp2/TEMP_01.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/temp2/USER_TEMP_02.dbf - dbid changed
    Datafile /appl/oracle/FOCUSDEV/temp2/USER_TEMP_03.dbf - dbid changed
    Control File /appl/oracle/FOCUSDEV/control/control1/control01.ctl - dbid changed
    Control File /appl/oracle/FOCUSDEV/control/control2/control02.ctl - dbid changed
    Control File /appl/oracle/FOCUSDEV/control/control3/control03.ctl - dbid changed
    Instance shut down

Database ID for database FOCUSDEV changed to 175736797.
All previous backups and archived redo logs for this database are unusable.
Database has been shutdown, open database with RESETLOGS option.
Succesfully changed database ID.
DBNEWID - Completed succesfully.

oracle@fgsdcrfocdb01:/appl/oracle[FOCUSDEV]>sqlplus "/as sysdba"

SQL*Plus: Release 10.2.0.4.0 - Production on Tue Jan 9 11:52:35 2018

Copyright (c) 1982, 2007, Oracle.  All Rights Reserved.

Connected to an idle instance.

SQL> startup mount
ORACLE instance started.

Total System Global Area 1048576000 bytes
Fixed Size                  2089176 bytes
Variable Size             255856424 bytes
Database Buffers          780140544 bytes
Redo Buffers               10489856 bytes
Database mounted.
SQL> ALTER DATABASE OPEN RESETLOGS;

Database altered.

SQL> exit
Disconnected from Oracle Database 10g Enterprise Edition Release 10.2.0.4.0 - 64bit Production
With the Partitioning option
oracle@fgsdcrfocdb01:/appl/oracle[FOCUSDEV]>
oracle@fgsdcrfocdb01:/appl/oracle[FOCUSDEV]>
oracle@fgsdcrfocdb01:/appl/oracle[FOCUSDEV]>
oracle@fgsdcrfocdb01:/appl/oracle[FOCUSDEV]>
oracle@fgsdcrfocdb01:/appl/oracle[FOCUSDEV]>ps -ef|grep pmon
oracle    5178     1  0 11:53 ?        00:00:00 ora_pmon_FOCUSDEV
oracle    5976 14816  0 11:55 pts/2    00:00:00 grep pmon
oracle   31698     1  0  2017 ?        00:07:47 ora_pmon_FOCUSPRF
oracle@fgsdcrfocdb01:/appl/oracle[FOCUSDEV]>
oracle@fgsdcrfocdb01:/appl/oracle[FOCUSDEV]>rman target /

Recovery Manager: Release 10.2.0.4.0 - Production on Tue Jan 9 11:55:43 2018

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

connected to target database: FOCUSDEV (DBID=175736797)

RMAN>


======================================================================




oracle@fgsdcrfocdb01:/appl/oracle[FOCUSDEV]>rman rcvcat rman_fga/******@aorman11

Recovery Manager: Release 10.2.0.4.0 - Production on Tue Jan 9 12:05:04 2018

Copyright (c) 1982, 2007, Oracle.  All rights reserved.

connected to recovery catalog database

RMAN> connect target;

RMAN-00571: ===========================================================
RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============
RMAN-00571: ===========================================================
RMAN-06004: ORACLE error from recovery catalog database: RMAN-20001: target database not found in recovery catalog

RMAN> register database;

database registered in recovery catalog
starting full resync of recovery catalog
full resync complete

RMAN> 

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN Usefull
3
-- RMAN UseFull Commands

-- for RMAN Cloning check URL
http://rd-oracledba.blogspot.in/search/label/RMAN%20Cloning

RMAN will take database backup in two methods, default method is backup set.
1.backup set 
2.image copy
================================================================================================

-- Diff between backup set and image copy:
A backup set consists of one or more backup pieces, which are physical files written 
in a format that only RMAN can access.You can also take compressed backups using backup set.

Image copy is a bit-for-bit copy of a database file created on disk. Image copies are 
identical to copies created with operating system commands like cp on Linux or COPY on Windows, 
but are recorded in the RMAN repository and so are usable by RMAN.
================================================================================================

-- if you want to look at the current retention policy for all registered databases
-- you can do it like this:
 
select a.name "db_name", b.value 
 from rc_database a join rc_rman_configuration b using (db_key) 
where b.name = 'RETENTION POLICY'; 
================================================================================================

-- Monitor RMAN Backups:

set pages 2000 lines 200
COL STATUS FORMAT a9
col START_TIME for a20
col END_TIME for a20
COL hrs FORMAT 999.99

SELECT session_key, session_recid,
    INPUT_TYPE,
    STATUS,
    TO_CHAR(START_TIME,'mm/dd/yy hh24:mi') start_time,
    TO_CHAR(END_TIME,'mm/dd/yy hh24:mi') end_time,
    ELAPSED_SECONDS/3600 hrs,
    INPUT_BYTES/1024/1024/1024 SUM_BYTES_BACKED_IN_GB,
    OUTPUT_BYTES/1024/1024/1024 SUM_BACKUP_PIECES_IN_GB,
    OUTPUT_DEVICE_TYPE    
 FROM V$RMAN_BACKUP_JOB_DETAILS
ORDER BY SESSION_KEY;
================================================================================================

-- BACKUP SET examples :

-- To take full backup using tag:
RMAN> BACKUP AS BACKUPSET TAG 'FULL_DB' DATABASE PLUS ARCHIVELOG;

-- To take compressed backups:
RMAN> BACKUP AS COMPRESSED BACKUPSET DATABASE PLUS ARCHIVELOG;

-- To creates a level 1 differential incremental backup:
RMAN> BACKUP INCREMENTAL LEVEL 1 DATABASE;

-- To creates a level 1 cumulative incremental backup:
RMAN> BACKUP INCREMENTAL LEVEL 1 CUMULATIVE DATABASE;

-- To take archivelog backup:
rman> backup archivelog all;
rman> backup filesperset 10 archivelog all;
rman> backup archivelog all delete all input;  
rman> backup archivelog all not backed up 1 times;
rman> backup archivelog all not backed up 1 times tag 'arch_tape_backup';
rman> backup  as compressed backupset filesperset 1 archivelog until time 'sysdate - 2/24';

-- To list backups:
rman> list backup summary;
rman> list backup;
rman> list backup of database:
rman> list backuppiece 'db_rameshxsx_vgdffj_01';
rman> list backupset 13202;
rman> list backup of datafile 10;
rman> list backupset of datafile 10;

-- To list and delete archive files:
rman> list archivelog all;
rman> list backup of archivelog all;
rman> list archivelog from sequence 1145 until sequence 1250;
rman> list backup of archivelog until time 'sysdate-2';
rman> list backup of archivelog from sequence 78895 until sequence 92566;

rman> delete archivelog all;
rman> delete archivelog until time 'sysdate -2';
rman> delete noprompt archivelog until time 'sysdate -3/24';
rman> delete archivelog all completed before 'sysdate-5';
rman> delete noprompt archivelog all  backed up 1 times to device type sbt;
rman> delete noprompt archivelog until time 'sysdate-2' backed up 1 times to device type disk;
rman> delete noprompt archivelog until time 'sysdate - 2/24' backed up 1 times to device type disk;

rman> delete noprompt archivelog until time 'sysdate - 2/24' backed up 1 times to device type sbt;

Note: All delete all input means RMAN will delete archive logs from archive destinations
once they are backed up.

# List archives by log sequence
RMAN> LIST BACKUP OF ARCHIVELOG FROM SEQUENCE 3398;

# List archives with NEXT_TIME (see <a href="http://docs.oracle.com/cd/B28359_01/server.111/b28320/dynviews_1016.htm">v$archived_log.next_time</a>) is  greater then FROM TIME - last day (24 hours)
RMAN> LIST BACKUP OF ARCHIVELOG FROM TIME "SYSDATE-1";

# List archives between two dates 
RMAN> LIST BACKUP OF ARCHIVELOG 
  FROM TIME "TO_DATE('09/05/2013 22:00:00', 'MM/DD/YYYY hh24:mi:ss')" 
  UNTIL TIME "TO_DATE('09/06/2013 04:00:00', 'MM/DD/YYYY hh24:mi:ss')"; 

================================================================================================

-- Image copy examples:

-- To take full image backup with archivelogs
RMAN> BACKUP AS COPY TAG 'FULL_DB' DATABASE PLUS ARCHIVELOG; // with archive logs

RMAN> BACKUP AS COPY INCREMENTAL LEVEL 0 TAG  'FULL_DB'  DATABASE;

-- To take full image backup to specific location:
rman> backup as copy database tag 'full_db' format '/u02/backup/%b';

rman> backup as copy database tag 'full_db' format '/u01/backup/%f_%b';

(or)

allocate channel ch1 device type disk format '/u02/backup/%b';
backup as copy database tag 'full_db';
release channel ch1;

-- To take incremental for image backup:
RMAN> BACKUP INCREMENTAL LEVEL 1 FOR RECOVER OF COPY WITH TAG 'FULL_DB' DATABASE;

-- Rollforward full image backup with incremental:
RMAN> RECOVER COPY OF DATABASE WITH TAG 'FULL_DB';
or 
RMAN> RECOVER COPY OF DATABASE WITH TAG 'FULL_DB' UNTIL TIME 'SYSDATE-1';

-- Back Up Controlfile  as copy:
RMAN>BACKUP AS COPY CURRENT CONTROLFILE;

-- Backup recovery area to tape:
RMAN> BACKUP RECOVERY AREA TAG 'FULL_DB';

-- To take archivelog copy backup
RMAN> BACKUP AS COPY ARCHIVELOG;

-- To delete archivelogs copy backup:
RMAN> DELETE COPY OF ARCHIVELOG;

-- To list copy backups:
RMAN> LIST COPY OF BACKUP;
RMAN> LIST COPY OF ARCHIVELOG;
RMAN> LIST COPY OF ARCHIVELOG FROM SEQUENCE 10;
RMAN> List Copy of archivelog from sequence 10 until sequence 20;
RMAN> LIST COPY;

-- Delete copy backups:
RMAN> delete copy of database tag='REFRESH_DB_8th_DEC';
RMAN> delete copy TAG='REFRESH_DB_8th_DEC';
================================================================================================

-- Restore and Recover:
  
RESTORE CONTROLFILE FROM "/backup/rman/control_file_bkp"; 
RESTORE CONTROLFILE FROM AUTOBACKUP;
RESTORE ARCHIVELOG FROM SEQUENCE 56767 UNTIL SEQUENCE 56770 THREAD 1;
RESTORE DATABASE;
RECOVER DATABASE;
RECOVER DATABASE UNTIL CANCEL USING BACKUP CONTROLFILE;
RECOVER DATABASE SKIP FOREVER TABLESPACE
TEST_TS1
TEST_TS2
TEST_TS3;
================================================================================================

-- Set Commands:

set until sequence 978878 thread 2;
set archivelog destination to '/backup/ARCH';
================================================================================================

-- Crosscheck and Expired:

Crosschecks update RMAN repository information about backups whose repository records do not 
match their physical status. 

For example, if a user removes archived logs from disk with an os commands (ex: rm) , the 
repository still indicates that the logs are on disk, when in fact logs are not there. 
So by using crosscheck command we are checking physical existance of files and if files are 
not there then rman will mark these missing/deleted files as expired.

rman> crosscheck backup;
rman> crosscheck backup of database;

rman> crosscheck backupset;
rman> crosscheck copy;
rman> crosscheck archivelog all ;

rman> list expired;
rman> list expired archivelog all;
rman> list expired backup;
rman> list expired backup of archivelog all;
rman> delete expired backup;
rman> delete expired archivelog all;
rman> delete force noprompt expired copy tag='REFRESH_DB_8th_DEC';

RMAN> list backup completed between 'sysdate -1' and 'sysdate';
RMAN> list backup completed between 'sysdate -14' and 'sysdate -7';
RMAN> list backup of database completed between 'sysdate -7' and 'sysdate';
RMAN> list backup of database completed between "to_date('10/07/2019','dd/mm/yyyy')" and "to_date('16/07/2019','dd/mm/yyyy')";
RMAN> LIST backup of database completed after "to_date('01/10/2018','mm/dd/yyyy')";
RMAN> list backup of database completed between "to_date('01/10/2018','dd/mm/yyyy')" and "to_date('08/10/2018','dd/mm/yyyy')";

RMAN> list backup of archivelog from time "to_date('01/10/2018 22:00:00', 'dd/mm/yyyy hh24:mi:ss')" until time "to_date('08/10/2018 04:00:00', 'dd/mm/yyyy hh24:mi:ss')";
RMAN> list backup of archivelog time between "to_date('01-JAN-2018 00:00:00','DD-MON-YYYY HH24:MI:SS')" and "to_date('08-JAN-2018 00:00:00','DD-MON-YYYY HH24:MI:SS')";
RMAN> list backup of archivelog time between "to_date('01/08/2018','dd/mm/yyyy')" and "to_date('09/08/2018','dd/mm/yyyy')";
RMAN> list backup of archivelog from time "to_date('01-12-2018','mm-dd-yyyy')";

RMAN> list backup of archivelog from time "to_date('01/08/2018 22:00:00', 'dd/mm/yyyy hh24:mi:ss')" until time "to_date('08/08/2018 04:00:00', 'dd/mm/yyyy hh24:mi:ss')";

RMAN> list backup of spfile completed between "to_date('01-SEP-2018 00:00:00','DD-MON-YYYY HH24:MI:SS')" and "to_date('08-SEP-2018 00:00:00','DD-MON-YYYY HH24:MI:SS')";

RMAN> list backup of controlfile completed between "to_date('01-AUG-2018 00:00:00','DD-MON-YYYY HH24:MI:SS')" and "to_date('08-AUG-2018 00:00:00','DD-MON-YYYY HH24:MI:SS')";
RMAN> list backup of datafile 1 completed between 'sysdate -10' and 'sysdate';

RMAN> list backup of tablespace SYSTEM completed between 'sysdate -10' and 'sysdate';

RMAN> list backup of datafile 1 completed between '06-OCT-2018' and '25-DEC-2018'; 

================================================================================================

-- Obsolete backups:

Backups will become obsolete based on retention policy.For example if retention policy is 
"recovery window 7 days" then rman will mark backups as an obsolete after 7 days.

RMAN> REPORT OBSOLETE;
RMAN> DELETE OBSOLETE;
RMAN> DELETE FORCE OBSOLETE;
================================================================================================

-- validate :

You can use validate cmd to check database files and archived redo log files are physically 
and logically  corrupted.

RMAN> BACKUP VALIDATE;
RMAN> BACKUP VALIDATE DATABASE ARCHIVELOG ALL;
RMAN> VALIDATE BACKUPSET 3;
RMAN> VALIDATE DATAFILE 5;
RMAN> VALIDATE DATAFILECOPY ALL;
================================================================================================

-- Catalog files :

Add information about file copies and user-managed backups to the RMAN repository.

CATALOG START WITH '/u02/backup/';
CATALOG START WITH '+FRA_DG';
CATALOG BACKUPPIECE '/u02/backup/annnf0_full1_0.276.895785483';
CATALOG DATAFILECOPY '/u02/backup/users01.dbf' LEVEL 0;
CATALOG ARCHIVELOG '/u02/backup/thread_1_seq_8.321.895785769', '/u02/backup/thread_2_seq_2.326.895781619';
================================================================================================

-- Change :

Change command will update the availability status of backups and copies recorded in the 
RMAN repository.For example if you don't want any particular backup then 
we can mark them as unavailable.

CHANGE BACKUPSET 4 UNAVAILABLE;

CHANGE ARCHIVELOG ALL UNCATALOG; // for suppose if we moved archive files from one 
location to another location...then we can uncatlog those files by using change cmd.
================================================================================================

-- Configuration settings :

you can change rman configuration settings and below is one of the example 
to change the retention policy.

rman> show all;
rman> configure retention policy to redundancy 3;
rman> configure retention policy to recovery window of 7 days;
rman> configure retention policy clear;   // to set to default 
================================================================================================

-- Backup controlfile to trace :

RMAN> ALTER DATABASE BACKUP CONTROLFILE TO TRACE;

RMAN> ALTER DATABASE BACKUP CONTROLFILE TO TRACE AS '/U02/BACKUP/CONTROLFILE.CTL';
================================================================================================

-- Control File and Server Parameter File Autobackups:

If CONFIGURE CONTROLFILE AUTOBACKUP is ON, then RMAN automatically backs up the control 
file and the current sp file at the end of a successful BACKUP command.

RMAN> show CONTROLFILE AUTOBACKUP;

RMAN configuration parameters for database with db_unique_name RAMESH1 are:

CONFIGURE CONTROLFILE AUTOBACKUP ON; # default
================================================================================================

-- To run the rman script:

rman target / @rman_backup.cmd log=rman_backup.log

rman_backup.cmd
---------------

run
{ 
allocate channel ch1 device type disk FORMAT '/u02/backup/%b';
BACKUP AS COPY DATABASE TAG 'FULL_DB';
release channel ch1;
}
================================================================================================

-- Trace a rman session:

rman target / debug trace rman_ramesh1_crosscheck.trc log rman_ramesh1_crosscheck.log

RUN
{
ALLOCATE CHANNEL C1 DEVICE TYPE DISK;
ALLOCATE CHANNEL C2 DEVICE TYPE SBT;
ALLOCATE CHANNEL C3 DEVICE TYPE DISK;
ALLOCATE CHANNEL C4 DEVICE TYPE SBT;
CROSSCHECK COPY;

}
================================================================================================

-- control_file_record_keep_time parameter value change:

select name, ISSYS_MODIFIABLE from v$parameter where name='control_file_record_keep_time';
alter system set control_file_record_keep_time=10 scope=both sid='*';

================================================================================================

-- LIST & RESTORE SPFILE BACKUPS 
-- RESTORE spfile
RUN
{
  ALLOCATE CHANNEL T1 TYPE 'sbt_tape' PARMS 'ENV=(TDPO_OPTFILE=...tsm_ora.opt)' ;
  
  # restore spfile to specified location
  RESTORE SPFILE TO '/tmp/spfile<oracle_sid>.ora' ;
  
  # restore spfile as pfile to specified location
  RESTORE SPFILE TO PFILE '/tmp/init<oracle_sid>.ora' ;
}


RUN
{  
  ALLOCATE CHANNEL T1 TYPE 'sbt_tape' PARMS 'ENV=(TDPO_OPTFILE=...tsm_ora.opt)' ;

  # restore spfile before date
  SET UNTIL TIME "TO_DATE('01/01/2013 22:00:00', 'MM/DD/YYYY hh24:mi:ss')" ;
  RESTORE SPFILE TO PFILE '/tmp/init<oracle_sid>_20130101.ora' ;
  
  RELEASE CHANNEL T1 ;
}


---Full backup script example
rman target / catalog rmancat/Kjdrt103e@rcat1p
-- Full BRMAN Backup script
run 
{
   set command id to 'FullRMAN_Backup_RUAUDP';
   sql 'alter system checkpoint local';
   allocate channel t0 type 'sbt_tape';
   allocate channel t1 type 'sbt_tape';
   allocate channel t2 type 'sbt_tape';
   allocate channel t3 type 'sbt_tape';
   send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA)';
   backup 
     database
      skip inaccessible tag ruaudp_H_D_ON_20200612071539
      filesperset 20
      format 'rmanDBFull_%d_%s_%p_%t_D_20200612071539';
      (database);
   sql 'alter system switch logfile';
   sql 'alter system archive log current';
   crosscheck archivelog all;
   backup tag ruaudp_H_D_ON_20200612071539
      filesperset 100
      format 'rmanArchD_%d_%s_%p_%t_D_20200612071539'
      (archivelog all delete input);	  
	backup spfile tag ruaudp_H_D_ON_20200612071539 
	  format 'rmanSPfile_%d_%s_%p_%t_D_20200612071539'; 
	backup current controlfile tag ruaudp_H_D_ON_20200612071539 
	   format 'rmanCntrlFile_%d_%s_%p_%t_D_20200612071539'; 
   delete expired archivelog all;
   release channel t0;
   release channel t1;
   release channel t2;
   release channel t3;
}

run { 
 allocate channel ch1 type Disk maxpiecesize = 1900M FORMAT '/path/hbk_%t_set%s_piece%p_dbid%I.rman'; 
 backup incremental level 0 
 tag cold_db_f 
 filesperset 1 
 (database); 
 backup archivelog all delete all input FORMAT '/path/hbk_%t_set%s_piece%p_dbid%I.rman'; 
 backup spfile format '/oradata/orcl/rmanb/spfile_%d_%s_%T_dbid%I.rman'; 
 backup current controlfile format '/path/ctl_%t_dbid%I.rman'; 
} 
 


RUN
{
  ALLOCATE CHANNEL ch11 TYPE DISK MAXPIECESIZE 10G;
  BACKUP
  FORMAT '/u03/app/oracle/TEST/%d_D_%T_%u_s%s_p%p'
  DATABASE
  CURRENT CONTROLFILE
  FORMAT '/u03/app/oracle/TEST/%d_C_%T_%u'
  SPFILE
  FORMAT '/u03/app/oracle/TEST/%d_S_%T_%u'
  PLUS ARCHIVELOG
  FORMAT '/u03/app/oracle/TEST/%d_A_%T_%u_s%s_p%p';
  RELEASE CHANNEL ch11;
}

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN 12c Recovery
3
-- https://www.datavail.com/blog/recover-a-table-from-an-rman-backup-in-an-oracle-12c/
-- Single table recovery

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN Tablespace Recovery
3
-- Also check the step by step of restoration on different DB server
https://www.slideshare.net/OsamaMustafa/restore-rman-different-host

Today’s blog post will discuss how to recover a subset of an Oracle database. Many of you would have 
come across different recovery scenarios, but I’ll be talking about a very different one that happened to me. 
The following are the details after receiving a call from a client, and checking the environment myself.

i) This is a data warehouse production database, which is sized around 5TB, running on 10gR2 version on AIX 
platform.

ii) Weekly level 0 and frequent archive log compressed RMAN tape backup(Netbackup) is configured for this 
database.

iii) Client DBA confirmed that the level 0 backup was executed successfully. and started his scheduled 
purge activity for older partitions. He accidentally deleted the partitions that belong to year 2011 instead 
of requested deletion for year 2010 partitions for a table (due to typo on notepad using copy/paste of 
earlier commands.)

v) He found the issue after executing the required sql script by verifying the log file. He decided not 
to delete the  associated datafiles that belonged to year 2011 tablespace from DB and OS level.

vi) The range partitions are used, based on monthly data, and dedicated tablespaces are used for a year 
partition data. There are more than 200 tablespaces, spread across multiple partitioned tables.

vii) There was no recycle bin (flashback drop) feature enabled and no flashback feature is configured. 
This database also doesn’t have any standby databases configured.

viii) The logical backup for this database has never happened, but block change tracking was enabled 
for this database.

So, I recently got completed level 0 tape backup only.These older partitions are useful only during month 
end reporting. The traditional method of restoring the entire database would be time prone and also with 
the need of 5TB additional storage.

Thanks to RMAN feature (Ref MOS Note:223543.1), we can restore only subset of database. Hence suggested 
client that I would  create a test database with only required tablespaces. From the existing datafiles 
(tablespace) at OS level, I found the approximate size of deleted partition tablespace was around 300G. 
Along with required SYSTEM/SYSSAUX/UNDO tablespaces, the required disk space for this test database was 
around 420G.

Client SA team created a new test server identifical with the existing server.Most of the required additional mount points were created as soft links on the existing disk space of 600G(we need space for archivelogs too). After cloning the existing oracle home to new server, I used the following steps to complete this recovery activity.

1. Logged into DW production database(db name: test – as usual) and identified the required tablespaces are ‘SYSTEM’,’SYSAUX’,’UNDOTBS’ and ‘TEST_DETAIL_2011_TS’. Also identified the associated datafiles numbers. For eg. file_id’s 1,2,3,149,163,164,149,106,107,108,109,110,181,189 and 192.

2. Connected to rman recovery catalog schema(rman_cat) from this database and Identified the same TAG value used for all level 0 backup files,I consider the TAG value as “TEST_FULLDB_THU151013”. Also identified the require Media for these datafiles and controlfiles as HT0008,HT0014 and HT0015.Updated storage team to keep these Media into tape drive till this activity completion.

3. Logged into test database server and started the instance using nomount state with parameter values large_pool_size=500M and job_queue_processes=0.

4. Connected to RMAN utility with recovery catalog schema to restore the control files first.

RMAN> run
{
allocate channel t1 type ‘sbt_tape’;
send ‘NB_ORA_client=test’;
restore controlfile from tag ‘TEST_FULLDB_THU151013’;
release channel t1;
}

5. Mounted the database using sqlplus utility and disabled the block change tracking feature.

SQL> alter database mount;
SQL> ALTER DATABASE DISABLE BLOCK CHANGE TRACKING;

6. Connected to RMAN utility again with recovery caatlog schema to restore the required tablespaces.

RMAN> run
{
allocate channel t1 type ‘sbt_tape’;
allocate channel t2 type ‘sbt_tape’;
allocate channel t3 type ‘sbt_tape’;
send ‘NB_ORA_client=test’;
restore tablespace system,undotbs1,sysaux,TEST_DETAIL_2011_TS from tag ‘TEST_FULLDB_THU151013’;
sql “alter database datafile 1,2,3,149,163,164,149,106,107,108,109,110,181,189,192 online”;
release channel t1;
release channel t2;
release channel t3;
}

7. Gathered the last archivelog sequence backed up on this level 0 backup from RMAN utility.For 
eg 272150.

8. Created rman command file named recover_db.rman as the list of tablespaces to be skipped was huge. 
Used  ‘set until sequence’ clause to restore the required archive logs and recover the database. 
Here is the syntax used.

restore_db.rman
run
{
allocate channel t1 type ‘sbt_tape’;
allocate channel t2 type ‘sbt_tape’;
allocate channel t3 type ‘sbt_tape’;
send ‘NB_ORA_client=test’;
set until sequence 272151; ==> (Max sequence + 1)
recover database skip forever tablespace
ABC_IND_TS,ABC_DATA_TS,DEF_INDX_TS,DEF_REF_TS_01,DEF_REF_TS_01,ACCT_TAB_TS_01,ACCT_TAB_TS_02,
………………………………………………………………………………… ==> List of tablespaces other than 4 required
TPG_DATA_TS_01,TPG_IND_TS_01,USERS,XDB;
release channel t1;
release channel t2;
release channel t3;
}

9. Executed this command file using RMAN utility with recovery catalog schema.
RMAN> @restore_db.rman

10. Used sqlplus utility and opened the database using resetlogs option. Then converted this test 
database to run on noarchivelog mode.
SQL> recover database using backup controlfile until cancel;
cancel
SQL> alter database open resetlogs;
SQL> shutdown immediate
SQL> startup mount
SQL> alter database noarchivelog;
SQL> alter database open;

11. Confirmed the deleted partitions now exists with data on test database.
SQL> select count(1) from <table> partition(<part name>);

12. Handed over this test database and client DBA exported the partitions for year 2011 and 
imported into the production DW database.

So here we created a test database with the size of 420G instead of a whole database sized 5TB, 
which definitely saved time and space. Though there are much easier options available in any common 
production database environment (such as using restore from recyclebin or flashback standby database 
to point in time,) this method was really helpful when I couldn’t use those options.

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN Incrl bkup & reco. stdby
3
-- How to recover Standby database from a missing archivelog

-- Recovering a Standby database from a missing archivelog

-- A Physical Standby database relies on continuous application of archivelogs from a Primary 
-- Database to be in synch with it. In Oracle Database versions prior to 10g in the event of 
-- an archivelog gone missing or corrupt you had to rebuild the standby database from scratch.

-- In 10g you can use an incremental backup from SCN and recover the standby using the same to 
-- compensate for the missing archivelogs as shown below

-- Step 1: On the standby database check the current scn.

STDBY> set numwidth 30;
STDBY> select current_scn from v$database;

CURRENT_SCN
-----------
123456789

-- Step 2: On the primary database create the needed incremental backup from the above SCN

C:\Documents and Settings\frego>rman target /

RMAN> {
allocate channel c1 type disk; 
BACKUP INCREMENTAL FROM SCN 123456789 DATABASE
FORMAT '/tmp/incr_bkp/incr_bkp_%U';
}

-- Step 3: Cancel managed recovery at the standby database

STDBY>alter database recover managed standby database cancel;

-- scp the backup files to standby server to /tmp/incr_bkp folder.

-- Step 4: Catalog the Incremental Backup Files at the Standby Database

/tmp/incr_bkp > rman target /

RMAN> CATALOG START WITH '/tmp/incr_bkp/';

-- Step 5: Apply the Incremental Backup to the Standby Database

RMAN> RECOVER DATABASE NOREDO;

-- Step 6: Put the standby database back to managed recovery mode.

STDBY>> recover managed standby database disconnect;

-- From the alert.log you will notice that the standby database is still looking for the old log files

/*
	*************************************************
	FAL[client]: Failed to request gap sequence 
	GAP - thread 1 sequence ....
	**************************************************

	This is because the controlfile has not been updated.
	Hence the standby controlfile has to be recreated
*/

-- Step 7: On the primary create new standby controlfile

PRIM>alter database create standby controlfile as '/tmp/incr_bkp/standby01.ctl';

-- Step 8: At Standby .. Replace standby controlfile at all location as shown by controle_files parameter.

-- Copy the standby control file to the standby site. Shutdown the stanby database and replace 
-- the stanby controlfiles and restart the standby database in managed recovery mode...

-- Note: - FOR STANDBY DATABASES ON ASM additional steps is required after replacing the stanby 
-- control file. Like renaming datafiles ...
===============================================================================================================


-- Same as Above just and duplicate example


-- 2. Find the SCN number in the standby DB:

SQL> select current_scn from v$database;
CURRENT_SCN
-----------
57154168307

-- 3. If the apply process is running and not able to fetch the archive log gap files then the recovery 
 process need to be cancelled and the DB shutdown.

SQL>alter database recover managed standby database cancel;
SQL> shutdown;

-- 4. Now using the recorded SCN an incremental backup is run on the source database. This backs 
-- up all blocks which have changed since this SCN and will be applied directly on the target.

[oracle@lv-degdb10 bdump]$ rman target=/

RMAN> run {
 	allocate channel d1 type disk;
 	allocate channel d2 type disk;
	 BACKUP INCREMENTAL FROM SCN 59156548562 DATABASE FORMAT '/stdby_tmp/stdby_%U' tag 'FORSTANDBY';
	release channel d1;
	release channel d2;
}

-- 5. Then SCP copy these backup sets onto the target environment.

-- 6. Catalog these new backups for use by the controlfile on the target.

$ rman target /

RMAN> catalog start with '/opt/backup_drop';

-- 7. Mount the database and recover using the incremental backups recently cataloged.

RMAN> RECOVER DATABASE NOREDO;

-- 8. Get a list of the datafiles which are part of the database.

SQL> set lines 200
SQL> col name format a60
SQL> select file#, name from v$datafile order by file# ;

-- 9. Create a new standby controlfile from source DB and SCP to DG environment.

RMAN> BACKUP CURRENT CONTROLFILE FOR STANDBY FORMAT '/stdby_tmp/stdby_ctl_%U' tag 'FORSTDBY';

-- 10. Shutdown the database, place in mount mode and restore the standby control file.

RMAN> RESTORE STANDBY CONTROLFILE FROM '/opt/backup_drop/st_ctl_khfjdf6kd';

-- 11. Since the source and the target datafile paths are different with the new 
--   controlfile we need to let the existing data file path in the DG environment to be updated. 
--   Using the catalog command we can achieve this.

RMAN> CATALOG START WITH '+DATA01/LVDEGDB1/DATAFILE';

-- 12. Update the DG controlfile with new datafile path (if different diskgroups used).

RMAN> SWITCH DATABASE TO COPY;

-- 13. On the standby before restarting the Managed recovery process, clear the standby redo log files.

SQL>ALTER DATABASE CLEAR LOGFILE GROUP 1;
SQL ALTER DATABASE CLEAR LOGFILE GROUP 2;

-- 14. on the standby start-up the recovery process.

SQL>ALTER DATABASE RECOVER MANAGED STANDBY DATABASE DISCONNECT;

-- 15. Reconfirming the SCN number on source and target. The SCN’s are much closer than before

-- On source

SQL> select current_scn from v$database;
CURRENT_SCN
-----------
57154854789

-- On standby

SQL> select current_scn from v$database;
CURRENT_SCN
-----------
57154851498

-- Secondary database synced with Primary without using archive logs!

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN auxiliary-dup DB
3


-- save the below rman script in .rcv file and call that script in rman using 
-- cmdfile option
-- /comm_db/usmgenq/rman_usmgenq_refresh_aux_sct.rcv
run {
allocate auxiliary channel c1 device type DISK;
allocate auxiliary channel c2 device type DISK;
allocate auxiliary channel c3 device type DISK;
allocate auxiliary channel c4 device type DISK;
allocate auxiliary channel c5 device type DISK;
allocate auxiliary channel c6 device type DISK;
allocate auxiliary channel c7 device type DISK;
allocate auxiliary channel c8 device type DISK;

allocate channel t1 device type DISK;
allocate channel t2 device type DISK;
allocate channel t3 device type DISK;
allocate channel t4 device type DISK;
allocate channel t5 device type DISK;
allocate channel t6 device type DISK;
allocate channel t7 device type DISK;
allocate channel t8 device type DISK;

DUPLICATE TARGET DATABASE
  TO usmgenq
  FROM ACTIVE DATABASE
  NOFILENAMECHECK
;
}


-- run rman in background job
nohup rman target sys/"rr4m4db_6y6p"@usmgenp1 auxiliary sys/"rr4m4db_6y6p"@amolirumgdbqa01:1521/usmgenq.monsanto.com cmdfile=/comm_db/usmgenq/rman_usmgenq_refresh_aux_sct.rcv msglog /comm_db/usmgenq/usmgenq_refresh_logs_002.log  &

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN Restore
3
-- to check if there is any restore point created using 
-- CREATE RESTORE POINT PROD_REFRESH GUARANTEE FLASHBACK DATABASE;
RMAN> corsscheck archivelog all;
RMAN> validate archivelog all;
RMAN> list archivelog all;
RMAN> alter database flashback on;
RMAN> CREATE RESTORE POINT PROD_REFRESH GUARANTEE FLASHBACK DATABASE;

RMAN> LIST RESTORE POINT ALL;

OR 

-- SQL query to check the restore point and details


col NAME for a30
col time for a50
set linesize 400

select INST_ID, NAME, SCN, to_char(TIME,'MM/DD/YYYY HH24:MI:SS'), 
       DATABASE_INCARNATION#, GUARANTEE_FLASHBACK_DATABASE, STORAGE_SIZE 
FROM GV$RESTORE_POINT;


-- Backup Archive log from multiple location
run
{
allocate channel d1 type disk;
allocate channel d2 type disk;
allocate channel d3 type disk;
allocate channel d4 type disk;
allocate channel d5 type disk;
allocate channel d6 type disk;
allocate channel d7 type disk;
allocate channel d8 type disk;
backup archivelog FROM SEQUENCE 96363 UNTIL SEQUENCE 96488 thread 1 format '/opt/oracle/admin/rjin2/arch_%d_%T_%U';
release channel d1;
release channel d2;
release channel d3;
release channel d4;
release channel d5;
release channel d6;
release channel d7;
release channel d8;
}


-- Try to restore archive log from different/multiple location
RMAN> run
{
allocate channel d1 type disk;
allocate channel d2 type disk;
allocate channel d3 type disk;
allocate channel d4 type disk;
allocate channel d5 type disk;
allocate channel d6 type disk;
allocate channel d7 type disk;
allocate channel d8 type disk;
set archivelog destination to '/opt/oracle/admin/rjin2/';
restore archivelog from logseq=96363 until logseq=96488 thread=1;
release channel d1;
release channel d2;
release channel d3;
release channel d4;
release channel d5;
release channel d6;
release channel d7;
release channel d8;
}

-- Catalog backupset
catalog start with '/opt/oracle/admin/rjin2/';


-- easy way for the duplcation/auxiliary DB
rman target sys/xxxx@RJINUXP
connect auxiliary sys/xxxx@RJINUXR
run {
allocate channel prmy1 type disk;
allocate channel prmy2 type disk;
allocate channel prmy3 type disk;
allocate auxiliary channel stby1  type disk;
allocate auxiliary channel stby2  type disk;
allocate auxiliary channel stby3  type disk;
backup as copy archivelog from logseq 96363 until logseq 96488 thread=1 auxiliary format '+RJIN_FRA/';
}



-- If you must move the OS file of an RMAN backup, moving it at the OS level is perfectly fine 
-- and will not in any way alter your ability to restore it, but RMAN must know where to find 
-- it.  So how do you tell RMAN about that file's new location?  Enter CATALOG BACKUPPIECE.  
-- This command simply registers into the RMAN catalog (that is, the database's CONTROL FILES and 
-- possibly an RMAN Catalog database)
RMAN> catalog backuppiece 'D:\backup\fra\f681762_bkup_1_1';


-- And there is no risk to register a backuppiece from another database, as RMAN warns you that  
-- this backuppiece does not belong to this one and gives you the SID of the database 
-- it comes from:
RMAN> CATALOG BACKUPPIECE 'V:\backup\fra\0TS0SMQB_1_1' ;

ORA-19870: erreur lors de la restauration de l'ÚlÚment de sauvegarde V:\BACKUP\FRA\0TS0SMQB_1_1

ORA-19691: V:\BACKUP\FRA\0TS0SMQB_1_1 provient d'une autre base de donnÚes : id=3682310869, nom=OTHERDB

 

-- Just in passing, you can also catalog an RMAN datafile copy: 
RMAN> CATALOG DATAFILECOPY 'D:\oradata\users01.dbf'; 

-- and ARCHIVE LOGs: 

RMAN> CATALOG ARCHIVELOG 'D:\archives\MYDB\ARC0000027304_0837506108.arc', 'D:\archives\MYDB\ARC0000027308_0837506108.arc';

-- But what if you have many backuppieces to register with RMAN?   
-- Enter CATALOG RECOVERY AREA and CATALOG START WITH.

-- First, if you want to move many RMAN files into your Flash Recovery Area (FRA), 
-- do it at the OS level:
using cp command to copy backup/archive files to other disk
cp '+ARCH/rman/backup/bkup_190283_1_1' to 'D:/rman/backup_12345_1_1'

-- then run CATALOG RECOVERY AREA 
-- RMAN will list the files it found the ask for your manual confirmation to catalog all of them
-- https://community.oracle.com/blogs/dearDBA/2017/04/20/rman-how-to-use-catalog-start-with

Summary up:---
1) first move your RMAN files at the OS level. Don't be afraid to move files that do not pertain 
   to your DB: RMAN will detect them.
2) Run CATALOG START WITH 'newlocation' or CATALOG DB_RECOVERY_FILE_DEST to tell RMAN about the 
   new location
3) run CROSSCHECK for RMAN to list any file not found at the OS level as EXPIRED
4) run DELETE EXPIRED to remove any mention of the old location from the RMAN catalog

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN Arch to DiskGroup
3



-- copy back the required archive logs from mount point to diskgroup
RMAN> copy archivelog  '/oraclemg/usmgenq_archive_bkp_230418/thread_1_seq_181371.318.974158781' to '+ARCH';

or 


-- or catalog the archive log file to recovery purpose
RMAN>catalog archivelog '/oraclemg/usmgenq_archive_bkp_230418/thread_1_seq_181371.318.974158781'

<end node> 5P9i0s8y19Z
dt=Text
<node>
Archive frm ASM to Local Disc
3

-- How to automatically copy archivelogs from ASM to local disc

-- This script will create folder on local disk, copy archivelogs of yesterday to 
-- this folder and compress folder with zip

#!/bin/bash
. /home/oracle/.bash_profile
cd /home/oracle/backup/rman/archivelogs/
mkdir `date -d "1 day ago" "+%Y_%m_%d"`
. /home/oracle/grid_env
for i in $(asmcmd ls +FRA/TESTDB/ARCHIVELOG/`date -d "1 day ago" "+%Y_%m_%d"`);
do asmcmd cp +FRA/TESTDB/ARCHIVELOG/`date -d "1 day ago" "+%Y_%m_%d"`/$i /home/oracle/backup/rman/archivelogs/`date -d "1 day ago" "+%Y_%m_%d"`;
done
zip -r `date -d "1 day ago" "+%Y_%m_%d"`.zip `date -d "1 day ago" "+%Y_%m_%d"`
rm -r `date -d "1 day ago" "+%Y_%m_%d"`





ls | while read FILE
do
   asmcmd cp +ARCH/REMEDYP/ARCHIVELOG/2017_05_05 +data/orcl/datafile/$FILE
done



for i in $(asmcmd ls +ARCH/REMEDYP/ARCHIVELOG/2017_05_05); do
  asmcmd cp +ARCH/REMEDYP/ARCHIVELOG/2017_05_05/$i /remedy_datamigration/archive_log
done

<end node> 5P9i0s8y19Z
dt=Text
<node>
mv datafile to asm to asm
3
1.- Check the assumption is correct (datafile was created on a different diskgroup):
SQL> select file_name, status
from dba_data_files
where tablespace_name = 'xxx';
FILE_NAME	STATUS
------------------------------------------------ ---------
+DATB/xxx/datafile/yyy.339.718314941 AVAILABLE
+DATB/xxx/datafile/yyy.358.718303181 AVAILABLE
+DATB/xxx/datafile/yyy.338.718314943 AVAILABLE
+DATB/xxx/datafile/yyy.309.718325181 AVAILABLE
+DATA/xxx/datafile/yyy.366.724161769 AVAILABLE
+DATB/xxx/datafile/yyy.281.724238729 AVAILABLE

2.- Change the status of the datafile to offline:
SQL> alter database datafile '+DATA/xxx/datafile/yyy.366.724161769' offline;

3.- Copy the datafile using RMAN:
[oracle@ssssssssssssss bdump]$ rman target /
Recovery Manager: Release 10.2.0.4.0 - Production on Thu Jul 22 15:52:52 2010
Copyright (c) 1982, 2007, Oracle. All rights reserved.
connected to target database: xxx (DBID=4255406167)

RMAN> copy datafile '+DATA/xxx/datafile/yyy.366.724161769' to '+DATB';

4.- Update the Oracle data dictionary with the new information:
SQL> alter database rename
file '+DATA/xxx/datafile/yyy.366.724161769'
to '+DATB/xxx/datafile/yyy.280.725039609';

Once the datafile has been renamed in the data dictionary, Oracle removes the old copy of the file in ASM

5.- Rename the ASM datafile copy using RMAN.
[oracle@ssssssssssssss bdump]$ rman target /
Recovery Manager: Release 10.2.0.4.0 - Production on Thu Jul 22 15:58:31 2010
Copyright (c) 1982, 2007, Oracle. All rights reserved.
connected to target database: xxx (DBID=4255406167)

RMAN> switch datafile '+DATB/xxxx/datafile/yyy.280.725039609' to copy;


6.- Perform media recovery of the datafile:
RMAN> recover datafile '+DATB/xxx/datafile/yyy.280.725039609';

7.- Make the datafile available by changing the status to online:
SQL> alter database datafile '+DATB/xxx/datafile/yyy.280.725039609' online;

8.- Check the status and location of the datafile:
SQL> select file_name, status from dba_data_files where tablespace_name = 'yyy';
FILE_NAME	STATUS
------------------------------------------------ ---------
+DATB/xxx/datafile/yyy.339.718314941 AVAILABLE
+DATB/xxx/datafile/yyy.358.718303181 AVAILABLE
+DATB/xxx/datafile/yyy.338.718314943 AVAILABLE
+DATB/xxx/datafile/yyy.309.718325181 AVAILABLE
+DATB/xxx/datafile/yyy.280.725039609 AVAILABLE
+DATB/xxx/datafile/yyy.281.724238729 AVAILABLE



======================================================================================================
-- multiple datafiles


'+DATA/wpdbe/datafile/indexes.1422.1045074933','+DATA/wpdbe/datafile/icmlfq32.1421.1045075059' to '+DATA2/wpdbe/datafile/indexes.1422.1045074933','+DATA2/wpdbe/datafile/icmlfq32.1421.1045075059'

alter database datafile '+DATA/wpdbe/datafile/indexes.1422.1045074933' offline 
alter database datafile '+DATA/wpdbe/datafile/icmlfq32.1421.1045075059' offline;


1.- Check the assumption is correct (datafile was created on a different diskgroup):
SQL> select file_name, status, tablespace_name
from dba_data_files
where tablespace_name like 'ICM%';

2.- Change the status of the datafile to offline:
SQL> alter database datafile '+DATA/wpdbe/datafile/indexes.1422.1045074933' offline; 
SQL> alter database datafile '+DATA/wpdbe/datafile/icmlfq32.1421.1045075059' offline;

3.- Copy the datafile using RMAN:
[oracle@ssssssssssssss bdump]$ rman target /
RMAN> copy datafile '+DATA/wpdbe/datafile/indexes.1422.1045074933' to '+DATA2';
RMAN> copy datafile'+DATA/wpdbe/datafile/icmlfq32.1421.1045075059' to '+DATA2';


4.- Update the Oracle data dictionary with the new information:
SQL> alter database rename
file '+DATA/wpdbe/datafile/indexes.1422.1045074933','+DATA/wpdbe/datafile/icmlfq32.1421.1045075059'
to '+DATA2/wpdbe/datafile/indexes.1454.1047357651','+DATA2/wpdbe/datafile/icmlfq32.1455.1047357673';

Once the datafile has been renamed in the data dictionary, Oracle removes the old copy of the file in ASM

5.- Rename the ASM datafile copy using RMAN.
[oracle@ssssssssssssss bdump]$ rman target /
RMAN> switch datafile '+DATA2/wpdbe/datafile/indexes.1454.1047357651','+DATA2/wpdbe/datafile/icmlfq32.1455.1047357673' to copy;

6.- Perform media recovery of the datafile:
RMAN> recover datafile '+DATA2/wpdbe/datafile/indexes.1454.1047357651','+DATA2/wpdbe/datafile/icmlfq32.1455.1047357673';

7.- Make the datafile available by changing the status to online:
SQL> alter database datafile '+DATA2/wpdbe/datafile/indexes.1454.1047357651' online; 
SQL> alter database datafile '+DATA2/wpdbe/datafile/icmlfq32.1421.1045075059' online;

8.- Check the status and location of the datafile:
SQL> select file_name, status from dba_data_files where tablespace_name in ('ICMLFQ32','INDEXES');

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN dup DB
3
set echo on
run
{
 allocate channel tgt1 device type disk ;
 allocate channel tgt2 device type disk ;
 allocate auxiliary channel aux1 device type disk ;
 duplicate target database to UAT from active database
  spfile
      parameter_value_convert 'prod', 'uat', 'PROD', 'UAT'
   set control_files='+UAT1', '+UAT2'
   set db_file_name_convert='+PROD1', '+UAT1', '+PROD2', '+UAT2' 
   set log_file_name_convert='+PROD1', '+UAT1', '+PROD2', '+UAT2'
   set cluster_database='false'
  logfile
    group 1 ('+UAT1', '+UAT2') size 10m,
    group 2 ('+UAT1', '+UAT2') size 10m,
    group 3 ('+UAT1', '+UAT2') size 10m
 ;
} 

-------------------------------------------------------------------

--steps to duplicate the DB

-- Clone using RMAN DUPLICATE
--1) Add Static Listener Entry in UAT
[grid@uat01 ~]$ . oraenv
ORACLE_SID = [grid] ? +ASM1
The Oracle base has been set to /u01/app/oracle

Add below:

SID_LIST_LISTENER =
(SID_LIST =
  (SID_DESC =
    (GLOBAL_DBNAME = UAT)
    (ORACLE_HOME = /u01/app/oracle/product/11.2.0/dbhome_1)
    (SID_NAME = UAT)
   )
)

[grid@uat01 ~]$ lsnrctl reload

--2) Add TNS entry for UAT in PROD

UAT =
  (DESCRIPTION =
    (ADDRESS = (PROTOCOL = TCP)(HOST = uat01)(PORT = 1521))
    (CONNECT_DATA =
      (SERVER = DEDICATED)
      (SERVICE_NAME = UAT)
    )
  )
  
--3) Copy Password File from PROD to UAT

Copy Password file from PROD database Node 1 location $ORACLE_HOME/dbs/orapwPROD1 to 
UAT Node1 location $ORACLE_HOME/dbs/orapwUAT:


[oracle@prod01 ~]$ scp $ORACLE_HOME/dbs/orapwPROD1 uat01:/u01/app/oracle/product/11.2.0/dbhome_1/dbs/orapwUAT
  
-- 4) Verify TNS Connectivity to UAT from PROD
Make sure that connection from Prod Node 1 to UAT Node 1 is working via TNS and instance shows Idle instance:


[oracle@prod01 ~]$ sqlplus sys/oracle@uat as sysdba

-- 5) Create Directory Structures for UAT
Make sure that directory structure to support various parameters (e.g. audit_file_dest, etc.) for UAT database is pre-created with valid permissions. For example:

[oracle@uat01 ~]$ mkdir -p /u01/app/oracle/admin/UAT/adump

-- 6) Start UAT (auxiliary) instance in NOMOUNT mode
On Node 1 of UAT cluster, from oracle user, create parameter file initUAT.ora in $ORACLE_HOME/dbs directory with just below parameters:

initUAT.ora
-------------

db_name='UAT'
memory_max_target=10G
memory_target=8G

[oracle@uat01]$ sqlplus sys/oracle@uat as sysdba

SQL> startup nomount

-- 7) Connect RMAN to Target (PROD) and Auxiliary (UAT) using TNS

rman target sys/oracle@prod auxiliary sys/oracle@uat | tee /tmp/rmanDUPLICATE.log


-- 8) DUPLICATE Command Execution
set echo on
run
{
allocate channel tgt1 device type disk ;
allocate channel tgt2 device type disk ;
allocate auxiliary channel aux1 device type disk ;
duplicate target database to UAT from active database
  spfile
      parameter_value_convert 'prod', 'uat', 'PROD', 'UAT'
   set control_files='+UAT1', '+UAT2'
   set db_file_name_convert='+PROD1', '+UAT1', '+PROD2', '+UAT2' 
   set log_file_name_convert='+PROD1', '+UAT1', '+PROD2', '+UAT2'
   set cluster_database='false'
  logfile
    group 1 ('+UAT1', '+UAT2') size 10m,
    group 2 ('+UAT1', '+UAT2') size 10m,
    group 3 ('+UAT1', '+UAT2') size 10m
;
}

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN 8i
3
https://oracle-base.com/articles/8i/recovery-manager-8i 

-- Solution
-- 1. Restore control file using Backup Exec
-- -- 1-1. Create a restore job
-- -- 1-2. Select to the most recent backup set under Control Files in the restore selection list
-- -- 1-3. Set Oracle restore options

Select "Restore the control file only" option.  

Unselect "Recover using redo logs" option.

1-4. Submit the job.

-- 2. Restore database file using Recovery Manager (RMAN)
-- -- 2-1. Open command prompt then start rman

C:\>rman target=/ nocatalog
  
Recovery Manager: Release 8.1.7.0.0 - Production
  
RMAN-06006: connected to target database: ora817 (not mounted)
RMAN-06009: using target database controlfile instead of recovery catalog
 

-- -- 2-2. Mount the database

After the restore job of the control file only, the database is being nomount mode. 

RMAN> ALTER DATABASE MOUNT;
RMAN-03022: compiling command: alter db 
RMAN-06199: database mounted
 

-- -- 2-3. Run the following script

RUN {
    ALLOCATE CHANNEL ch0 TYPE 'SBT_TAPE';
    RESTORE DATABASE;
    RECOVER DATABASE;
    RELEASE CHANNEL ch0;
  }
 

 -- This command will fail with RMAN-06054: media recovery requesting unknown log: 
 -- thread 1 scn <number> because Oracle 8i RMAN cannot automatically detect the most 
 -- recent available REDO log which is called Online REDO log.

-- For instance of output of the script:

RMAN> RUN {
2>  ALLOCATE CHANNEL ch0 TYPE 'SBT_TAPE';
3>  RESTORE DATABASE;
4>  RECOVER DATABASE;
5>  RELEASE CHANNEL ch0;
6>  }

 

-- -- 2-4. Write down the SCN number and exit RMAN

375414 is the number in this instance.


-- 3. Continue to recover using sqlplus

-- -- 3-1. Open command prompt then start sqlplus 

C:\>sqlplus /nolog

  
SQL> connect / as sysdba
Connected.
 

-- -- 3-2. Make sure of the path of the Online REDO log

SQL> select * from v$logfile;
 

-- -- 3-3. Make sure of the status of the Online REDO log

SQL> select * from v$log;


-- -- 3-4. perform recover database command

RECOVER DATABASE USING BACKUP CONTROLFILE UNTIL CANCEL;
 

-- -- 3-5. Enter the path of the Online REDO log file

a) In this instance, requested SCN is 375414.
b) From the result of v$log, GROUP# 1 has the SCN 375414.
c) From the result of v$logfile, C:\ORACLE\ORADATA\ORA817\REDO03.LOG is a file of GROUP# 1.
d) In accordance with the result of v$log and v$log file, enter the full path to the prompt.


SQL> recover database using backup controlfile until cancel
ORA-00279: change 375414 generated at 05/11/2011 14:12:03 needed for thread 1
ORA-00289: suggestion : C:\ORACLE\ORA81\RDBMS\ARC00011.001
ORA-00280: change 375414 for thread 1 is in sequence #11
  
Specify log: {<RET>=suggested | filename | AUTO | CANCEL}
C:\ORACLE\ORADATA\ORA817\REDO03.LOG

-- -- 3-5 Cancel the recovery

Once the path of the Online REDO log is entered, the recover command requests the next log file.
Because REDO03.LOG (SCN 375414) is the log file the most recent available, enter CANCEL to the prompt.

ORA-00279: change 375417 generated at 05/11/2011 14:15:15 needed for thread 1
ORA-00289: suggestion : C:\ORACLE\ORA81\RDBMS\ARC00012.001
ORA-00280: change 375417 for thread 1 is in sequence #12
ORA-00278: log file 'C:\ORACLE\ORADATA\ORA817\REDO03.LOG' no longer needed for this recovery
  
Specify log: {<RET>=suggested | filename | AUTO | CANCEL}
CANCEL 
  
Media recovery cancelled.

-- -- 3-6 open the database with resetlogs option

SQL> alter database open resetlogs;
   Database altered.
 

-- 4. Get full backup using Backup Exec as soon as possible after the resetlogs

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN List cmds
3
RMAN LIST commands .
Oracle RMAN LIST commands ..

--- some usefull RMAN LIST commands .
 
RMAN> list backup summary;
RMAN> list backup of database;
RMAN> list backup;
RMAN> list backup of pluggable database anuj, anuj1;
RMAN> list copy of datafile  2, 3 ,6 ;
RMAN> list backup of datafile 4 summary;
RMAN> list archivelog all;
RMAN> list backup of archivelog all;
RMAN> list copy of database archivelog all;
RMAN> list incarnation;
RMAN> list backup of controlfile;
RMAN> list backup of spfile;
RMAN> list backup by file;
RMAN> list backup by file;
RMAN> list backup of datafile 1;
RMAN> list expired backup;
RMAN> list expired backup summary;
RMAN> list expired backup of archivelog all;
RMAN> list expired backup of datafile 10;
RMAN> list expired backup of archivelog all summary;
RMAN> list failure;
RMAN> list failure 641231 detail;
RMAN> list backup of tablespace anuj summary;
RMAN> list backup of tablespace test;
RMAN> list backup of archivelog from sequence 55;
RMAN> list backupset of datafile 1;
RMAN> list recoverable backup;
RMAN> LIST CONTROLFILECOPY "/tmp/cntrlfile.copy";
RMAN> LIST BACKUPSET OF DATAFILE 1;
RMAN> LIST backup tag 'ORCLEE_FULL';
RMAN> LIST BACKUPPIECE ' ';
RMAN> LIST BACKUP RECOVERABLE;
RMAN> list backup of archivelog from scn 853145 until scn 854039;
RMAN> LIST DATAFILECOPY '/u01/app/oracle/copy/users01.dbf';
RMAN> LIST COPY OF CONTROLFILE;
RMAN> list archivelog all backed up 1 times to disk;
RMAN> list backup of archivelog from scn 901427;
RMAN> list incarnation of database anuj ;
 
 
 
List of Database Incarnations
DB Key  Inc Key DB Name  DB ID            STATUS  Reset SCN  Reset Time
------- ------- -------- ---------------- --- ---------- ----------
1       1       ANUJ     3057090325       PARENT  1          25-DEC-16 16:28:05
2       2       ANUJ     3057090325       CURRENT 825576     25-DEC-16 18:25:29
 
===========
 
export NLS_DATE_FORMAT='DD-MON-YY HH24:MI:SS'
 
 
list backup of archivelog all
 
RMAN> LIST BACKUP OF ARCHIVELOG FROM SEQUENCE 220;
 
RMAN>list backup of archivelog sequence 89961 thread 2;
RMAN> LIST BACKUP OF ARCHIVELOG ;
 
 
list backup of tablespace users ;
list backup of database device type disk;
list copy of database completed between '01-AUGUST-2017' and '08-AUGUST-2017';
list copy of database completed between '01-AUGUST-2017' and '08-AUGUST-2017';
list backup of database completed between '01-AUGUST-2017' and '08-AUGUST-2017';
 
-- List Command with Date ( All are tested ) 
 
RMAN> list backup of datafile 1 completed between '07-jan-2012' and 'sysdate';
RMAN> list backup of archivelog  from time "to_date('01/08/2017 22:00:00', 'dd/mm/yyyy hh24:mi:ss')"   until time "to_date('08/08/2017 04:00:00', 'dd/mm/yyyy hh24:mi:ss')";
RMAN> list backup of archivelog time between "to_date('01-AUG-2017 00:00:00','DD-MON-YYYY HH24:MI:SS')" and "to_date('08-AUG-2017 00:00:00','DD-MON-YYYY HH24:MI:SS')";
RMAN> list backup of archivelog time between "to_date('01/08/2017','dd/mm/yyyy')" and "to_date('09/08/2017','dd/mm/yyyy')";
RMAN> list backup of database completed between "to_date('01/08/2017','dd/mm/yyyy')" and "to_date('08/08/2017','dd/mm/yyyy')";
RMAN> list backup of archivelog from time "to_date('01-08-2017','mm-dd-yyyy')";
RMAN> list backup of database completed between 'sysdate -7' and 'sysdate';
RMAN> list backup completed between 'sysdate -14' and 'sysdate';
RMAN> list backup completed between 'sysdate -14' and 'sysdate -7';
RMAN> list backup of spfile time between "to_date('01-AUG-2017 00:00:00','DD-MON-YYYY HH24:MI:SS')" and "to_date('08-AUG-2017 00:00:00','DD-MON-YYYY HH24:MI:SS')";
RMAN> list backup of database completed between "to_date('06/17/2010','mm/dd/yyyy')" and "to_date('06/19/2010','mm/dd/yyyy')";
RMAN> list backup of database completed between "to_date('01/08/2017','dd/mm/yyyy')" and "to_date('09/08/2017','dd/mm/yyyy')";
RMAN> list backup of archivelog time between "to_date('20-MAR-2013 00:00:00','DD-MON-YYYY HH24:MI:SS')" and "to_date('25-MAR-2013 00:00:00','DD-MON-YYYY HH24:MI:SS')";
RMAN> list backup of archivelog time between "to_date('01/08/2017','dd/mm/yyyy')" and "to_date('09/09/2017','dd/mm/yyyy')";
RMAN> LIST backup of database completed after "to_date('01/08/2017','mm/dd/yyyy')";
RMAN> list backup of archivelog  from time "to_date('01/08/2017 22:00:00', 'dd/mm/yyyy hh24:mi:ss')"   until time "to_date('08/08/2017 04:00:00', 'dd/mm/yyyy hh24:mi:ss')";
RMAN> LIST BACKUP OF ARCHIVELOG  FROM TIME "TO_DATE('08/16/2017 22:00:00', 'MM/DD/YYYY hh24:mi:ss')"   UNTIL TIME "TO_DATE('08/17/2017 03:00:00', 'MM/DD/YYYY hh24:mi:ss')";
 
========================


xx
RMAN> list backup of datafile;
 
RMAN> list backupset tag 'T2017';
 
List of Backup Sets
===================
 
 
BS Key  Size       Device Type Elapsed Time Completion Time
------- ---------- ----------- ------------ ---------------
184     299.57M    DISK        00:00:42     17-AUG-17
        BP Key: 184   Status: AVAILABLE  Compressed: YES  Tag: TAG20170817T010006
        Piece Name: /dumps/ICRAC/20170817_icrac1_186_1_952218007
 
  List of Archived Logs in backup set 184
  Thrd Seq     Low SCN    Low Time  Next SCN   Next Time
  ---- ------- ---------- --------- ---------- ---------
  1    259     22824594   16-AUG-17 22847740   16-AUG-17
  1    260     22847740   16-AUG-17 22934969   17-AUG-17
  2    239     22723071   16-AUG-17 22847951   16-AUG-17
  2    240     22847951   16-AUG-17 22923793   17-AUG-17
  2    241     22923793   17-AUG-17 22935012   17-AUG-17
 
RMAN> LIST BACKUP OF ARCHIVELOG FROM TIME "SYSDATE-1";
 
 
List of Backup Sets
===================
 
 
BS Key  Size       Device Type Elapsed Time Completion Time
------- ---------- ----------- ------------ ---------------
184     299.57M    DISK        00:00:42     17-AUG-17
        BP Key: 184   Status: AVAILABLE  Compressed: YES  Tag: TAG20170817T010006
        Piece Name: /dumps/ICRAC/20170817_icrac1_186_1_952218007
 
  List of Archived Logs in backup set 184
  Thrd Seq     Low SCN    Low Time  Next SCN   Next Time
  ---- ------- ---------- --------- ---------- ---------
  1    257     22723067   16-AUG-17 22798860   16-AUG-17
  1    258     22798860   16-AUG-17 22824594   16-AUG-17
  1    259     22824594   16-AUG-17 22847740   16-AUG-17
  1    260     22847740   16-AUG-17 22934969   17-AUG-17
  2    239     22723071   16-AUG-17 22847951   16-AUG-17
  2    240     22847951   16-AUG-17 22923793   17-AUG-17
  2    241     22923793   17-AUG-17 22935012   17-AUG-17
 
 
full backup info 
 
RMAN> list backup of database summary completed after 'sysdate - 7';
 
 
List of Backups
===============
Key     TY LV S Device Type Completion Time    #Pieces #Copies Compressed Tag
------- -- -- - ----------- ------------------ ------- ------- ---------- ---
6       B  F  A DISK        02-SEP-17 13:10:39 1       1       YES        ORCLEE_FULL
 
 
RMAN>  list backup of controlfile ;
 
 
List of Backup Sets
===================
 
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ------------------
7       Full    9.36M      DISK        00:00:01     02-SEP-17 13:10:50
        BP Key: 7   Status: AVAILABLE  Compressed: NO  Tag: TAG20170902T131049
        Piece Name: /u01/app/RmanBackup/c-3057090325-20170902-02
  Control File Included: Ckp SCN: 854026       Ckp time: 02-SEP-17 13:10:49
 
 
 
==========
 
Recovery Manager complete.
[oracle@oraasm11g ~]$ export NLS_DATE_FORMAT='DD-MON-YY HH24:MI:SS'
[oracle@oraasm11g ~]$ rman target /
 
RMAN> list incarnation of database anuj ;
 
List of Database Incarnations
DB Key  Inc Key DB Name  DB ID            STATUS  Reset SCN  Reset Time
------- ------- -------- ---------------- --- ---------- ----------
1       1       ANUJ     3057090325       PARENT  1          25-DEC-16 16:28:05
2       2       ANUJ     3057090325       CURRENT 825576     25-DEC-16 18:25:29
 
 
 
RMAN> list backup summary;
 
using target database control file instead of recovery catalog
 
List of Backups
===============
Key     TY LV S Device Type Completion Time #Pieces #Copies Compressed Tag
------- -- -- - ----------- --------------- ------- ------- ---------- ---
6       B  F  A DISK        02-SEP-17       1       1       YES        ORCLEE_FULL
7       B  F  A DISK        02-SEP-17       1       1       NO         TAG20170902T131049
8       B  A  A DISK        02-SEP-17       1       1       NO         ORCLEE_ARCHIVE
 
RMAN> list backup ;
 
 
List of Backup Sets
===================
 
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ---------------
6       Full    223.16M    DISK        00:00:45     02-SEP-17
        BP Key: 6   Status: AVAILABLE  Compressed: YES  Tag: ORCLEE_FULL
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_11_1_FULL
  List of Datafiles in backup set 6
  File LV Type Ckp SCN    Ckp Time  Name
  ---- -- ---- ---------- --------- ----
  1       Full 854000     02-SEP-17 +DATA/anuj/datafile/system.268.931544353
  2       Full 854000     02-SEP-17 +DATA/anuj/datafile/sysaux.270.931544485
  3       Full 854000     02-SEP-17 +DATA/anuj/datafile/undotbs1.269.931544399
  4       Full 854000     02-SEP-17 +DATA/anuj/datafile/users.272.931544539
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ---------------
7       Full    9.36M      DISK        00:00:01     02-SEP-17
        BP Key: 7   Status: AVAILABLE  Compressed: NO  Tag: TAG20170902T131049
        Piece Name: /u01/app/RmanBackup/c-3057090325-20170902-02
  SPFILE Included: Modification time: 02-SEP-17
  SPFILE db_unique_name: ANUJ
  Control File Included: Ckp SCN: 854026       Ckp time: 02-SEP-17
 
BS Key  Size       Device Type Elapsed Time Completion Time
------- ---------- ----------- ------------ ---------------
8       291.50K    DISK        00:00:00     02-SEP-17
        BP Key: 8   Status: AVAILABLE  Compressed: NO  Tag: ORCLEE_ARCHIVE
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_13_1_ARCHIVE
 
  List of Archived Logs in backup set 8
  Thrd Seq     Low SCN    Low Time  Next SCN   Next Time
  ---- ------- ---------- --------- ---------- ---------
  1    5       853145     02-SEP-17 853302     02-SEP-17
  1    6       853302     02-SEP-17 853310     02-SEP-17
  1    7       853310     02-SEP-17 854039     02-SEP-17
  1    8       854039     02-SEP-17 854047     02-SEP-17
 
 
RMAN> list backup of database;
 
 
List of Backup Sets
===================
 
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ---------------
6       Full    223.16M    DISK        00:00:45     02-SEP-17
        BP Key: 6   Status: AVAILABLE  Compressed: YES  Tag: ORCLEE_FULL
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_11_1_FULL
  List of Datafiles in backup set 6
  File LV Type Ckp SCN    Ckp Time  Name
  ---- -- ---- ---------- --------- ----
  1       Full 854000     02-SEP-17 +DATA/anuj/datafile/system.268.931544353
  2       Full 854000     02-SEP-17 +DATA/anuj/datafile/sysaux.270.931544485
  3       Full 854000     02-SEP-17 +DATA/anuj/datafile/undotbs1.269.931544399
  4       Full 854000     02-SEP-17 +DATA/anuj/datafile/users.272.931544539
 
RMAN> list backup;
 
List of Backup Sets
===================
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ---------------
6       Full    223.16M    DISK        00:00:45     02-SEP-17
        BP Key: 6   Status: AVAILABLE  Compressed: YES  Tag: ORCLEE_FULL
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_11_1_FULL
  List of Datafiles in backup set 6
  File LV Type Ckp SCN    Ckp Time  Name
  ---- -- ---- ---------- --------- ----
  1       Full 854000     02-SEP-17 +DATA/anuj/datafile/system.268.931544353
  2       Full 854000     02-SEP-17 +DATA/anuj/datafile/sysaux.270.931544485
  3       Full 854000     02-SEP-17 +DATA/anuj/datafile/undotbs1.269.931544399
  4       Full 854000     02-SEP-17 +DATA/anuj/datafile/users.272.931544539
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ---------------
7       Full    9.36M      DISK        00:00:01     02-SEP-17
        BP Key: 7   Status: AVAILABLE  Compressed: NO  Tag: TAG20170902T131049
        Piece Name: /u01/app/RmanBackup/c-3057090325-20170902-02
  SPFILE Included: Modification time: 02-SEP-17
  SPFILE db_unique_name: ANUJ
  Control File Included: Ckp SCN: 854026       Ckp time: 02-SEP-17
 
BS Key  Size       Device Type Elapsed Time Completion Time
------- ---------- ----------- ------------ ---------------
8       291.50K    DISK        00:00:00     02-SEP-17
        BP Key: 8   Status: AVAILABLE  Compressed: NO  Tag: ORCLEE_ARCHIVE
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_13_1_ARCHIVE
 
  List of Archived Logs in backup set 8
  Thrd Seq     Low SCN    Low Time  Next SCN   Next Time
  ---- ------- ---------- --------- ---------- ---------
  1    5       853145     02-SEP-17 853302     02-SEP-17
  1    6       853302     02-SEP-17 853310     02-SEP-17
  1    7       853310     02-SEP-17 854039     02-SEP-17
  1    8       854039     02-SEP-17 854047     02-SEP-17
 
 
RMAN> list archivelog all;
 
specification does not match any archived log in the repository
 
RMAN> list backup of archivelog all;
 
 
List of Backup Sets
===================
 
 
BS Key  Size       Device Type Elapsed Time Completion Time
------- ---------- ----------- ------------ ---------------
8       291.50K    DISK        00:00:00     02-SEP-17
        BP Key: 8   Status: AVAILABLE  Compressed: NO  Tag: ORCLEE_ARCHIVE
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_13_1_ARCHIVE
 
  List of Archived Logs in backup set 8
  Thrd Seq     Low SCN    Low Time  Next SCN   Next Time
  ---- ------- ---------- --------- ---------- ---------
  1    5       853145     02-SEP-17 853302     02-SEP-17
  1    6       853302     02-SEP-17 853310     02-SEP-17
  1    7       853310     02-SEP-17 854039     02-SEP-17
  1    8       854039     02-SEP-17 854047     02-SEP-17
 
 
RMAN> list backup of archivelog from sequence 4;
 
 
List of Backup Sets
===================
 
 
BS Key  Size       Device Type Elapsed Time Completion Time
------- ---------- ----------- ------------ ------------------
8       291.50K    DISK        00:00:00     02-SEP-17 13:10:54
        BP Key: 8   Status: AVAILABLE  Compressed: NO  Tag: ORCLEE_ARCHIVE
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_13_1_ARCHIVE
 
  List of Archived Logs in backup set 8
  Thrd Seq     Low SCN    Low Time           Next SCN   Next Time
  ---- ------- ---------- ------------------ ---------- ---------
  1    5       853145     02-SEP-17 12:54:24 853302     02-SEP-17 12:58:27
  1    6       853302     02-SEP-17 12:58:27 853310     02-SEP-17 12:58:27
  1    7       853310     02-SEP-17 12:58:27 854039     02-SEP-17 13:10:52
  1    8       854039     02-SEP-17 13:10:52 854047     02-SEP-17 13:10:54
 
 
RMAN> list incarnation;
 
 
List of Database Incarnations
DB Key  Inc Key DB Name  DB ID            STATUS  Reset SCN  Reset Time
------- ------- -------- ---------------- --- ---------- ----------
1       1       ANUJ     3057090325       PARENT  1          25-DEC-16
2       2       ANUJ     3057090325       CURRENT 825576     25-DEC-16
 
RMAN> list backup of datafile 1;
 
 
List of Backup Sets
===================
 
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ---------------
6       Full    223.16M    DISK        00:00:45     02-SEP-17
        BP Key: 6   Status: AVAILABLE  Compressed: YES  Tag: ORCLEE_FULL
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_11_1_FULL
  List of Datafiles in backup set 6
  File LV Type Ckp SCN    Ckp Time  Name
  ---- -- ---- ---------- --------- ----
  1       Full 854000     02-SEP-17 +DATA/anuj/datafile/system.268.931544353
 
 
RMAN> list backup of controlfile ;
 
 
List of Backup Sets
===================
 
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ------------------
7       Full    9.36M      DISK        00:00:01     02-SEP-17 13:10:50
        BP Key: 7   Status: AVAILABLE  Compressed: NO  Tag: TAG20170902T131049
        Piece Name: /u01/app/RmanBackup/c-3057090325-20170902-02
  Control File Included: Ckp SCN: 854026       Ckp time: 02-SEP-17 13:10:49
 
 
RMAN> list backup of spfile;
 
 
List of Backup Sets
===================
 
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ------------------
7       Full    9.36M      DISK        00:00:01     02-SEP-17 13:10:50
        BP Key: 7   Status: AVAILABLE  Compressed: NO  Tag: TAG20170902T131049
        Piece Name: /u01/app/RmanBackup/c-3057090325-20170902-02
  SPFILE Included: Modification time: 02-SEP-17 12:53:04
  SPFILE db_unique_name: ANUJ
 
 
 
RMAN> list backup by file;
 
 
List of Datafile Backups
========================
 
File Key     TY LV S Ckp SCN    Ckp Time           #Pieces #Copies Compressed Tag
---- ------- -  -- - ---------- ------------------ ------- ------- ---------- ---
1    6       B  F  A 854000     02-SEP-17 13:09:54 1       1       YES        ORCLEE_FULL
2    6       B  F  A 854000     02-SEP-17 13:09:54 1       1       YES        ORCLEE_FULL
3    6       B  F  A 854000     02-SEP-17 13:09:54 1       1       YES        ORCLEE_FULL
4    6       B  F  A 854000     02-SEP-17 13:09:54 1       1       YES        ORCLEE_FULL
 
List of Archived Log Backups
============================
 
Thrd Seq     Low SCN    Low Time           BS Key  S #Pieces #Copies Compressed Tag
---- ------- ---------- ------------------ ------- - ------- ------- ---------- ---
1    5       853145     02-SEP-17 12:54:24 8       A 1       1       NO         ORCLEE_ARCHIVE
1    6       853302     02-SEP-17 12:58:27 8       A 1       1       NO         ORCLEE_ARCHIVE
1    7       853310     02-SEP-17 12:58:27 8       A 1       1       NO         ORCLEE_ARCHIVE
1    8       854039     02-SEP-17 13:10:52 8       A 1       1       NO         ORCLEE_ARCHIVE
 
List of Control File Backups
============================
 
CF Ckp SCN Ckp Time           BS Key  S #Pieces #Copies Compressed Tag
---------- ------------------ ------- - ------- ------- ---------- ---
854026     02-SEP-17 13:10:49 7       A 1       1       NO         TAG20170902T131049
List of SPFILE Backups
======================
 
Modification Time  BS Key  S #Pieces #Copies Compressed Tag
------------------ ------- - ------- ------- ---------- ---
02-SEP-17 12:53:04 7       A 1       1       NO         TAG20170902T131049
 
 
 
RMAN> LIST backup tag 'ORCLEE_FULL';
 
 
List of Backup Sets
===================
 
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ------------------
6       Full    223.16M    DISK        00:00:45     02-SEP-17 13:10:39
        BP Key: 6   Status: AVAILABLE  Compressed: YES  Tag: ORCLEE_FULL
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_11_1_FULL
  List of Datafiles in backup set 6
  File LV Type Ckp SCN    Ckp Time           Name
  ---- -- ---- ---------- ------------------ ----
  1       Full 854000     02-SEP-17 13:09:54 +DATA/anuj/datafile/system.268.931544353
  2       Full 854000     02-SEP-17 13:09:54 +DATA/anuj/datafile/sysaux.270.931544485
  3       Full 854000     02-SEP-17 13:09:54 +DATA/anuj/datafile/undotbs1.269.931544399
  4       Full 854000     02-SEP-17 13:09:54 +DATA/anuj/datafile/users.272.931544539
 
 
RMAN> list recoverable backup;
 
 
List of Backup Sets
===================
 
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ------------------
6       Full    223.16M    DISK        00:00:45     02-SEP-17 13:10:39
        BP Key: 6   Status: AVAILABLE  Compressed: YES  Tag: ORCLEE_FULL
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_11_1_FULL
  List of Datafiles in backup set 6
  File LV Type Ckp SCN    Ckp Time           Name
  ---- -- ---- ---------- ------------------ ----
  1       Full 854000     02-SEP-17 13:09:54 +DATA/anuj/datafile/system.268.931544353
  2       Full 854000     02-SEP-17 13:09:54 +DATA/anuj/datafile/sysaux.270.931544485
  3       Full 854000     02-SEP-17 13:09:54 +DATA/anuj/datafile/undotbs1.269.931544399
  4       Full 854000     02-SEP-17 13:09:54 +DATA/anuj/datafile/users.272.931544539
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ------------------
7       Full    9.36M      DISK        00:00:01     02-SEP-17 13:10:50
        BP Key: 7   Status: AVAILABLE  Compressed: NO  Tag: TAG20170902T131049
        Piece Name: /u01/app/RmanBackup/c-3057090325-20170902-02
  SPFILE Included: Modification time: 02-SEP-17 12:53:04
  SPFILE db_unique_name: ANUJ
  Control File Included: Ckp SCN: 854026       Ckp time: 02-SEP-17 13:10:49
 
BS Key  Size       Device Type Elapsed Time Completion Time
------- ---------- ----------- ------------ ------------------
8       291.50K    DISK        00:00:00     02-SEP-17 13:10:54
        BP Key: 8   Status: AVAILABLE  Compressed: NO  Tag: ORCLEE_ARCHIVE
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_13_1_ARCHIVE
 
  List of Archived Logs in backup set 8
  Thrd Seq     Low SCN    Low Time           Next SCN   Next Time
  ---- ------- ---------- ------------------ ---------- ---------
  1    5       853145     02-SEP-17 12:54:24 853302     02-SEP-17 12:58:27
  1    6       853302     02-SEP-17 12:58:27 853310     02-SEP-17 12:58:27
  1    7       853310     02-SEP-17 12:58:27 854039     02-SEP-17 13:10:52
  1    8       854039     02-SEP-17 13:10:52 854047     02-SEP-17 13:10:54
 
 
RMAN> list backup of archivelog from scn 853145 until scn 854039;
 
List of Backup Sets
===================
 
 
BS Key  Size       Device Type Elapsed Time Completion Time
------- ---------- ----------- ------------ ------------------
8       291.50K    DISK        00:00:00     02-SEP-17 13:10:54
        BP Key: 8   Status: AVAILABLE  Compressed: NO  Tag: ORCLEE_ARCHIVE
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_13_1_ARCHIVE
 
  List of Archived Logs in backup set 8
  Thrd Seq     Low SCN    Low Time           Next SCN   Next Time
  ---- ------- ---------- ------------------ ---------- ---------
  1    5       853145     02-SEP-17 12:54:24 853302     02-SEP-17 12:58:27
  1    6       853302     02-SEP-17 12:58:27 853310     02-SEP-17 12:58:27
  1    7       853310     02-SEP-17 12:58:27 854039     02-SEP-17 13:10:52
 
RMAN>  list backupset 8;
 
 
List of Backup Sets
===================
 
 
BS Key  Size       Device Type Elapsed Time Completion Time
------- ---------- ----------- ------------ ------------------
8       291.50K    DISK        00:00:00     02-SEP-17 13:10:54
        BP Key: 8   Status: AVAILABLE  Compressed: NO  Tag: ORCLEE_ARCHIVE
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_13_1_ARCHIVE
 
  List of Archived Logs in backup set 8
  Thrd Seq     Low SCN    Low Time           Next SCN   Next Time
  ---- ------- ---------- ------------------ ---------- ---------
  1    5       853145     02-SEP-17 12:54:24 853302     02-SEP-17 12:58:27
  1    6       853302     02-SEP-17 12:58:27 853310     02-SEP-17 12:58:27
  1    7       853310     02-SEP-17 12:58:27 854039     02-SEP-17 13:10:52
  1    8       854039     02-SEP-17 13:10:52 854047     02-SEP-17 13:10:54
 
 
RMAN> list backup of datafile 1 completed between '01-sep-2017' and 'sysdate';
RMAN> list backup of datafile 1 completed between '01-sep-2017' and 'sysdate';
 
 
List of Backup Sets
===================
 
 
BS Key  Type LV Size       Device Type Elapsed Time Completion Time
------- ---- -- ---------- ----------- ------------ ------------------
6       Full    223.16M    DISK        00:00:45     02-SEP-17 13:10:39
        BP Key: 6   Status: AVAILABLE  Compressed: YES  Tag: ORCLEE_FULL
        Piece Name: /u01/app/RmanBackup/ANUJ_20170902_11_1_FULL
  List of Datafiles in backup set 6
  File LV Type Ckp SCN    Ckp Time           Name
  ---- -- ---- ---------- ------------------ ----
  1       Full 854000     02-SEP-17 13:09:54 +DATA/anuj/datafile/system.268.931544353
 
 

 
RMAN>report need backup days=2;
RMAN> report unrecoverable;
 
REPORT NEED BACKUP RECOVERY WINDOW OF n DAYS
Displays objects requiring backup to satisfy a recovery window-based retention policy.
 
REPORT NEED BACKUP REDUNDANCY n
Displays objects requiring backup to satisfy a redundancy-based retention policy.
 
REPORT NEED BACKUP DAYS n
Displays files that require more than n days' worth of archived redo log files for recovery.
 
REPORT NEED BACKUP INCREMENTAL n
Displays files that require application of more than n incremental backups for recovery.
 
 
RMAN> report schema ;
 
RMAN-06139: WARNING: control file is not current for REPORT SCHEMA
Report of database schema for database with db_unique_name ANUJ
 
List of Permanent Datafiles
===========================
File Size(MB) Tablespace           RB segs Datafile Name
---- -------- -------------------- ------- ------------------------
1    0        SYSTEM               ***     +DATA/anuj/datafile/system.268.931544353
2    0        SYSAUX               ***     +DATA/anuj/datafile/sysaux.270.931544485
3    0        UNDOTBS1             ***     +DATA/anuj/datafile/undotbs1.269.931544399
4    0        USERS                ***     +DATA/anuj/datafile/users.272.931544539
 
List of Temporary Files
=======================
File Size(MB) Tablespace           Maxsize(MB) Tempfile Name
---- -------- -------------------- ----------- --------------------
2    256      TEMP2                256         +DATA/anuj/tempfile/temp2.277.931545697

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN bkup status frm sqlplus
3
Rman backup status 
Rman backup output via sql  
v$rman_output to review  backups

-- v$rman_output goes away with a restart

set linesize 200  pagesize 200
select output
from v$rman_output where session_recid = (select max(session_recid) from v$rman_status)
order by recid ;
----------------------------------------------------------------

set linesize 200  pagesize 200
select output
from v$rman_output where session_recid in (select session_recid from v$rman_status
where start_time > sysdate -7)
order by recid ;

set linesize 200  pagesize 200
select output
from v$rman_output where session_recid in (select session_recid from v$rman_status
where start_time > sysdate -7)
order by recid ;
-----------------------------------------------------------------


alter session set nls_date_format='DD-MON-YYYY hh24:mi:ss';

set  linesize 200
select object_type,mbytes_processed, start_time, end_time,status
from v$rman_status
where session_recid = (select max(session_recid) from v$rman_status) and operation !='RMAN'
order by recid

<end node> 5P9i0s8y19Z
dt=Text
<node>
Steps of RMAN recovery
3
--- Steps for media recovery Using RMAN

Step 01:
 --- Mount or open the database. Mount the database when performing whole database recovery, or open the 
 --- database when performing online tablespace recovery.

STARTUP FORCE MOUNT;
Step 02:
To perform incomplete recovery, use the SET UNTIL command to specify the time, SCN, or log sequence number at which 
recovery terminates. Alternatively, specify the UNTIL clause on the RESTORE and RECOVER commands.

Step 03:
Restore the necessary files with the RESTORE command.

Step 04:
Recover the datafiles with the RECOVER command.

Step 05:
Place the database in its normal state. For example, open it or bring recovered tablespaces online.

Restore and recover the whole database
RMAN> STARTUP FORCE MOUNT;
RMAN> RESTORE DATABASE;
RMAN> RECOVER DATABASE;
RMAN> ALTER DATABASE OPEN;

Script Code:
STARTUP NOMOUNT;
RUN
{
   ALLOCATE CHANNEL c1 DEVICE TYPE sbt;
   RESTORE DATABASE;
   ALTER DATABASE MOUNT;   
   RECOVER DATABASE;
}
Restore and recover a tablespace
RMAN> SQL 'ALTER TABLESPACE users OFFLINE';
RMAN> RESTORE TABLESPACE users;
RMAN> RECOVER TABLESPACE users;
RMAN> SQL 'ALTER TABLESPACE users ONLINE';
Restore and recover a datafile
RMAN> SQL 'ALTER DATABASE DATAFILE 32 OFFLINE';
RMAN> RESTORE DATAFILE 32;
RMAN> RECOVER DATAFILE 32;
RMAN> SQL 'ALTER DATABASE DATAFILE 32 ONLINE';
Restore and recover the Control file from Backup
Restore the control file, (to all locations specified in the parameter file) then restore the database, using that control file:

STARTUP NOMOUNT;
RUN
{
   ALLOCATE CHANNEL c1 DEVICE TYPE sbt;
   RESTORE CONTROLFILE;
   ALTER DATABASE MOUNT;
   RECOVER DATABASE;
}

Create a new control file
If all control file copies are lost, you can create a new control file using the NORESETLOGS option and open the database 
after doing media recovery. An existing standby database instance can generate the script to create a new control file by 
using the following statement

SQL> ALTER DATABASE BACKUP CONTROLFILE TO TRACE NORESETLOGS;
Recovery from the Loss of an Online Redo Log File
To add a new member to a redo log group, issue the following statement:

SQL> ALTER DATABASE ADD LOGFILE MEMBER 'log_file_name' REUSE TO GROUP n
Disaster Recovery

In a disaster situation where all files are lost you can only recover to the last SCN in the archived redo logs. 
Beyond this point the recovery would have to make reference to the online redo logs which are not present. Disaster 
recovery is therefore a type of incomplete recovery.

Step 01: Connect to RMAN
$rman catalog=rman/rman@orcl target=sys/oracle@orcl
Step 02: Recover the control file if needed.
RMAN> startup nomount;
RMAN> restore controlfile;
RMAN> alter database mount;
Step 03: Collect the last SCN using SQL*Plus as SYS
SQL> SELECT archivelog_change#-1 FROM v$database;

ARCHIVELOG_CHANGE#-1
--------------------
             1203813
Step 04: Restore and Recover database using RMAN.
 
RMAN> run {
        set until scn 1203813;
        restore database;
        recover database;
        alter database open resetlogs;
        }

Restore Validation

Restore Validation confirms that a restore could be run, by confirming that all database files exist and are free 
of physical and logical corruption, this does not generate any output.

RMAN> RESTORE DATABASE VALIDATE;

<end node> 5P9i0s8y19Z
dt=Text
<node>
restore
3
restore spfile or pfile
start the DB with pfile or spfile in nomount stag

-- restore the control file in nomount stage
-- once restore then start DB in mount stage

run
{
	allocate channel t0 type 'sbt_tape';
	allocate channel t1 type 'sbt_tape';
	send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA,NSR_CLIENT=lrau1p24)';
	restore controlfile from tag=SPD1P_H_D_ON_202005252000;
}

--- Once completed goto sqlplus "/as sysdba" and mount the database
sqlplus "/as sysdba"
SQL>alter database mount;
SQL>select name,open_mode from v$database;

-- once mounted again gobackup to RMAN console with catalog loggin
run
{
	allocate channel t0 type 'sbt_tape';
	allocate channel t1 type 'sbt_tape';
	send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA,NSR_CLIENT=lrau1p24)';
	restore database from tag=SPD1P_H_D_ON_202005252000;
}

--- get the timestamp of the last scn and sequence to recover from the recovery date
select sequence#, thread#,substr(name,1,96),creator, to_char(first_time,'DD-MON HH24:MI'), to_char(completion_time,'mm/dd/yyyy hh24:mi:ss'),
 to_char(completion_time,'DD-MM-RRRR HH24:MI:SS')askla
 from v$archived_log
 where completion_time between to_date('05/25/2020 00:00:00','mm/dd/yyyy hh24:mi:ss')
                           and to_date('05/26/2020 04:59:59','mm/dd/yyyy hh24:mi:ss')
 order by 1 desc ;
 
run
{
	allocate channel t0 type 'sbt_tape';
	allocate channel t1 type 'sbt_tape';
	send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA,NSR_CLIENT=lrau1p24)';
	set until time "to_date('26-05-2020 00:00:00','DD-MM-RRRR HH24:MI:SS')";
	recover database;
}

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN Set NEWNAME
3

-- RMAN Example: Redirecting an Oracle Restore Using SET NEWNAME 
-- When you redirect a restore for Oracle database 11gR2 or later by using the SET NEWNAME FOR DATABASE, or SET NEWNAME FOR TABLESPACE 
-- commands, you must specify variables in the file name to avoid name collisions.

-- Procedure
-- To avoid name collisions, specify at least one of the substitution variables in the SET NEWNAME command: %b, %f, or %U. 
-- For information on the supported variables, see supported Oracle Redirected Restore File Name Variables variable.
run
{
set newname for database to "/u02/app/oracle/oradata/TST1/%U";
restore database until time="TO_DATE('11/13/2013 01:53:36', 'MM/DD/YYYY HH24:MI:SS')";
switch datafile all;
}
exit;
run {
recover database until scn 7266782191960;
}
exit;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Recover table
3
RECOVER TABLE SH.SALES:SALES_1998, SH.SALES:SALES_1999
    UNTIL SEQUENCE 354
    AUXILIARY DESTINATION '/tmp/oracle/recover'
    REMAP TABLE 'SH'.'SALES':'SALES_1998':'HISTORIC_SALES_1998',
              'SH'.'SALES':'SALES_1999':'HISTORIC_SALES_1999' 
    REMAP TABLESPACE 'SALES_TS':'SALES_PRE_2000_TS'; 



-- date mention below is just before sometime of drop table executed	
recover table SCOTT.SALGRADE until time “to_date('08/09/2016 18:49:40','mm/dd/yyyy hh24:mi:ss')”
auxiliary destination '/u03/arch/TEST/BACKUP'
datapump destination '/u03/arch/TEST/BACKUP';	


-- REMAP_TABLE – For restoring the table to a new name
recover table SCOTT.SALGRADE until time “to_date('08/09/2016 18:49:40','mm/dd/yyyy hh24:mi:ss')”
auxiliary destination '/u03/arch/TEST/BACKUP'
datapump destination '/u03/arch/TEST/BACKUP'
REMAP_TABLE ‘SCOTT'.'SALGRADE':'SALGRADE_BKP';


-- 2. NOTABLEIMPORT:  This will just generate the table dump from the backup set. It won't import the dump.
recover table SCOTT.SALGRADE until time “to_date('08/09/2016 18:49:40','mm/dd/yyyy hh24:mi:ss')”
auxiliary destination '/u03/arch/TEST/BACKUP'
datapump destination '/u03/arch/TEST/BACKUP'
NOTABLEIMPORT;

-- auxiliary instance
run
{
configure channel DEVICE TYPE SBT parms 'ENV=(NSR_SERVER=nwbss,NSR_CLIENT=db-host)';
set auxiliary instance parameter file to '/tmp/initaux.ora';
recover table 'TESTDBA'.'TEST' until time "to_date('08/10/2016 12:00:00','mm/dd/yyyy hh24:mi:ss')"
REMAP TABLE 'STCDBA'.'TEST':'TEST_PREV';
} 
 

-- Table RECTEST in schema SMEDS to be recovered into new table SMEDS.TEST4_RECTEST. 
-- The auxiliary instance datafiles will be restored to ‘/testcases/rectbl‘.
$ rman target sys/oracle@t12ccdb log=recover_table5.log 
RMAN> RECOVER TABLE SMEDS."RECTEST" OF PLUGGABLE DATABASE T12CPDB1
          UNTIL SEQUENCE 64 thread 1
          AUXILIARY DESTINATION '/testcases/rectbl'
          REMAP TABLE 'SMEDS'.'RECTEST':'TEST4_RECTEST';
-- It uses the controlfile autobackup to restore the controlfile to mount the dummy instance.
-- It then restores the controlfile for the auxiliary instance
-- In cases where you do not want the table to be import but just need the export dump, 
-- you can use notableimport option;

-- Run the below rman code block with notableimport option:
run 
{
RECOVER TABLE SMEDS."RECTEST" OF PLUGGABLE DATABASE T12CPDB1
UNTIL SEQUENCE 64 thread 1
AUXILIARY DESTINATION '/testcases/abc/rectbl'
datapump destination '/testcases/abc/rectb/dpump/'
dump file 'export.dmp'
notableimport; 
} 

<end node> 5P9i0s8y19Z
dt=Text
<node>
resto or del archivelogs
3


--To list an individual backup, any of the three alternatives bellow would be valid query using rman:
RMAN> list backup of archivelog logseq=28845; 
RMAN> list backup of archivelog logseq 120316; 
RMAN> list backup of archivelog sequence 120316; 

--To view backups of archivelog between two sequences:
RMAN> list backup of archivelog sequence between 120316 and 120317; 
RMAN> list backup of archivelog from logseq 412593 until logseq 412656; 

--Use the SUMMARY directive to view only the backupsets affected:
RMAN> list backup of archivelog from logseq 412593 until logseq 412656 summary; 
RMAN> list backup of archivelog sequence between 120316 and 120317 summary; 

--To view backups completed before a specific date:
RMAN> list backup completed before "to_date( '18.12.2009 18:00:00', 'DD.MM.YYYY HH24:MI:SS')"; 
RMAN> list backup of archivelog all summary completed before "to_date( '18.12.2009 18:00:00', 'DD.MM.YYYY HH24:MI:SS')";

--To list archivelogs recognized by the controlfile:
RMAN>list archivelog sequence between 110880 and 110881; 
 
-- restore the missing archivelogs on perticular nodes
125740 - 125753 -- thread 1
133679 - 133689 -- thread 2

RESTORE ARCHIVELOG SEQUENCE  80159 thread 2;

restore archivelog from sequence 202167 until sequence 202170 thread 2;

restore archivelog from sequence 133680 until sequence 133689 thread 2;


OR 

restore archivelog from logseq=80159 until logseq=80165 thread=2 

run {
   allocate channel t0 type 'sbt_tape';
   allocate channel t1 type 'sbt_tape';
   allocate channel t2 type 'sbt_tape';
   #send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA)';
   send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_DATA_VOLUME_POOL=CNABOOST,NSR_GROUP=CNAPROD_ORA)';
  #restore archivelog sequence 28845 thread 2;
#restore archivelog from logseq=9583 until logseq=9605 thread=1;
#restore archivelog from logseq=9583 until logseq=9605 thread=2;
restore archivelog sequence 61511 thread 1;
}

run {
   allocate channel t0 type 'sbt_tape';
   allocate channel t1 type 'sbt_tape';
     send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA)';
	restore archivelog sequence 22688 thread 1;
}

 run {
    allocate channel t0 type 'sbt_tape';
    allocate channel t1 type 'sbt_tape';
    allocate channel t2 type 'sbt_tape';
    send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA)';
	RESTORE ARCHIVELOG SEQUENCE  22688 thread 1;
   }

run {
    set command id to '1620550867';
   sql 'alter system checkpoint local';
   allocate channel t0 type 'sbt_tape';
   allocate channel t1 type 'sbt_tape';
   allocate channel t2 type 'sbt_tape';
   allocate channel t3 type 'sbt_tape';
    allocate channel t4 type 'sbt_tape';
    allocate channel t5 type 'sbt_tape';
    allocate channel t6 type 'sbt_tape';
     send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA)';
     CROSSCHECK ARCHIVELOG ALL;

thread 1 from 19141 - 19170
thread 2   from 23721  - 23755  

run
{
	allocate channel t0 type 'sbt_tape';
	allocate channel t1 type 'sbt_tape';
	allocate channel t12 type 'sbt_tape';
	allocate channel t13 type 'sbt_tape';
	allocate channel t14 type 'sbt_tape';
	allocate channel t15 type 'sbt_tape';
	send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_DATA_VOLUME_POOL=CNABOOST,NSR_GROUP=CNAPROD_ORA)';
	restore archivelog from sequence 19141 thread 1 until sequence 19170 thread 1;
};

run
{
	allocate channel t0 type 'sbt_tape';
	allocate channel t1 type 'sbt_tape';
	allocate channel t12 type 'sbt_tape';
	allocate channel t13 type 'sbt_tape';
	allocate channel t14 type 'sbt_tape';
	allocate channel t15 type 'sbt_tape';
	send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_DATA_VOLUME_POOL=CNABOOST,NSR_GROUP=CNAPROD_ORA)';
	restore archivelog from sequence 23721 thread 2 until sequence 23755 thread 2;
};  


RMAN>delete archivelog all;
RMAN>delete archivelog until time ‘SYSDATE-10’;
RMAN>delete archivelog from time ‘SYSDATE-10’
RMAN>delete archivelog from time ‘SYSDATE-10’ until time ‘SYSDATE-2’;
RMAN>delete archivelog from sequence 1000;
RMAN>delete archivelog until sequence 1500;
RMAN>delete archivelog from sequence 1000 until sequence 1500;


Note : Also, you can use noprompt statement for do not yes-no question.
RMAN>delete noprompt archivelog until time ‘SYSDATE-10’; 
 



delete archivelog from sequence 1000 until sequence 1500;


for CLMCCP Puneet will ping you for restore.... 
 

 
-- delete these    thread 1   19141- 19180   thread 2 23753    23765 
 
delete archivelog from sequence 19144 until sequence 19180 thread 1;

delete archivelog from sequence 23753 until sequence 23765 thread 2;




restore ARCHIVELOG FROM TIME 'SYSDATE-1' UNTIL TIME 'SYSDATE';
restore ARCHIVELOG FROM TIME "to_date('07/11/05 00:00:01','MM/DD/YY HH24:MI:SS')" UNTIL TIME 'SYSDATE';
restore ARCHIVELOG FROM TIME "to_date('07/10/17 08:20:00','MM/DD/YY HH24:MI:SS')" UNTIL TIME "to_date('07/10/17 15:00:00','MM/DD/YY HH24:MI:SS')";


restore archivelog from tag=TAG20100205T162010;

-- Archive Log Restore in Different Location From Tape
run
{
allocate channel t1 type 'sbt_tape' parms 'ENV=(TDPO_OPTFILE=/usr/tivoli/tsm/client/oracle/bin64/tdpo.opt)';
set archivelog destination to '/backup/rmantemp/archivelog/';
restore archivelog from logseq=##### until logseq=#####;
}



-- Archive Log Restore in Different Location From Disk
run
{
allocate channel dev1 type disk;
set archivelog destination to 'D:\archivelog_restore';
restore archivelog from logseq=##### until logseq=#####;
}

<end node> 5P9i0s8y19Z
dt=Text
<node>
recover single table
3
-- https://support.oracle.com/epmos/faces/DocumentDisplay?_afrLoop=11860765430896&id=2430319.1&displayIndex=1&_afrWindowMode=0&_adf.ctrl-state=cu7r9rblx_117

GOAL
NOTE: In the images and/or the document content below, the user information and environment data used represents fictitious data from the Oracle sample 
schema(s), Public Documentation delivered with an
Oracle database product or other training material. Any similarity to actual environments, actual persons, living or dead, is purely coincidental and 
not intended in any manner.
For the purposes of this document, the following fictitious environment is used as an example to describe the procedure:

Database Name: PROD
Table name: scott.test_tab

***************

------------------------------------------------------------------------------------
------------------------------------------------------------------------------------
--- for PITR there musht be full backup completed ..
 
-- how to check scn numer
SELECT DBMS_FLASHBACK.get_system_change_number FROM dual;

 
$ rman target=/


This is very handy, when target database is having very large SGA (like 120 GB or more) ,
and when we need to recover a single table, but server does not have that much memory, or when their is limitation of supported hardware)

 
/*
initialization parameters used for automatic instance:
db_name=PROD
db_unique_name=ahDi_pitr_PROD
compatible=12.2.0
db_block_size=8192
db_files=200
diagnostic_dest=/u01/app/oracle/PROD/diag
_system_trig_enabled=FALSE
sga_target=40960M <<<<<<<<<<<<<<<<<<< HERE is the problem ( 40 GB  )
processes=200
db_create_file_dest=/ACFSDUMP/PROD
log_archive_dest_1='location=/ACFSDUMP/PROD'
#No auxiliary parameter file used
*/

------- if there is a huge sga then you can start auxiliary DB with small sga 
SOLUTION :
Create a pfile for auxiliary instance with just memory related parameters

SGA_target = 2048 M
SGA_MAX_SIZE=2048 M

-- Below is an example to use pfile in recover table command

run {
SET AUXILIARY INSTANCE PARAMETER FILE TO '/<path>/init_aux.ora';
recover table scott.test_tab 
until scn 1796160 
auxiliary destination '/<path>/aux'
blah blah etc commands;
}


auxiliary destination '' -- #Location where all the related files for auxiliary instance will be placed
datapump destination '' -- #Location where the export dump of the table will be placed

run
{
RECOVER TABLE SCOTT.EMP, SCOTT.DEPT
    UNTIL TIME 'SYSDATE-1'
    AUXILIARY DESTINATION '/tmp/oracle/recover'
    DATAPUMP DESTINATION '/tmp/recover/dumpfiles'
    DUMP FILE 'emp_dept_exp_dump.dat'
    NOTABLEIMPORT;
}	
	
-- MERWHP
run
{
recover table MIS.CODE_LIB_DEDUCT_LIMIT_LIAB,MIS.CODE_LIB_DEDUCT_LIMIT_WC,MIS.PROGRAM_SUBPROGRAM_LKU,MIS.PRODUCTS,MIS.PAFTRANS_SUMMARY,MIS.SUBPROGRAM_COVERAGE_ROLLUP_WIP,MIS.PRODUCER,MIS.ACCOUNT,MIS.MISTERM_ENHANCED
until time "to_date('04/27/2021 23:59:59','mm/dd/yyyy hh24:mi:ss')"
AUXILIARY DESTINATION '/u01/oracle/zfs-dr/datapump/aux_merwhp_tbls'
DATAPUMP DESTINATION '/u01/oracle/zfs-dr/datapump/aux_merwhp_tbls/expdp_dumpfls'
DUMP FILE 'expdp_merwhp_RITM0572485_08May2021.dmp'
NOTABLEIMPORT;
}

--- testing completed on emplo and was import without any issues
run
{
recover table cae0748.emplo
until time "to_date('05/24/2021 12:20:33','mm/dd/yyyy hh24:mi:ss')"
auxiliary destination '/u01/oracle/zfs-dr/datapump/merwhtbl_rman_bkp/recover_tbls'
datapump destination '/u01/oracle/zfs-dr/datapump/merwhtbl_rman_bkp/recover_tbls'
dump file 'expdp_cae0748_emplo_24May2021122033.dmp'
notableimport;
}

-- recover until # SCN
RECOVER TABLE TEST.T1
  UNTIL SCN 1853267
  AUXILIARY DESTINATION '/u01/aux'  
  REMAP TABLE 'TEST'.'T1':'T1_PREV';

 

-- recover until # TIME
RECOVER TABLE TEST.T1
  UNTIL TIME "TO_DATE('01-JAN-2013 15:00', 'DD-MON-YYYY HH24:MI')"
  AUXILIARY DESTINATION '/u01/aux'  
  REMAP TABLE 'TEST'.'T1':'T1_PREV';

 

-- recover table with no table import
RECOVER TABLE TEST.T1
  UNTIL SCN 1853267
  AUXILIARY DESTINATION '/u01/aux'
  DATAPUMP DESTINATION '/u01/export'
  DUMP FILE 'test_t1_prev.dmp'
  NOTABLEIMPORT;
  
--- remap tables
RECOVER TABLE TEST.T1 OF PLUGGABLE DATABASE pdb1
  UNTIL SCN 1853267
  AUXILIARY DESTINATION '/u01/aux'  
  REMAP TABLE 'TEST'.'T1':'T1_PREV';
  
--- remap tablespace in 
RECOVER TABLE TEST.T1
  UNTIL SCN 1853267
  AUXILIARY DESTINATION '/u01/aux'  
  REMAP TABLE 'TEST'.'T1':'T1_PREV'
  REMAP TABLESPACE 'USERS':'EXAMPLES';  
 

--- remap schema from test to test2
RECOVER TABLE TEST.T1
  UNTIL SCN 1853267
  AUXILIARY DESTINATION '/u01/aux'  
  REMAP TABLE 'TEST'.'T1':'TEST2'.'T1_PREV'
  REMAP TABLESPACE 'USERS':'EXAMPLES';  
  
--- recover table partition
RECOVER TABLE SH.SALES:SALES_1998, SH.SALES:SALES_1999
    UNTIL SEQUENCE 354
    AUXILIARY DESTINATION '/tmp/oracle/recover'
    REMAP TABLE 'SH'.'SALES':'SALES_1998':'HISTORIC_SALES_1998',
              'SH'.'SALES':'SALES_1999':'HISTORIC_SALES_1999' 
    REMAP TABLESPACE 'SALES_TS':'SALES_PRE_2000_TS';  
  
-- recover and remap multiple schema's and table
RECOVER TABLE HR.DEPARTMENTS, SH.CHANNELS
UNTIL TIME 'SYSDATE – 1' 
AUXILIARY DESTINATION '/tmp/auxdest'
REMAP TABLE hr.departments:example.new_departments, sh.channels:example.new_channels;   

<end node> 5P9i0s8y19Z
dt=Text
<node>
sequence from scn
3

-- check and restore the sequence#
select  inst_id,sequence#,thread#,first_change#,next_change#,
    archived,applied,deleted,status,creator,registrar,name
from gv$archived_log
where sequence# >=24515 --between 30919 and 31082
-- and creator='ARCH' and registrar='ARCH'
order by sequence# asc
;

select inst_id,sequence#,thread#,first_change#,next_change#,
    archived,applied,deleted,status,creator,registrar
from gv$archived_log
where 8067274637927 between FIRST_CHANGE# and NEXT_CHANGE#
 -- and creator='ARCH' and registrar='ARCH'
order by sequence# asc
;

run 
{
allocate channel t0 device type 'sbt_tape';
allocate channel t1 device type 'sbt_tape';
allocate channel t2 device type 'sbt_tape';
send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_DATA_VOLUME_POOL=CNABOOST,NSR_GROUP=CNAPROD_ORA)';
#restore archivelog logseq=40895 thread=1;
restore archivelog from logseq=24270 until logseq=24286 thread=1;
}


======================================================================================
Select sequence#,FIRST_CHANGE#,NEXT_CHANGE# from v$archived_log where &scn between FIRST_CHANGE# and NEXT_CHANGE#;;
Enter value for scn: 8066434210620
old:Select sequence#,FIRST_CHANGE#,NEXT_CHANGE# from v$archived_log where &scn between FIRST_CHANGE# and NEXT_CHANGE#
new:Select sequence#,FIRST_CHANGE#,NEXT_CHANGE# from v$archived_log where 8214521367989 between FIRST_CHANGE# and NEXT_CHANGE#

   SEQUENCE#    FIRST_CHANGE#     NEXT_CHANGE#
____________ ________________ ________________
       22270    8066434052178    8066434220311
       28254    8066434024530    8066434221417

  1* Select sequence#,FIRST_CHANGE#,NEXT_CHANGE# from v$archived_log where &scn between FIRST_CHANGE# and NEXT_CHANGE#
SQL>

list backup of archivelog sequence 22270 and 28254

list backup of archivelog sequence 22270

list backup of archivelog sequence 28254;

restore archivelog from logseq=80159 until logseq=80165 thread=2 

-- clmccp DB lrau1p17/18
run 
{
allocate channel t0 device type 'sbt_tape';
allocate channel t1 device type 'sbt_tape';
allocate channel t2 device type 'sbt_tape';
send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA)';
restore archivelog from logseq=44102 thread=2;
#restore archivelog from logseq=28829 until logseq=28884 thread=2;
}


send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA)';

run {
set command id to '1633431900';
allocate channel t0 type 'sbt_tape';
allocate channel t1 type 'sbt_tape';
allocate channel t2 type 'sbt_tape';
send 'NSR_ENV=(NSR_SERVER=lrau1p26,NSR_GROUP=CNAPROD_ORA)';
restore archivelog logseq=88593 thread=1;
}

alter session set nls_date_format = 'DD-MON-YYYY HH24:MI:SS';

select name, thread#, sequence#, status, first_time, next_time ,FIRST_CHANGE#,NEXT_CHANGE#,deleted
from gv$archived_log
where standby_dest = 'NO' 
  and 1074842787 between FIRST_CHANGE# and NEXT_CHANGE#;

select thread#, sequence#,FIRST_CHANGE#, FIRST_TIME,NEXT_CHANGE#,NEXT_TIME, name, status, deleted 
  from gv$archived_log 
 where standby_dest = 'NO' 
   and first_change#>=1074842787;



restore archivelog from logseq=22678 until logseq=22680 thread=1

<end node> 5P9i0s8y19Z
dt=Text
<node>
device type disk
3
-- Date 17/May/2021 09:56 PM
run{
allocate channel ch1 device type disk;
allocate channel ch2 device type disk;
allocate channel ch3 device type disk;
allocate channel ch4 device type disk;
 backup full format '/u01/oracle/zfs-dr/datapump/merwhtbl_rman_bkp/rmanDB_%d_%U'
 (database include current controlfile);
 sql "alter system archive log current";
 crosscheck archivelog all;
 backup full format '/u01/oracle/zfs-dr/datapump/merwhtbl_rman_bkp/rmanarch_%d_%U'
 archivelog all delete input;
 backup current controlfile format '/u01/oracle/zfs-dr/datapump/merwhtbl_rman_bkp/rmanctl_%d_%u_%s';
}


run { 
 allocate channel ch1 type Disk maxpiecesize = 1900M FORMAT '/u01/oracle/zfs-dr/datapump/merwhtbl_rman_bkp/rmanDB_%d_%U'; 
 backup incremental level 0 
 tag cold_db_f 
 filesperset 1 
 (database); 
 backup archivelog all delete all input FORMAT '/u01/oracle/zfs-dr/datapump/merwhtbl_rman_bkp/rmanDB_%d_%U'; 
 backup spfile format '/u01/oracle/zfs-dr/datapump/merwhtbl_rman_bkp/rmanDB_%d_%U'; 
 backup current controlfile format '/u01/oracle/zfs-dr/datapump/merwhtbl_rman_bkp/rmanDB_%d_%U'; 
} 

<end node> 5P9i0s8y19Z
dt=Text
<node>
Backup Info
3
--Backup Levels
Level = 0 -- • A level 0 incremental backup, similar to a full backup, contains all data file blocks.
Level = 1 -- • A differential level 1 incremental backup contains only blocks modified 
		  --   since the last incremental backup. 
Level = 1 CUMULATIVE -- • A cumulative level 1 incremental backup contains only blocks 
                     --   modified since the last level 0 incremental backup.

   
-- Monthly Backup
S  M  T  W  T  F  S
0  1  1  1C 1  1  1c

S  M  T  W  T  F  S
1C 1  1  1 1C  1  1 

S  M  T  W  T  F  S
1C 1  1  1 1C  1  1 

S  M  T  W  T  F  S
1C 1  1  1 1C  1  1 


-- Weekly Backup
S  M  T  W  T  F  S
0  1  1  1C 1  1 1C

S  M  T  W  T  F  S
0  1  1  1C 1  1 1C

S  M  T  W  T  F  S
0  1  1  1C 1  1 1C
	
S  M  T  W  T  F  S
0  1  1  1C 1  1 1C


rman catalog rman/rman_201@arccatdb target rman/rman@devracdb msglog=/devdb_rmanbkups/rman_bkup/rman_INCR_1_${ORACLE_SID}_$bkup_date.log


#!/bin/sh
export ORACLE_SID=arccatdb
bkup_date="`date +%m%d%Y`"
rman catalog rman/rman_201@arccatdb<< EOF
connect target sys/sysregracdb@regracdb
run
{
        ALLOCATE CHANNEL c1 device type disk;
        BACKUP
        FORMAT '/recovery/oracle/rman_bkups/bkups/$bkup_date_%d_DB_%u_%s_%p.bak'
        INCREMENTAL LEVEL = 0 (DATABASE include current controlfile);
        BACKUP ARCHIVELOG ALL
        DELETE INPUT FORMAT '/recovery/oracle/rman_bkups/archlogs/archFiles_$bkup_date_%d_%u_%s';
        RELEASE CHANNEL c1;
        sql 'alter system switch logfile';
}
exit;
EOF

--Cold backup (archivelog or noarchivelog mode)
run 
{
    allocate channel t1 type disk;
    shutdown immediate;
    startup mount;
    backup database include current controlfile format '/u01/ora_backup/rman/%d_%u_%s';
    alter database open;
}



--1. Turn on block checking
--REASON: The aim is to detect, very early the presence of corrupt blocks in the database. 
--        This has a slight performance overhead, but Checksums allow Oracle to detect early corruption 
--		  caused by underlying disk, storage system, or I/O system problems.

SQL> alter system set db_block_checking = true scope=both;


--2. Turn on block tracking when using RMAN backups (if running 10g or above)
--REASON: This will allow RMAN to backup only those blocks that have changed since the last full backup, 
--		  which will reduce the time taken to back up, as less blocks will be backed up.

SQL> alter database enable block change tracking using file ‘/u01/oradata/ora1/change_tracking.f’;


--3. Duplex log groups and members and have more than one archive log dest
--REASON: If an archivelog is corrupted or lost, by having multiple copies in multiple locations, 
--		  the other logs will still be available and could be used.

-- If an online log is DELETEd or becomes corrupt, you will have another member that can be used to 
-- recover if required.

SQL> alter system set log_archive_dest_2='location=/new/location/archive2' scope=both;
SQL> alter database add logfile member '/new/location/redo21.log' to group 1;

/*
 4. When backing up the database use the 'check logical' parameter

REASON: This will cause RMAN to check for logical corruption within a block as well as the normal
head/tail checksumming. This is the best way to ensure that you will get a good backup.

*/

RMAN> backup check logical database plus archivelog DELETE input;

/*

5. Test your backup

REASON: This will do everything except actually restore the database. This is the best method to determine 
if your backup is good and usable before being in a situation where it is
critical and issues exist.
*/

RMAN> restore validate database;

/*

6. Have each datafile in a single backup piece

REASON: When doing a partial restore RMAN must read through the entire piece to get the
datafile/archivelog requested. The smaller the backup piece the quicker the restore can
complete. This is especially relevent with tape backups of large databases or where the
restore is only on individual / few files.

*/

RMAN> backup database filesperset 1 plus archivelog DELETE input;

/*
7. Maintain your RMAN catalog/controlfile
REASON: Choose your retention policy carefully. Make sure that it compliments your tape subsystem
retention policy, requirements for backup recovery strategy. If not using a catalog, ensure that your 
controlfile record keep time instance parameter matches your retention policy.
*/

SQL> alter system set control_file_record_keep_time=21 scope=both;
--This will keep 21 days of backup records.

--Run regular catalog maintenance.

--REASON: crosschecking will check that the catalog/controlfile matches the physical backups. If a backup 
-- is missing, it will set the piece to 'EXPIRED' so when a restore is started, that it will not be eligible, 
-- and an earlier backup will be used. To remove the expired backups from the catalog/controlfile use the 
-- DELETE expired command.



nohup rman target sys/""rr4m4db_6y6p""@usmgenp1 auxiliary sys/""rr4m4db_6y6t""@amolirumgdbts01:1521/usmgent.monsanto.com cmdfile=/comm_db/usmgent/rman_usmgent_refresh_aux_sct.rcv msglog /comm_db/usmgent/usmgent_refresh_logs_19May2018.log  &

  -- below script
  --/comm_db/usmgent/rman_usmgent_refresh_aux_sct.rcv  
 
run {
allocate auxiliary channel c1 device type DISK;
allocate auxiliary channel c2 device type DISK;
allocate auxiliary channel c3 device type DISK;
allocate auxiliary channel c4 device type DISK;
allocate auxiliary channel c5 device type DISK;
allocate auxiliary channel c6 device type DISK;
allocate auxiliary channel c7 device type DISK;
allocate auxiliary channel c8 device type DISK;

allocate channel t1 device type DISK;
allocate channel t2 device type DISK;
allocate channel t3 device type DISK;
allocate channel t4 device type DISK;
allocate channel t5 device type DISK;
allocate channel t6 device type DISK;
allocate channel t7 device type DISK;
allocate channel t8 device type DISK;

DUPLICATE TARGET DATABASE
  TO usmgent
  FROM ACTIVE DATABASE
  NOFILENAMECHECK
;
}

<end node> 5P9i0s8y19Z
dt=Text
<node>
RMAN Drop DB
3
-- Best practice to Drop database using RMAN
-- As per Best practice, take full backup of the database which you will be dropping
-- DataPump export will be the good option
-- If using RMAN then move the backup files to TAPE, as we are dropping the backups also 
RMAN> CONNECT TARGET SYS@test1

target database Password: password
connected to target database: TEST1 (DBID=39525561)

RMAN> STARTUP FORCE MOUNT
RMAN> SQL 'ALTER SYSTEM ENABLE RESTRICTED SESSION';
RMAN> DROP DATABASE INCLUDING BACKUPS NOPROMPT;   

<end node> 5P9i0s8y19Z
dt=Text
<node>
Tablespace's
2
--- Get the temporary usage Monthly 
with 
pivot1 AS
(
    SELECT MIN(snap_id) AS begin_snap_id
      FROM dba_hist_snapshot
	 where trunc(begin_interval_time, 'DD')  >= trunc(sysdate - 40, 'DD')
),
pivot2 as
(
	SELECT
		trunc(ash.sample_time,'MI') sample_time,
		ash.SESSION_ID,
		ash.SESSION_SERIAL#,
		ash.SQL_ID,
		ash.sql_exec_id,
		U.temporary_tablespace,
		max(temp_space_allocated)/(1024*1024) max_temp_per_sql_mb
	from dba_hist_active_sess_history ash
	INNER JOIN dba_users U ON ash.user_id = U.user_id
	where ash.session_type = 'FOREGROUND'
	  and ash.temp_space_allocated > 0
	-- and U.temporary_tablespace = 'TEMP3'
	  and snap_id > (SELECT begin_snap_id FROM pivot1)
	GROUP BY trunc(ash.sample_time, 'MI'), ash.session_id,temp_space_allocated,
		ash.session_serial#, ash.sql_id, ash.sql_exec_id, u.temporary_tablespace
), 
pivot3 AS 
(
-- only to get grouped temp tablespace with sample datetime from pivot2
    SELECT temporary_tablespace, sample_time,
        SUM(max_temp_per_sql_mb) total_temp_permin_mb
    FROM pivot2
    GROUP BY temporary_tablespace, sample_time
    ORDER BY temporary_tablespace, sample_time
)
SELECT temporary_tablespace,
    dd.tablespace_size / ( 1024 * 1024) temp_max_size_mb,
    trunc(sample_time, 'DD') AS day,
    MAX(total_temp_permin_mb) max_temp_per_day_mb
FROM pivot3, dba_temp_free_space dd 
where dd.tablespace_name = pivot3.temporary_tablespace
GROUP BY temporary_tablespace, dd.tablespace_size / ( 1024 * 1024), trunc(sample_time, 'DD')
--having trunc(sample_time, 'DD') >= to_date('01-11-13', 'DD-MM-YY')
ORDER BY temporary_tablespace, day;



SELECT
  	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'00',1,0)),'9999') "00",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'01',1,0)),'9999') "01",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'02',1,0)),'9999') "02",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'03',1,0)),'9999') "03",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'04',1,0)),'9999') "04",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'05',1,0)),'9999') "05",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'06',1,0)),'9999') "06",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'07',1,0)),'9999') "07",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'08',1,0)),'9999') "08",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'09',1,0)),'9999') "09",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'10',1,0)),'9999') "10",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'11',1,0)),'9999') "11",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'12',1,0)),'9999') "12",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'13',1,0)),'9999') "13",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'14',1,0)),'9999') "14",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'15',1,0)),'9999') "15",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'16',1,0)),'9999') "16",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'17',1,0)),'9999') "17",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'18',1,0)),'9999') "18",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'19',1,0)),'9999') "19",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'20',1,0)),'9999') "20",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'21',1,0)),'9999') "21",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'22',1,0)),'9999') "22",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'23',1,0)),'9999') "23",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'24',1,0)),'9999') "24",    
    ash.SESSION_ID,
    ash.SESSION_SERIAL#,
    ash.SQL_ID,
    ash.sql_exec_id,
    U.temporary_tablespace,
    --max(temp_space_allocated)/(1024*1024) max_temp_per_sql_mb
    dbms_xplan.format_size2(temp_space_allocated)
from dba_hist_active_sess_history ash,dba_users U
where ash.user_id = U.user_id
  and ash.session_type = 'FOREGROUND'
  and ash.temp_space_allocated > 0
 and U.temporary_tablespace = 'TEMP'
--  and snap_id > (SELECT begin_snap_id FROM pivot1)
GROUP BY ash.session_id,temp_space_allocated, ash.session_serial#, ash.sql_id, ash.sql_exec_id, u.temporary_tablespace
;







select /*+ FIRST_ROWS(10) */
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'00',1,0)),'9999') "00",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'01',1,0)),'9999') "01",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'02',1,0)),'9999') "02",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'03',1,0)),'9999') "03",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'04',1,0)),'9999') "04",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'05',1,0)),'9999') "05",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'06',1,0)),'9999') "06",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'07',1,0)),'9999') "07",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'08',1,0)),'9999') "08",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'09',1,0)),'9999') "09",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'10',1,0)),'9999') "10",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'11',1,0)),'9999') "11",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'12',1,0)),'9999') "12",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'13',1,0)),'9999') "13",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'14',1,0)),'9999') "14",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'15',1,0)),'9999') "15",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'16',1,0)),'9999') "16",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'17',1,0)),'9999') "17",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'18',1,0)),'9999') "18",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'19',1,0)),'9999') "19",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'20',1,0)),'9999') "20",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'21',1,0)),'9999') "21",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'22',1,0)),'9999') "22",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'23',1,0)),'9999') "23",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'24',1,0)),'9999') "24",  
    to_char(sum(decode(to_char(ash.sample_time,'HH24'),'25',1,0)),'9999') "25",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'26',1,0)),'9999') "26",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'27',1,0)),'9999') "27",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'28',1,0)),'9999') "28",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'29',1,0)),'9999') "29",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'30',1,0)),'9999') "30",
	to_char(sum(decode(to_char(ash.sample_time,'HH24'),'31',1,0)),'9999') "31"    
from  dba_hist_active_sess_history ash;    

<end node> 5P9i0s8y19Z
dt=Text
<node>
Tablespace
3
-- Create Tablespace scripts
CREATE TABLESPACE SS_DATA_MGMT_BASE_TBL DATAFILE '+DATA' SIZE 2G AUTOEXTEND ON NEXT 5M MAXSIZE UNLIMITED
LOGGING
ONLINE
EXTENT MANAGEMENT LOCAL AUTOALLOCATE
SEGMENT SPACE MANAGEMENT AUTO
FLASHBACK ON;



CREATE TABLESPACE striim_user_tbls DATAFILE '+DATA_ETE' SIZE 2G 
AUTOEXTEND ON NEXT 5M MAXSIZE 10g
EXTENT MANAGEMENT LOCAL AUTOALLOCATE
SEGMENT SPACE MANAGEMENT AUTO
FLASHBACK ON;


create user striim_user
identified by "S$riim02020U"
default tablespace striim_user_tbls
temporary tablespace temp
profile APPSPROFILE;

grant create session,resource to striim_user;
grant unlimited tablespace to striim_user;
alter user striim_user quota unlimited on striim_user_tbls;


create tablespace cust360_dc_data '+DATA' SIZE 2G AUTOEXTEND ON NEXT 5M MAXSIZE UNLIMITED;

create tablespace cust360_dc_index '+DATA' SIZE 2G AUTOEXTEND ON NEXT 5M MAXSIZE UNLIMITED;

alter tablespace ilog 

alter database datafile 'E:\ORACLE\TCUAUST\ILOG01.DBF' resize 200m;

--- Query to check usage from Oracle 11.2 version
select * from dba_tablespace_usage_metrics  
order by USED_PERCENT desc;

 
-- to check the tablespace datafile size
select tablespace_name, file_name,dbms_xplan.format_size(bytes)file_size
from dba_data_files
where tablespace_name='MIS_WORK'
order by file_size

select dbms_xplan.format_time_s(4500) display_time from dual
================================================================================

select tablespace_name,dbms_xplan.format_size(bytes)
from dba_data_files
where tablespace_name in ('SYSAUX')


select owner, segment_name, segment_type,dbms_xplan.format_size(bytes) Object_Size, tablespace_name
from dba_segments
where tablespace_name in ('USERS')
order by 4 desc


select owner, segment_name,dbms_xplan.format_size(bytes) table_sizes
from dba_segments
where segment_name in ('ARCH_RATING_FACTOR_CR','ARCH_RATING_FACTOR_RQ')

select owner, segment_name,dbms_xplan.format_size(bytes) table_sizes
from dba_segments
where segment_name in ('AUD$')

SELECT tablespace_name, allocated,Free_Space,Used_Space,"% Free", "% Used",MaxBytes
FROM(
select  a.tablespace_name tablespace_name,
       dbms_xplan.format_size(a.bytes_alloc) Allocated,
       dbms_xplan.format_size(nvl(b.bytes_free, 0)) Free_Space,
       dbms_xplan.format_size((a.bytes_alloc - nvl(b.bytes_free, 0))) Used_Space,
       dbms_xplan.format_size((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
       dbms_xplan.format_size(100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100)) "% Used",
       dbms_xplan.format_size(round(maxbytes)) MaxBytes       
from  ( select  f.tablespace_name,
               sum(f.bytes) bytes_alloc,
               sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
        from dba_data_files f 
        group by tablespace_name) a,
      ( select  f.tablespace_name,
               sum(f.bytes) bytes_free
        from dba_free_space f
        group by tablespace_name) b
where a.tablespace_name = b.tablespace_name (+)
) 
--where tablespace_name like 'MIS_WORK%' 
ORDER BY 6 asc;

================================================================================

--- best script to check the usage of tablespaces
SELECT Tablespace_Name, "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM(
select  a.tablespace_name Tablespace_Name,
       round(a.bytes_alloc / 1024 / 1024) "Allocated (MB)",
       round(nvl(b.bytes_free, 0) / 1024 / 1024) "Free (MB)",
       round((a.bytes_alloc - nvl(b.bytes_free, 0)) / 1024 / 1024) "Used (MB)",
       round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
       100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Used",
       round(maxbytes/1024 / 1024) "Max. Bytes (MB)"
from  ( select  f.tablespace_name,
               sum(f.bytes) bytes_alloc,
               sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
        from dba_data_files f
        group by tablespace_name) a,
      ( select  f.tablespace_name,
               sum(f.bytes)  bytes_free
        from dba_free_space f
        group by tablespace_name) b
where a.tablespace_name = b.tablespace_name (+)
union all
select h.tablespace_name,
       round(sum(h.bytes_free + h.bytes_used) / 1048576) megs_alloc,
       round(sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / 1048576) megs_free,
       round(sum(nvl(p.bytes_used, 0))/ 1048576) megs_used,
       round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) Pct_Free,
       100 - round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) pct_used,
       round(sum(f.maxbytes) / 1048576) max
from   sys.v_$TEMP_SPACE_HEADER h, sys.v_$Temp_extent_pool p, dba_temp_files f
where  p.file_id(+) = h.file_id
and    p.tablespace_name(+) = h.tablespace_name
and    f.file_id = h.file_id
and    f.tablespace_name = h.tablespace_name
group by h.tablespace_name
)  --where Tablespace_name in ('MIS_WORK')
order by 6 asc;

select a.*, 'alter database  datafile '''||file_name||''' resize '||total_mb||'m;' alter_cmd
from 
(
	select df.tablespace_name Tablespace,
			df.totalspace Total_MB,
			totalusedspace Used_MB,
			(df.totalspace - tu.totalusedspace) Free_MB,
			round(100 * ( (df.totalspace - tu.totalusedspace)/ df.totalspace)) precent_free,
			file_name
	from
		(select file_name, tablespace_name, round(sum(bytes) / 1048576) TotalSpace
		 from dba_data_files 
		 group by tablespace_name, file_name) df,
		(select round(sum(bytes)/(1024*1024)) totalusedspace, tablespace_name
		 from dba_segments 
		 group by tablespace_name) tu
	where df.tablespace_name = tu.tablespace_name 
 ) a
 where Tablespace in ('DOCDIST_INDEXES');


select file_name, tablespace_name, autoextensible, round(sum(BYTES/1024/1024/1024)) MAXSIZE
--   ,'alter database datafile '''||file_name||''' AUTOEXTEND ON  NEXT 100M MAXSIZE UNLIMITED;' auto_yes,
  -- ,'alter database datafile '''||file_name||''' AUTOEXTEND off;' auto_no
   from dba_data_files
    where tablespace_name in('DOCDIST_INDEXES')
   --   and autoextensible = 'YES'
 --     and autoextensible = 'NO'
    group by file_name, tablespace_name, autoextensible
  --  having sum(BYTES/1024/1024/1024) < 25
   -- order by  sum(BYTES/1024/1024/1024) asc;

-- temporary tablespace usage
SELECT Tablespace_Name, "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM(
select h.tablespace_name Tablespace_Name,
       round(sum(h.bytes_free + h.bytes_used) / 1048576) "Allocated (MB)",
       round(sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / 1048576) "Free (MB)",
       round(sum(nvl(p.bytes_used, 0))/ 1048576) "Used (MB)",
       round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) "% Free",
       100 - round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) "% Used",
       round(sum(f.maxbytes) / 1048576) "Max. Bytes (MB)"
from   sys.v_$TEMP_SPACE_HEADER h, sys.v_$Temp_extent_pool p, dba_temp_files f
where  p.file_id(+) = h.file_id
and    p.tablespace_name(+) = h.tablespace_name
and    f.file_id = h.file_id
and    f.tablespace_name = h.tablespace_name
group by h.tablespace_name
)  --where Tablespace_name in ('MIS_WORK')
order by 6 asc;



SELECT tablespace_name, "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM(
select  a.tablespace_name tablespace_name,
       round(a.bytes_alloc / 1024 / 1024) "Allocated (MB)",
       round(nvl(b.bytes_free, 0) / 1024 / 1024) "Free (MB)",
       round((a.bytes_alloc - nvl(b.bytes_free, 0)) / 1024 / 1024) "Used (MB)",
       round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
       100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Used",
       round(maxbytes/1024 / 1024) "Max. Bytes (MB)"
from  ( select  f.tablespace_name,
               sum(f.bytes) bytes_alloc,
               sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
        from dba_data_files f 
        group by tablespace_name) a,
      ( select  f.tablespace_name,
               sum(f.bytes)  bytes_free
        from dba_free_space f
        group by tablespace_name) b
where a.tablespace_name = b.tablespace_name (+)
) 
where tablespace_name in ('ESBDATA')
ORDER BY 6 asc


-- reduce temporary tablespace tempfiles
select file_name,tablespace_name,autoextensible,dbms_xplan.format_size(bytes)file_size ,
'alter database tempfile '''||file_name||''' resize 10g;'
from dba_temp_files 
where regexp_like(file_name,'+DATA_ETE\/*','i')
order by 3 asc, 4 desc
;
======================================================================================

--- Tablespace Utilization Script (including AUTOEXTEND) for generating 
--- report of more than 80 % used tablespaces (IN GB)

set pages 50000 lines 32000
col tablespace_name format a30
col TABLESPACE_NAME heading "Tablespace|Name"
col Allocated_size heading "Allocated|Size(GB)" form 99999999.99
col Current_size heading "Current|Size(GB)" form 99999999.99
col Used_size heading "Used|Size(GB)" form 99999999.99
col Available_size heading "Available|Size(GB)" form 99999999.99
col Pct_used heading "%Used (vs)|(Allocated)" form 99999999.99

select a.tablespace_name
        ,a.alloc_size/1024/1024/1024 Allocated_size
        ,a.cur_size/1024/1024/1024 Current_Size
        ,(u.used+a.file_count*65536)/1024/1024/1024 Used_size
        ,(a.alloc_size-(u.used+a.file_count*65536))/1024/1024/1024 Available_size
        ,((u.used+a.file_count*65536)*100)/a.alloc_size Pct_used
from     dba_tablespaces t
        ,(select t1.tablespace_name
        ,nvl(sum(s.bytes),0) used
        from  dba_segments s
        ,dba_tablespaces t1
         where t1.tablespace_name=s.tablespace_name(+)
         group by t1.tablespace_name) u
        ,(select d.tablespace_name
        ,sum(greatest(d.bytes,nvl(d.maxbytes,0))) alloc_size
        ,sum(d.bytes) cur_size
        ,count(*) file_count
        from dba_data_files d
        group by d.tablespace_name) a
where t.tablespace_name=u.tablespace_name
  and ((u.used+a.file_count*65536)*100)/a.alloc_size>80
  and t.tablespace_name=a.tablespace_name
  and t.tablespace_name like 'UNDO%'
order by t.tablespace_name
/

set pagesize 2000 line 150

col tablespace_name format a20
col allocated_mb    format 9,999,999.99
col used_mb         format 9,999,999.99
col free_space_mb   format 9,999,999.99
col percent_used    format 999.9

SELECT SUBSTR(df.tablespace_name,1,20) tablespace_name, df.bytes/1024/1024 allocated_mb,
(df.bytes-nvl(dfs.bytes,0))/1024/1024 used_mb,
NVL(dfs.bytes/1024/1024,0) free_space_mb, round((df.bytes-nvl(dfs.bytes,0))/df.bytes * 100,2) percent_used
FROM (select sum(bytes) bytes, tablespace_name from dba_data_files group by tablespace_name) df,
(select sum(bytes) bytes,tablespace_name from dba_free_space
group by tablespace_name) dfs WHERE df.tablespace_name =dfs.tablespace_name (+)
order by 5 desc;


-- Tablespace Utilization % in MB
select * 
from 
(
	select df.tablespace_name Tablespace,
			df.totalspace Total_MB,
			totalusedspace used_MB,
			(df.totalspace - tu.totalusedspace) free_MB,			
			round(100 * ( (df.totalspace - tu.totalusedspace)/ df.totalspace)) Percentage_Free
	from
		(select tablespace_name, round(sum(bytes) / 1048576) TotalSpace
		 from dba_data_files 
		 group by tablespace_name) df,
		(select round(sum(bytes)/(1024*1024)) totalusedspace, tablespace_name
		 from dba_segments 
		 group by tablespace_name) tu
	where df.tablespace_name = tu.tablespace_name 
 ) 
 --where Tablespace='SENUS_01'
order by USED_MB,Percentage_Free desc

--- shows datafiles also
select * 
from 
(
	select df.tablespace_name Tablespace,
			df.totalspace Total_MB,
			totalusedspace Used_MB,
			(df.totalspace - tu.totalusedspace) Free_MB,
			round(100 * ( (df.totalspace - tu.totalusedspace)/ df.totalspace)) precent_free,
			file_name
	from
		(select file_name, tablespace_name, round(sum(bytes) / 1048576) TotalSpace
		 from dba_data_files 
		 group by tablespace_name, file_name) df,
		(select round(sum(bytes)/(1024*1024)) totalusedspace, tablespace_name
		 from dba_segments 
		 group by tablespace_name) tu
	where df.tablespace_name = tu.tablespace_name 
 ) where Tablespace='&tablespace_name'


-- Check which datafiles are autoextensible YES
col file_name for a50
col tablespace_name for a8
select file_name, tablespace_name, autoextensible, round(sum(BYTES/1024/1024/1024)) MAXSIZE
   from dba_data_files
    where tablespace_name='CCAT_FILENET1' 
--      and autoextensible!='YES'
    group by file_name, tablespace_name, autoextensible
  --  having sum(BYTES/1024/1024/1024) < 25
    order by  sum(BYTES/1024/1024/1024) asc;


-- show datafiles less then 25 GB in size
col file_name for a50
col tablespace_name for a8
select file_name, tablespace_name, autoextensible, round(sum(BYTES/1024/1024/1024)) MAXSIZE
   from dba_data_files
    where tablespace_name='ADLI01'
    group by file_name, tablespace_name, autoextensible
    having sum(BYTES/1024/1024/1024) < 25
    order by  sum(BYTES/1024/1024/1024) asc;

alter database datafile '+DATA/SPCR/DATAFILE/spc_op.298.894107375' resize 70000m

alter database datafile '/gmis/oradata59/ADLI01_67.gm' RESIZE 10G;
alter database datafile '/gmis/oradata59/ADLI01_67.gm' AUTOEXTEND on next 20m maxsize unlimited;

ALTER DATABASE DATAFILE '+DATA/gscd/datafile/supply_chain_int_stg_index.308.877033827' RESIZE 800M;
ALTER DATABASE DATAFILE '+DATA/gscd/datafile/supply_chain_int_stg_index.308.877033827' AUTOEXTEND ON  NEXT 100M MAXSIZE UNLIMITED;

alter database datafile '/gmis/oradata73/ADLI01_86.gm' autoextend off;


alter tablespace PAFTRAN_GL_ACCT_2019_T_V01 add datafile '+DATA_WH' size 10g autoextend on next 1g maxsize 20g;

select file_name, tablespace_name, autoextensible, round(sum(BYTES/1024/1024/1024)) MAXSIZE,
   'alter database datafile '''||file_name||''' AUTOEXTEND ON  NEXT 100M MAXSIZE UNLIMITED;' auto_yes,
   'alter database datafile '''||file_name||''' AUTOEXTEND off;' auto_no
   from dba_data_files
    where tablespace_name = 'TS_OLTP' 
   --   and autoextensible = 'YES'
 --     and autoextensible = 'NO'
    group by file_name, tablespace_name, autoextensible
  --  having sum(BYTES/1024/1024/1024) < 25
   -- order by  sum(BYTES/1024/1024/1024) asc;
;
================================================================================


--
-- Temporary Tablespace Usage.
--
 
SET PAUSE ON
SET PAUSE 'Press Return to Continue'
SET PAGESIZE 60
SET LINESIZE 300
 
COL TABLESPACE_SIZE FOR 999,999,999,999
COL ALLOCATED_SPACE FOR 999,999,999,999
COL FREE_SPACE FOR 999,999,999,999
 
SELECT *
FROM   dba_temp_free_space
/

x
--
-- Temporary Tablespace Sort Usage.
--
 
SET PAUSE ON
SET PAUSE 'Press Return to Continue'
SET PAGESIZE 60
SET LINESIZE 300 
SELECT 
   A.tablespace_name tablespace, 
   D.mb_total,
   SUM (A.used_blocks * D.block_size) / 1024 / 1024 mb_used,
   D.mb_total - SUM (A.used_blocks * D.block_size) / 1024 / 1024 mb_free
FROM 
   v$sort_segment A,
(
SELECT 
   B.name, 
   C.block_size, 
   SUM (C.bytes) / 1024 / 1024 mb_total
FROM 
   v$tablespace B, 
   v$tempfile C
WHERE 
   B.ts#= C.ts#
GROUP BY 
   B.name, 
   C.block_size
) D
WHERE 
   A.tablespace_name = D.name
GROUP by 
   A.tablespace_name, 
   D.mb_total
/


-- Temporary teablespace used in %

SELECT a.tablespace_name,
    ROUND((c.total_blocks*b.block_size)/1024/1024/1024,2) "Total Size [GB]",
    ROUND((a.used_blocks*b.block_size)/1024/1024/1024,2) "Used_size[GB]",
    ROUND(((c.total_blocks-a.used_blocks)*b.block_size)/1024/1024/1024,2) "Free_size[GB]",
    ROUND((a.max_blocks*b.block_size)/1024/1024/1024,2) "Max_Size_Ever_Used[GB]",            
    ROUND((a.max_used_blocks*b.block_size)/1024/1024/1024,2) "MaxSize_ever_Used_by_Sorts[GB]" ,
    ROUND((a.used_blocks/c.total_blocks)*100,2) "Used Percentage"
FROM V$sort_segment a,
	dba_tablespaces b,
     (SELECT tablespace_name,SUM(blocks) total_blocks 
	   FROM dba_temp_files 
	  GROUP by tablespace_name) c
WHERE a.tablespace_name=b.tablespace_name 
  AND a.tablespace_name=c.tablespace_name;


select a.tablespace_name, b.Total_MB,
       b.Total_MB - round(a.used_blocks*8/1024) Current_Free_MB,
       round(used_blocks*8/1024)                Current_Used_MB,
      round(max_used_blocks*8/1024)             Max_used_MB
from v$sort_segment a,
 (select round(sum(bytes)/1024/1024) Total_MB from dba_temp_files ) b;

-- check the sessions that using temp tablespace:
SELECT s.sid, s.username, u.tablespace, 
	s.sql_hash_value||'/'||u.sqlhash hash_value, 
	u.segtype, u.contents, u.blocks
FROM v$session s, v$tempseg_usage u
WHERE s.saddr=u.session_addr
order by u.blocks;

-- As you can see, there are different segment types. Most of time, SORT is the one we need to check. 
-- If you are lucky enough, or the client only have 1 SQL cursor, you will get the SQL hash value in 
-- the above result.

-- However, the tempspace can be used by any open cursor in that session. The current SQL is 
-- not necessary the culprit. In that case, we can check it from v$sql:

select hash_value, sorts, rows_processed/executions
  from v$sql
 where hash_value in (select hash_value from v$open_cursor where sid=7448)
   and sorts > 0
   and PARSING_SCHEMA_NAME='ALEXZENG3'
 order by rows_processed/executions;

--result of the above query
   HASH_VALUE      SORTS ROWS_PROCESSED/EXECUTIONS
------------- ---------- -------------------------
    887856235      30506                .000196676
   2631006892      30227                .001323276
   3490377209        632                46993.6709

-- Now it’s very obviously, the SQL 3490377209 sorts lots of rows every time. It used most 
-- of the tempspace in this session


-- The following query displays information about each statement that is using space 
-- in a sort segment. This query will need slight modification to run on Oracle 8i 
-- databases, since the dba_tablespaces view did not have a block_size column in Oracle 8i.
-- http://dbspecialists.com/wp-content/uploads/2017/03/temp_space.html
SELECT   S.sid || ',' || S.serial# sid_serial, S.username,
         T.blocks * TBS.block_size / 1024 / 1024 mb_used, T.tablespace,
         T.sqladdr address, Q.hash_value, Q.sql_text
FROM     v$sort_usage T, v$session S, v$sqlarea Q, dba_tablespaces TBS
WHERE    T.session_addr = S.saddr
AND      T.sqladdr = Q.address (+)
AND      T.tablespace = TBS.tablespace_name
ORDER BY S.sid;


-- Give date and time to check old usage of temporary tablespace
SELECT BEGIN_INTERVAL_TIME,END_INTERVAL_TIME,B.NAME,
    ROUND((TABLESPACE_SIZE*8*1024)/1024/1024,2) SIZE_MB,
    ROUND((TABLESPACE_MAXSIZE*8*1024)/1024/1024,2) MAXSIZE_MB,
    ROUND((TABLESPACE_USEDSIZE*8*1024)/1024/1024,2) USEDSIZE_MB,
    ROUND(((TABLESPACE_USEDSIZE*8*1024)/1024/1024)/((TABLESPACE_MAXSIZE*8*1024)/1024/1024)*100,2) "Used_Percentage"
FROM DBA_HIST_TBSPC_SPACE_USAGE A
    JOIN V$TABLESPACE B ON (A.TABLESPACE_ID = B.TS#)
    JOIN DBA_HIST_SNAPSHOT C ON (A.SNAP_ID = C.SNAP_ID)
WHERE NAME = 'OLTP_TMP01' -- Tablespacename to check the gradual growth of particular tablespace
    AND BEGIN_INTERVAL_TIME BETWEEN to_date('10/01/2017 00:00:00','MM/DD/YYYY HH24:MI:SS')
                                AND TO_DATE ('10/01/2017 10:00:00','MM/DD/YYYY HH24:MI:SS')
ORDER BY 1 DESC 

================================================================================

-- UNDO Tablespace 
select tsu.tablespace_name, ceil(tsu.used_mb) "size MB", 
	  decode(ceil(tsf.free_mb), NULL,0,ceil(tsf.free_mb)) "free MB", 
	  decode(100 - ceil(tsf.free_mb/tsu.used_mb*100), NULL, 100, 100 - ceil(tsf.free_mb/tsu.used_mb*100)) "% used"
  from (
	select tablespace_name, sum(bytes)/1024/1024 used_mb
 	from  dba_data_files 
	group by tablespace_name 
	union all
 	select tablespace_name || '  **TEMP**', 
		  sum(bytes)/1024/1024 used_mb
 	from  dba_temp_files group by tablespace_name) tsu, 
		(select tablespace_name, sum(bytes)/1024/1024 free_mb
 from  dba_free_space group by tablespace_name) tsf
where tsu.tablespace_name = tsf.tablespace_name (+)
order by 4
/

<end node> 5P9i0s8y19Z
dt=Text
<node>
Temp Tablespace
3
-- Shrinking a Locally Managed Temporary Tablespace
Large sort operations performed by the database may result in a temporary tablespace growing 
and occupying a considerable amount of disk space. After the sort operation completes, the 
extra space is not released; it is just marked as free and available for reuse. Therefore, a 
single large sort operation might result in a large amount of allocated temporary space that 
remains unused after the sort operation is complete. For this reason, the database enables 
you to shrink locally managed temporary tablespaces and release unused space.

You use the SHRINK SPACE clause of the ALTER TABLESPACE statement to shrink a temporary tablespace, 
or the SHRINK TEMPFILE clause of the ALTER TABLESPACE statement to shrink a specific tempfile of a 
temporary tablespace. Shrinking frees as much space as possible while maintaining the other attributes 
of the tablespace or tempfile. The optional KEEP clause defines a minimum size for the tablespace or tempfile.

Shrinking is an online operation, which means that user sessions can continue to allocate sort extents if needed, 
and already-running queries are not affected.

The following example shrinks the locally managed temporary tablespace lmtmp1 to a size of 20M.

ALTER TABLESPACE lmtemp1 SHRINK SPACE KEEP 2256g;

The following example shrinks the tempfile lmtemp02.dbf of the locally managed temporary tablespace lmtmp2.
Because the KEEP clause is omitted, the database attempts to shrink the tempfile to the minimum possible size.

ALTER TABLESPACE lmtemp2 SHRINK TEMPFILE '/u02/oracle/data/lmtemp02.dbf';


--
-- Displays the temp sort space currently in use by users.
--
 
SET PAUSE ON
SET PAUSE 'Press Return to Continue'
COLUMN tablespace FORMAT A20
COLUMN temp_size FORMAT A15
COLUMN sid_serial FORMAT A15
COLUMN username FORMAT A20
COLUMN program FORMAT A50 
col SID_SERIAL#_INSTAID for a20
col sql_id for a30
SELECT b.tablespace,
       dbms_xplan.format_size2(b.blocks*p.value) temp_size,
       ''''||a.sid||','||a.serial#||'@'||a.inst_id||'''' sid_Serial#_instaID,
       NVL(a.username, '(oracle)') AS username,
       a.program,
       a.status,
       a.sql_id
FROM   gv$session a,
       gv$sort_usage b,
       gv$parameter p
WHERE  p.name  = 'db_block_size'
AND    a.saddr = b.session_addr
AND    a.inst_id=b.inst_id
AND    a.inst_id=p.inst_id
ORDER BY b.tablespace, b.blocks
;


select 'alter database tempfile '''||file_name||''' autoextend off;'
from dba_temp_files
where autoextensible='YES'
;

-- temporary tablespace usage
SELECT Tablespace_Name, "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM(
select h.tablespace_name Tablespace_Name,
       round(sum(h.bytes_free + h.bytes_used) / 1048576) "Allocated (MB)",
       round(sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / 1048576) "Free (MB)",
       round(sum(nvl(p.bytes_used, 0))/ 1048576) "Used (MB)",
       round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) "% Free",
       100 - round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) "% Used",
       round(sum(f.maxbytes) / 1048576) "Max. Bytes (MB)"
from   sys.v_$TEMP_SPACE_HEADER h, sys.v_$Temp_extent_pool p, dba_temp_files f
where  p.file_id(+) = h.file_id
and    p.tablespace_name(+) = h.tablespace_name
and    f.file_id = h.file_id
and    f.tablespace_name = h.tablespace_name
group by h.tablespace_name
)  --where Tablespace_name in ('MIS_WORK')
order by 6 asc;


SELECT Tablespace_Name, Aquired_Size "Aquired_Size", Free_Space "Free_Space", "Used", "% Free", "% Used", "Max. Bytes" 
FROM(
select h.tablespace_name Tablespace_Name,
       dbms_xplan.format_size((sum(h.bytes_free + h.bytes_used))) Aquired_Size,
       dbms_xplan.format_size((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)))) Free_Space,
       dbms_xplan.format_size((sum(nvl(p.bytes_used, 0)))) "Used",
       dbms_xplan.format_size(((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100)) "% Free",
       dbms_xplan.format_size(100 - ((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100)) "% Used",
       dbms_xplan.format_size((sum(f.maxbytes) )) "Max. Bytes"
from   sys.v_$TEMP_SPACE_HEADER h, sys.v_$Temp_extent_pool p, dba_temp_files f
where  p.file_id(+) = h.file_id
and    p.tablespace_name(+) = h.tablespace_name
and    f.file_id = h.file_id
and    f.tablespace_name = h.tablespace_name
group by h.tablespace_name
)  --where Tablespace_name in ('MIS_WORK')
order by 6 asc
;


alter tablespace temp shrink space keep 1g;


--- modify the parameters of temp files
select 'alter database tempfile '''||file_name||''' AUTOEXTEND ON NEXT 100m MAXSIZE 50g;'
from dba_temp_files
where tablespace_name='TEMP'
;


alter tablespace temp add tempfile '+DATA_DM' size 25g autoextend on next 1g maxsize 32700m;

alter tablespace temp add tempfile '+DATA' size 10g autoextend off;


--- check the current and max allocated size of temp tablespace 
select  file_name,tablespace_name,dbms_xplan.format_size2(bytes)current_size,dbms_xplan.format_size2(maxbytes)allocated_size,autoextensible
from dba_temp_files
where tablespace_name='USER_TEMP'
;

--- total size 
select tablespace_name,dbms_xplan.format_size2(sum(bytes))
from dba_temp_files
group by tablespace_name,dbms_xplan.format_size2(bytes)
--order by dbms_xplan.format_size2(sum(bytes)) asc
;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Undo Tablespace
3
--- Who is using UNDO Tablespace
select s.sid, 
       s.username,
       sum(ss.value) / 1024 / 1024 as undo_size_mb
from  v$sesstat ss
  join v$session s on s.sid = ss.sid
  join v$statname stat on stat.statistic# = ss.statistic#
where stat.name = 'undo change vector size'
and s.type <> 'BACKGROUND'
and s.username IS NOT NULL
group by s.sid, s.username
Order by undo_size_mb desc;
******************************************************************

-- Finding what's consuming the most UNDO

-- Very often DBA's see that one or more session seem to be hogging the UNDO tablespace.  
-- You need to find out what user and which SQL statement is eating up all the UNDO space.

SQL> select s.sql_text from v$sql s, v$undostat u
where u.maxqueryid=s.sql_id;

-- You can also use following SQL to find out most undo used by a session for a currently 
-- executing transaction.

SQL> select s.sid,s.username,t.used_urec,t.used_ublk
from v$session s, v$transaction t
where s.saddr = t.ses_addr
order by t.used_ublk desc;

-- To find out which session is currently using the most UNDO
SQL>select s.sid, t.name, s.value
from v$sesstat s, v$statname t
where s.statistic#=t.statistic#
and t.name='undo change vector size'
order by s.value desc;

SQL>select sql.sql_text, t.used_urec records, t.used_ublk blocks,
(t.used_ublk*8192/1024) kb from v$transaction t,
v$session s, v$sql sql
where t.addr=s.taddr
and s.sql_id = sql.sql_id
-- and s.username ='LTC_TEMP'
  and s.sid=121

******************************************************************


ALTER TABLESPACE UNDOTBS1
     ADD DATAFILE '+DATA' size 20g AUTOEXTEND ON NEXT 5g
         MAXSIZE UNLIMITED; 

<end node> 5P9i0s8y19Z
dt=Text
<node>
DB Files
3
<end node> 5P9i0s8y19Z
dt=Text
<node>
ControlFile
4
--- create control file
http://amit7oracledba.blogspot.in/2012/10/how-to-recreate-control-file-in-oracle.html

https://chenguangblog.wordpress.com/2011/09/02/ora-01207-file-is-more-recent-than-control-file-old-control-file/

<end node> 5P9i0s8y19Z
dt=Text
<node>
RdoLog Size
4
-- If you want the size of the redo log members (files on disk) size, then use the query below:
set linesize 300
column REDOLOG_FILE_NAME format a50
SELECT
    a.GROUP#,
    a.THREAD#,
    a.SEQUENCE#,
    a.ARCHIVED,
    a.STATUS,
    b.MEMBER    AS REDOLOG_FILE_NAME,
    (a.BYTES/1024/1024) AS SIZE_MB
FROM v$log a
JOIN v$logfile b ON a.Group#=b.Group# 
ORDER BY a.GROUP# ASC;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Reclaim DataFile
4
-- Reclaim datafile size
select 'alter database datafile '''||file_name||''' resize ' ||
    ceil( (nvl(hwm,1)*dbs.value)/1024/1024 )  || 'm;' cmd
from dba_data_files a,
    ( 
        select file_id, max(block_id+blocks-1) hwm
          from dba_extents
         group by file_id 
     ) b,
     (select value from v$parameter where name = 'db_block_size')dbs
where a.file_id = b.file_id(+)
 and regexp_like(file_name,'+DATA_ETE\/*','i')
 and ceil( blocks* dbs.value/1024/1024) - ceil( (nvl(hwm,1)*dbs.value)/1024/1024 ) > 0
;


/* Formatted on 05/19/2016 2:45:14 AM (QP5 v5.185.11230.41888) */
SELECT File_ID, Tablespace_name, file_name, High_Water_Mark, current_size_in_GB,
    'ALTER DATABASE DATAFILE '''||file_name||''' resize '|| High_Water_Mark|| 'M;' script_reclaim
FROM 
(
    WITH v_file_info
         AS (SELECT FILE_NAME, FILE_ID, BLOCK_SIZE
               FROM dba_tablespaces tbs, dba_data_files df
              WHERE tbs.tablespace_name = df.tablespace_name)
    SELECT A.FILE_ID,
           A.FILE_NAME,
           A.TABLESPACE_NAME,
           CEIL ( (NVL (hwm, 1) * v_file_info.block_size) / 1024 / 1024) High_Water_Mark,
           CEIL (BLOCKS * v_file_info.block_size / 1024 / 1024 / 1024) current_size_in_GB
      FROM dba_data_files A,
           v_file_info,
           (  SELECT file_id, MAX (block_id + BLOCKS - 1) hwm
                FROM dba_extents
            GROUP BY file_id) b
     WHERE A.file_id = b.file_id(+) 
       AND A.file_id = v_file_info.file_id
       AND tablespace_name='DATA' -- << change the tablespace name to reclaim the datafile size
)     
WHERE  High_Water_Mark <> current_size_in_GB;

ALTER DATABASE DATAFILE '+ASMTXNDATA/txndcw/datafile/all_temp_tables.284.882569903' RESIZE 6M     


===============================================================================
col name for a32
col size_m for 999,999,999
col used_m for 999,999,999
col pct_used for 999

SELECT name
, ceil( space_limit / 1024 / 1024) SIZE_M
, ceil( space_used / 1024 / 1024) USED_M
, decode( nvl( space_used, 0),
  0, 0
  , ceil ( ( space_used / space_limit) * 100) ) PCT_USED
FROM v$recovery_file_dest
ORDER BY name
/

<end node> 5P9i0s8y19Z
dt=Text
<node>
Create tablespaces
3
CREATE TABLESPACE CPASS_Data_Encrypt 
DATAFILE '+ASMDATA' SIZE 2G AUTOEXTEND OFF,
  '+ASMDATA' SIZE 2G AUTOEXTEND OFF,
  '+ASMDATA' SIZE 1G AUTOEXTEND ON NEXT 1M MAXSIZE UNLIMITED,
  '+ASMDATA' SIZE 1G AUTOEXTEND OFF
LOGGING
ONLINE
EXTENT MANAGEMENT LOCAL AUTOALLOCATE
SEGMENT SPACE MANAGEMENT AUTO
FLASHBACK ON;

CREATE TABLESPACE CPASS_indx_Encrypt 
DATAFILE '+ASMDATA' SIZE 2G AUTOEXTEND OFF,
  '+ASMDATA' SIZE 2G AUTOEXTEND OFF,
  '+ASMDATA' SIZE 1G AUTOEXTEND ON NEXT 1M MAXSIZE UNLIMITED,
  '+ASMDATA' SIZE 1G AUTOEXTEND OFF
LOGGING
ONLINE
EXTENT MANAGEMENT LOCAL AUTOALLOCATE
SEGMENT SPACE MANAGEMENT AUTO
FLASHBACK ON;

ALTER TABLESPACE CPASS_indx_Encrypt ADD DATAFILE '+ASMDATA' SIZE 2G AUTOEXTEND OFF

<end node> 5P9i0s8y19Z
dt=Text
<node>
Upgrade & Patching
2

===============================================================================================
-- 12c Patching information
select to_char(action_time,'DD-MM-YYYY HH:MI:SS AM')Patched_On, description, Patch_id, action, status,
	con_id
from cdb_registry_sqlpatch
order by patch_id, action;

-- check be interim patches have installed in this oracle home
-- will return the info related ORACLE_HOME, Central Inventory, 
Opatch version, OUI Version and log file.

$ORACLE_HOME/OPatch/opatch lsinventory
===============================================================================================

-- Patching details for the Oracle products
Doc ID : 1454618.1

Patch 32518631 - Database Proactive Bundle Patch 12.1.0.2.210420
(Doc ID 888828.1)

<end node> 5P9i0s8y19Z
dt=Text
<node>
Apply Patch 
3
******************************************************************************
-- Below are the pre-requisite of the patch
******************************************************************************
==============================================
-- Before applying patches on windows server database for oracle, need to stop all runing processes.
-- below is the commands and checks to be done ...

windows patch 

Prerequisite check “CheckActiveFilesAndExecutables” failed

Tasklist /m ora*
taskkill /pid processid_number /F
==============================================

-- check the hostname of the server where you are applying the patch
hostname

-- check the os of the server
uname -a

-- take the homes from oratab file
cat /etc/oratab

-- take the inventory location
cat cat /etc/oraInst.loc

-- take the listener and pmon entries
ps -ef|grep pmon

ps -ef|grep tns

-- check the services running on the listeners
lsnrctl status <<listener name which you will get from above ps -ef|grep tns command>>

lsnrctl services lsnrctl status <<listener name which you will get from above ps -ef|grep tns command>>

-- take the version of the current database and applied patches details
sqlplus "/as sysdba"
sql> set lines 32000
sql> select * from registry$history;

-- take the information of ASM/Cluster if present
ps -ef |grep pmon
--------select +ASM
. oraenv (+ASM)
crsctl stat res -t

-- take the opatch version
$ORACLE_HOME/OPatch/./opatch -version

-- take the lsinventory details
$ORACLE_HOME/OPatch/./opatch lsinventory

-- take the prereq check of the patch to be applied from it's location
/u01/app/oracle/product/11.2.0.4/OPatch/./opatch prereq CheckConflictAgainstOHWithdetail -phbaseDIR /rmana1/patch/25476126/22502505


-- backup the Oracle Home folder if possible for safe purpose (not required but in-case)

-- take the location of the patch folder/directory

<end node> 5P9i0s8y19Z
dt=Text
<node>
DB Upgrade frm 11201 to 11204
3
-- follow the URL

https://sadanandhudge.wordpress.com/2015/11/11/database-upgrade-from-11-2-0-1-to-11-2-0-4-on-linux-64bit/

<end node> 5P9i0s8y19Z
dt=Text
<node>
Opatch info
3


--------------------------------------------------------------------------------------------------
---->>>> DRT  
-- RDBMS
$ORACLE_HOME/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME

-- GRID
$ORACLE_HOME/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME

-- RDBMS
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30364137
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30304402

-- GRID
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30364137
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30304402
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30304434
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/26983807

-- RDBMS (for all folders and sub-folders of patches)
$ORACLE_HOME/OPatch/opatch prereq CheckSystemSpace -phBaseFile /u01/oracle/zfs-dr/datapump/patches_2020/logs/checksystemspace_RDBMS_basfile.txt 

-- GRID (for all folders and sub-folders of patches)
$ORACLE_HOME/OPatch/opatch prereq CheckSystemSpace -phBaseFile /u01/oracle/zfs-dr/datapump/patches_2020/logs/checksystemspace_GRID_basfile.txt 

-- RDBMS -- root account
$ORACLE_HOME/OPatch/opatchauto apply /u01/oracle/zfs-dr/datapump/patches_2020/30464171 -oh $ORACLE_HOME -analyze 

-- GRID -- root account
$ORACLE_HOME/OPatch/opatchauto apply /u01/oracle/zfs-dr/datapump/patches_2020/30464171 -oh $ORACLE_HOME -analyze 

--------------------------------------------------------------------------------------------------
---->>>> PRD
-- RDBMS
$ORACLE_HOME/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME

-- GRID
$ORACLE_HOME/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME

-- RDBMS
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30364137
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30304402

-- GRID
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30364137
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30304402
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30304434
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/26983807

-- RDBMS (for all folders and sub-folders of patches)
$ORACLE_HOME/OPatch/opatch prereq CheckSystemSpace -phBaseFile /u01/oracle/zfs-dr/datapump_new/patches_2020/logs/checksystemspace_RDBMS_basfile.txt 

-- GRID (for all folders and sub-folders of patches)
$ORACLE_HOME/OPatch/opatch prereq CheckSystemSpace -phBaseFile /u01/oracle/zfs-dr/datapump_new/patches_2020/logs/checksystemspace_GRID_basfile.txt 

-- RDBMS -- root account
$ORACLE_HOME/OPatch/opatchauto apply /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171 -oh $ORACLE_HOME -analyze 

-- GRID -- root account
$ORACLE_HOME/OPatch/opatchauto apply /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171 -oh $ORACLE_HOME -analyze 

<end node> 5P9i0s8y19Z
dt=Text
<node>
opatch pre-checks
3


-- * Prechecks for the Opatche *
--1) check lsinventory
export ORACLE_HOME=/u01/oracle/product/12.1.0.2
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
$ORACLE_HOME/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME

--- select oraenv as +ASM 
export ORACLE_HOME=/u01/grid/product/12.1.0.2/grid
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
$ORACLE_HOME/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME


--2) check all the subfolders of the patches for prerequirements
export ORACLE_HOME=/u01/oracle/product/12.1.0.2
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
/u01/oracle/product/12.1.0.2/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/27547374
/u01/oracle/product/12.1.0.2/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/26983807
/u01/oracle/product/12.1.0.2/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/28537740
/u01/oracle/product/12.1.0.2/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/23312691

--- select oraenv as +ASM 
export ORACLE_HOME=/u01/grid/product/12.1.0.2/grid
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
/u01/grid/product/12.1.0.2/grid/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/27547374
/u01/grid/product/12.1.0.2/grid/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/26983807
/u01/grid/product/12.1.0.2/grid/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/28537740
/u01/grid/product/12.1.0.2/grid/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/28553949/23312691


--3) check the space for patche applying for both homes using root account
/u01/oracle/product/12.1.0.2/OPatch/opatch prereq CheckSystemSpace -phBaseFile /u01/oracle/zfs-dr/datapump/patches_2020/logs/checksystemspace_basfile.txt 

/u01/grid/product/12.1.0.2/grid/OPatch/opatch prereq CheckSystemSpace -phBaseFile /u01/oracle/zfs-dr/datapump/patches_2020/logs/checksystemspace_basfile.txt 

--4) Analyze the applying patch using root account for both homes
export ORACLE_HOME=/u01/oracle/product/12.1.0.2
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
$ORACLE_HOME/OPatch/opatchauto apply /u01/oracle/zfs-dr/datapump/patches_2020/28553949 -oh /u01/oracle/product/12.1.0.2 -analyze 

--- select oraenv as +ASM 
export ORACLE_HOME=/u01/grid/product/12.1.0.2/grid
export PATH=$ORACLE_HOME/OPatch:$PATH
opatch version
echo $ORACLE_HOME
$ORACLE_HOME/OPatch/opatchauto apply /u01/oracle/zfs-dr/datapump/patches_2020/28553949 -oh /u01/grid/product/12.1.0.2/grid -analyze 



--------------------------------------------------------------------------------------------------
---->>>> DRT  
-- RDBMS
$ORACLE_HOME/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME

-- GRID
$ORACLE_HOME/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME

-- RDBMS
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30364137
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30304402

-- GRID
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30364137
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30304402
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30304434
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/26983807

-- RDBMS (for all folders and sub-folders of patches)
$ORACLE_HOME/OPatch/opatch prereq CheckSystemSpace -phBaseFile /u01/oracle/zfs-dr/datapump/patches_2020/logs/checksystemspace_RDBMS_basfile.txt 

-- GRID (for all folders and sub-folders of patches)
$ORACLE_HOME/OPatch/opatch prereq CheckSystemSpace -phBaseFile /u01/oracle/zfs-dr/datapump/patches_2020/logs/checksystemspace_GRID_basfile.txt 

-- RDBMS -- root account
$ORACLE_HOME/OPatch/opatchauto apply /u01/oracle/zfs-dr/datapump/patches_2020/30464171 -oh $ORACLE_HOME -analyze 

-- GRID -- root account
$ORACLE_HOME/OPatch/opatchauto apply /u01/oracle/zfs-dr/datapump/patches_2020/30464171 -oh $ORACLE_HOME -analyze 

--------------------------------------------------------------------------------------------------
---->>>> PRD
-- RDBMS
$ORACLE_HOME/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME

-- GRID
$ORACLE_HOME/OPatch/opatch lsinventory -detail -oh $ORACLE_HOME

-- RDBMS
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30364137
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30304402

-- GRID
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30364137
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30304402
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30304434
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/26983807

-- RDBMS (for all folders and sub-folders of patches)
$ORACLE_HOME/OPatch/opatch prereq CheckSystemSpace -phBaseFile /u01/oracle/zfs-dr/datapump_new/patches_2020/logs/checksystemspace_RDBMS_basfile.txt 

-- GRID (for all folders and sub-folders of patches)
$ORACLE_HOME/OPatch/opatch prereq CheckSystemSpace -phBaseFile /u01/oracle/zfs-dr/datapump_new/patches_2020/logs/checksystemspace_GRID_basfile.txt 

-- RDBMS -- root account
$ORACLE_HOME/OPatch/opatchauto apply /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171 -oh $ORACLE_HOME -analyze 

-- GRID -- root account
$ORACLE_HOME/OPatch/opatchauto apply /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171 -oh $ORACLE_HOME -analyze 

<end node> 5P9i0s8y19Z
dt=Text
<node>
opatch apply
3

----->>> After the pre-check are completed, follow the below steps

-- before starting to apply grid patche using root account
/csapps/grid/product/12.1.0.2/grid/bin/./crsctl stop has
/csapps/grid/product/12.1.0.2/grid/bin/./crsctl start has

-- set env.
export ORACLE_HOME=/csapps/grid/product/12.1.0.2/grid
export PATH=/csapps/grid/product/12.1.0.2/grid/OPatch:$PATH
opatch version

-- before starting to apply patches check which process are using Oracle/Grid homes
-- Oracle account
fuser -uc /csapps/oracle/product/12.1.0.2
/* -- you can also check the below process is used or not
fuser -uc /csapps/oracle/product/12.1.0.2/lib/libsqlplus.so
*/

-- grid account
fuser -uc /csapps/grid/product/12.1.0.2/grid


-- apply patch command (using root account)

-- Do not shutdown has (ASM)
/csapps/grid/product/12.1.0.2/grid/OPatch/opatchauto apply /csapps/oracle/jan2020_patches/30464171 -oh /csapps/grid/product/12.1.0.2/grid 

-- To apply rdbms patche by keeping DB up and running execute the below into all DBs
-- Do not shutdown DBs, Keep them up and running 
/*

create a scripts to ecexute below commands in all DBs

lrch1d43.cna.com:oracle:spd1c:/depot/oracle/temp
->vi dbstart.ksh
lrch1d43.cna.com:oracle:spd1c:/depot/oracle/temp
->cat dbstart.ksh
#ALL_DATABASES=`ps -ef|grep ora_smon_ |grep -v grep|awk -F"_" '{print $3 " " $4}'|sort`
ALL_DATABASES=`cat /etc/oratab|grep -v "^#"|grep -v "N$"|cut -f1 -d: -s`
ps -ef |grep pmon
ps -ef |grep tns
for DB in $ALL_DATABASES
do
   unset  TWO_TASK
   export ORACLE_SID=$DB
   export ORACLE_HOME=`grep "^${DB}:" /etc/oratab|cut -d: -f2 -s`
   export PATH=$ORACLE_HOME/bin:$PATH
   echo "---> Database $ORACLE_SID, using home $ORACLE_HOME"
   sqlplus -s "/as sysdba" <<ENDofSQL
   set sqlprompt "_date':'_user'@'_connect_identifier> "


grant execute on dbms_sql to xdb;
grant execute on dbms_lob to xdb;
grant execute on utl_file to xdb;
@?/rdbms/admin/utlrp.sql

ENDofSQL
done

lrch1d43.cna.com:oracle:spd1c:/depot/oracle/temp


*/

-- run it from root user
export ORACLE_HOME=/csapps/oracle/product/12.1.0.2
export PATH=/csapps/oracle/product/12.1.0.2/OPatch:$PATH
opatch version

/csapps/oracle/product/12.1.0.2/OPatch/opatchauto apply /csapps/oracle/jan2020_patches/30464171 -oh /csapps/oracle/product/12.1.0.2
 
-- if the database are not started after applying patches then use below scripts
/depot/oracle/temp/dbverbose.ksh

/* -- script looks like this
->cat /depot/oracle/temp/dbverbose.ksh
#ALL_DATABASES=`ps -ef|grep ora_smon_ |grep -v grep|awk -F"_" '{print $3 " " $4}'|sort`
ALL_DATABASES=`cat /etc/oratab|grep -v "^#"|grep -v "N$"|cut -f1 -d: -s`
ps -ef |grep pmon
ps -ef |grep tns
for DB in $ALL_DATABASES
do
   unset  TWO_TASK
   export ORACLE_SID=$DB
   export ORACLE_HOME=`grep "^${DB}:" /etc/oratab|cut -d: -f2 -s`
   export PATH=$ORACLE_HOME/bin:$PATH
   echo "---> Database $ORACLE_SID, using home $ORACLE_HOME"
   sqlplus -s "/as sysdba" <<ENDofSQL
   set sqlprompt "_date':'_user'@'_connect_identifier> "
startup;

grant execute on dbms_sql to xdb;
grant execute on dbms_lob to xdb;
grant execute on utl_file to xdb;
@?/rdbms/admin/utlrp.sql

set linesize 190
set pages 1000
set long 32000
COLUMN id_plus_exp FORMAT 990 HEADING i
COLUMN parent_id_plus_exp FORMAT 990 HEADING p
COLUMN plan_plus_exp FORMAT a60
COLUMN object_node_plus_exp FORMAT a8
COLUMN other_tag_plus_exp FORMAT a29
COLUMN other_plus_exp FORMAT a44
col HOSTNAME for a18
col BLOCKED for a7
col STARTUP_TIME for a19
select I.instance_name INS_NAME,I.host_name HOSTNAME,I.STATUS,
           I.DATABASE_STATUS DB_STATUS,D.open_mode,D.database_role,
           I.LOGINS, to_char(I.STARTUP_TIME,'DD-MON-YY HH24:MI:SS') STARTUP_TIME
from v\$instance I ,v\$database D ;
ENDofSQL
$ORACLE_HOME/OPatch/datapatch -verbose
done
->


*/

-- check if verbose and version history of DBs 
col comp_name for a50
col version for a10
col status for a9
select comp_name, version, status from dba_registry;
select BUNDLE_SERIES,PATCH_UID,PATCH_ID,VERSION,ACTION,STATUS,ACTION_TIME ,DESCRIPTION from dba_registry_sqlpatch;

-- apply the ojvm using oracle account
-- ensure the path of the ORACLE_HOME should be said on oracle account
-- before applying OJVM patch shutdown all DBs
cd /csapps/oracle/jan2020_patches/30502041
/csapps/oracle/product/12.1.0.2/OPatch/opatch apply

-- atlast execute the below script 
-- this is for ojvm patches 
/depot/oracle/temp/dbpatch_verbose_jvm.ksh

/*
->cat dbpatch_verbose_jvm.ksh
ALL_DATABASES=`ps -ef|grep ora_smon_ |grep -v grep|awk -F"_" '{print $3 " " $4}'|sort`
#ALL_DATABASES=`cat /etc/oratab|grep -v "^#"|grep -v "N$"|cut -f1 -d: -s`
ps -ef |grep pmon
ps -ef |grep tns
for DB in $ALL_DATABASES
do
   unset  TWO_TASK
   export ORACLE_SID=$DB
   export ORACLE_HOME=`grep "^${DB}:" /etc/oratab|cut -d: -f2 -s`
   export PATH=$ORACLE_HOME/bin:$PATH
   echo "---> Database $ORACLE_SID, using home $ORACLE_HOME"
   sqlplus -s "/as sysdba" <<ENDofSQL
   set sqlprompt "_date':'_user'@'_connect_identifier> "

shutdown immediate;
echo "put the database into upgrade mode"
startup upgrade;
echo "apply the OJVM patch with datapatch verbose option"
host /csapps/oracle/product/12.1.0.2/OPatch/datapatch -verbose
echo "shutdown databases after upgradation is completed"
shutdown immediate;
echo "Startup normal DBs"
startup;

set lines 3200 pages 10000
col comp_name for a50
col version for a10
col status for a9
select comp_name, version, status from dba_registry;
select BUNDLE_SERIES,PATCH_UID,PATCH_ID,VERSION,ACTION,STATUS,ACTION_TIME ,DESCRIPTION from dba_registry_sqlpatch;

set long 32000
COLUMN id_plus_exp FORMAT 990 HEADING i
COLUMN parent_id_plus_exp FORMAT 990 HEADING p
COLUMN plan_plus_exp FORMAT a60
COLUMN object_node_plus_exp FORMAT a8
COLUMN other_tag_plus_exp FORMAT a29
COLUMN other_plus_exp FORMAT a44
col HOSTNAME for a18
col BLOCKED for a7
col STARTUP_TIME for a19
select I.instance_name INS_NAME,I.host_name HOSTNAME,I.STATUS,
           I.DATABASE_STATUS DB_STATUS,D.open_mode,D.database_role,
           I.LOGINS, to_char(I.STARTUP_TIME,'DD-MON-YY HH24:MI:SS') STARTUP_TIME
from v\$instance I ,v\$database D ;
ENDofSQL
#$ORACLE_HOME/OPatch/datapatch -verbose
done
#/csapps/oracle/agent12c/core/12.1.0.4.0/bin/./emctl status agent
#/csapps/oracle/agent12c/core/12.1.0.4.0/bin/./emctl stop agent

*/

<end node> 5P9i0s8y19Z
dt=Text
<node>
patch conf.
3

---->>>> DRT  
-- RDBMS
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30364137
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30304402

-- GRID
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30364137
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30304402
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/30304434
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump/patches_2020/30464171/26983807


---->>>> PRD
-- RDBMS
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30364137
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30304402

-- GRID
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30364137
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30304402
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/30304434
$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir /u01/oracle/zfs-dr/datapump_new/patches_2020/30464171/26983807

<end node> 5P9i0s8y19Z
dt=Text
<node>
download latest opatch
3
1) Please download the latest OPatch version from My Oracle Support (MOS) using the next reference:

Patch 6880880 

Or using the next URL:

https://updates.oracle.com/download/6880880.html


2) In the "Platform" field select the relevant platform that corresponds to the Oracle product.

3) Click the Download button

<end node> 5P9i0s8y19Z
dt=Text
<node>
check opatch details
3
-- Once the patch has been applied successfully, verify it in the database like below.
sqlplus / as sysdba
set serveroutput on
exec dbms_qopatch.get_sqlpatch_status; 

<end node> 5P9i0s8y19Z
dt=Text
<node>
(New node)
3

-- cancel the logs shipping from primary DB
alter system set log_archive_dest_state_2=defer;

-- if there is any error then ORA-01153: an incompatible media recovery is active
-- then use below 
alter database recover managed standby database disconnect from session;
srvctl relocate scan -scannumber 1
srvctl relocate mgmtdb
srvctl stop LISTENER

$ORACLE_HOME/bin/./crsctl stop crs

$ORACLE_HOME/bin/./crsctl start crs

env |grep ORA
sudo su - 
. oraenv
+ASM1

$ORACLE_HOME/OPatch/./opatchauto apply /u01/oracle/patch_2021/32518631 -oh $ORACLE_HOME

sudo su - oracle
. oraenv
MERWHP1

srvctl stop instance -db MERWHP -i MERWHP1 -stopoption immediate

$ORACLE_HOME/OPatch/./opatch rollback -id 21866762

srvctl start instance -db MERWHP -i MERWHP1

srvctl relocate scan -scannumber 1
srvctl stop listener

sudo su - root
$ORACLE_HOME/OPatch/./opatchauto apply /u01/oracle/patch_2021/32518631 -oh $ORACLE_HOME

-- on second node
srvctl enable mgmtdb -n mrlnprddbadm02

-- execute from node from where you want to relocate
srvctl relocate mgmtdb -n mrlnprddbadm02


sudo su - root
. oraenv
MERWHP1
$ORACLE_HOME/OPatch/./opatchauto apply /u01/oracle/patch_2021/32518631 -oh $ORACLE_HOME

$ORACLE_HOME/OPatch/./opatchauto resume

sudo su - oracle
srvctl stop instance -db MERWHP -i MERWHP1 -stopoption immediate
$ORACLE_HOME/OPatch/./opatch apply /u01/oracle/patch_2021/bug_patch/21866762 -oh $ORACLE_HOME

srvctl start instance -db MERWHP -i MERWHP1

. oraenv
+ASM1
srvctl relocate scan -scannumber 1
srvctl start listener
srvctl status scan 

. oraenv
MERWHP1
srvctl relocate mgmtdb -n mrlnprddbadm01



$ORACLE_HOME/OPatch/./opatch rollbackup -id 21866762

srvctl start instance -db merwhr -i MERWHR1

$ORACLE_HOME/OPatch/./opatchauto resume

srvctl stop instance -db MERWHP -i MERWHP1 -stopoption immediate



srvctl relocate scan -scannumber 1

srvctl status scan
srvctl status scan

srvctl stop listener


alter trigger system.audit_ddl_trg disable;


select name,open_mode from v$database;


set serveroutput on
exec dbms_qopatch.get_sqlpatch_status;


SQL> alter database recover managed standby database cancel;

Database altered.

SQL> alter database recover managed standby database disconnect from session;

Database altered.

<end node> 5P9i0s8y19Z
dt=Text
<node>
DataPump & exp/imp
2
<end node> 5P9i0s8y19Z
dt=Text
<node>
DBMS_DATAPUMP API
3
-- Oracle DBMS_DATAPUMP API
-- http://www.morganslibrary.org/reference/pkgs/dbms_datapump.html

-- Add the file to the data pump import/export file set
 
PROCEDURE add_file (
    handle       IN  NUMBER,
    filename     IN  VARCHAR2,
    directory    IN  VARCHAR2 DEFAULT NULL,
    filesize     IN  VARCHAR2 DEFAULT NULL,
    filetype     IN  NUMBER DEFAULT KU$_FILE_TYPE_DUMP_FILE,
    reusefile    IN  NUMBER DEFAULT NULL
  );
 
-- Attach the current database session to a data pump job process
 
FUNCTION attach (
    job_name     IN  VARCHAR2 DEFAULT NULL,
    job_owner    IN  VARCHAR2 DEFAULT NULL
  )
  RETURN NUMBER;
 
-- Permits the specification of data pump job table data filtering
 
PROCEDURE data_filter (
    handle        IN  NUMBER,
    name          IN  VARCHAR2,
    value         IN  NUMBER | CLOB | VARCHAR2,
    table_name    IN  VARCHAR2 DEFAULT NULL,
    schema_name   IN  VARCHAR2 DEFAULT NULL
  );
 
-- Detach the current database session to a data pump job process
 
PROCEDURE detach (
    handle    IN  NUMBER
  );
 
-- Returns the extended data pump file information
 
PROCEDURE get_dumpfile_info (
    filename      IN     VARCHAR2,
    directory     IN     VARCHAR2,
    info_table    OUT    ku$_dumpfile_info,
    filetype      OUT    NUMBER
  );
 
-- Returns the status of a data pump job
 
FUNCTION get_status (
    handle     IN  NUMBER,
    mask       IN  INTEGER,
    timeout    IN  NUMBER DEFAULT NULL
  )
  RETURN ku$_Status;
 
PROCEDURE get_status (
    handle        IN  NUMBER,
    mask          IN  INTEGER,
    timeout       IN  NUMBER DEFAULT NULL,
    job_state     OUT VARCHAR2,
    status        OUT ku$_Status1010 | ku$_Status1020
  );
 
-- Permits the insertion of a message into the log file
 
PROCEDURE log_entry (
    handle          IN  NUMBER,
    message         IN  VARCHAR2,
    log_file_only   IN  NUMBER DEFAULT 0
  );
 
-- Permits the specification of data pump job metadata filtering
 
PROCEDURE metadata_filter (
    handle         IN  NUMBER,
    name           IN  VARCHAR2,
    value          IN  VARCHAR2 | CLOB,
    object_path    IN  VARCHAR2 DEFAULT NULL,
    object_type    IN  VARCHAR2 DEFAULT NULL
  );
  
1. To include or exclude individual named objects (e.g., tables, procedures, etc.) use the NAME_EXPR or NAME_LIST filter along with the object_path parameter:
DBMS_DATAPUMP.METADATA_FILTER(h1,'NAME_EXPR','LIKE PAYROLL%','VIEW');

Result: the only views exported in the job are those with names that begin with ‘PAYROLL’. (As you might imagine, the filter value ‘LIKE PAYROLL%’ is 
		used in a SQL expression in the query used to fetch the view definitions.) As I mentioned in the earlier post, the object_path parameter ‘VIEW’ 
		will cause the correct dependent objects (grants, etc.) to be included/excluded along with the views.

2. To include or exclude an entire object type, use INCLUDE_PATH_EXPR, EXCLUDE_PATH_EXPR, INCLUDE_PATH_LIST, EXCLUDE_PATH_LIST. For example, if you want to 
   exclude all functions, procedures and packages from the job:

DBMS_DATAPUMP.METADATA_FILTER(h1,'EXCLUDE_PATH_EXPR','IN (''FUNCTION'', ''PROCEDURE'',''PACKAGE'')');

(If you wanted to exclude a particular named procedure you would use the NAME_EXPR filter with the ‘PROCEDURE’ object path.)

One last point: be clear about the difference between INCLUDE and EXCLUDE. If you use an EXCLUDE_PATH_* filter, everything except the object 
types specified by the filter value will be in the job. If you use an INCLUDE_PATH_* filter, only the object types specified by the filter value 
will be in the job.

DBMS_DATAPUMP.METADATA_FILTER(h1,'SCHEMA_EXPR','IN (''HR'')');

or

DBMS_DATAPUMP.METADATA_FILTER(h1,'SCHEMA_LIST','''HR''');
DBMS_DATAPUMP.METADATA_FILTER(h1,'SCHEMA_LIST','''HR''');
DBMS_DATAPUMP.METADATA_FILTER(h1,'SCHEMA_LIST','''HR''');
DBMS_DATAPUMP.METADATA_FILTER(h1,'SCHEMA_LIST','''HR''');
DBMS_DATAPUMP.METADATA_FILTER(h1,'SCHEMA_LIST','''HR''');

-- Permits the specification of data pump job object re-mappings
 
PROCEDURE metadata_remap (
    handle         IN  NUMBER,
    name           IN  VARCHAR2,
    old_value      IN  VARCHAR2,
    value          IN  VARCHAR2,
    object_type    IN  VARCHAR2 DEFAULT NULL
  );
 
-- Permits the specification of data pump job metadata transformations
 
PROCEDURE metadata_transform (
    handle         IN  NUMBER,
    name           IN  VARCHAR2,
    value          IN  VARCHAR2 | NUMBER,
    object_type    IN  VARCHAR2 DEFAULT NULL
  );
 
-- Declares a new data pump job returning handle required for other API calls
 
FUNCTION open (
    operation      IN  VARCHAR2,
    job_mode       IN  VARCHAR2,
    remote_link    IN  VARCHAR2 DEFAULT NULL,
    job_name       IN  VARCHAR2 DEFAULT NULL,
    version        IN  VARCHAR2 DEFAULT 'COMPATIBLE',
    compression    IN  NUMBER DEFAULT KU$_COMPRESS_METADATA
  )
  RETURN NUMBER;
 
-- Permits the specification of data pump job parallelization degree
 
PROCEDURE set_parallel (
    handle     IN  NUMBER,
    degree     IN  NUMBER
  );
 
-- Permits the specification of data pump job-processing options
 
PROCEDURE set_parameter (
    handle     IN  NUMBER,
    name       IN  VARCHAR2,
    value      IN  NUMBER | VARCHAR2
  );
 
-- Begin or resume the execution of a data pump job
 
PROCEDURE start_job (
    handle          IN  NUMBER,
    skip_current    IN  NUMBER DEFAULT 0,
    abort_step      IN  NUMBER DEFAULT 0,
    cluster_ok      IN  NUMBER DEFAULT 1,
    service_name    IN  VARCHAR2 DEFAULT NULL
  );
 
-- Terminate the execution of a data pump job
 
PROCEDURE stop_job (
    handle         IN  NUMBER,
    immediate      IN  NUMBER DEFAULT 0,
    keep_master    IN  NUMBER DEFAULT NULL,
    delay          IN  NUMBER DEFAULT 60
  );
 
-- Runs a data pump job until it completes or aborts
 
PROCEDURE wait_for_job (
    handle        IN  NUMBER,
    job_state     OUT VARCHAR2
  );
 
Here is the command line version of the schema export once again that is the slightly more involved version utilizing PL/SQL API coding as the interface.
 
C:\> expdp bert/bert directory=data_pump_dir dumpfile=multi_schema.dmp schemas=bert,movies
 
DECLARE
  handle NUMBER;
  status VARCHAR2(20);
BEGIN
  handle := DBMS_DATAPUMP.OPEN ('EXPORT', 'SCHEMA');
  DBMS_DATAPUMP.ADD_FILE (handle, 'multi_schema.dmp', 'DATA_PUMP_DIR');
  DBMS_DATAPUMP.METADATA_FILTER (handle, 'SCHEMA_EXPR', 'IN (''BERT'',''MOVIES'')');
  DBMS_DATAPUMP.START_JOB (handle);
  DBMS_DATAPUMP.WAIT_FOR_JOB (handle, status);
END;
/



CONNECT SYSTEM/password

DECLARE
  ind NUMBER;              -- Loop index
  h1 NUMBER;               -- Data Pump job handle
  percent_done NUMBER;     -- Percentage of job complete
  job_state VARCHAR2(30);  -- To keep track of job state
  le ku$_LogEntry;         -- For WIP and error messages
  js ku$_JobStatus;        -- The job status from get_status
  jd ku$_JobDesc;          -- The job description from get_status
  sts ku$_Status;          -- The status object returned by get_status
BEGIN

-- Create a (user-named) Data Pump job to do a "full" import (everything
-- in the dump file without filtering).

  h1 := DBMS_DATAPUMP.OPEN('IMPORT','FULL',NULL,'EXAMPLE2');

-- Specify the single dump file for the job (using the handle just returned)
-- and directory object, which must already be defined and accessible
-- to the user running this procedure. This is the dump file created by
-- the export operation in the first example.

  DBMS_DATAPUMP.ADD_FILE(h1,'example1.dmp','DMPDIR');

-- A metadata remap will map all schema objects from HR to BLAKE.

  DBMS_DATAPUMP.METADATA_REMAP(h1,'REMAP_SCHEMA','HR','BLAKE');

-- If a table already exists in the destination schema, skip it (leave
-- the preexisting table alone). This is the default, but it does not hurt
-- to specify it explicitly.

  DBMS_DATAPUMP.SET_PARAMETER(h1,'TABLE_EXISTS_ACTION','SKIP');

-- Start the job. An exception is returned if something is not set up properly.

  DBMS_DATAPUMP.START_JOB(h1);

-- The import job should now be running. In the following loop, the job is 
-- monitored until it completes. In the meantime, progress information is 
-- displayed. Note: this is identical to the export example.
 
 percent_done := 0;
  job_state := 'UNDEFINED';
  while (job_state != 'COMPLETED') and (job_state != 'STOPPED') loop
    dbms_datapump.get_status(h1,
           dbms_datapump.ku$_status_job_error +
           dbms_datapump.ku$_status_job_status +
           dbms_datapump.ku$_status_wip,-1,job_state,sts);
    js := sts.job_status;

-- If the percentage done changed, display the new value.

     if js.percent_done != percent_done
    then
      dbms_output.put_line('*** Job percent done = ' ||
                           to_char(js.percent_done));
      percent_done := js.percent_done;
    end if;

-- If any work-in-progress (WIP) or Error messages were received for the job,
-- display them.

       if (bitand(sts.mask,dbms_datapump.ku$_status_wip) != 0)
    then
      le := sts.wip;
    else
      if (bitand(sts.mask,dbms_datapump.ku$_status_job_error) != 0)
      then
        le := sts.error;
      else
        le := null;
      end if;
    end if;
    if le is not null
    then
      ind := le.FIRST;
      while ind is not null loop
        dbms_output.put_line(le(ind).LogText);
        ind := le.NEXT(ind);
      end loop;
    end if;
  end loop;

-- Indicate that the job finished and gracefully detach from it. 

  dbms_output.put_line('Job has completed');
  dbms_output.put_line('Final job state = ' || job_state);
  dbms_datapump.detach(h1);
END;
/




-- COMPRESSION
dbms_datapump.set_parameter(handle => l_dp_handle, name => 'COMPRESSION', value => 'ALL');
dbms_datapump.set_parameter(handle => l_dp_handle, name => 'COMPRESSION', value => 'DATA_ONLY');
dbms_datapump.set_parameter(handle => l_dp_handle, name => 'COMPRESSION', value => 'METADATA_ONLY');

-- CONTENT
dbms_datapump.set_parameter(handle => h1, name => 'INCLUDE_METADATA', value => 1); ALL
dbms_datapump.set_parameter(handle => h1, name => 'INCLUDE_METADATA', value => 0); DATA_ONLY
dbms_datapump.data_filter(handle => h1, name => 'INCLUDE_ROWS', value => 0); METADATA_ONLY

-- DATA_OPTIONS
dbms_datapump.set_parameter(handle => l_dp_handle, name => 'DATA_OPTIONS', value => dbms_datapump.KU$_DATAOPT_XMLTYPE_CLOB);

-- EXCLUDE
dbms_datapump.metadata_filter(l_dp_handle, 'SCHEMA_EXPR', '<> (''SCHEMANAME'')');
dbms_datapump.metadata_filter(l_dp_handle, 'EXCLUDE_PATH_EXPR', 'IN (''INDEX'', ''SYNONYMS'', ''GRANTS'', ''STATISTICS'')');

-- INCLUDE
dbms_datapump.metadata_filter(l_dp_handle, 'SCHEMA_EXPR', 'IN (''SCHEMANAME'')');

-- PARALLEL
dbms_datapump.set_parallel(handle => h1, degree => n);

-- REMAP_DATA
dbms_datapump.data_remap(handle => h1, name => 'COLUMN_FUNCTION', table_name => 'TAB1', column => 'COL1', function => 'UWCLASS.TESTPACKAGE.SETTESTID', schema => 'UWCLASS');

-- QUERY
dbms_datapump.data_filter(handle => h1, name => 'SUBQUERY', value => 'WHERE col1 = 1', table_name => null, schema_name => null);

-- REUSE_DUMPFILES
dbms_datapump.add_file(handle => l_dp_handle, filename => 'test.dmp', directory => 'CTEMP', reusefile => 1);

-- SCHEMAS
dbms_datapump.metadata_filter(l_dp_handle, 'SCHEMA_LIST', '''ALIGNE''');

-- TABLES
dbms_datapump.metadata_filter(handle => h1, name => 'NAME_EXPR', value => 'IN (''TEST'',''TEST2'')', object_type => 'TABLE');

-- export create user statement in schema mode (only if datapump_exp_full_database role is granted)
dbms_datapump.set_parameter(handle => h1, name => 'USER_METADATA', value => 1); 

-- don't export create user statement in schema mode
dbms_datapump.set_parameter(handle => h1, name => 'USER_METADATA', value => 0); 

-- INCLUDE_PATH_EXPR and EXCLUDE_PATH_EXPR
Defines which object paths are included in, or excluded from, the job. You use these filters to select only certain object types from 
the database or dump file set. Objects of paths satisfying the condition are included (INCLUDE_PATH_EXPR) or excluded (EXCLUDE_PATH_EXPR) 
from the operation. The object_path parameter is not supported for these filters.

-- REMAP_SCHEMA
OBJECT TYPE = SCHEMA OBJECTS
Any schema object in the job that matches the object_type parameter and was located in the old_value schema will be moved to the value schema.


-----------------------------------------------------------------------------------------------------------------

-- expdp/impdp using PL/SQL
DECLARE
     l_dp_handle           NUMBER;
     l_last_job_state           VARCHAR2(30) := 'UNDEFINED';
     l_job_state           VARCHAR2(30) := 'UNDEFINED';
     l_sts                KU$_STATUS;
     v_file_handle          UTL_FILE.FILE_TYPE;
     v_exists               BOOLEAN;
     v_dbname               VARCHAR2(12);
     v_expfile               VARCHAR2(32);
     v_explog               VARCHAR2(32);
     v_expfile1               VARCHAR2(32);
     v_explog1               VARCHAR2(32);
     v_expfile2               VARCHAR2(32);
     v_explog2               VARCHAR2(32);
     v_length               NUMBER;
     v_blocksize               NUMBER;
     v_jobstate               VARCHAR2(30);
     v_jobstatus               KU$_JOBSTATUS;
     v_status               KU$_STATUS;
     v_scn                    NUMBER;
BEGIN
     SELECT name
INTO v_dbname
     FROM v$database;

     v_expfile := v_dbname||'_exp.dmp';
     v_explog := v_dbname||'_exp.log';
     v_expfile1 := v_dbname||'1_exp.dmp';
     v_explog1 := v_dbname||'1_exp.log';
     v_expfile2 := v_dbname||'2_exp.dmp';
     v_explog2 := v_dbname||'2_exp.log';

     DBMS_OUTPUT.ENABLE(1000000);
     -- See if old file exists and if so rename
     UTL_FILE.FGETATTR('DUMP_FILES',v_expfile1,v_exists, v_length, v_blocksize);
     IF v_exists
     THEN
          dbms_output.put_line('Renaming '||v_expfile1||' to '||v_expfile2);
          UTL_FILE.FRENAME(src_location => 'DUMP_FILES', src_filename => v_expfile1, dest_location => 'DUMP_FILES', dest_filename => v_expfile2, overwrite => TRUE);
          dbms_output.put_line('Renaming '||v_explog1||' to '||v_explog2);
          UTL_FILE.FRENAME(src_location => 'DUMP_FILES', src_filename => v_explog1, dest_location => 'DUMP_FILES', dest_filename => v_explog2, overwrite => TRUE);
          dbms_output.put_line('Files renamed.');
     END IF;
     --Rename current file
     UTL_FILE.FGETATTR('DUMP_FILES',v_expfile,v_exists, v_length, v_blocksize);
     IF v_exists
     THEN
          dbms_output.put_line('Renaming '||v_expfile||' to '||v_expfile1);
          UTL_FILE.FRENAME(src_location => 'DUMP_FILES', src_filename => v_expfile, dest_location => 'DUMP_FILES', dest_filename => v_expfile1, overwrite => TRUE);
          dbms_output.put_line('Renaming '||v_explog||' to '||v_explog1);
          UTL_FILE.FRENAME(src_location => 'DUMP_FILES', src_filename => v_explog, dest_location => 'DUMP_FILES', dest_filename => v_explog1, overwrite => TRUE);
          dbms_output.put_line('Files renamed.');
     END IF;

     --Begin Full export
     dbms_output.put_line('Beginning Export');     
     -- Get current database SCN

     SELECT current_scn
     INTO v_scn
     FROM v$database;

     l_dp_handle := dbms_datapump.open(operation => 'EXPORT',job_mode => 'FULL', remote_link => NULL, job_name =>'NIGHTLY_EXPORT', version => 'LATEST');
     dbms_datapump.add_file(handle => l_dp_handle, filename =>v_expfile, directory => 'DUMP_FILES', filetype => DBMS_DATAPUMP.KU$_FILE_TYPE_DUMP_FILE);
     dbms_datapump.add_file(handle => l_dp_handle, filename =>v_explog, directory => 'DUMP_FILES', filetype => DBMS_DATAPUMP.KU$_FILE_TYPE_LOG_FILE);
     dbms_datapump.set_parameter(handle => l_dp_handle, name => 'FLASHBACK_SCN', value => v_scn); -- Same as running consistent mode in traditional export
     dbms_datapump.start_job(l_dp_handle);
     --Begin loop to determine if job has completed
     v_jobstate := 'UNDEFINED';
     WHILE(v_jobstate != 'COMPLETED') and (v_jobstate != 'STOPPED')
     LOOP
          DBMS_DATAPUMP.GET_STATUS(
               handle => l_dp_handle,
               mask => 15, -- DBMS_DATAPUMP.ku$_status_job_error + DBMS_DATAPUMP.ku$_status_job_stats + DBMS_DATAPUMP.ku$_status_wip
               timeout => NULL,
               job_state => v_jobstate,
               status => v_status
          );
          v_jobstatus := v_status.job_status;
     END LOOP; 

     dbms_output.put_line('Export completed with state: '||v_jobstate);
     dbms_datapump.detach(l_dp_handle);
END;

<end node> 5P9i0s8y19Z
dt=Text
<node>
expdp/impdpd
3

-- running in background
nohup expdp \'/as sysdba\' DUMPFILE=ags_backup_25Mar2017.dmp LOGFILE=ags_backup_25Mar2017.log directory=DATA_PUMP_DIR schemas=AGS &

nohup expdp \'/as sysdba\' directory=DATA_PUMP_DIR dumpfile=expdp_TASK000212689_grower_idea_fsp_28Jun2017.dmp logfile=expdp_TASK000212689_grower_idea_fsp_28Jun2017.log schemas=GROWER_IDEA &

nohup expdp \'/as sysdba\' directory=expdp_mipp dumpfile=expdp_mipp_mip_prod_25Jul2017_%U.dmp logfile=logfile_expdp_mippp_mip_prod_25Jul2017.log filesize=4g parallel=4 schemas=MIP_PROD


nohup expdp \'/as sysdba\' directory=REFRESH_DIR dumpfile=expdp_privs_missing_31May2018.dmp logfile=expdp_privs_missing_31May2018_logs.log include=role_grant,grant,synonym

nohup impdp \"/as sysdba\" directory=DATA_PUMP_DIR dumpfile=expdp_WO0000001561465_valcap_podvcp_%U.dmp logfile=impdp_WO0000001561465_valcap_podvct.log remap_schema=VALUE_CAPTURE:ITS_SCHEMA parallel=5 table_exists_action=replace &

-- not using nohup but routing it nohup007.out file
nohup expdp "'/as sysdba'" directory=expdp dumpfile=expdp_RITM0521962_prod_drt_tbls_09OCT2019_%U.dmp logfile=expdp_RITM0521962_prod_drt_tbls_09OCT2019_logs.log tables=MR_PRELOAD.EPC_CNAUMBLINECOV,MR_PRELOAD.EPC_JOB,MR_PRELOAD.EPC_ETLCOVTERMOPTION,MR_PRELOAD.EPC_CNAFACULTATIVEREINSURANCE,MR_PRELOAD.EPC_TYPELIST,MR_PRELOAD.EPC_UWISSUE,MR_PRELOAD.EPC_UWISSUETYPE,MR_PRELOAD.EPC_UWISSUEHISTORY,MR_PRELOAD.EPC_USER_DIM_WORK,MR_PRELOAD.EPC_ETLCOVTERMOPTION exclude=statistics paralel=5 &> nohup007.out &

nohup impdp "'/as sysdba'" directory=impdp dumpfile=expdp_RITM0521962_prod_drt_tbls_09OCT2019_%U.dmp logfile=impdpexpdp_RITM0521962_prod_drt_tbls_09OCT2019_logs.log table_exists_action=replace parallel=5 &> impdp_nohup.out &


---------------------------------------------------------------------------------------------
-- example, assume that you only wanted to omit the storage clauses for all tables:
root>  impdp scott/tiger transform=segment_attributes:storage:n 

-- the following directs the import (impdp) to ignore the existing tablespace specifications 
-- and re-map the tablespace names:
root>  impdp scott/tiger transform=segment_attributes:n remap_tablespace=users:prodts 

-- You can also combine transform=segment_attributes parameters to perform multiple operations on the dmp file DDL. 
root>  impdp scott/tiger transform=SEGMENT_ATTRIBUTES:n:table,STORAGE:N:table

--# transform parameter will not work in adjacent with table_exsits_action parameters
--#
---------------------------------------------------------------------------------------------

hotdelarchnday


set lines 320 pages 1000
show parameters db_name
col directory_name for a30
col directory_path Â for a70
select directory_name,directory_path from dba_directories;
create or replace directory full_db_exp as '/shared231/exp008/ilvp';
grant read,write on directory full_db_exp to public;

-- 
/bin/ksh /csapps/oracle/cnascripts/multitask.sh -I -c /csapps/oracle/backup/scripts/cna_dbexport.joblist -t /csapps/oracle/tmp/cna_dbexport -m 4

nohup exp "'/ as sysdba'" file=exp_full_irisp_DB_bkup_14Apr2021.dmp log=exp__full_irisp_DB_bkup_14Apr2021_log.log full=y &

nohup exp "'/ as sysdba'" file=exp_full_ilvp_DB_bkup_14Apr2021.dmp log=exp__full_ilvp_DB_bkup_14Apr2021_log.log full=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_aemcmp_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_aemcmp_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_clmccip_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_clmccip_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_ecmp1p2p_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_ecmp1p2p_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_trustwap_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_trustwap_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_ecmrdr4p_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_ecmrdr4p_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_ecmrdr3p_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_ecmrdr3p_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_ecmrdr2p_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_ecmrdr2p_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_ecmradrp_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_ecmradrp_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_ecmp1p4p_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_ecmp1p4p_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_ecma1p1p_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_ecma1p1p_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_ecma1p2p_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_ecma1p2p_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_ecma1p3p_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_ecma1p3p_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_ecma1p4p_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_ecma1p4p_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &


nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_ecmfsrp_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_ecmfsrp_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y &

nohup expdp "'/as sysdba'" directory=full_db_exp dumpfile=expdp_full_ecmp1p3p_DB_bkup_07Apr2021_%U.dmp logfile=expdp_full_ecmp1p3p_DB_bkup_07Apr2021_logs.log full=y exclude=statistics parallel=5 reuse_dumpfiles=y & 
 


-- par file contents
userid="/ as sysdba" 
schemas=VALUE_CAPTURE 
directory=DATA_PUMP_DIR 
dumpfile=VALUE_CAPTURE_PODVCP_210418_%U.dmp 
logfile=VALUE_CAPTURE_PODVCP_210418.log 
job_name=VALUE_CAP_EXP 
exclude=table:"IN('FILE_CONTENT','FILE_REPOSITORY','INTEG_IMP_LOG_DETAILS','ITS_USER', 
'ITS_USER_TO_CROP','ITS_USER_TO_COMPANY','ITS_USER_TO_PROFILE','PROFILE','FEATURE','FEATURE_ACTION')" 
parallel=8 

-- same as above command, but using command line
nohup impdp \"/as sysdba\" directory=DATA_PUMP_DIR dumpfile=VALUE_CAPTURE_PODVCP_210418_%U.dmp logfile=impdp_value_capture_podvcP_to_podvcQ_210418_log.log schemas=VALUE_CAPTURE job_name=VALUE_CAP_imp table_exists_action=replace parallel=8 &

==================================================================
-- run the above sql query to check the job name and table name

expdp \'/as sysdba\' attach=SYS_EXPORT_SCHEMA_04


exp userid=dba_batch file=TASK000132954_MPM_USMGENP_02May2017.dmp log=TASK000132954_MPM_USMGENP_02May2017.log owner=mpm statistics=none
===================================================================

--- while export/import you can check the archive usage
select * from v$recovery_area_usage;

-- Speed up Import with TRANSFORM=DISABLE_ARCHIVE_LOGGING in #Oracle 12c
impdp adam/adam directory=DPDIR tables=big transform=disable_archive_logging:y

-- Another option is to suppress redo generation only for the import of indexes, in my example with the command
-- In this example, we only suppress the redo generation for indexes during the import.  
-- In this case, an abort would require manual rebuilding of the indexes.
impdp adam/adam directory=DPDIR tables=big transform=disable_archive_logging:y:index 
 
-- Disable logging for whole imported file so for tables and indexes 
impdp hr/hr DIRECTORY=dpdump_dir DUMPFILE=hr.dmp SCHEMAS=hr TRANSFORM=DISABLE_ARCHIVE_LOGGING:Y 

-- Disable logging just for indexes
impdp hr/hr DIRECTORY=dpdump_dir DUMPFILE=hr.dmp SCHEMAS=hr  TRANSFORM=DISABLE_ARCHIVE_LOGGING:Y:INDEX

-- Disable logging just for indexes - different way
impdp hr/hr DIRECTORY=dpdump_dir DUMPFILE=hr.dmp SCHEMAS=hr TRANSFORM=DISABLE_ARCHIVE_LOGGING:Y TRANSFORM=DISABLE_ARCHIVE_LOGGING:N:TABLE 
 

nohup impdp "'/as sysdba'" directory=MRLAN_EXPDP dumpfile=exp_PAPCUSER_27092019.dmp 
logfile=impdp_exp_PAPCUSER_27092019.log remap_schema=papcuser:mr_landing 
remap_tablespace=EPC_INDEX:MR_LANDING_TABLES remap_tablespace=EPC_LOB:MR_LANDING_LOB remap_tablespace=EPC_LOB:MR_LANDING_INDEXES 
remap_tablespace=EPC_ADMIN:MR_LANDING_TABLES remap_tablespace=EPC_STAGING:MR_LANDING_TABLES remap_tablespace=EPC_TYPELIST:MR_LANDING_TABLES 
remap_tablespace=EPC_OP:MR_LANDING_TABLES remap_tablespace=PAPCUSER_SELECT:MR_LANDING_SELECT TRANSFORM=DISABLE_ARCHIVE_LOGGING:Y:TABLE 
TRANSFORM=DISABLE_ARCHIVE_LOGGING:Y:INDEX table_exists_action=replace &

------------------------------------------------------------------------------------------

-- to check where the expdp - data pump workers are running 
select * from gv$session where regexp_like(module,'*data*','i');

-- check if backgroud session is present for export/import jobs
select inst_id, sid,serial#,process,sql_id,schemaname,
    username,osuser,status,action job_name,machine,program,
    module,to_char(sql_exec_start,'mm/dd/yyyy hh24:mi:ss')sql_started
from gv$session 
where schemaname = 'SYS' 
  and type <> 'BACKGROUND'
 --and not regexp_like(program,'rman*','i')
 --and regexp_like(action,'sys_export*','i') 
  and module = 'Data Pump Master'
  and status = 'ACTIVE';

--- Below Queries will help to know the precentage completion of export/import
SELECT x.job_name,b.state,b.job_mode,b.DEGREE
, x.owner_name, P.totalwork, P.sofar
, ROUND((P.sofar/P.totalwork)*100,2) done
, P.time_remaining
FROM dba_datapump_jobs b
LEFT JOIN dba_datapump_sessions x ON (x.job_name = b.job_name)
LEFT JOIN v$session y ON (y.saddr = x.saddr)
LEFT JOIN v$sql z ON (y.sql_id = z.sql_id)
LEFT JOIN v$session_longops P ON (P.sql_id = y.sql_id)
WHERE y.module='Data Pump Worker'
AND P.time_remaining > 0; 

------------------------------------------------------------------------------------------

--- Expdp/Impdp monitoring
select SID,username,OPNAME,SOFAR,TOTALWORK,SOFAR/TOTALWORK*100 "Work Done %",
	to_char(START_TIME,'mm/dd/yyyy hh24:mi:ss') "start_time",
	to_char(sysdate + TIME_REMAINING/3600/24,'mm/dd/yyyy hh24:mi:ss') "End_at",
	to_char(sysdate,'mm/dd/yyyy hh24:mi:ss')Date_Now
from v$session_longops
where sofar!=TOTALWORK 
  and totalwork!=0

-- what is running in expdp/impdp
SELECT 
	 SUBSTR(sql_text,INSTR(sql_text,'INTO "'),30) table_name,
	 rows_processed,
	 ROUND((sysdate-to_date(first_load_time,'yyyy-mm-dd hh24:mi:ss'))*24*60,1) minutes,
	 TRUNC(rows_processed/((sysdate-to_date(first_load_time,'yyyy-mm-dd hh24:mi:ss'))*24*60)) rows_per_min
FROM   sys.v_$sqlarea
WHERE  sql_text LIKE 'INSERT %INTO "%'
	   AND  command_type = 2
	   AND  open_versions > 0;


select substr(sql_text,instr(sql_text,'INTO "'),30) table_name,
         rows_processed,
         round((sysdate-to_date(first_load_time,'yyyy-mm-dd hh24:mi:ss'))*24*60,1) minutes,
         trunc(rows_processed/((sysdate-to_date(first_load_time,'yyyy-mm-dd hh24:mi:ss'))*24*60)) rows_per_min
  from   sys.v_$sqlarea
  where  sql_text like 'INSERT %INTO "%'
    and  command_type = 2
    and  open_versions > 0;


--- Expdp/Impdp monitoring
select SID,username,OPNAME,SOFAR,TOTALWORK,SOFAR/TOTALWORK*100 "Work Done %",
	to_char(START_TIME,'mm/dd/yyyy hh24:mi:ss') "start_time",
	to_char(sysdate + TIME_REMAINING/3600/24,'mm/dd/yyyy hh24:mi:ss') "End_at",
	to_char(sysdate,'mm/dd/yyyy hh24:mi:ss')Date_Now
from v$session_longops
where sofar!=TOTALWORK 
  and totalwork!=0
  
  
-- Oracle DataPump Utility



-- Once the job has started the status can be checked using.
system@db10g> select * from dba_datapump_jobs;


-- Oracles export import utilities helps to move data between schemas and databases. With export and import feature one can 
-- backup data in operating system files, restore data if required. Following example explains exactly how EXPORT and IMPORT utilities 
-- are used to perform above mentioned activities.

exp test_user/test_user@dev file=TLD_test_0805.dmp log=TLD_test_0805_exp.log statistics=none tables=employee

-- In the above example, only employee table will be exported to dump file from test_user schema. If you want to do EXPORT for multiple 
-- tables, add names of tables within parenthesis separated by comma [tables=(emp,dept)]. We can further filter by adding query parameter. 
-- Data which satisfies the given condition are only exported to file. The example with QUERY parameter is as follows:

exp test_user/test_user@dev file=TLD_test_0805.dmp log=TLD_test_0805_exp.log statistics=none tables=employee query=\"where emp_city=\'PUNE\'\"

-- In the above example, only employee whose city is PUNE will be filtered and retrieved to the dump file.

exp test_user/test_user@dev owner=test_user file=TLD_test_0805.dmp log=TLD_test_0805_exp.log statistics=none

-- In the above example export will be performed on OWNER test_user. All the objects and data of test_user will be exported. If you do not 
-- want to export rows then mention ROWS=N. By default ROWS=Y.

-- The original EXPORT IMPORT is a default feature in ORACLE. Now ORACLE has introduced Data Pump from 10g onwards which replaces export import utility.

-- Can one export to multiple files?/ Can one beat the Unix 2 Gig limit?
-- From Oracle8i, the export utility supports multiple output files. This feature enables large exports 
-- to be divided into files whose sizes will not exceed any operating system limits (FILESIZE= parameter). 
-- When importing from multi-file export you must provide the same filenames in the same sequence in the 
-- FILE= parameter. Look at this example:
-- URL : http://www.orafaq.com/wiki/Import_Export_FAQ
exp SCOTT/TIGER FILE=D:F1.dmp,E:F2.dmp FILESIZE=10m LOG=scott.log


-- What are the common Import/ Export problems?
* ORA-00001: Unique constraint (...) violated
You are importing duplicate rows. Use IGNORE=YES to skip tables that already exist (imp will give an error if the object is re-created).

* ORA-01555: Snapshot too old
Ask your users to STOP working while you are exporting or try using parameter CONSISTENT=NO

* ORA-01562: Failed to extend rollback segment
Create bigger rollback segments or set parameter COMMIT=Y while importing

* IMP-00015: Statement failed ... object already exists...
Use the IGNORE=Y import parameter to ignore these errors, but be careful as you might end up with duplicate rows


------------------------------------------------------------------------------------------------------------------------------------------------------------


/* 				ORACLE - DATA PUMP
	
A very high speed utility for moving data and meta-data from one database to another database.

Fast Data Movement between databases (Twice the speed when compared to EXPORT utility and twenty to thirty times faster when performing IMPORT.

Only time you would/ should use the original (exp & imp) is when you need backward compatibility to an earlier version that does not have Data 
Pump export & import (expdp & impdp). 

Basically if you wanted to import a 10g export into a pre-10g database or import into a 10g database from a pre-10g database.
DATA PUMP – ORACLE 10G

New feature in ORACLE 10g that replaces normal export/import even though exp/imp are supported.

First we must create a directory object which will be accessed for export of mentioned tables. The directory object will be mapped to directory 
location where the dump files will be held.

create directory dir_obj as '/home/oracle/dir';

Here a directory object named dir_obj has been created which points to directory location /home/oracle/dir where the dump files are held. 
ORACLE introduced a default directory called DATA_PUMP_DIR which can also be used for dump files. But the user show have the privilege to 
use the default directory.

Once the directory object has been created, READ and WRITE privileges are to be granted on the directory object to the users who will be 
accessing for export/import activities.

grant read, write on directory dir_obj to test_user;

In the above statement test_user has been granted with read and write privileges on dir_obj. Now test_user can write dump files to dir_obj 
and even read existing dump files for doing import.

*/

-- Now to perform EXPORT of employee table from test_user schema:

expdp test_user/test_user@dev10g directory=dir_obj tables=employee dumpfile=test_user.dmp logfile=test_user_exp.log

OR

expdp test_user/test_user@dev10g tables=employee dumpfile=dir_obj:test_user.dmp logfile=dir_obj:test_user_exp.log

OR

expdp tables=employee dumpfile=dir_obj:test_user.dmp logfile=dir_obj:test_user_exp.log


-- All the above 3 examples perform same action, ie., make dump file of employee table from test_user schema. When E3 is run, the username and 
-- password is prompted.

-- Now if we want to further filter and we want only selected rows in a table which meets the condition, then the following export statement with 
-- the help of QUERY parameter retrieves only the data matching condition to dump file.

expdp test_user/test_user@dev10g dumpfile=dp_dir:TU_Q.dmp logfile=dp_dir:TU_Q_exp.log tables=airport query=airport:\'\"where airport_code=1\"\'

expdp system/sys88qadb@qadb dumpfile=tu_q.dmp logfile=imp_tu_q.log tables=transhms.DOWNLOAD_DOC_CATEGORY_MAPPING query=transhms.DOWNLOAD_DOC_CATEGORY_MAPPING:\'\"where DESCRIPTION=\'Application Form\'\"\'


-- You can use Data Pump Export utility to export multiple tables. The following example shows the syntax to export tables:
expdp test_user/test_user@dev10g DIRECTORY=dp_dir 
DUMPFILE=multiple_tbls.dmp LOGFILE=multiple_tbls_exp.log 
TABLES=employees,jobs,departments

-- And adding QUERY again on one table when using multiple tables:
expdp test_user/test_user@dev10g 
DIRECTORY=dp_dir 
DUMPFILE=multiple_tbls.dmp 
LOGFILE=multiple_tbls_exp.log 
TABLES=employees,jobs,departments 
QUERY=jobs:\'\”where job_id = 407\”\'

-- In the above case both the departments and jobs tables are completely exported and employee records of jod_id 407 are exported from employee table.

expdp test_user/test_user@dev10g 
schemas=test_user 
include=TABLE:\"IN (\'EMP\', \'DEPT\')\" 
directory=TEST_DIR 
dumpfile=include_test.dmp 
logfile=include_test_expdp.log

-- In the above example from the schema test_user only objects which are mentioned in INCLUDE parameter are exported. Rest are ignored.

expdp test_user/test_user@dev10g 
schemas=test_user 
EXCLUDE=SEQUENCE, TABLE:\”IN (\'EMP,\ 'DEPT\')\”  --'
directorty=test_dir 
dumpfile=exclude_test.dmp 
logfile=exclude_test_exp.log 

-- In the above example, EXCLUDE parameter has been used. Here EXCLUDE parameter does not export sequences and tables mentioned. Rest of 
-- all the objects for test_user schema are exported.

 
-->> Table Import:

-- As we have seen how to do Export on a particular table, set of tables and also using QUERY parameter, now let us see how to do the import 
-- of the dump files being created in the directory through directory object.

-- Performing Data pump IMPORT is quite easy and twenty to thirty times faster than original IMPORT. Following examples give a clear picture 
-- of IMPORT Data Pump Utility.

impdp test_user/test_user@qadb86 tables=emp_s dumpfile=dp_dir:test.dmp logfile=dp_dir:test.log 
-- In the above example we are doing import of same schema but of different databases.

impdp system/sysdev@dev10g tables=emp_s dumpfile=dp_dir:test.dmp logfile=dp_dir:test.log remap_schema=test_user:test_2 transhms:transhms_reg
-- Lets assume that we have done export of a table emp_s from test_user schema and now we want to do import of the table to test_2 schema. In 
-- this case we use the above syntax where remap_schema keyword has been used. It is similar to fromuser & touser in original import.

-- Let us now import more than one tables.

impdp test_user/test_user@dev10g tables=employee,dept,course dumpfile=test_dir:test.dmp logfile=test_dir:test_imp.log
-- In the above example the dumpfile will be imported to test_user schema to tables employee, dept and course. Note that the table structure is 
-- same as of the tables exported from.

impdp test_user/test_user@dev10g schemas=test_user include=function, package, procedure, table:”='emp'” dumpfile=test.dmp logfile=test_imp.dmp
-- In the above example the include parameter will only import functions, packages, procedures owned by test_user schema and employee table and all its dependent objects.

expdp rchaudhari@r1 
directory=oradata8 
dumpfile=expdp_Device_24Apr2012.dmp 
logfile=log_Device_24Apr2012.log 
tables=snox4transnox_gca.device 
query=snox4transnox_gca.device:\"where device_id in\(SELECT DEVICE_ID FROM TRANSNOX_gca.TRANSACTION X WHERE X.TIME_STAMP BETWEEN TO_DATE\(\'02\/28\/2012 00:00:00\',\'mm\/dd\/yyyy hh24:mi:ss\'\) AND  TO_DATE\(\'04\/02\/2012 23:59:59\',\'mm\/dd\/yyyy hh24:mi:ss\'\)\)\" 
include=table,table_data,statistics,constraint 
compression=all

expdp rchaudhari@r1 
directory=oradata8 
dumpfile=expdp_ADMIN_TRANSACTION_24Apr2012.dmp 
logfile=log_ADMIN_TRANSACTION_24Apr2012.log 
tables=transnox_gca.ADMIN_TRANSACTION 
query=transnox_gca.ADMIN_TRANSACTION:\"where TIME_STAMP BETWEEN TO_DATE\(\'02\/28\/2012 00:00:00\',\'mm\/dd\/yyyy hh24:mi:ss\'\) AND TO_DATE\(\'04\/02\/2012 23:59:59\',\'mm\/dd\/yyyy hh24:mi:ss\'\)\" 
include=table,table_data,statistics,constraint 
REUSE_DUMPFILES=y 
CONTENT=all


expdp bdas directory=dash 
dumpfile=exp_trans_13m.dmp 
logfile=exp_trans_13m.log 
schemas=transnox_gca 
include=table:\"like \'TRANS%\'\" 
query=\"where transaction_id \>\= 2111429013\"

expdp rchaudhari directory=dash 
dumpfile=exp_trans_13m.dmp 
logfile=exp_trans_13m.log 
schemas=transnox_gca 
include=table:\"like \'TRANS%\'\" 
query=\"where transaction_id \>\= 2111429013\" 
content=data_only 
compression=all 
reuse_dumpfiles=y


expdp rchaudhari/isplN01805@COL122 
directory=arch 
dumpfile=expdp_trans_response_info_12052015.dmp 
logfile=expdp_trans_response_info_12052015.log 
tables=TRANSNOX_GCA.TRANS_RESPONSE_INFO 
query=TRANSNOX_GCA.TRANS_RESPONSE_INFO:\" WHERE TRANSACTION_ID \>\ 2381397201\" 
content=data_only 
compression=all 
reuse_dumpfiles=y
 
expdp rchaudhari@r1 
directory=oradata8 
dumpfile=expdp_ADMIN_TRANS_CASH_BALANCE_24Apr2012.dmp 
logfile=log_ADMIN_TRANS_CASH_BALANCE_24Apr2012.log 
tables=transnox_gca.ADMIN_TRANS_CASH_BALANCE 
query=transnox_gca.ADMIN_TRANS_CASH_BALANCE:\"where ADMIN_TRANS_ID in\(select ADMIN_TRANS_ID from TRANSNOX_GCA.ADMIN_TRANSACTION where TIME_STAMP BETWEEN TO_DATE\(\'02\/28\/2012 00:00:00\',\'mm\/dd\/yyyy hh24:mi:ss\'\) AND TO_DATE\(\'04\/02\/2012 23:59:59\',\'mm\/dd\/yyyy hh24:mi:ss\'\)\)\" 
include=table,table_data,statistics,constraint 
REUSE_DUMPFILES=y 
CONTENT=all

expdp rchaudhari@r1 
directory=oradata8 
dumpfile=expdp_DEVICE_PROCESSOR_INFO_24Apr2012.dmp 
logfile=log_DEVICE_PROCESSOR_INFO_24Apr2012.log 
tables=TRANSNOX_GCA.DEVICE_PROCESSOR_INFO

expdp rchaudhari@r1 
directory=oradata8 
dumpfile=expdp_CUST_ADDRESS_24Apr2012.dmp 
logfile=log_CUST_ADDRESS_24Apr2012.log 
tables=transnox_gca.CUST_ADDRESS 
query=transnox_gca.CUST_ADDRESS:\"where CUSTOMER_CODE in\(select CUSTOMER_CODE from transnox_gca.task where task_id in\(select task_id from TRANSNOX_GCA.TRANSACTION where TIME_STAMP BETWEEN TO_DATE\(\'02\/28\/2012 00:00:00\',\'mm\/dd\/yyyy hh24:mi:ss\'\) AND TO_DATE\(\'04\/02\/2012 23:59:59\',\'mm\/dd\/yyyy hh24:mi:ss\'\)\)\)\" 
include=table,table_data,statistics,constraint 
REUSE_DUMPFILES=y 
CONTENT=all

expdp rchaudhari 
directory=ora6 
dumpfile=app_mer_doc_moneris.dmp 
logfile=app_mer_doc_moneries.log 
tables=transmoneris.app_mer_documents 
include=table,table_data 
compression=all 
query=transmoneris.app_mer_documents:\" where Application_id in\(100849,100836,95759,95472,95932,95917,95789,93689,82794,82854,82848,94455\)\"

expdp rchaudhari@r1 
directory=oradata8 
dumpfile=expdp_CARD_NUMBER_MASTER_24Apr2012.dmp 
logfile=log_CARD_NUMBER_MASTER_24Apr2012.log 
tables=transnox_gca.CARD_NUMBER_MASTER 
query=transnox_gca.CARD_NUMBER_MASTER:\"where CARD_SEQNO in\(select CARD_NUMBER from Transnox_GCA.TRANS_CARD where TRANSACTION_ID in\(select TRANSACTION_ID from TRANSNOX_GCA.TRANSACTION where TIME_STAMP BETWEEN TO_DATE\(\'02\/28\/2012 00:00:00\',\'mm\/dd\/yyyy hh24:mi:ss\'\) AND TO_DATE\(\'04\/02\/2012 23:59:59\',\'mm\/dd\/yyyy hh24:mi:ss\'\)\)\)\" 
include=table,table_data,statistics,constraint 
REUSE_DUMPFILES=y 
CONTENT=all

expdp rchaudhari@r1 
directory=oradata8 
dumpfile=expdp_MERCHANT_24Apr2012.dmp 
logfile=log_MERCHANT_24Apr2012.log 
tables=snox4transnox_gca.MERCHANT 
query=snox4transnox_gca.MERCHANT:\"where MERCHANT_ID in\(select MERCHANT_ID from SNOX4Transnox_GCA.DEVICE where DEVICE_ID in\(select DEVICE_ID from TRANSNOX_GCA.TRANSACTION where TIME_STAMP BETWEEN TO_DATE\(\'02\/28\/2012 00:00:00\',\'mm\/dd\/yyyy hh24:mi:ss\'\) AND TO_DATE\(\'04\/02\/2012 23:59:59\',\'mm\/dd\/yyyy hh24:mi:ss\'\)\)\)\" 
include=table,table_data,statistics,constraint 
REUSE_DUMPFILES=y 
CONTENT=all


-- If export is done by table level and one of the table failed to import the data…
expdp / directory=bkup 
dumpfile=exp_tnox_gca_org1.dmp 
logfile=exp_tnox_gca_org.log  
tables=transnox_gca.TRANS_RESPONSE_INFO_ORG1,transnox_gca.TRANSACTION_ORG1,transnox_gca.TRANS_CARD_ORG1,transnox_gca.TRANS_CARD_HISTORY_ORG1,transnox_gca.TASK_TIME_LOG_ORG,transnox_gca.TASK_ORG1  
include=table,table_data 
compression=all

-- then you can import the table separately… 
impdp / directory=tbackup 
dumpfile=exp_tnox_gca_org1.dmp 
logfile=impdp_exp_tnox_gca_org12.log 
remap_schema=transnox_gca:transnox_gca_22a 
tables=transnox_gca.trans_response_info_org1 
remap_tablespace=trans_data3:tgca_22_data




-->> Schema Export:

-- Following examples will explain how to perform export of a schema.

expdp test_user/test_user@dev10g schemas=test_user directory=test_dir dumpfile=schema_test.dmp logfile=schema_test_exp.dmp
-- In the above example export is performed on all the objects, data and meta-data of test_user schema .

expdp system/sysdev@dev10g schemas=test_user,test_1,test_2 dumpfile=test_dir:multiple_schemas.dmp logfile=test_dir:multiple_schemas_exp.log
-- In the above example we are performing export of objects from more than one schema.



-->> Schema Import:

-- Following examples will explain about the import procedure of schema.

-- Below is the example we have performed import of schema from the dump file test.dmp which was accessed from test_dir directory.
impdp system/sysdev@dev10g 
schemas=test_user 
dumpfile=test_dir:test.dmp 
logfile=test_dir:test_imp.log 
remap_schema=test_user:test_2 
REMAP_SCHEMA=FROM:TO

impdp test_user/test_user@dev10g 
schemas=test_user 
directory=test_dir 
dumpfile=test.dmp 
logfile=test.log 
EXCLUDE=TABLE:\"LIKE \'DEF%\'\" 

 expdp / directory=bkup dumpfile=expdp_bkup_UAT_12661_21Sep2015.dmp logfile=expdp_bkup_UAT_12661_21Sept2015.log full=y 
 exclude=statistics,table:\" like \'SC_TEMP%\'\",table:\" like \'SN_TEMP%\'\" compression=all 
-- and

-- Exporting the schema tables without some tables like SN_TEMP, statistics
expdp system@dev11g 
directory=data_pump_dir 
dumpfile=dev11g231_84.dmp 
logfile=dev11g231_84.log 
schemas=OFAC,SNOX_BS,SNOX4TRANSNOX_API,SNOXGCA_91X_20101P,TNOXGCA_91X_20101P,TRANSNOX_API,TRANSNOX_BS,TRANSNOX_CNW,TRANSNOX_GLORY,TRANSNOX_IOX,TRANSNOX_WM 
exclude=statistics,TABLE:\"LIKE \'SN_TEMP%\'\", TABLE:\"LIKE \'SC_TEMP%\'\" 
compression=all 
reuse_dumpfiles=y

-- Importing the schema with selected objects and selected tables data
impdp test_user/test_user@dev10g 
schemas=test_user 
directory=test_dir 
dumpfile=test.dmp 
logfile=test.log 
INCLUDE=procedure,table 
QUERY=emp:\'\”where deptid=30\”\'


-- We have used INCLUDE parameter when performing import, which means that only mentioned objects are imported to schema while rest are not. 
-- We have also used QUERY. Hence only data satisfying the condition are actually imported.

-- REMAP_TABLESPACE option has been used to import objects of one tablespace to another tablespace by giving the following command
impdp test_user/test_user@dev10g 
DIRECTORY=test_dir 
DUMPFILE=test.dmp 
LOGFILE=test_exp.log 
REMAP_TABLESPACE=users:sales


-- One of the most important feature available with Data Pump is the job feature. The data pump process work as a background job in 
-- database. We can detach ourself from the session and re-attach to monitor the session. Also we can stop or pause the job.


expdp test_user/test_user@dev10g schemas=test_user dumpfile=test_dir:test_job.dmp logfile=test_dir:test_job.log job_name=test parallel=4
-- In the above example we have added two parameters (job_name & parallel). We have named the job name as test and we are running parallel 
-- processing for export.

nohup expdp \"/as sysdba\" directory=DATA_PUMP_DIR dumpfile=expdp_TASK000443055_Value_Capture_prod_cpy_%U.dmp logfile=expdp_TASK000443055_Value_Capture_prod_cpy_logs.log parallel=5 schemas=VALUE_CAPTURE exclude=table:\"in \(\'FILE_CONTENT\',\'FILE_REPOSITORY\',\'INTEG_IMP_LOG_DETAILS\'\)\",statistics,db_link &


nohup expdp \"/as sysdba\" directory=DATA_PUMP_DIR dumpfile=expdp_TASK000664522_MIPP_05Mar18_%U.dmp logfile=expdp_TASK000664522_MIPP_06Mar2018.log schemas=MIP_PROD parallel=5 &

-- if there is a same location shared and you have to start multiple nohup export in background
-- then one nohup output file can be redirect
nohup expdp \"/ as sysdba\" directory=data_pump_dir dumpfile=export_EPM_FDMEE_safe_backup_23July18_%U.dmp logfile=export_EPM_FDMEE_safe_backup_23July18.log schemas=EPM_FDMEE exclude=statistics PARALLEL=8 > output_safe_backup.out &


-- running in background
nohup expdp \'/as sysdba\' DUMPFILE=ags_backup_25Mar2017.dmp LOGFILE=ags_backup_25Mar2017.log directory=DATA_PUMP_DIR schemas=AGS &

nohup expdp \'/as sysdba\' directory=DATA_PUMP_DIR dumpfile=expdp_TASK000212689_grower_idea_fsp_28Jun2017.dmp logfile=expdp_TASK000212689_grower_idea_fsp_28Jun2017.log schemas=GROWER_IDEA &

nohup expdp \'/as sysdba\' directory=expdp_mipp dumpfile=expdp_mipp_mip_prod_25Jul2017_%U.dmp logfile=logfile_expdp_mippp_mip_prod_25Jul2017.log filesize=4g parallel=4 schemas=MIP_PROD


nohup expdp \'/as sysdba\' directory=REFRESH_DIR dumpfile=expdp_privs_missing_31May2018.dmp logfile=expdp_privs_missing_31May2018_logs.log include=role_grant,grant,synonym

nohup impdp \"/as sysdba\" directory=DATA_PUMP_DIR dumpfile=expdp_WO0000001561465_valcap_podvcp_%U.dmp logfile=impdp_WO0000001561465_valcap_podvct.log remap_schema=VALUE_CAPTURE:ITS_SCHEMA parallel=5 table_exists_action=replace &


/*
	When the export starts, we can press Control+C to get the interactive prompt (Export>). If we try the same in normal export/import 
we will get some error message and the process will fail.

When we are in interactive mode we can issue status command and various details. Also we can query following views:

•	DBA_DATAPUMP_JOBS - all active Data Pump jobs and the state of each job
•	USER_DATAPUMP_JOBS – summary of the user’s active Data Pump jobs
•	DBA_DATAPUMP_SESSIONS – all active user sessions that are attached to a Data Pump job
•	V$SESSION_LONGOPS – shows all progress on each active Data Pump job

We can also stop the running job at anytime and resume after sometime when required. The job_name is first detached from the 
running data pump session by firing stop_job command. The job is stopped now.

*/

-- When we want to start the job again where it was left off, it can be done in oracle 10g data pump. It is done as follows:

expdp test_user/test_user@dev10g attach=job_name





-->> INCLUDE=<include_list>

-- The job is again started where it was left off. This is one of the most important advantage of using data pump over normal export/import utility.

expdp uwclass/uwclass SCHEMAS=uwclass DIRECTORY=data_pump_dir DUMPFILE=demo20.dmp INCLUDE=table

expdp uwclass/uwclass SCHEMAS=uwclass DIRECTORY=data_pump_dir DUMPFILE=demo21.dmp INCLUDE=\"IN ('SERVERS', 'SERV_INST')\"

expdp uwclass/uwclass SCHEMAS=uwclass DIRECTORY=data_pump_dir DUMPFILE=demo22.dmp INCLUDE=procedure

expdp uwclass/uwclass SCHEMAS=uwclass DIRECTORY=data_pump_dir DUMPFILE=demo23.dmp INCLUDE=INDEX:\"LIKE 'PK%\" --'

EXCLUDE=<exclude_criterion>

-- exclude all (nonreferential) constraints, except for NOT NULL constraints and any constraints needed for successful table creation and loading
expdp uwclass/uwclass SCHEMAS=uwclass DIRECTORY=data_pump_dir DUMPFILE=demo12.dmp EXCLUDE=constraint

-- exclude referential integrity (foreign key) constraints
expdp uwclass/uwclass SCHEMAS=uwclass DIRECTORY=data_pump_dir DUMPFILE=demo13.dmp EXCLUDE=ref_constraint

-- exclude object grants on all object types and system priv grants
expdp uwclass/uwclass SCHEMAS=uwclass DIRECTORY=data_pump_dir DUMPFILE=demo14.dmp EXCLUDE=grant


-- excludes the definitions of users
expdp uwclass/uwclass SCHEMAS=uwclass DIRECTORY=data_pump_dir DUMPFILE=demo15.dmp EXCLUDE=user

-- excludes views
expdp uwclass/uwclass SCHEMAS=uwclass DIRECTORY=data_pump_dir DUMPFILE=demo16.dmp EXCLUDE=view,package,function

--To exclude a specific user and all objects of that user, specify a filter such as the following (where hr is the schema name of the user you want to exclude):
expdp uwclass/uwclass FULL=y DIRECTORY=data_pump_dir DUMPFILE=demo17.dmp EXCLUDE=SCHEMA:\"='HR'\"

-- Take full backup and exclude list of schemas
expdp / directory=BKUP_ARCH dumpfile=expdp_121_reportingDB_03Mar2016.dmp logfile=expdp_Server121_reportingDB_03Mar2016.log full=y compression=all exclude=SCHEMA:\" in \(\'ANONYMOUS\',\'APEX_030200\',\'APEX_PUBLIC_USER\',\'APPQOSSYS\',\'CTXSYS\',\'DBSNMP\',\'DIP\',\'EXFSYS\',\'FLOWS_FILES\',\'MDDATA\',\'MDSYS\',\'MGMT_VIEW\',\'OLAPSYS\',\'OPS$DBJOBS\',\'ORACLE_OCM\',\'ORDDATA\',\'ORDPLUGINS\',\'ORDSYS\',\'OUTLN\',\'OWBSYS\',\'OWBSYS_AUDIT\',\'SCOTT\',\'SI_INFORMTN_SCHEMA\',\'SPATIAL_CSW_ADMIN_USR\',\'SPATIAL_WFS_ADMIN_USR\',\'SQLTXADMIN\',\'SQLTXPLAIN\',\'SYS\',\'SYSMAN\',\'SYSTEM\',\'WMSYS\',\'XDB\',\'XS$NULL\'\)\"

The EXCLUDE and INCLUDE parameters are mutually exclusive.
It is not possible to specify both the INCLUDE parameter and the EXCLUDE parameter in the same job.
Incorrect syntax (error: UDE-00011):
expdp scott/tiger@dev dumpfile=exp_test.dmp INCLUDE=TABLE:"IN ('EMP', 'DEPT')" EXCLUDE=INDEX:"= 'PK_EMP'"

--- Exclude and Include expdp/impdp contains the below objects which can be export/import ‘ed
 
USER
SYSTEM_GRANT
ROLE_GRANT
DEFAULT_ROLE
TABLESPACE_QUOTA
PROCACT_SCHEMA
SYNONYM
SEQUENCE
OBJECT_GRANT
TABLE
OBJECT_GRANT
INDEX
CONSTRAINT
PACKAGE_SPEC
FUNCTION
OBJECT_GRANT
PROCEDURE
OBJECT_GRANT
ALTER_PACKAGE_SPEC
ALTER_FUNCTION
ALTER_PROCEDURE
VIEW
OBJECT_GRANT
PACKAGE_BODY
REF_CONSTRAINT
TRIGGER
INDEX
MATERIALIZED_VIEW
JOB
REFRESH_GROUP
PROCACT_SCHEMA


INDEX,CONSTRAINT,REF_CONSTRAINT

-->> TRANSPORT_TABLESPACES=<tablespace_name [, ...]>

--The default tablespace of the user performing the export must not be set to one of the tablespaces being transported
expdp uwclass/uwclass 
DIRECTORY=data_pump_dir 
DUMPFILE=demo05.dmp
LOGFILE=demo5.log
TRANSPORT_TABLESPACES=users,example 
TRANSPORT_FULL_CHECK=y 


conn / as sysdba

ALTER TABLESPACE users READ ONLY;
ALTER TABLESPACE example READ ONLY;

expdp uwclass/uwclass 
DIRECTORY=data_pump_dir 
DUMPFILE=demo05.dmp
TRANSPORT_TABLESPACES=users,example 
TRANSPORT_FULL_CHECK=y LOGFILE=demo5.log

ALTER TABLESPACE users READ WRITE;
ALTER TABLESPACE example READ WRITE;



-->> QUERY=<[schema.][table_name:]query_where_clause>

expdp uwclass TABLES=airplanes DUMPFILE=data_pump_dir:demo30.dmp QUERY=airplanes:\"WHERE program_id = ''737''\"

--to export using joining the tables
expdp rchaudhari@qadb 
directory=ORADATA1 dumpfile=expdp_trans_response_info logfile=expdp_trans_response_info tables=transnox_gca.trans_response_info 
query=transnox_gca.trans_response_info:\" where transaction_id in \(SELECT transaction_id FROM TRANSNOX_GCA.TRANSACTION WHERE transnox_gca.TRANSACTION.time_stamp BETWEEN TO_DATE\(\'01/01/2011 00:00:00\',\'mm/dd/yyyy hh24:mi:ss\'\) AND TO_DATE\(\'12/19/2011 23:59:59\',\'mm/dd/yyyy hh24:mi:ss\'\)\)\" 
include=table,table_data 
reuse_dumpfiles=y

--- use objects to exclude/include in expdp/impdp
statistics,
procedure,
function,
package,
package_body,
trigger,
index,
index_partition,
materialized_view,
sequence,
synonym,
type,
view,
index_statistics,
ref_constraint,
object_grant,
job

-->> Network import 

-- With network mode imports, one doesn't need any intermediate dump files (GREAT, no more FTP'ing of dump files). Data is exported across 
-- a database link and imported directly into the target database. 

Example: 

SQL> create user new_scott identified by tiger;

User created.

SQL> grant connect, resource to new_scott;

Grant succeeded.

SQL> grant read, write on directory dmpdir to new_scott;

Grant succeeded.

SQL> grant create database link to new_scott;

Grant succeeded.

SQL> conn new_Scott/tiger

Connected.

SQL> create database link old_scott connect to scott identified by tiger using 'orcl.oracle.com';

Database link created.

impdp new_scott/tiger DIRECTORY=dmpdir NETWORK_LINK=old_scott remap_schema=scott:new_scott

impdp system/sys88qadb@qadb 
dumpfile=  
logfile=imp_transnox_gateway_logs.log 
schemas=transnox_cpass,snox4transnox_cpass,tnoxpass_gway_00513,snoxpass_gway_00513 
remap_schema=snox4transnox_cpass:snox4transnox_api_escrow 
remap_schema=transnox_cpass:transnox_iox_escrow 
remap_schema=tnoxpass_gway_00513:tnoxpass_gway_00513_escrow 
remap_schema=snoxpass_gway_00513:snoxpass_gway_00513_escrow 
exclude=grant,synonym

-- All work is performed on the target system. The only reference to the source systems is via the database link. 

-->> COMPRESSION

-- The COMPRESSION parameter allows you to decide what, if anything, you wish to compress in your export. The syntax is shown below.
-- COMPRESSION={ALL | DATA_ONLY | METADATA_ONLY | NONE}

/* The available options are:
    * ALL: Both metadata and data are compressed.
    * DATA_ONLY: Only data is compressed.

    * METADATA_ONLY: Only metadata is compressed. This is the default setting.
    * NONE: Nothing is compressed.
*/

-- Here is an example of the COMPRESSION parameter being used.

expdp test/test schemas=TEST directory=TEST_DIR dumpfile=TEST.dmp logfile=expdpTEST.log

-- compression=all
-- The COMPATIBLE initialization parameter should be set to "11.0.0" or higher to use these options, except for the METADATA_ONLY option, 
-- which is available with a COMPATIBLE setting of "10.2".


-->> PARTITION_OPTIONS

-- The PARTITION_OPTIONS parameter determines how partitions will be handled during export and import operations. The syntax is shown below.
-- PARTITION_OPTIONS={none | departition | merge}

/* The allowable values are:

    * NONE: The partitions are created exactly as they were on the system the export was taken from.
    * DEPARTITION: Each partition and sub-partition is created as a separate table, named using a combination of the table and (sub-)partition name.
    * MERGE: Combines all partitions into a single table.

The NONE and MERGE options are not possible if the export was done using the TRANSPORTABLE parameter with a partition or subpartition filter. 
If there are any grants on objects being departitioned, an error message is generated and the objects are not loaded.
*/
    
-- export the partition options
expdp test/test directory=TEST_DIR  dumpfile=TEST.dmp  logfile=expdpTEST.log  tables=test.tab1  partition_options=merge
expdp test/test directory=TEST_DIR  dumpfile=TEST.dmp  logfile=expdpTEST.log  tables=test.tab1  partition_options=DEPARTITION
expdp test/test directory=TEST_DIR  dumpfile=TEST.dmp  logfile=expdpTEST.log  tables=test.tab1  partition_options=NONE


-- Take the export of muliple partition of the same table but exclude some objects
expdp / 
directory=dpump 
dumpfile=expdp_partition_table.dmp 
logfile=log_partition_table.log 
exclude=statistics,index,grant,object_grant,comment 
tables=('SNOX4TRANSNOX_CPASS."INFONOX_SERVICE_USAGE":SYS_P441', 'SNOX4TRANSNOX_CPASS."INFONOX_SERVICE_USAGE":SYS_P421')
REUSE_DUMPFILES=Y

expdp / 
directory=dpump 
dumpfile=expdp_partition_table.dmp 
logfile=log_partition_table.log 
exclude=statistics,index,grant,object_grant,comment 
tables=SNOX4TRANSNOX_CPASS.INFONOX_SERVICE_USAGE:SYS_P401,SNOX4TRANSNOX_CPASS.INFONOX_SERVICE_USAGE:SYS_P441 
REUSE_DUMPFILES=Y
 
-- import partition table in different non-partition table
impdp rchaudhari 
directory=dpump 
dumpfile=expdp_partition_table.dmp 
logfile=impdp_log_partition_table.log 
remap_schema=snox4transnox_cpass:rchaudhari 
remap_table=infonox_service_usage:infonox1 
partition_options=merge

--- Transending Archiving Example for export/import parition tables

-- Create all par file for future references..

#-- MERCHANTSCOUT_SCORES
directory=ORA11 
dumpfile=expdp_CAP1_MERCHANTSCOUT_SCORES_29Apr2014.dmp 
logfile=logs_expdp_CAP1_MERCHANTSCOUT_SCORES_29Apr2014.log 
exclude=STATISTICS,INDEX,GRANT,OBJECT_GRANT,COMMENT,REF_CONSTRAINT,CONSTRAINT 
TABLES=('TRANSCAPITALONE."MERCHANTSCOUT_SCORES":SYS_P1123','TRANSCAPITALONE."MERCHANTSCOUT_SCORES":SYS_P1183','TRANSCAPITALONE."MERCHANTSCOUT_SCORES":SYS_P1262') 
REUSE_DUMPFILES=Y 
COMPRESSION=ALL

#-- pre_set_transaction_state_log
directory=ORA11 
dumpfile=expdp_CAP1_PRE_SET_XTNS_STATE_LOG_29Apr2014.dmp 
logfile=logs_expdp_CAP1_PRE_SET_XTNS_STATE_LOG_29Apr2014.log 
exclude=STATISTICS,INDEX,GRANT,OBJECT_GRANT,COMMENT,REF_CONSTRAINT,CONSTRAINT 
TABLES=('TRANSCAPITALONE."PRE_SET_TRANSACTION_STATE_LOG":SYS_P1121','TRANSCAPITALONE."PRE_SET_TRANSACTION_STATE_LOG":SYS_P1181','TRANSCAPITALONE."PRE_SET_TRANSACTION_STATE_LOG":SYS_P1241') 
REUSE_DUMPFILES=Y 
COMPRESSION=ALL

#-- settlement_batch_history
directory=ORA11 
dumpfile=expdp_CAP1_SETTLEMENT_BATCH_HIST_29Apr2014.dmp 
logfile=logs_expdp_CAP1_SETTLEMENT_BATCH_HIST_29Apr2014.log 
exclude=STATISTICS,INDEX,GRANT,OBJECT_GRANT,COMMENT,REF_CONSTRAINT,CONSTRAINT 
TABLES=('TRANSCAPITALONE."SETTLEMENT_BATCH_HISTORY":SYS_P1122','TRANSCAPITALONE."SETTLEMENT_BATCH_HISTORY":SYS_P1182','TRANSCAPITALONE."SETTLEMENT_BATCH_HISTORY":SYS_P1261') 
REUSE_DUMPFILES=Y 
COMPRESSION=ALL

#-- transactions_merchantscout_det
directory=ORA11 
dumpfile=expdp_CAP1_XTNS_MERCSC_DET_29Apr2014.dmp 
logfile=logs_expdp_CAP1_XTNS_MERCSC_DET_29Apr2014.log 
exclude=STATISTICS,INDEX,GRANT,OBJECT_GRANT,COMMENT,REF_CONSTRAINT,CONSTRAINT 
TABLES=('TRANSCAPITALONE."TRANSACTIONS_MERCHANTSCOUT_DET":SYS_P1904','TRANSCAPITALONE."TRANSACTIONS_MERCHANTSCOUT_DET":SYS_P1905','TRANSCAPITALONE."TRANSACTIONS_MERCHANTSCOUT_DET":SYS_P1906') 
REUSE_DUMPFILES=Y 
COMPRESSION=ALL

#-- vital_daily_dt_hist
directory=ORA11 
dumpfile=expdp_CAP1_VITAL_DAILY_DT_HIST_29Apr2014.dmp 
logfile=logs_expdp_CAP1_VITAL_DAILY_DT_HIST_29Apr2014.log 
exclude=STATISTICS,INDEX,GRANT,OBJECT_GRANT,COMMENT,REF_CONSTRAINT,CONSTRAINT 
TABLES=('TRANSCAPITALONE."VITAL_DAILY_DT_HIST":SYS_P1141','TRANSCAPITALONE."VITAL_DAILY_DT_HIST":SYS_P1201','TRANSCAPITALONE."VITAL_DAILY_DT_HIST":SYS_P1281') 
REUSE_DUMPFILES=Y 
COMPRESSION=ALL

#-- vital_dt_extention_hist
directory=ORA11 
dumpfile=expdp_CAP1_VITAL_DT_EXTENTN_HIST_29Apr2014.dmp 
logfile=logs_expdp_CAP1_VITAL_DT_EXTENTN_HIST_29Apr2014.log 
exclude=STATISTICS,INDEX,GRANT,OBJECT_GRANT,COMMENT,REF_CONSTRAINT,CONSTRAINT 
TABLES=('TRANSCAPITALONE."VITAL_DT_EXTENTION_HIST":SYS_P1142','TRANSCAPITALONE."VITAL_DT_EXTENTION_HIST":SYS_P1202','TRANSCAPITALONE."VITAL_DT_EXTENTION_HIST":SYS_P1282') 
REUSE_DUMPFILES=Y 
COMPRESSION=ALL

#-- vital_transactions_hist
directory=ORA11 
dumpfile=expdp_CAP1_VITAL_XTNS_HIST_29Apr2014.dmp 
logfile=logs_expdp_CAP1_VITAL_XTNS_HIST_29Apr2014.log 
exclude=STATISTICS,INDEX,GRANT,OBJECT_GRANT,COMMENT,REF_CONSTRAINT,CONSTRAINT 
TABLES=('TRANSCAPITALONE."VITAL_TRANSACTIONS_HIST":SYS_P1161','TRANSCAPITALONE."VITAL_TRANSACTIONS_HIST":SYS_P1221','TRANSCAPITALONE."VITAL_TRANSACTIONS_HIST":SYS_P1301') 
REUSE_DUMPFILES=Y 
COMPRESSION=ALL

#-- xtn_upload_stats
directory=ORA11 
dumpfile=expdp_CAP1_XTN_UPLOAD_STATS_29Apr2014.dmp 
logfile=logs_expdp_CAP1_XTN_UPLOAD_STATS_29Apr2014.log 
exclude=STATISTICS,INDEX,GRANT,OBJECT_GRANT,COMMENT,REF_CONSTRAINT,CONSTRAINT 
TABLES=('TRANSCAPITALONE."XTN_UPLOAD_STATS":SYS_P1864','TRANSCAPITALONE."XTN_UPLOAD_STATS":SYS_P1865','TRANSCAPITALONE."XTN_UPLOAD_STATS":SYS_P1866') 
REUSE_DUMPFILES=Y 
COMPRESSION=ALL



-- import partition table in different non-partition table
impdp rchaudhari directory=ORADATA10 
dumpfile=expdp_CAP1_MERCHANTSCOUT_SCORES_13OCT2013.dmp 
logfile=logs_impdp_CAP1_MERCHANTSCOUT_SCORES_13OCT2013.log  
remap_table=MERCHANTSCOUT_SCORES:MERCHANTSCOUT_SCORES_13OCT2013 

-->> REUSE_DUMPFILES

-- The REUSE_DUMPFILES parameter can be used to prevent errors being issued if the export attempts to write to a dump file that already exists.
-- REUSE_DUMPFILES={Y | N}

-- When set to "Y", any existing dumpfiles will be overwritten. When the default values of "N" is used, an error is issued if the dump file already exists.

expdp test/test schemas=TEST directory=TEST_DIR dumpfile=TEST.dmp logfile=expdpTEST.log reuse_dumpfiles=y



-->> REMAP_TABLE

-- This parameter allows a table to be renamed during the import operations performed using the TRANSPORTABLE method. It can also be used to
-- alter the base table name used during PARTITION_OPTIONS imports. The syntax is shown below.

-- REMAP_TABLE=[schema.]old_tablename[.partition]:new_tablename

-- An example is shown below.

impdp test/test tables=TAB1 directory=TEST_DIR dumpfile=TEST.dmp logfile=impdpTEST.log remap_table=TEST.TAB1:TAB2

-- Existing tables are not renamed, only tables created by the import.


-->> DATA_OPTIONS

--SKIP_CONSTRAINT_ERRORS

-- During import operations using the external table acces method, setting the DATA_OPTIONS parameter to SKIP_CONSTRAINT_ERRORS allows 
-- load operations to continue through non-deferred constraint violations, with any violations logged for future reference. Without this, 
-- the default action would be to roll back the whole operation. The syntax is shown below.

-- DATA_OPTIONS=SKIP_CONSTRAINT_ERRORS

-- An example is shown below.
impdp test/test tables=TAB1 directory=TEST_DIR dumpfile=TEST.dmp logfile=impdpTEST.log data_options=SKIP_CONSTRAINT_ERRORS

/* This parameter has no impact on deferred constraints, which still cause the operation to be rolled back once a violation is detected. 
If the object being loaded has existing unique indexes or constraints, the APPEND hint will not be used, which may adversely affect performance.
XML_CLOBS
During an export, if XMLTYPE columns are currently stored as CLOBs, they will automatically be exported as uncompressed CLOBs. If on 
the other hand they are currently stored as any combination of object-relational, binary or CLOB formats, they will be exported in 
compressed format by default. Setting the DATA_OPTIONS parameter to XML_CLOBS specifies that all XMLTYPE columns should be exported as 
uncompressed CLOBs, regardless of the default action. The syntax is shown below.
*/

-- DATA_OPTIONS=XML_CLOBS

-- An example is shown below.
expdp test/test tables=TAB1 directory=TEST_DIR dumpfile=TEST.dmp logfile=expdpTEST.log version=11.1 data_options=xml_clobs

-- Both the export and import must use the same XML schema and the job version must be set to 11.0.0 or higher.


-->> REMAP_DATA

-- During export and import operations, the REMAP_DATA parameter allows you to associate a remap packaged function that will accept the 
-- column value as a parameter and return a modified version of the data. The syntax is shown below.

-- REMAP_DATA=[schema.]tablename.column_name:[schema.]pkg.function

-- This can be used to mask sensitive data during export and import operations by replacing the original data with random alternatives. 
-- The mapping is done on a column-by-column basis, as shown below.

expdp test/test 
tables=TAB1 
directory=TEST_DIR 
dumpfile=TEST.dmp 
logfile=expdpTEST.log 
remap_data:tab1.col1:remap_pkg.remap_col1 
remap_data:tab1.col2:remap_pkg.remap_col2

-- The remapping function must return the same datatype as the source column and it must not perform a commit or rollback.

--Export Only users with their grants..
Expdp system directory=dpump dumpfile=exp_tsys_employee.dmp logfile=exp_tsys_employee.log include=users,grant schemas=<user list to export>


-->> CONTENT

-- Below e.g. takes the Structural export dump only and not the data from the tables
expdp rahulc@aqprod 
directory=expdp_dir 
dumpfile=exp_bkups_of_gcaSchemas_4_ICP.dmp 
logfile=exp_bkups_of_gcaSchemas_4_ICP.log 
exclude=statistics 
schemas=transnox_gca,snox4transnox_gca,tnoxgca_91x_20101p,snoxgca_91x_20101p,tnoxgca59,snoxgca59 
content=metadata_only 
compression=all


--export the schemas including all objects but not tables objects
expdp rahulc@tempe_parallel 
directory=ora4 
dumpfile=exp_transmoneris_str_bkups.dmp 
logfile=exp_transmoneris_str_bkups.log 
include=function,index,index_partition,materialized_view,package,package_body,procedure,sequence,synonym,trigger,type,view 
schemas=transmoneris


-- Take the Export of Tables and Import them in different schema of other DB
expdp rchaudhari@tempe_22 
directory=dpump 
dumpfile=expdp_load_Details.dmp 
logfile=expdp_load_Details.log 
exclude=statistics,grants 
tables=tnoxgca_91x_20103n4.LOAD_DETAILS


-- Import command which import the table from x schema to Y schema’s table, if the table exists in Y schema then use the option 
-- TABLE_EXISTS_ACTION={SKIP,APPEND,REPLACE,TRUNCATE} to import in same tables it’s like ignore=y from normal export/import command
/*

table_exists_action=skip:  This says to ignore the data in the import file and leave the existing 
			table untouched.  This is the default and it is not a valid argument if you set 
			content=data_only.

table_exists_action=append:  This says to append the export data onto the existing table, leaving 
			the existing rows and adding the new rows from the dmp file.  Of course, the number 
			and types of the data columns must match to use the append option.  Just like the 
			append hint, Oracle will not re-user any space on the freelists and the high-water 
			mark for the table will be raised to accommodate the incoming rows.

table_exists_action=truncate:  This says to truncate the existing table rows, leaving the table 
			definition and replacing the rows from the expdp dmp file being imported.  To use this 
			option you must not have any referential integrity (constraints) on the target table.  
			You use the table_exists_action=truncate when the existing table columns match the 
			import table columns.  The truncate option cannot be used over a db link or with a 
			cluster table.

table_exists_action=replace:  This says to delete the whole table and replace both the table 
			definition and rows from the import dmp file.  To use this option you must not have any 
			referential integrity (constraints) on the target table.  You use the 
			table_exists_action=replace when the existing table columns do not match the import table 
			columns.

*/

impdp rchaudhari 
dumpfile=ld_3n4.dmp 
directory=dpump 
logfile=impdp_ld_3n4.log 
tables=load_details 
remap_schema=tnoxgca_91x_20103n4:TNOXGCA_91X_20103 
TABLE_EXISTS_ACTION=append


-- Export of multiple schemas and import only one table from one schema.
expdp / 
directory=ora3 
dumpfile=expdp_QCPW_15Nov2011_QCPWDB62.dmp 
logfile=expdp_QCPW_15Nov2011_QCPWDB62.log 
schemas=acm,checkcash,qcp,qcredit,wumt 
exclude=statistics,table:" like 'SC_TEMP%'",table:" like 'SN_TEMP%'" 
compression=all
 

impdp / directory=qcp62_ora3 
dumpfile=expdp_QCPW_15Nov2011_QCPWDB62.dmp 
logfile=impdp_expdp_QCPW_15Nov2011_QCPWDB62.log  
tables=QCREDIT.RELEASE_HISTORY 
remap_schema=QCREDIT:rchaudhari


-- table the export of the table 
expdp rahulc directory=ora4 dumpfile=expdp_CUSTOMER_FINGUREPRINT.dmp logfile=expdp_CUSTOMER_FINGUREPRINT.log tables=qcp.CUSTOMER_FINGERPRINTS data_options=xml_clobs exclude=statistics,index,ref_constraint,constraint,grant,object_grant,trigger compression=all
 
-- truncate the table and then import it
impdp rchaudhari directory=ORADATA2 dumpfile=expdp_CUSTOMER_FINGUREPRINT.dmp logfile=logs_expdp_telecheck_sign.log TABLE_EXISTS_ACTION=truncate content=data_only

expdp rahulc directory=ora4 dumpfile=expdp_data1.dmp logfile=expdp_data1.log tables=qcp.customer_signatures data_options=XML_CLOBS exclude=statistics,index,ref_constraint,constraint,grant,object_grant,trigger compression=all content=data_only

impdp rchaudhari directory=ORADATA2 dumpfile=expdp_data1.dmp logfile=logs_expdp_data1.log TABLE_EXISTS_ACTION=truncate content=data_only

expdp rahulc directory=ora4 dumpfile=expdp_data2.dmp logfile=expdp_data12.log tables=checkcash.limit_enrollment_response data_options=XML_CLOBS exclude=statistics,index,ref_constraint,constraint,grant,object_grant,trigger compression=all content=data_only

impdp rchaudhari directory=ORADATA2 dumpfile=expdp_data2.dmp logfile=logs_expdp_data2.log TABLE_EXISTS_ACTION=truncate content=data_only



expdp rahulc directory=ORA10 dumpfile=expdp_data4.dmp logfile=expdp_data124.log tables=snox4transnox_oneview.snox_user_access data_options=XML_CLOBS exclude=statistics,index,ref_constraint,constraint,grant,object_grant,trigger compression=all content=data_only




---- tablespace level export
expdp bert/bert directory=data_pump_dir dumpfile=multi_tablespace.dmp tablespaces=users,sysaux


-- Network_Link import example.
-- DB link on importing DB server should be present, like here txnDCW1 is DBLink which is created on txnDCE1 - importing DB server
impdp rchaudhari directory=bkup NETWORK_LINK=txnDCW1 flashback_scn=2096060466 logfile=impdp_NTlink_txnDCW1_txnDCE1.log schemas=transnox_cpass,snox4transnox_cpass,webfort exclude=table:\"like \'SN_TEMP%\'\",statistics


-- Creating New vbs for TransIT DB
expdp rchaudhari directory=bkup dumpfile=expdp_new_vbs_08Mar2015_release.dmp logfile=expdp_new_vbs_08Mar2015_release.log schemas=TRANSIT_GATEWAY_SNOX_316,TRANSIT_GATEWAY_TNOX_316,TRANSIT_FE_SNOX_316,TRANSIT_FE_TNOX_316,TRANSIT_SMSNOX_SNOX_315,TRANSIT_SMSNOX_TNOX_315 exclude=TABLE:\"LIKE \'SN_TEMP%\'\", TABLE:\"LIKE \'SC_TEMP%\'\"


-- export the selected transactionids
expdp rchaudhari directory=BKUPS dumpfile=expdp_cust_sign.dmp logfile=expdp_cust_sign_log.log tables=qcp.CUSTOMER_SIGNATURES query=\"where transactionid IN \(\'300283\',\'897098\',\'992043\',\'1559588\',\'1774103\',\'2050258\',\'2936041\',\'3219944\',\'3243896\',\'4650705\',\'6844593\',\'7301975\',\'8749677\',\'8860928\',\'9009792\',\'9598699\',\'9600281\',\'9614545\',\'9616078\',\'9616889\',\'9866422\',\'9871298\',\'9877193\',\'9994409\',\'10262644\',\'10459858\',\'10476630\',\'10586635\',\'10656846\',\'10698516\',\'10749517\',\'10839025\',\'10898043\',\'10899594\',\'10959197\',\'10996111\',\'11176047\',\'11180216\',\'11561230\',\'11561653\',\'11710481\',\'11711240\',\'11711503\',\'11720150\',\'11735567\',\'11862460\',\'12008756\',\'12181719\',\'12189951\',\'12204386\',\'12247412\',\'12256532\',\'12271466\',\'12359546\',\'12386062\',\'12403906\',\'12446770\',\'12491288\',\'12524752\',\'12531560\',\'12564861\',\'12593246\',\'12662850\',\'12678807\',\'12703048\',\'12704055\',\'12709764\',\'12853403\',\'12899304\',\'13049878\',\'13113885\',\'13156073\',\'13170434\',\'13229310\',\'13229829\',\'13264966\',\'13456260\',\'13497928\',\'13500596\',\'13607573\',\'13611337\',\'13615656\',\'13617238\',\'13654372\',\'13761565\',\'13804760\',\'13966105\',\'13966684\',\'13978932\',\'14038170\',\'14070698\',\'14088254\',\'14163381\',\'14386857\',\'14391784\',\'14415779\',\'14428247\',\'14445144\',\'14524988\',\'14567446\',\'14741092\',\'14742041\',\'14783898\',\'14836642\',\'15067498\',\'15069144\',\'15498121\',\'15511487\',\'15548910\',\'15738936\',\'15758209\',\'15922900\',\'16010971\',\'16183385\',\'16221152\',\'16239806\',\'16393081\',\'16460913\',\'16527979\',\'16706587\',\'16708070\',\'16851685\',\'26088799\',\'26176656\',\'26647712\',\'26685105\',\'26944534\',\'27213326\',\'27285890\',\'27355083\',\'28560280\',\'29787471\',\'30220346\',\'30561392\',\'30687462\',\'30892171\',\'31081923\',\'31631615\',\'31770551\',\'33620693\',\'34583124\',\'35255025\',\'36103919\',\'36115290\',\'36585697\',\'36598726\',\'36719386\',\'36867014\',\'36871367\',\'36993684\',\'37074443\',\'141131630\',\'141214627\',\'141409955\',\'141799970\',\'142205236\',\'142326889\',\'142717163\',\'142829582\',\'142910341\',\'142912869\',\'143523932\',\'244936277\',\'245723906\',\'246069808\',\'4246958309\',\'4249345343\',\'4249946376\',\'4249950653\',\'4250021670\',\'4251891814\',\'4650082513\',\'4650152451\',\'4650674263\',\'4650792157\',\'4652483637\',\'4652661852\',\'4654121823\',\'4654181853\',\'4654816056\',\'4654985300\',\'4654999563\',\'4674910640\',\'4676610187\',\'4677086298\',\'4677473048\',\'4677555363\',\'4677805338\',\'4678664930\',\'4678708530\',\'4679436832\',\'4679739818\',\'4680414319\',\'4680656767\',\'4682502633\',\'4683244716\',\'4894337781\',\'4894740527\',\'4895250424\',\'4895684789\',\'4895883301\',\'4896702787\',\'4897229133\',\'4898660869\',\'4900690561\',\'4901060429\',\'4902204274\',\'4903965767\',\'4906622013\',\'6930350138\',\'6931136626\',\'6938714706\',\'6943186734\',\'6949673341\',\'6952281654\'\)\"


expdp rchaudhari@rptdce directory=bkups dumpfile=try_merging_ptables.dmp logfile=try_merging_ptables.log tables=transnox_cpass.TRANS_ADDITIONAL_INFO exclude=index,constraint,REF_CONSTRAINT


-- Take only user's (schemas only) backups
expdp rchaudhari directory=bkup dumpfile=expdp_tsysusers.dmp logfile=expdp_tsysusers.log schemas=adutta,bkupdata,bsager,buchhold,dbaudit,dcurrier,djoshi,dmuley,gpipatanangkura,hyadav,jdecker,jlayani,jpatel,ksingh,leblance,maheshchadare,mbadhe,mchauhan,monideeparoy,nitesha,nmohanty,pgupta,pong,ppadmanabhan,rgadewar,rhalverson,rkanti,romanwar,rraghav,rshiwalkar,rtuscher,sagrawal,sbhamare,schemadiff,sduggirala,sgadewar,sgayam,sgurav,skamble,skumar,skumbhare,ssuryavanshi,uachanta,vchanda,zhongchy include=user,role_grant,grant,object_grant reuse_dumpfiles=y

-- Exlcude one table from the schema backup
expdp rchaudhari directory=ora11 dumpfile=expdp_app_mer_documents_16Feb2016.dmp logfile=impdp_expdp_app_mer_docs_16Feb2016.log schemas=transsigue compression=all exclude=statistics,table:\"=\'APP_MER_DOCUMENTS\'\"

-----------------------------------------------------------------------------------------------------------------

-- running in background
nohup expdp \'/as sysdba\' DUMPFILE=ags_backup_25Mar2017.dmp LOGFILE=ags_backup_25Mar2017.log directory=DATA_PUMP_DIR schemas=AGS &

nohup expdp \'/as sysdba\' directory=DATA_PUMP_DIR dumpfile=expdp_TASK000212689_grower_idea_fsp_28Jun2017.dmp logfile=expdp_TASK000212689_grower_idea_fsp_28Jun2017.log schemas=GROWER_IDEA &

nohup expdp \'/as sysdba\' directory=expdp_mipp dumpfile=expdp_mipp_mip_prod_25Jul2017_%U.dmp logfile=logfile_expdp_mippp_mip_prod_25Jul2017.log filesize=4g parallel=4 schemas=MIP_PROD


nohup expdp \'/as sysdba\' directory=REFRESH_DIR dumpfile=expdp_privs_missing_31May2018.dmp logfile=expdp_privs_missing_31May2018_logs.log include=role_grant,grant,synonym

nohup impdp \"/as sysdba\" directory=DATA_PUMP_DIR dumpfile=expdp_WO0000001561465_valcap_podvcp_%U.dmp logfile=impdp_WO0000001561465_valcap_podvct.log remap_schema=VALUE_CAPTURE:ITS_SCHEMA parallel=5 table_exists_action=replace &


-- par file contents
userid="/ as sysdba" 
schemas=VALUE_CAPTURE 
directory=DATA_PUMP_DIR 
dumpfile=VALUE_CAPTURE_PODVCP_210418_%U.dmp 
logfile=VALUE_CAPTURE_PODVCP_210418.log 
job_name=VALUE_CAP_EXP 
exclude=table:"IN('FILE_CONTENT','FILE_REPOSITORY','INTEG_IMP_LOG_DETAILS','ITS_USER','ITS_USER_TO_CROP','ITS_USER_TO_COMPANY','ITS_USER_TO_PROFILE','PROFILE','FEATURE','FEATURE_ACTION')" 
parallel=8 

-- same as above command, but using command line
nohup impdp \"/as sysdba\" directory=DATA_PUMP_DIR dumpfile=VALUE_CAPTURE_PODVCP_210418_%U.dmp logfile=impdp_value_capture_podvcP_to_podvcQ_210418_log.log schemas=VALUE_CAPTURE job_name=VALUE_CAP_imp table_exists_action=replace parallel=8 &

==================================================================
-- run the above sql query to check the job name and table name

expdp \'/as sysdba\' attach=SYS_EXPORT_SCHEMA_04


exp userid=dba_batch file=TASK000132954_MPM_USMGENP_02May2017.dmp log=TASK000132954_MPM_USMGENP_02May2017.log owner=mpm statistics=none
===================================================================

--- if you have a .gz dump file and you do not have the free space in server
--- then you can directly start import like below
mknod imp_pipe.dmp p
nohup gunzip -c < PCTRAR_DBEXPORT_201809140400.dmp.gz > imp_pipe.dmp  &  
nohup imp userid=\'/ as sysdba\' fromuser=PCSYSTEM touser=PCSYSTEM file=imp_pipe.dmp log=imp_pctrar_pcsystem_15NOV2018.log buffer=999999999 commit=y resumable=y analyze=n & 

or 

nohup impdp userid=\'/ as sysdba\' directory=impdp schemas=PCSYSTEM dumpfile=imp_pipe.dmp logfile=imp_pctrar_pcsystem_15NOV2018.log -- check this paramerts buffer=999999999 commit=y resumable=y analyze=n & 

<end node> 5P9i0s8y19Z
dt=Text
<node>
exp imp Monitor
3
--- Below Queries will help to know the precentage completion of export/import
SELECT x.job_name,b.state,b.job_mode,b.DEGREE
, x.owner_name,z.sql_text, P.message
, P.totalwork, P.sofar
, ROUND((P.sofar/P.totalwork)*100,2) done
, P.time_remaining
FROM dba_datapump_jobs b
LEFT JOIN dba_datapump_sessions x ON (x.job_name = b.job_name)
LEFT JOIN v$session y ON (y.saddr = x.saddr)
LEFT JOIN v$sql z ON (y.sql_id = z.sql_id)
LEFT JOIN v$session_longops P ON (P.sql_id = y.sql_id)
WHERE y.module='Data Pump Worker'
AND P.time_remaining > 0; 

SELECT ROUND(sofar/totalwork*100,2)  percent_completed, 
     v$session_longops.* 
FROM v$session_longops 
WHERE sofar <> totalwork 
ORDER BY target, SID;
------------------------------------------------------------------------------------------

--- Expdp/Impdp monitoring
select SID,username,OPNAME,SOFAR,TOTALWORK,SOFAR/TOTALWORK*100 "Work Done %",
	to_char(START_TIME,'mm/dd/yyyy hh24:mi:ss') "start_time",
	to_char(sysdate + TIME_REMAINING/3600/24,'mm/dd/yyyy hh24:mi:ss') "End_at",
	to_char(sysdate,'mm/dd/yyyy hh24:mi:ss')Date_Now
from v$session_longops
where sofar!=TOTALWORK 
  and totalwork!=0

-- what is running in expdp/impdp
SELECT 
	 SUBSTR(sql_text,INSTR(sql_text,'INTO "'),30) table_name,
	 rows_processed,
	 ROUND((sysdate-to_date(first_load_time,'yyyy-mm-dd hh24:mi:ss'))*24*60,1) minutes,
	 TRUNC(rows_processed/((sysdate-to_date(first_load_time,'yyyy-mm-dd hh24:mi:ss'))*24*60)) rows_per_min
FROM   sys.v_$sqlarea
WHERE  sql_text LIKE 'INSERT %INTO "%'
	   AND  command_type = 2
	   AND  open_versions > 0;


select substr(sql_text,instr(sql_text,'INTO "'),30) table_name,
         rows_processed,
         round((sysdate-to_date(first_load_time,'yyyy-mm-dd hh24:mi:ss'))*24*60,1) minutes,
         trunc(rows_processed/((sysdate-to_date(first_load_time,'yyyy-mm-dd hh24:mi:ss'))*24*60)) rows_per_min
  from   sys.v_$sqlarea
  where  sql_text like 'INSERT %INTO "%'
    and  command_type = 2
    and  open_versions > 0;

<end node> 5P9i0s8y19Z
dt=Text
<node>
sqlcli command prompt
2
set SQLPATH=U:\sqlcl\bin

<end node> 5P9i0s8y19Z
dt=Text
<node>
bridge command
3
-- 8. BRIDGE:
-- BRIDGE command works like a database link. i.e we can move data between databases without
-- creating the database link. And also it supports LONG columns.

--- Creating a table NEW_TAB in local database from remote database (172.30.224.176:1540/D2RRESO)
SQL> BRIDGE NEW_TAB as "jdbc:Oracle:thin:SYSTEM/ORACLE@172.30.224.176:1540/D2RRESO"(select * from siebel.s_user);

Created table NEW_TAB and inserted 1,798 rows

-- For insert also:
SQL> BRIDGE INSERT INTO TEST_TAB2 as "jdbc:Oracle:thin:SYSTEM/ORACLE@172.30.224.176:1540/D2RRESO"(select * from siebel.s_user);

Created table INSERT INTO NEW_TAB and inserted 1,798 rows 


bridge insert into collqr.user_profile_info as "jdbc:Oracle:thin:SYSTEM/ORACLE@collqnr"(Select * from 


BRIDGE department_new as "jdbc:oracle:thin:SYSTEM/ORACLE@172.33.242.33:1540/employees"(select * from department_new);
BRIDGE INSERT INTO department_new as "jdbc:oracle:thin:SYSTEM/ORACLE@172.33.242.33:1540/employees"(select * from department_new);



BRIDGE apers.aper_ent_agency_wip as "jdbc:Oracle:thin:cae0748@mrlnete-scan.cna.com:1521/merwh2c"(select * from w94bat.aper_ent_agency_wip);

<end node> 5P9i0s8y19Z
dt=Text
<node>
login.sql
3
set sqlformat ansiconsole
--set lines 320 pages 1000

--set _JAVA_OPTIONS="-Xmx512M"
set statusbar on
set statusbar default editmode dbid cursor

set highlighting on
set highlighting keyword foreground blue
set highlighting identifier foreground magenta
set highlighting string foreground red
set highlighting number foreground cyan
set highlighting comment background white
set highlighting comment foreground black 
SET HIGHLIGHTING DEFAULT BOLD ON

set errorlogging on

alias sofar_sql=select sl.inst_id, sl.sid, sl.serial#, sl.username, sl.opname, sl.target,
       sl.sql_id, ROUND(sl.sofar/sl.totalwork * 100)||'%' WorkDone,
       to_char(sl.start_time,'mm/dd/yyyy hh24:mi:ss')start_time,
       to_char(sysdate + TIME_REMAINING/3600/24,'mm/dd/yyyy hh24:mi:ss') End_At,
       dbms_xplan.format_time_S(time_remaining) Time_Remaining,
       s.module, sl.message,
       (select substr(sql_text,1,70) from gv$sqlarea sa where s.sql_id = sa.sql_id and sa.inst_id=s.inst_id)sql_query
from gv$session_longops sl, gv$session s
where sl.sid = s.sid
  and sl.serial# = s.serial#
  and sl.sql_id=s.sql_id
  and sl.sofar <> 0 and sl.totalwork <> 0
  and ROUND(sl.sofar/sl.totalwork * 100, 2) <>100
  and sl.sql_id like :sql_id
order by sl.username,sl.opname asc;

alias locks2=col username for a20
col owner for a20
col osuser for a15
col machine for a30
col module for a30
col object_name heading "Object|Name" for a20
col object_type heading "Object|Type" for a10
SELECT unique s.inst_id,s.SID SID,p.spid,s.SERIAL# SERIAL,Oracle_Username Username, owner,
        Object_Name, Object_Type, s.osuser, s.sql_id, S.MACHINE,s.module,
        DECODE(l.BLOCK, 0, 'Not Blocking', 1, 'Blocking', 2, 'Global') STATUS,
        DECODE(v.locked_mode, 0, 'None', 1, 'Null', 2, 'Row-S (SS)', 3, 'Row-X (SX)', 4, 'Share', 5, 'S/Row-X (SSX)', 6, 'Exclusive', TO_CHAR(lmode) ) MODE_HELD
        ,'alter system kill session ' || ''''|| s.sid || ',' || s.serial# || ',@'||s.inst_id ||''' immediate;'  "Kill_Command"
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s, gv$process p
WHERE v.object_id = d.object_id
  AND (v.object_id = l.id1)
  AND v.session_id = s.SID
  and s.paddr = p.addr
  and (d.owner <>'SYS' or s.type <> 'BACKGROUND')
  and s.sid like :sid
ORDER BY s.sid asc, Oracle_Username asc;

alias locks=col username for a20
col owner for a20
col osuser for a15
col machine for a30
col module for a30
col object_name heading "Object|Name" for a20
col object_type heading "Object|Type" for a10
SELECT unique s.inst_id,s.SID SID,p.spid,s.SERIAL# SERIAL,Oracle_Username Username, owner,  
        Object_Name, Object_Type, s.osuser, s.sql_id, S.MACHINE,s.module,
        DECODE(l.BLOCK, 0, 'Not Blocking', 1, 'Blocking', 2, 'Global') STATUS,
        DECODE(v.locked_mode, 0, 'None', 1, 'Null', 2, 'Row-S (SS)', 3, 'Row-X (SX)', 4, 'Share', 5, 'S/Row-X (SSX)', 6, 'Exclusive', TO_CHAR(lmode) ) MODE_HELD
        ,'alter system kill session ' || ''''|| s.sid || ',' || s.serial# || ',@'||s.inst_id ||''' immediate;'  "Kill_Command"
FROM gv$locked_object v, dba_objects d, gv$lock l, gv$session s, gv$process p
WHERE v.object_id = d.object_id
  AND (v.object_id = l.id1)
  AND v.session_id = s.SID
  and s.paddr = p.addr
  and (d.owner <>'SYS' or s.type <> 'BACKGROUND')
ORDER BY s.sid asc, Oracle_Username asc;

alias dbstatus=select name, open_mode from v$database;

alias inst_info=col HOST_NAME for a25
select inst_id, instance_name, host_name, 
	 to_char(startup_time, 'mm/dd/yyyy hh24:mi:ss') "Startup time" 
from gv$instance;

alias tbls=SELECT Tablespace_Name, "Allocated (MB)", "Free (MB)", "Used (MB)", "% Free", "% Used", "Max. Bytes (MB)" 
FROM(
select  a.tablespace_name Tablespace_Name,
       round(a.bytes_alloc / 1024 / 1024) "Allocated (MB)",
       round(nvl(b.bytes_free, 0) / 1024 / 1024) "Free (MB)",
       round((a.bytes_alloc - nvl(b.bytes_free, 0)) / 1024 / 1024) "Used (MB)",
       round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
       100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Used",
       round(maxbytes/1024 / 1024) "Max. Bytes (MB)"
from  ( select  f.tablespace_name,
               sum(f.bytes) bytes_alloc,
               sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
        from dba_data_files f
        group by tablespace_name) a,
      ( select  f.tablespace_name,
               sum(f.bytes)  bytes_free
        from dba_free_space f
        group by tablespace_name) b
where a.tablespace_name = b.tablespace_name (+)
union all
select h.tablespace_name,
       round(sum(h.bytes_free + h.bytes_used) / 1048576) megs_alloc,
       round(sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / 1048576) megs_free,
       round(sum(nvl(p.bytes_used, 0))/ 1048576) megs_used,
       round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) Pct_Free,
       100 - round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) pct_used,
       round(sum(f.maxbytes) / 1048576) max
from   sys.v_$TEMP_SPACE_HEADER h, sys.v_$Temp_extent_pool p, dba_temp_files f
where  p.file_id(+) = h.file_id
and    p.tablespace_name(+) = h.tablespace_name
and    f.file_id = h.file_id
and    f.tablespace_name = h.tablespace_name
group by h.tablespace_name
) 
order by 6 asc;

alias dbfile=select a.*, 'alter database  datafile '''||file_name||''' resize '||total_mb||'m;' alter_cmd
from 
(
	select df.tablespace_name Tablespace,
			df.totalspace Total_MB,
			totalusedspace Used_MB,
			(df.totalspace - tu.totalusedspace) Free_MB,
			round(100 * ( (df.totalspace - tu.totalusedspace)/ df.totalspace)) precent_free,
			file_name
	from
		(select file_name, tablespace_name, round(sum(bytes) / 1048576) TotalSpace
		 from dba_data_files 
		 group by tablespace_name, file_name) df,
		(select round(sum(bytes)/(1024*1024)) totalusedspace, tablespace_name
		 from dba_segments 
		 group by tablespace_name) tu
	where df.tablespace_name = tu.tablespace_name 
 ) a
 where Tablespace in upper(:tablespace_name);

alias dbfiles01= select file_name, tablespace_name, autoextensible, round(sum(BYTES/1024/1024/1024)) MAXSIZE
   from dba_data_files
  where tablespace_name in upper(:tablespace_name)
    group by file_name, tablespace_name, autoextensible;

alias spid=select s.inst_id, p.spid, s.sid, s.serial#, s.schemaname, s.machine, s.osuser,
  s.status
from gv$session s, gv$process p
where s.paddr = p.addr
  and s.sid=:spid;

alias users=select username, account_status, created from dba_users where username like upper(:username);

alias job_name=select jobname, nodeid, owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline 
from ctmuser.cms_jobdef 
where jobname like upper(:job_bame);

alias sofar=
select sl.inst_id, sl.sid, sl.serial#, sl.username, sl.opname, sl.target,
       sl.sql_id, ROUND(sl.sofar/sl.totalwork * 100)||'%' WorkDone,
       to_char(sl.start_time,'mm/dd/yyyy hh24:mi:ss')start_time,
       to_char(sysdate + TIME_REMAINING/3600/24,'mm/dd/yyyy hh24:mi:ss') End_At,
       dbms_xplan.format_time_S(time_remaining) Time_Remaining,
       s.module, sl.message, 
       (select substr(sql_text,1,70) from gv$sqlarea sa where s.sql_id = sa.sql_id and sa.inst_id=s.inst_id)sql_query
from gv$session_longops sl, gv$session s
where sl.sid = s.sid
  and sl.serial# = s.serial#
  and sl.sql_id=s.sql_id
  and sl.sofar <> 0 and sl.totalwork <> 0 
  and ROUND(sl.sofar/sl.totalwork * 100, 2) <>100
order by sl.username,sl.opname asc
;

alias sofar1=col username format a10
col OPNAME format a30
col SOFAR format 999999999
col 'WorkDone%' format 999.99
col Start_time format a20
col "End_At" for a20
select sl.inst_id, sl.sid, sl.serial#, sl.username, sl.opname,s.module,TOTALWORK, 
       ROUND(sl.sofar/sl.totalwork * 100, 2) "WorkDone%",    
       sl.target_desc, to_char(sl.start_time,'mm/dd/yyyy hh24:mi:ss')start_time,
       to_char(sl.last_update_time,'mm/dd/yyyy hh24:mi:ss')last_update_time,
       to_char(sysdate + TIME_REMAINING/3600/24,'DD-MON-YY hh24:mi:ss') "End_At",
       sl.message
from gv$session_longops sl, gv$session s
where sl.sid = s.sid
  and sl.serial# = s.serial#
  and sl.sofar <> 0 and sl.totalwork <> 0
order by sl.username asc, sl.start_time desc  
;

alias sofar2=col username format a10
col OPNAME format a30
col SOFAR format 999999999
col 'WorkDone%' format 999.99
col Start_time format a20
col "End_At" for a20
select inst_id, SID, username, OPNAME, SOFAR,
	TOTALWORK, SOFAR/TOTALWORK*100 "WorkDone%",
	to_char(START_TIME,'DD-MON-YY hh24:mi:ss') "start_time",
	to_char(sysdate + TIME_REMAINING/3600/24,'DD-MON-YY hh24:mi:ss') "End_At",message,
     sql_id
  from gv$session_longops
 where sofar!=TOTALWORK
   and totalwork!=0
 order by 1;

alias privs=
select sys_context('userenv','db_name')DB_name, af.type, af.grantee,
	af.privs, af.Admin_Opt, af.table_name, af.owner
from 
(
    select 
        'ROLE' Type, grantee grantee, granted_role privs, 
        admin_option Admin_Opt, '--' table_name, '--' owner
    from dba_role_privs
    --where grantee='MIS'
    union
    select 	
        'SYSTEM' Type, grantee grantee, privilege privs, 
        admin_option Admin_Opt, '--' table_name,'--' owner
    from dba_sys_privs
    --where grantee='MIS'
    union
    select 
        'TABLE' Type, grantee grantee, privilege privs, grantable Admin_Opt, 
        table_name table_name, owner owner
    from dba_tab_privs
    where table_name not like 'BIN$%'
    )af, dba_users du
where af.grantee = du.username
  and du.username like upper(:username)
order by 2;

set serveroutput on
alias nuser=begin
 dbms_utility.exec_ddl_statement
 (
	'CREATE USER '||:users ||' IDENTIFIED BY '||:password ||
	' DEFAULT TABLESPACE USERS TEMPORARY TABLESPACE TEMP PROFILE CPROFILE'
);
dbms_utility.exec_ddl_statement
 (
	'grant create session to '||:users
);
dbms_output.put_line('  USER = '||:users);
dbms_output.put_line(' PASSWORD = '||:password);
end;
/

alias insta=col HOST_NAME for a25
select inst_id, instance_name, host_name, status DB_status, 
	 to_char(startup_time, 'mm/dd/yyyy hh24:mi:ss') "Startup time" 
from gv$instance;

alias fd_obj=col owner for a30
col object_name for a30
select owner, object_name,object_type, status, to_char(created,'mm/dd/yyyy hh24:mi:ss')created
from dba_objects
where object_name like upper(:object_name);

alias privs_tabs=select grantee,owner,table_name,grantor,privilege
from dba_tab_privs
where table_name like upper(:table_name);

alias sql_id=SELECT * FROM TABLE (DBMS_XPLAN.DISPLAY_AWR (:sql));

alias job_dbinfo=select jobname, nodeid, owner, author, schedtab, wdaystr scheday, fromtime hour,descript,cmdline 
from ctmuser.cms_jobdef 
where regexp_like(jobname,upper(:dbname),'i');

set serveroutput on
alias duser=begin
 dbms_utility.exec_ddl_statement
 (
	'DROP USER '||:users ||';'
);
end;
/

alias access_obj=select a.object, a.type, b.inst_id, a.sid, b.serial#, b.sql_id, b.username, b.schemaname, 
	b.osuser, b.module, b.program, b.event
from gv$access a, gv$session b
where a.sid=b.sid
--  and b.schemaname='W94BAT'
  and a.object like upper(:object_name)
order by a.type asc;

alias access_usr=select a.object, a.type, b.inst_id, a.sid, b.serial#, b.sql_id, b.username, b.schemaname, 
	b.osuser, b.module, b.program, b.event
from gv$access a, gv$session b
where a.sid=b.sid
  and b.schemaname like upper(:object_owner)
order by a.type asc;

alias tbls_name=SELECT tablespace_name, allocated,Free_Space,Used_Space,"% Free", "% Used",MaxBytes
FROM(
select  a.tablespace_name tablespace_name,
       dbms_xplan.format_size(a.bytes_alloc) Allocated,
       dbms_xplan.format_size(nvl(b.bytes_free, 0)) Free_Space,
       dbms_xplan.format_size((a.bytes_alloc - nvl(b.bytes_free, 0))) Used_Space,
       dbms_xplan.format_size((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) "% Free",
       dbms_xplan.format_size(100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100)) "% Used",
       dbms_xplan.format_size(round(maxbytes)) MaxBytes       
from  ( select  f.tablespace_name,
               sum(f.bytes) bytes_alloc,
               sum(decode(f.autoextensible, 'YES',f.maxbytes,'NO', f.bytes)) maxbytes
        from dba_data_files f 
        group by tablespace_name) a,
      ( select  f.tablespace_name,
               sum(f.bytes) bytes_free
        from dba_free_space f
        group by tablespace_name) b
where a.tablespace_name = b.tablespace_name (+)
) 
where tablespace_name like upper(:tbls_name) 
ORDER BY 6 asc;

alias temps=SELECT Tablespace_Name, Aquired_Size "Aquired_Size", Free_Space "Free_Space", "Used", "% Free", "% Used", "Max. Bytes" 
FROM(
select h.tablespace_name Tablespace_Name,
       dbms_xplan.format_size((sum(h.bytes_free + h.bytes_used))) Aquired_Size,
       dbms_xplan.format_size((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)))) Free_Space,
       dbms_xplan.format_size((sum(nvl(p.bytes_used, 0)))) "Used",
       dbms_xplan.format_size(((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100)) "% Free",
       dbms_xplan.format_size(100 - ((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100)) "% Used",
       dbms_xplan.format_size((sum(f.maxbytes) )) "Max. Bytes"
from   sys.v_$TEMP_SPACE_HEADER h, sys.v_$Temp_extent_pool p, dba_temp_files f
where  p.file_id(+) = h.file_id
and    p.tablespace_name(+) = h.tablespace_name
and    f.file_id = h.file_id
and    f.tablespace_name = h.tablespace_name
group by h.tablespace_name
)
order by 6 asc;

alias sid=
select inst_id,sid,serial#,username,schemaname,status,sql_id
    osuser,machine,module,
    'alter system kill session ' || ''''|| s.sid || ',' || s.serial# || ',@'||s.inst_id ||''' immediate;'  "Kill_Command"
from gv$session s
where sid like :sid;

alias temp_usg=SELECT b.tablespace,
       dbms_xplan.format_size2(b.blocks*p.value) temp_size,
       ''''||a.sid||','||a.serial#||'@'||a.inst_id||'''' sid_Serial#_instaID,
       NVL(a.username, '(oracle)') AS username,
       a.program,
       a.status,
       a.sql_id
FROM   gv$session a,
       gv$sort_usage b,
       gv$parameter p
WHERE  p.name  = 'db_block_size'
AND    a.saddr = b.session_addr
AND    a.inst_id=b.inst_id
AND    a.inst_id=p.inst_id
ORDER BY b.tablespace, b.blocks
;

<end node> 5P9i0s8y19Z
dt=Text
<node>
URLs for DBAs to study
2
-- good URL's for study

--- MySQL date_Forma function link 
http://www.w3schools.com/sql/func_date_format.asp

-- Oracle version upgrade
http://onlineappsdba.com/index.php/2009/01/22/upgrade-oracle-database-10g-to-11g-r1-111x/

-- sql scripts
www.idevelopment.info/ 

-- shell scripts and all DBA scripts
http://dba-tips.blogspot.com/2014/02/oracle-database-administration-scripts.html


-- Hints for Optimization Approaches
http://www.oradev.com/hints.jsp

-- Configurating RMAN variables.
http://www.sc.ehu.es/siwebso/KZCC/Oracle_10g_Documentacion/server.101/b10734/rcmconfg.htm

-- export through the procedure
http://ergemp.blogspot.com/2008/02/scheduling-datapump-in-oracle-10g.html


http://www.dbazine.com/oracle/or-articles/still1 --- x ternal table


 http://books.google.co.in/books?id=14ZH0eZV6G8C&pg=PA231&lpg=PA231&dq=how+to+use+catupgrade.sql+in+oracle&source=bl&ots=brbd1N16Uz&sig=-2EYsmhfpEvgtHav6FM0G9_oUeA&hl=en&ei=SQipSavQDIm9kAW9ttjIDQ&sa=X&oi=book_result&resnum=6&ct=result#PPA131,M1 

-- example of converting rows into columns 
http://mennan.kagitkalem.com/ConvertingRowsToColumnsInOracle.aspx

-- for all undocumented init parameters
select ksppinm "Init_Param", ksppdesc "Description" 
from X$KSPPI
order by ksppinm asc

--index creation
http://www.psoug.org/reference/indexes.html#ixns

-- Good DBA query
http://www.shutdownabort.com

-- RMAN Site
http://www.tiplib.com/kb/25/1/rman


--main link
http://dotproject.infonox.com:5000/index.php?m=projects&a=view&project_id=75


-- Oracle 10g New Features: Flashback and RMAN
http://www.orafaq.com/node/31

-- use this sit for reference for RMAN
http://download.oracle.com/docs/cd/B28359_01/backup.111/b28270/rcmquick.htm


-- 10G RMAN Part 1 and part 2
http://www.dbazine.com/blogs/blog-cf/chrisfoot/10grmanpart1
http://www.dbazine.com/blogs/blog-cf/chrisfoot/10grmanpart2


--replication sites
http://www.akadia.com/services/ora_replication_guide.html -- good coding

-- Streams Replication
http://www.oracle.com/technology/books/pdfs/book_rep_chap6_ce2.pdf

--Advance replications
http://www.wisdomforce.com/dweb/resources/docs/advanced_replication.pdf 

-- Replication Step-by-Step
http://stanford.edu/dept/itss/docs/oracle/10g/server.101/b10728/repsimpd.htm


-- RMAN Help
http://ss64.com/ora/rman_list.html

http://www.ctoedge.com/content/how-backup-and-restore-oracle-database-without-rman

-- RMAN
http://www.idevelopment.info/data/Oracle/DBA_tips/RMAN_9i/RMAN9_50.shtml

-- rman script explanation step by step
http://www.idevelopment.info/data/DBA_tips/RMAN_9i/RMAN9_7.shtml


****************************************  URLs for study  **************************************** 

<end node> 5P9i0s8y19Z
dt=Text
<node>
Archive logs
2
--One way to calculate the total amount required for archive file space is by querying 
--the V$ARCHIVED_LOG view from within the source Oracle database. The 
--following query shows you how to do so: 

select trunc(COMPLETION_TIME), count(*)*100 size_in_MB
from v$archived_log
group by trunc(COMPLETION_TIME);

TRUNC(COM SIZE_IN_MB
--------- ----------
15-MAY-11 500


-- 2 ways to move archivelogs – both need RMAN
https://blog.dbi-services.com/2-ways-to-move-archivelogs-both-need-rman/

--
-- Display Archive Log Generation by Day
--
SET PAGESIZE 60
SET LINESIZE 300
SET VERIFY OFF
 
COL "Generation Date" FORMAT a20
 
SELECT TRUNC(completion_time)  "Generation Date" ,
   round(SUM(blocks*block_size)/1048576,0) "Total for the Day in MB"
FROM gv$archived_log
GROUP BY TRUNC(completion_time)
ORDER BY TRUNC(completion_time)
/

-- Archivelog generation on a daily basis:
select trunc(COMPLETION_TIME,'DD') Day, thread#, 
	round(sum(BLOCKS*BLOCK_SIZE)/1048576) MB,
	count(*) Archives_Generated 
  from v$archived_log
group by trunc(COMPLETION_TIME,'DD'),thread# 
order by 1;


-- Archive log generation on an hourly basis:
set pages 1000
select trunc(COMPLETION_TIME,'HH') Hour,thread# , 
	round(sum(BLOCKS*BLOCK_SIZE)/1048576) MB, count(*) Archives 
 from v$archived_log
group by trunc(COMPLETION_TIME,'HH'), thread#  
order by 1 ;

-- find the archivelog switches on an hourly basis that happened in the past one week 
col DAY for a15
col 00 for a10
col 01 for a10
col 02 for a10
col 03 for a10
col 04 for a10
col 05 for a10
col 06 for a10
col 07 for a10
col 08 for a10
col 09 for a10
col 10 for a10
col 11 for a10
col 12 for a10
col 13 for a10
col 14 for a10
col 15 for a10
col 16 for a10
col 17 for a10
col 18 for a10
col 19 for a10
col 20 for a10
col 21 for a10
col 22 for a10
col 23 for a10
col 24 for a10
SELECT to_date(first_time) DAY,
	to_char(sum(decode(to_char(first_time,'HH24'),'00',1,0)),'9999') "00",
	to_char(sum(decode(to_char(first_time,'HH24'),'01',1,0)),'9999') "01",
	to_char(sum(decode(to_char(first_time,'HH24'),'02',1,0)),'9999') "02",
	to_char(sum(decode(to_char(first_time,'HH24'),'03',1,0)),'9999') "03",
	to_char(sum(decode(to_char(first_time,'HH24'),'04',1,0)),'9999') "04",
	to_char(sum(decode(to_char(first_time,'HH24'),'05',1,0)),'9999') "05",
	to_char(sum(decode(to_char(first_time,'HH24'),'06',1,0)),'9999') "06",
	to_char(sum(decode(to_char(first_time,'HH24'),'07',1,0)),'9999') "07",
	to_char(sum(decode(to_char(first_time,'HH24'),'08',1,0)),'9999') "08",
	to_char(sum(decode(to_char(first_time,'HH24'),'09',1,0)),'9999') "09",
	to_char(sum(decode(to_char(first_time,'HH24'),'10',1,0)),'9999') "10",
	to_char(sum(decode(to_char(first_time,'HH24'),'11',1,0)),'9999') "11",
	to_char(sum(decode(to_char(first_time,'HH24'),'12',1,0)),'9999') "12",
	to_char(sum(decode(to_char(first_time,'HH24'),'13',1,0)),'9999') "13",
	to_char(sum(decode(to_char(first_time,'HH24'),'14',1,0)),'9999') "14",
	to_char(sum(decode(to_char(first_time,'HH24'),'15',1,0)),'9999') "15",
	to_char(sum(decode(to_char(first_time,'HH24'),'16',1,0)),'9999') "16",
	to_char(sum(decode(to_char(first_time,'HH24'),'17',1,0)),'9999') "17",
	to_char(sum(decode(to_char(first_time,'HH24'),'18',1,0)),'9999') "18",
	to_char(sum(decode(to_char(first_time,'HH24'),'19',1,0)),'9999') "19",
	to_char(sum(decode(to_char(first_time,'HH24'),'20',1,0)),'9999') "20",
	to_char(sum(decode(to_char(first_time,'HH24'),'21',1,0)),'9999') "21",
	to_char(sum(decode(to_char(first_time,'HH24'),'22',1,0)),'9999') "22",
	to_char(sum(decode(to_char(first_time,'HH24'),'23',1,0)),'9999') "23",
	to_char(sum(decode(to_char(first_time,'HH24'),'24',1,0)),'9999') "24"
from v$log_history
where to_date(first_time) > sysdate-1
GROUP by to_char(first_time,'YYYY-MON-DD'), to_date(first_time)
order by to_date(first_time)
/

-------------------------------------------------------------------------------------

-- Utilisation (MB) du FRA
set lines 100
col name format a60
 
select
   name,
  floor(space_limit / 1024 / 1024) "Size MB",
  ceil(space_used / 1024 / 1024) "Used MB"
from v$recovery_file_dest;
 
-- FRA Occupants
SELECT * FROM V$FLASH_RECOVERY_AREA_USAGE;
 
-- Location and size of the FRA
show parameter db_recovery_file_dest
 
-- Size, used, Reclaimable 
SELECT
  ROUND((A.SPACE_LIMIT / 1024 / 1024 / 1024), 2) AS FLASH_IN_GB, 
  ROUND((A.SPACE_USED / 1024 / 1024 / 1024), 2) AS FLASH_USED_IN_GB, 
  ROUND((A.SPACE_RECLAIMABLE / 1024 / 1024 / 1024), 2) AS FLASH_RECLAIMABLE_GB,
  SUM(B.PERCENT_SPACE_USED)  AS PERCENT_OF_SPACE_USED
FROM
  V$RECOVERY_FILE_DEST A,
  V$FLASH_RECOVERY_AREA_USAGE B
GROUP BY
  SPACE_LIMIT, 
  SPACE_USED , 
  SPACE_RECLAIMABLE ;
 
-- After that you can resize the FRA with:
-- ALTER SYSTEM SET db_recovery_file_dest_size=xxG;
 
-- Or change the FRA to a new location (new archives will be created to this new location):
-- ALTER SYSTEM SET DB_RECOVERY_FILE_DEST='/u....';
-------------------------------------------------------------------------------------


-- Daily
select trunc(COMPLETION_TIME,'DD') Day, thread#, 
round(sum(BLOCKS*BLOCK_SIZE)/1024/1024/1024) GB,
count(*) Archives_Generated from v$archived_log 
group by trunc(COMPLETION_TIME,'DD'),thread# order by 1;

-- Hourly
set pages 1000
alter session set nls_date_format = 'DD-MON-YYYY HH24:MI:SS';

select trunc(COMPLETION_TIME,'HH') Hour,thread# , 
round(sum(BLOCKS*BLOCK_SIZE)/1024/1024/1024) GB,
count(*) Archives from v$archived_log 
group by trunc(COMPLETION_TIME,'HH'),thread#  order by 1 ;

-- Daily Archive Log Generation :
select trunc(COMPLETION_TIME,'DD') Day, thread#, 
round(sum(BLOCKS*BLOCK_SIZE)/1024/1024/1024) GB,
count(*) Archives_Generated from v$archived_log 
group by trunc(COMPLETION_TIME,'DD'),thread# order by 1;

--- Hourly basis
select trunc(COMPLETION_TIME,'HH') Hour,thread# , 
round(sum(BLOCKS*BLOCK_SIZE)/1024/1024/1024) GB,
count(*) Archives from v$archived_log 
group by trunc(COMPLETION_TIME,'HH'),thread#  order by 1 ;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Archive to No-Archive Mode
2
Currently my database is in NOARCHIVELOG mode.  What would be 
the proper steps to switch to ARCHIVELOG mode?

 
 In order to switch to ARCHIVELOG mode from NOARCHIVELOG mode do the following:

 -- make the changes in init.ora / spfile with the following information
log_archive_dest='/u01/oradata/archlog' (for example)
log_archive_format='%t_%s.dbf' (for example)
log_archive_start=true


-- shutdown the datatabase in immediate mode
SQL> shutdown immediate;

-- startup mount
SQL> startup mount;


SQL>alter database archivelog;

-- below command check the database is in archivelog mode or noarchivelog mode
SQL>archive log list;

-- and then open the database in safe mode
SQL>alter database open;
-------------------------------------------------------------------------------------

---  Disable Archive Log Mode
sqlplus / as sysdba

SQL> archive log list;
SQL> shutdown immediate
SQL> startup mount
SQL> alter database noarchivelog;
SQL> alter database open;
SQL> archive log list;


--- convert archivelog mode to no archivelog mode into RAC systems
--login to instance
sqlplus "/as sysdba"

SQL> alter system set CLUSTER_DATABASE=FALSE scope=spfile; 
SQL> alter system set LOG_ARCHIVE_START= FALSE scope=spfile;  -- optional

srvctl stop database -d merdmr

. oraenv
MERDMR2
sqlplus "/as sysdba"

SQL> startup mount

SQL> alter database noarchivelog;

SQL> alter system set CLUSTER_DATABASE=TRUE scope=spfile; 

SQL> shutdown immediate;

srvctl start database -d merdmr

SQL> set lines 500 pages 500
SQL> col HOST_NAME for a25
select inst_id, instance_name, host_name,
         to_char(startup_time, 'mm/dd/yyyy hh24:mi:ss') "Startup time"
from gv$instance;
SQL>   2    3
   INST_ID INSTANCE_NAME    HOST_NAME                 Startup time
---------- ---------------- ------------------------- -------------------
         2 MERDMR2          mrlndrtdbadm04.cna.com    09/03/2019 07:53:08
         1 MERDMR1          mrlndrtdbadm03.cna.com    09/03/2019 07:53:07


-------------------------------------------------------------------------------------

---  Enable Archive Log Mode

sqlplus / as sysdba

SQL> archive log list

SQL> show parameter recovery_file_dest

SQL> alter system set log_archive_dest_1='LOCATION=+FRA2' scope = both;

OR for ASM location

SQL> alter system set log_archive_dest_1='LOCATION=/u02/app/oracle/oradata/orcl/arch' scope = both;

SQL> shutdown immediate

SQL> startup mount

SQL> alter database archivelog;

SQL> alter database open;

SQL> archive log list

<end node> 5P9i0s8y19Z
dt=Text
<node>
General Notes
2


-- set autotrace traceonly for tracing the sql queries in sql*plus
set autotrace traceonly

<end node> 5P9i0s8y19Z
dt=Text
<node>
Oracle Wallet
2
-- wallet creatification adding
https://oracle-base.com/articles/linux/create-self-signed-ssl-certificates
https://oracle-base.com/articles/misc/utl_http-and-ssl
https://docops.ca.com/ca-wla-ae-wcc/11-4-2/en/additional-resources/create-oracle-wallets-with-certificates

--- Adding certificated using orapki utility
orapki wallet create -wallet /u01/app/oracle/product/11.2.0/dbhome/wallet -pwd Monsanto$.1 -auto_login

orapki wallet display -wallet $ORACLE_HOME/wallet -pwd Monsanto$.1

orapki cert create -wallet $ORACLE_HOME/wallet -request "${ORACLE_HOME}/wallet/*.cer" -cert "${ORACLE_HOME}/wallet/*.cer" -validity 3650 -pwd Monsanto$.1 -auto_login

orapki wallet display -wallet ./ -pwd WalletPasswd123
  
orapki wallet add -wallet wallet_location -cert certificate_location -trusted_cert -auto_login_only  
orapki cert add -wallet $ORACLE_HOME/wallet -request "${ORACLE_HOME}/wallet/thawte Primary Root CA - G3.cer" -cert "${ORACLE_HOME}/wallet/thawte Primary Root CA - G3.cer" -validity 3650 -pwd Monsanto$.1
orapki cert add -wallet $ORACLE_HOME/wallet -request "${ORACLE_HOME}/wallet/thawte Primary Root CA - G3.cer" -cert "${ORACLE_HOME}/wallet/thawte Primary Root CA - G3.cer"
orapki wallet add -wallet $ORACLE_HOME/wallet -request "${ORACLE_HOME}/wallet/ thawte Primary Root CA.cer" -cert "${ORACLE_HOME}/wallet/ thawte Primary Root CA.cer" -validity 3650 -pwd Monsanto$.1
orapki wallet add -wallet $ORACLE_HOME/wallet -request "${ORACLE_HOME}/wallet/thawte Primary Root CA - G3.cer" -cert "${ORACLE_HOME}/wallet/thawte Primary Root CA - G3.cer" -validity 3650 -pwd Monsanto$.1
   
orapki wallet add -wallet $ORACLE_HOME/wallet -trusted_cert -cert "${ORACLE_HOME}/wallet/thawte Primary Root CA - G2.cer" -pwd Monsanto$.1
orapki wallet add -wallet $ORACLE_HOME/wallet -request "${ORACLE_HOME}/wallet/thawte Primary Root CA - G2.cer" -cert "${ORACLE_HOME}/wallet/thawte Primary Root CA - G2.cer" -validity 3650 -pwd Monsanto$.1
orapki wallet add -wallet $ORACLE_HOME/wallet -request "${ORACLE_HOME}/wallet/thawte Primary Root CA - G3.cer" -cert "${ORACLE_HOME}/wallet/thawte Primary Root CA - G3.cer" -validity 3650 -pwd Monsanto$.1
orapki wallet add -wallet $ORACLE_HOME/wallet -request "${ORACLE_HOME}/wallet/thawte Primary Root CA.cer" -cert "${ORACLE_HOME}/wallet/thawte Primary Root CA.cer" -validity 3650 -pwd Monsanto$.1



orapki wallet create -wallet /u01/app/oracle/product/11.2.0/dbhome_2/wallet -pwd Monsanto$.1 -auto_login

orapki wallet display -wallet $ORACLE_HOME/wallet -pwd Monsanto$.1

orapki wallet add -wallet $ORACLE_HOME/wallet -trusted_cert -cert "${ORACLE_HOME}/wallet/thawte Primary Root CA - G2.cer" -pwd Monsanto$.1
orapki wallet add -wallet $ORACLE_HOME/wallet -request "${ORACLE_HOME}/wallet/thawte Primary Root CA - G2.cer" -cert "${ORACLE_HOME}/wallet/thawte Primary Root CA - G2.cer" -validity 3650 -pwd Monsanto$.1


--- example to delete the certificates
--- copy the installed cert and then remove it
orapki wallet remove -wallet . -dn 'CN=www.cenduitsolutions.com,OU=Cenduit LLC,O=Cenduit LLC,L=Durham,ST=North Carolina,C=US,2.5.4.17=27703,STREET=4825 Creekstone Drive,STREET=Suite 400,SERIAL_NUM=4312751,1.3.6.1.4.1.311.60.2.1.2=Delaware,1.3.6.1.4.1.311.60.2.1.3=US,2.5.4.15=Private Organization' -trusted_cert -pwd "Welcome1"

<end node> 5P9i0s8y19Z
dt=Text
<node>
FlashBack recovery
2
-- This view indicates how much flashback log data is available for your database. 
SELECT OLDEST_FLASHBACK_SCN, OLDEST_FLASHBACK_TIME 
FROM V$FLASHBACK_DATABASE_LOG;


--A Separate Background Process For Writing Flashback Logs
-- RVWR (Recovery Writer, a.k.a Flashback Writer) was introduced in Oracle 10g to write 
-- flashback data from the Flashback Buffer in the SGA to the flashback database logs on disk.

-- This view indicates how much flashback log data is available for your database. 
SELECT OLDEST_FLASHBACK_SCN, OLDEST_FLASHBACK_TIME 
FROM V$FLASHBACK_DATABASE_LOG;

-- recyclebin to get the table name which was drop . 
SELECT OBJECT_NAME, ORIGINAL_NAME, TYPE
FROM USER_RECYCLEBIN
WHERE BASE_OBJECT = (SELECT BASE_OBJECT FROM USER_RECYCLEBIN
WHERE ORIGINAL_NAME = 'RECYCLETEST')
AND ORIGINAL_NAME != 'RECYCLETEST';


-- display the version of modified values of the columns in a table.
SELECT UNDO_SQL
FROM FLASHBACK_TRANSACTION_QUERY
WHERE XID = '05000C004AD10100';

select versions_starttime, versions_endtime, versions_xid,
versions_operation, APPLICATIONID, BUSINESS_STREET, BUSINESS_CITY, BUSINESS_STATE --column name to check the values
from transfastcap.temp versions between timestamp minvalue and maxvalue
order by VERSIONS_STARTTIME

--- put the versions_xid in hextoraw('') sreach condition and check the result.
-- it'll return all the DML statment which was execute for that versions_xid column
SELECT UNDO_SQL FROM FLASHBACK_TRANSACTION_QUERY WHERE XID = hextoraw('F0000800BB000000');


--- database will in flash time for 7 Hrs, for the session.
-- Once you logout the flash back will be disabled
EXEC dbms_flashback.enable_at_time(SYSTIMESTAMP - 3/24);

-- to disable the flashback mode
EXEC DBMS_FLASHBACK.DISABLE


select *
from agent_master
as of timestamp sysdate-2


--to purge the table
ALTER SESSION SET CURRENT_SCHEMA=transcapitalone;
PURGE TABLE transcapitalone."BIN$pnCDGt7Ts1bgQK8KGZY6yg==$0"; 


--- purge all the dropped objects which are present in recycle bin 
BEGIN
   FOR P IN (SELECT 'Purge table '||owner||'."'||object_name||'"' ptbl FROM sys.DBA_RECYCLEBIN)
   LOOP
      BEGIN
         EXECUTE IMMEDIATE P.ptbl;
      EXCEPTION
         WHEN OTHERS THEN NULL;
      END;
   END LOOP;
END;
/

--- Flash Back Query

-- Oracle Flashback Query can only be used if the server is configured to use Automatic 
-- Undo Management, rather than traditional rollback segments. The maximum time period 
-- that can be flashbacked to is defined using the UNDO_RETENTION parameter in the 
-- init.ora file. Alternatively, this parameter can be set using:

ALTER SYSTEM SET UNDO_RETENTION = <seconds>;

--- privilege to flashback any table 
GRANT FLASHBACK ANY TABLE to <username>;

--- Query to get the deleted data before 10 minutes
SELECT * FROM LOOKUP_TRANS_STATUS
 AS OF TIMESTAMP (SYSTIMESTAMP - INTERVAL '10' MINUTE); 
 
-- so like wish u can insert the data back in the table  
INSERT INTO LOOKUP_TRANS_STATUS
 SELECT * FROM LOOKUP_TRANS_STATUS
  AS OF TIMESTAMP (SYSTIMESTAMP - INTERVAL '10' MINUTE);
-- if wanna selected data from deleted data then  
   WHERE CONDITION... = ?;
 
 

--To select data as if we where in the past, you can use a flashback query. How long 
--you can go back depends on the size of the UNDO tablespace and on how quickly that fills up. 

--If you want to see the content of the table 1 hour ago you can query it like:

SELECT *
FROM tablename
AS OF TIMESTAMP SYSTIMESTAMP - INTERVAL '1' HOUR;


--If you want to see the content of the table 2 days ago you can query it like:

SELECT *
FROM tablename
AS OF TIMESTAMP SYSTIMESTAMP - INTERVAL '2' DAY;

--or you can select the status per SCN number.

--To query the current SCN number:

SELECT DBMS_FLASHBACK.GET_SYSTEM_CHANGE_NUMBER() FROM DUAL; 


--To select a SCN number (System Change Number) on a specific timestamp:

SELECT TIMESTAMP_TO_SCN('11-JUN-09 10.30.09.000000000 AM') FROM dual; 


--With this SCN number you can query in the past with "scn-number":

SELECT *
FROM tablename
AS OF SCN "scn-number";


--To select changes on a table since a specific System Change Numbers (SCN):

SELECT * FROM tabelnaam
VERSIONS BETWEEN SCN SCN_x AND MAXVALUE; 
 

-- Initialization Parameters 
 
--Setting the location OF the flashback 
recovery area db_recovery_file_dest=/oracle/flash_recovery_area 
 
 
--Setting the size OF the flashback 
recovery area db_recovery_file_dest_size=2147483648 
 
--Setting the retention TIME FOR flashback files (IN minutes)
-- 2 days
db_flashback_retention_target=2880 




/*
Flashback Table Just like the flashback query helps retrieve rows of a table, 
FLASHBACK TABLE helps restore the state of a table to a certain 
point in time even if a table structure changed has occurred since 
then. The following command will take us to the table state at the
specified timestamp.
*/
 
FLASHBACK TABLE EMPLOYEE TO 
TIMESTAMP ('15-SEP-08 8:50:58','DD-MON-YY HH24: MI: SS');
 
/*
This command will not only restore the tables, but also the 
associated objects like indexes, constraints etc.
*/
 
 
/*
Flashback Drop
Oracle 10g introduces the function "Flashback drop". If a DROP 
TABLE command has been issued for the table EMPLOYEE, we can 
still restore the entire table by issuing the following command:
*/
 
FLASHBACK TABLE EMPLOYEE TO BEFORE DROP;
 
-- Recovering a dropped table doesn't any easier than this!
 
 
/*
Flashback database
Flashback Database requires the creation and configuration of 
an Oracle Flash Recovery Area before this feature can be used. 
 
"Flash Recovery Area", created by the DBA, is the allocation of 
space on the disk to hold all the recovery related files (Flashback 
Logs, Redo Archive logs, RMAN backups, and copies of control files).
 
Use the initialization parameters db_recovery_file_dest and 
b_recovery_file_dest_size to set the destination and the size 
of the recovery area.
 
Set Flashback to enabled to make Oracle database enter the 
flashback mode. The database must be mounted as Exclusive and 
not open. The database also has to be in the ARCHIVELOG MODE 
before we can use this feature:
*/
 
ALTER DATABASE ARCHIVELOG;
 
-- start the database in EXCLUSIVE mode:
 
SHUTDOWN IMMEDIATE;
STARTUP MOUNT EXCLUSIVE
 
 
-- enter flashback mode:
 
ALTER DATABASE FLASHBACK ON;
 
 
-- issue the Flashback command and rewind the database to 
-- the state it was in one hour ago.
 
Flashback database TO TIMESTAMP sysdate-(1/24);
 
-- after the system comes back with FLASHBACK COMPLETE, 
-- open the database:
 
ALTER DATABASE OPEN RESETLOGS;
 
-- the database is now restored. 
 
-- note that we have the option 
-- of using SCN instead of timestamp.

Check table present with other commands in recyclebin

-- From current session:
Show recyclebin

select * from user_recyclebin;

--From SYSDBA user
Select * from dba_recyclebin;

-- Purge the recyclebin from current session

--Remove only one object from current user:
PURGE TABLE test;

-- Remove all objects from current user:
PURGE RECYCLEBIN;

-- Purge all dropped object from recycle-bin for all user with SYSDBA
PURGE DBA_RECYCLEBIN;

-- Drop command with Purge so that object not move to recycle-bin
DROP table TEST purge;




--- Flash Back Query

-- Oracle Flashback Query can only be used if the server is configured to use Automatic 
-- Undo Management, rather than traditional rollback segments. The maximum time period 
-- that can be flashbacked to is defined using the UNDO_RETENTION parameter in the 
-- init.ora file. Alternatively, this parameter can be set using:

ALTER SYSTEM SET UNDO_RETENTION = <seconds>;

--- Query to get the deleted data before 10 minutes
SELECT * FROM LOOKUP_TRANS_STATUS
 AS OF TIMESTAMP (SYSTIMESTAMP - INTERVAL '10' MINUTE); 
 
-- so like wish u can insert the data back in the table  
INSERT INTO LOOKUP_TRANS_STATUS
 SELECT * FROM LOOKUP_TRANS_STATUS
  AS OF TIMESTAMP (SYSTIMESTAMP - INTERVAL '10' MINUTE);
-- if wanna selected data from deleted data then  
   WHERE CONDITION... = ?;
 
 

--To select data as if we where in the past, you can use a flashback query. How long 
--you can go back depends on the size of the UNDO tablespace and on how quickly that fills up. 

--If you want to see the content of the table 1 hour ago you can query it like:

SELECT *
FROM tablename
AS OF TIMESTAMP SYSTIMESTAMP - INTERVAL '1' HOUR;


--If you want to see the content of the table 2 days ago you can query it like:

SELECT *
FROM tablename
AS OF TIMESTAMP SYSTIMESTAMP - INTERVAL '2' DAY;

--or you can select the status per SCN number.

--To query the current SCN number:

SELECT DBMS_FLASHBACK.GET_SYSTEM_CHANGE_NUMBER() FROM DUAL; 


--To select a SCN number (System Change Number) on a specific timestamp:

SELECT TIMESTAMP_TO_SCN('11-JUN-09 10.30.09.000000000 AM') FROM dual; 


--With this SCN number you can query in the past with "scn-number":

SELECT *
FROM tablename
AS OF SCN "scn-number";


--To select changes on a table since a specific System Change Numbers (SCN):

SELECT * FROM tabelnaam
VERSIONS BETWEEN SCN SCN_x AND MAXVALUE; 


--LASHBACK TABLE helps restore the state of a table to a certain point
--in time even if a table structure changed has occurred since then. The
--following simple command will take us to the table state at the
--specified timestamp.
FLASHBACK TABLE employee TO TIMESTAMP  to_date('27-Feb-09 05:00:00 PM','DD-MON-YY HH:MI:SS PM');


--Oracle 10g has provided another useful feature term as the Flashback
--drop. For our example if a DROP TABLE has been issued for the table
--EMPLOYEE we can still restore the whole table by issuing the following
--command.
FLASHBACK TABLE EMPLOYEE TO BEFORE DROP;

<end node> 5P9i0s8y19Z
dt=Text
<node>
GoldenGate
2
--Skipping a transaction in GoldenGate
http://appcrawler.com/wordpress/2012/03/08/skipping-a-transaction-in-goldengate/


-- Oracle GoldenGate: Skipping Erroneous Transactions
http://www.vitalsofttech.com/oracle-goldengate-skipping-erroneous-transactions/


info exttrail *

info rmttrail *

-- To rerun the previous command use “!”
!

<end node> 5P9i0s8y19Z
dt=Text
<node>
12c silent install & de-install
2

-- Check url for Oracle 12.1.0.2 silent install and de-install
https://valehagayev.wordpress.com/2016/09/08/oracle-12-1-0-2-silent-install-and-de-installation-on-oel/

<end node> 5P9i0s8y19Z
dt=Text
<node>
Listener Errors
2
Oracle - Detecting Listener Problems

-- When the listener fails to establish the connections, you can always find the evidence of the
-- problem in listener log file under location $ORACLE_HOME/network/log/listener.log ...

lsnrctl stat

-- check the log file name here

-- from the log file

cat `lsnrctl stat LISTENER_CDB1|grep Log|awk '{print $4}'`|grep "ORA-"

Here are some common errors related listeners

* ORA-12500 TNS:listener failed to start a dedicated server process  - This is generally 
associated with memory shortages or permission problems in UNIX.

* ORA-3113 end-of-file on communication channel - This is generally a network failure

* TNS-12547 TNS:lost contact - This can be corrected by increasing the connect_timeout_listener parameter.

* TNS-12224 TNS:no listener - Clients will get this message if the listener process is not running.

* ORA-12570 TNS:packet reader failure - This is a network problem.

* ORA-12571 TNS:packet writer failure - This is a network problem

Note that in many cases, a failure of the listener will not be logged on the database server, 
but will instead be presented as a message on the client workstation.  Hence, the vast majority 
of listener errors are reported by end-users.

Now let's examine how we can configure multiple listeners.

Note:  Starting in R2, the listener log is not activated by default.  You have to turn on 
listener logging:   logging_listener_name=on


Check port 1521

netstat -an -O |find /i "1521"

tnsping xe

Some times LOCAL_LISTENER parameter is not properly registered..

alter system set LOCAL_LISTENER='(ADDRESS=(PROTOCOL=TCP)(HOST=<<SERVER_NAME>>)(PORT=1521))' scope=both;
alter system register;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Create database manual
2
CREATE DATABASE CSMPRD
LOGFILE GROUP 1 ('/oracle/CSMPRD/redo1/redo01a.log','/oracle/CSMPRD/redo1/redo01b.log') SIZE 100M,
GROUP 2 ('/oracle/CSMPRD/redo2/redo02a.log','/oracle/CSMPRD/redo2/redo02b.log') SIZE 200M,
GROUP 3 ('/oracle/CSMPRD/redo3/redo03a.log','/oracle/CSMPRD/redo3/redo03b.log') SIZE 200M,
GROUP 4 ('/oracle/CSMPRD/redo4/redo04a.log','/oracle/CSMPRD/redo4/redo04b.log') SIZE 200M
MAXLOGFILES 10
MAXLOGMEMBERS 5
MAXLOGHISTORY 1
MAXDATAFILES 500
MAXINSTANCES 1
CHARACTER SET AL32UTF8
DATAFILE '/oracle/CSMPRD/system1/system01.dbf' SIZE 400M 
SYSAUX DATAFILE '/oracle/CSMPRD/system1/sysaux.dbf' SIZE 400M
default TEMPorary TABLESPACE temp
TEMPFILE '/oracle/CSMPRD/temp1/temp01.dbf' SIZE 400M
UNDO TABLESPACE UNDOTBS 
DATAFILE '/oracle/CSMPRD/undo1/undotbs01.dbf' SIZE 400M;


post installation scripts:-
@?/rdbms/admin/catalog.sql
@?/rdbms/admin/catproc.sql
@$ORACLE_HOME/sqlplus/admin/pupbld.sql

<end node> 5P9i0s8y19Z
dt=Text
<node>
DBLink in other schema
2

-- To close a database link follow either of the instructions below:
-- it will release the merwhp dblink session connected to target DBs.
Alter Session Close Database Link merwhp;

or

exec DBMS_SESSION.CLOSE_DATABASE_LINK ('MERWHP');

----------------------------------------------------------------------------------------------------

-- URL help
-- http://ba6.us/?q=db_links_via_proxy_user

Pointing a private database link at another database without knowing the password...

-- Get the original link DDL from the SOURCEDB

-- Run this query to get link definitions:

SELECT OWNER, DB_LINK, DBMS_METADATA.GET_DDL('DB_LINK',DB_LINK,OWNER) as DDL 
FROM DBA_DB_LINKS;

-- I now have DDL for the link I am interested in... it includes an encrypted version of the password 
-- needed to log into TARGET_USER:

CREATE DATABASE LINK MYLINK
CONNECT TO "TARGET_USER" IDENTIFIED BY VALUES '0526043491995E0A2D4CD80665CF98F671D9F7642EB4B6AA69'
USING 'TARGETDB1';

-- Get access to the link owner schema

-- Use proxy user authentication to allow access to the owner of the link on SOURCEDB for "ImaDBA" user. 
-- This is required to drop and receate a private DB link.

connect system@sourcedb

alter user sourceuser grant connect through ImaDBA;
-- Grant permissions if required
grant create database link to sourceuser;

connect ImaDBA[sourceuser]@sourcedb

-- Recreate the link using the new source
-- Using the DDL from above, replace TARGETDB1 with TARGETDB2, the new target.

drop database link MYLINK;
CREATE DATABASE LINK MYLINK
CONNECT TO "TARGET_USER" IDENTIFIED BY VALUES '0526043491995E0A2D4CD80665CF98F671D9F7642EB4B6AA69'
USING 'TARGETDB2';

-- Test the link
select count(*) from dual@MYLINK;

-- Clean up and revoke permissions if required
connect system@sourcedb
revoke create database link from sourceuser;
ALTER USER sourceuser REVOKE CONNECT THROUGH ImaDBA;

======================================================================================================


->ps -ef |grep pmon_|grep -e papcintr
oracle   10689     1  0 Feb03 ?        00:00:15 ora_pmon_papcintr1
lrch1d34.cna.com:oracle:seed12c:/home/oracle
->newsid papcintr
The Oracle base has been changed from /csapps/oapp/oracle to /csapps/oracle
Current sid is: papcintr1
lrch1d34.cna.com:oracle:papcintr1:/home/oracle
->sqlplus "/as sysdba"

SQL> alter user cad9290 grant connect through cae0748p;

User altered.

SQL> grant create database link to cad9290;

Grant succeeded.

SQL> exit

->sqlplus cae0748p

SQL> connect cae0748p[cad9290]
Enter password:
Connected.
SQL> show user
USER is "CAD9290"

SQL> CREATE DATABASE LINK PAPCINTP  CONNECT TO EPCINT_WCB IDENTIFIED BY "v5m4if!a3az" USING 'PAPCINTP';

Database link created.

SQL> select count(*) from all_tables@PAPCINTP;

  COUNT(*)
----------
       264

SQL> exit 

sqlplus "/as sysdba"


SQL> revoke create database link from CAD9290;

Revoke succeeded.

SQL> ALTER USER CAD9290 REVOKE CONNECT THROUGH cae0748p;

User altered.

SQL>

<end node> 5P9i0s8y19Z
dt=Text
<node>
Alert logs
2
 -- Write message to alert.log
 exec dbms_system.ksdwrt(2, 'Look Ma, I can write to the alert.log file!');
 PL/SQL procedure successfully completed.

 -- Flush the buffer
 exec dbms_system.ksdfls;
 PL/SQL procedure successfully completed. 
===============================================================================================

-- DBMS_SYSTEM.KSDWRT Write messages to Oracle alert log
-- Oracle provides a procedure to insert messages to the alert log and/or trace files for testing/development purposes. 
-- This can be used to check the effectiveness of the monitoring tools/scripts used in the environment, to understand how 
-- well the monitoring tool captures the messages in the alert log.
SQL> exec dbms_system.ksdwrt(1, 'This message goes to trace file in the udump location');
 
PL/SQL procedure successfully completed.
 
SQL> exec dbms_system.ksdwrt(2, 'This message goes to the alert log');
 
PL/SQL procedure successfully completed.
 
SQL> exec dbms_system.ksdwrt(3, 'This message goes to the alert log and trace file in the udump location');
===============================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
adrci
2
adrci> show incident
adrci> show incident -mode detail -p "incident_id=6201"
adrci> show trace /u01/app/oracle/diag/rdbms/orcl/orcl/incident/incdir_6201/orcl_ora_2299_i6201.trc

select log_mode,force_logging from v$database;

-- The locations of the various diagnostics directories can be displayed using the V$DIAG_INFO view.

COLUMN name FORMAT A25
COLUMN value FORMAT A65

SELECT name, value FROM v$diag_info;

NAME                      VALUE
------------------------- -----------------------------------------------------------------
Diag Enabled              TRUE
ADR Base                  /u01/app/oracle
ADR Home                  /u01/app/oracle/diag/rdbms/orcl/orcl
Diag Trace                /u01/app/oracle/diag/rdbms/orcl/orcl/trace
Diag Alert                /u01/app/oracle/diag/rdbms/orcl/orcl/alert
Diag Incident             /u01/app/oracle/diag/rdbms/orcl/orcl/incident
Diag Cdump                /u01/app/oracle/diag/rdbms/orcl/orcl/cdump
Health Monitor            /u01/app/oracle/diag/rdbms/orcl/orcl/hm
Default Trace File        /u01/app/oracle/diag/rdbms/orcl/orcl/trace/orcl_ora_19975.trc
Active Problem Count      0
Active Incident Count     0

11 rows selected.

===========================================================

Viewing the Alert Log

-- Depending on your setup, you may have multiple homes (Database, Listener, Grid Infrastructure etc.). 
-- It is important you point to the correct home before issuing any commands.

adrci> show home
ADR Homes:
diag/rdbms/orcl/orcl
diag/tnslsnr/ol6-112/listener
adrci> set home diag/rdbms/orcl/orcl
adrci>


-- With the home set, we can look at the contents of the alert log. The help text for the SHOW ALERT 
-- command provides some examples.

Examples:
  show alert
  show alert -p "message_text like '%incident%'"
  show alert -tail 20


-- We might decide to look for errors in the alert log with a command like the following.

adrci> show alert -p "message_text like '%ORA-%'"

ADR Home = /u01/app/oracle/diag/rdbms/orcl/orcl:
*************************************************************************
Output the results to file: /tmp/alert_1781_13990_orcl_1.ado
adrci>
We could also do a UNIX-style "tail -f" of the alert log using the following command, even on Windows.

adrci> show alert -tail -f
=================================================================================================================


-- Viewing Trace Files
-- The alert log will often make reference to trace files. These can be viewed directly using 
-- the SHOW TRACE command.
adrci> show trace /u01/app/oracle/diag/rdbms/orcl/orcl/incident/incdir_72697/orcl_ora_18310_i72697.trc


-- Managing Diagnostic Information (Purging Trace Files)
-- The PURGE command can be used to remove some or all of the diagnostic information from the repository. 
-- The HELP PURGE command describes the usage.
adrci> help purge

  Usage: PURGE [[-i <id1> | <id1> <id2>] |
               [-age <mins> [-type ALERT|INCIDENT|TRACE|CDUMP|HM|UTSCDMP]]]:

  Purpose: Purge the diagnostic data in the current ADR home. If no
           option is specified, the default purging policy will be used.

  Options:
    [-i id1 | id1 id2]: Users can input a single incident ID, or a
    range of incidents to purge.

    [-age <mins>]: Users can specify the purging policy either to all
    the diagnostic data or the specified type. The data older than <mins>
    ago will be purged

    [-type ALERT|INCIDENT|TRACE|CDUMP|HM|UTSCDMP]: Users can specify what type of
    data to be purged.

  Examples:
    purge
    purge -i 123 456
    purge -age 60 -type incident

adrci>


-- So to purge all diagnostic information, including trace files, older than 1 month you would issue the following.

adrci> purge -age 43200
adrci>


-- Problems and Incidents
-- When a problem occurs on the database, it is logged in the alert log and an incident is created. 
-- Doing a search of the alert log with the following command will reveal some information about the incident.

adrci> show alert -p "message_text like '%incident%'"


==================================================================================



 --- A simpler solution is to display the problem from the command line directly using the SHOW PROBLEM command.
adrci> show problem

ADR Home = /u01/app/oracle/diag/rdbms/orcl/orcl:
*************************************************************************
PROBLEM_ID           PROBLEM_KEY                                                 LAST_INCIDENT        LASTINC_TIME
-------------------- ----------------------------------------------------------- -------------------- ----------------------------------------
1                    ORA 3137 [3120]                                             71593                2013-08-09 10:16:43.714000 +01:00
2                    ORA 7445 [kghalo()]                                         72697                2013-10-09 10:05:17.154000 +01:00
2 rows fetched

adrci>


-- The same problem can occur multiple times, so a single problem may result in multiple incidents. 
-- Incidents are displayed using the SHOW INCIDENT command.

adrci> show incident

ADR Home = /u01/app/oracle/diag/rdbms/orcl/orcl:
*************************************************************************
INCIDENT_ID          PROBLEM_KEY                                                 CREATE_TIME
-------------------- ----------------------------------------------------------- ----------------------------------------
71593                ORA 3137 [3120]                                             2013-08-09 10:16:43.714000 +01:00
72697                ORA 7445 [kghalo()]                                         2013-10-09 10:05:17.154000 +01:00
2 rows fetched

adrci>


-- Once you have identified an incident of interest, you can look at it in more detail by altering 
-- the mode in the SHOW INCIDENT command.

adrci> show incident -mode detail -p "incident_id=72697"

ADR Home = /u01/app/oracle/diag/rdbms/lstu/lstu:
*************************************************************************

**********************************************************
INCIDENT INFO RECORD 1
**********************************************************
   INCIDENT_ID                   72697
   STATUS                        ready
   CREATE_TIME                   2013-10-09 10:05:17.154000 +01:00
   PROBLEM_ID                    2
   CLOSE_TIME                    <NULL>
   FLOOD_CONTROLLED              none
   ERROR_FACILITY                ORA
   ERROR_NUMBER                  7445
   ERROR_ARG1                    kghalo()
   ERROR_ARG2                    SIGSEGV
   ERROR_ARG3                    ADDR:0x9FFFFFFFBFFFF000
   ERROR_ARG4                    PC:0x40000000065AE680
   ERROR_ARG5                    Address not mapped to object
   ERROR_ARG6                    <NULL>
   ERROR_ARG7                    <NULL>
   ERROR_ARG8                    <NULL>
   ERROR_ARG9                    <NULL>
   ERROR_ARG10                   <NULL>
   ERROR_ARG11                   <NULL>
   ERROR_ARG12                   <NULL>
   SIGNALLING_COMPONENT          <NULL>
   SIGNALLING_SUBCOMPONENT       <NULL>
   SUSPECT_COMPONENT             <NULL>
   SUSPECT_SUBCOMPONENT          <NULL>
   ECID                          <NULL>
   IMPACTS                       0
   PROBLEM_KEY                   ORA 7445 [kghalo()]
   FIRST_INCIDENT                72697
   FIRSTINC_TIME                 2013-10-09 10:05:17.154000 +01:00
   LAST_INCIDENT                 72697
   LASTINC_TIME                  2013-10-09 10:05:17.154000 +01:00
   IMPACT1                       0
   IMPACT2                       0
   IMPACT3                       0
   IMPACT4                       0
   KEY_NAME                      ProcId
   KEY_VALUE                     287.6
   KEY_NAME                      Client ProcId
   KEY_VALUE                     oracle@biro01 (TNS V1-V3).18310_1
   KEY_NAME                      ECID
   KEY_VALUE                     55774dc6ecfa57a3:2a5146fe:13ffc25ce34:-8000-0000000000055601.1
   KEY_NAME                      PQ
   KEY_VALUE                     (0, 1381309514)
   KEY_NAME                      SID
   KEY_VALUE                     1125.45841
   OWNER_ID                      1
   INCIDENT_FILE                 /u01/app/oracle/diag/rdbms/orcl/lstu/trace/orcl_ora_18310.trc
   OWNER_ID                      1
   INCIDENT_FILE                 /u01/app/oracle/diag/rdbms/orcl/orcl/incident/incdir_72697/orcl_ora_18310_i72697.trc
1 rows fetched
adrci>

-- Creating Packages to Send to Oracle Support

-- If you can't solve the problem yourself, you can use the Incident Packaging Service (IPS) to 
-- gather all pertinent information so it can be sent to Oracle Support. This should reduce the amount 
-- of time you waste trying to identify what information is necessary for them to identify and solve the problem.

-- First, create the package using the problem ID displayed by the SHOW PROBLEM command.

adrci> ips create package problem 2 correlate all
Created package 1 based on problem id 2, correlation level all

adrci>

-- Next, create a zip to send to Oracle Support by specifying the package number displayed by the above command.
adrci> ips generate package 1 in "/tmp"

-- Generated package 1 in file /tmp/IPSPKG_20140610100342_COM_1.zip, mode complete
adrci>

-- The package is now zipped and ready to upload to Oracle Support.
$ ls /tmp/IPSPKG*.zip
/tmp/IPSPKG_20140610100342_COM_1.zip
$

-- By default retention is 720 hours for short policy and 8760 hours for long policy.

Short policy include the following files :(Trace files, Core dump files, Packaging information)
Long policy include the following files:(Incident information, Incident dumps, Alert logs)

-- To set the purging policy to 7 days

-- check the settings for Short and long Policys
adrci> show control

-- Modify it for 7 days
adrci> set control (SHORTP_POLICY=72)
adrci> set control (LONGP_POLICY=72)

-- 5 days
adrci> set control (SHORTP_POLICY=120); 
-- 1 week
adrci> set control (LONGP_POLICY=720); 

-- To Manually purge all trace files older than 1 day (1440 mins): Including core files: cdmp*

-- 4320 min for 4 days (1440 min in a day)
-- 24 hrs a day and 1440 mins in a day
adrci> purge -age 4320

OR
-- This example purges all incident data from the last hour:
adrci> purge -age 60 -type incident

-- command will manually purge all tracefiles older than 2 days (1440*2=2880 minutes):
adrci> purge -age 2880 -type trace

-- To purge core files older than 6 days  
adrci> purge -age 4320 -type CDUMP


-- It might be needed to also run the following additional command:  
adrci> purge -age 4320 -type UTSCDMP


-- To remove sub-folders >6 days-old having a name like "CDMP_" from TRACE.
-- Purge XML based Alert log file:
adrci> purge -age 60 -type ALERT

-- To purge diagnostic data that is older than the amount of time (minutes) 
-- given in the purge command. For ex to purge diagnostic data that is over 1 day 
-- old (1440 minutes).
adrci> PURGE -age 1440 -type ALERT

--You can also pruge TRACE files with same method:
adrci> PURGE -age 1440 -type TRACE

-- do not clean up the Text-formatted alert.log file.
-- The ADRCI interface is only supposed to modify the XML-formatted alert file, not the Text-formatted alert file,


-- This displays the last 50 entries in the alert log in your terminal session.
adcri> show alert -tail 50

-- trail the alert log file
adcri> show alert -tail -f


set control (SHORTP_POLICY = 2)
set control (LONGP_POLICY = 4)

-- delete trace older then 1 min
purge -age 1 -type trace

<end node> 5P9i0s8y19Z
dt=Text
<node>
copy from to cmd
2
 --- Refer to the following list for a description of each term or clause:

FROM database
 --- The database that contains the data to be copied. If you omit the FROM clause, the source defaults to the 
database to which SQL*Plus is connected (that is, the database that other commands address). You must use a 
FROM clause to specify a source database other than the default.

TO database
 --- The database containing the destination table. If you omit the TO clause, the destination defaults to the 
database to which SQL*Plus is connected (that is, the database that other commands address). You must use a 
TO clause to specify a destination database other than the default.

database
 --- Specifies username[/password] @connect_identifier of the Oracle source or destination database you wish 
to COPY FROM or COPY TO. If you do not specify password in either the COPY FROM clause or the COPY TO clause, 
SQL*Plus will prompt you for it. SQL*Plus suppresses the display of your password response.

 --- You must include the connect_identifier clause which consists of an Oracle Net connection string, to 
specify the source or destination database. The exact syntax depends upon the Oracle Net communications 
protocol your Oracle installation uses. For more information, refer to the Oracle Net manual appropriate 
for your protocol or contact your DBA.

APPEND
 --- Inserts the rows from query into destination_table if the table exists. If destination_table does not exist, 
COPY creates it.

CREATE
 --- Inserts the rows from query into destination_table after first creating the table. If destination_table 
already exists, COPY returns an error.

INSERT
 --- Inserts the rows from query into destination_table. If destination_table does not exist, COPY returns an 
error. When using INSERT, the USING query must select one column for each column in the destination_table.

REPLACE
 --- Replaces destination_table and its contents with the rows from query. If destination_table does not exist, 
COPY creates it. Otherwise, COPY drops the existing table and replaces it with a table containing the copied data.

destination_table
 --- Represents the table you wish to create or to which you wish to add data.

(column, column, column, ...)
 --- Specifies the names of the columns in destination_table. You must enclose a name in double quotes if it 
contains lowercase letters or blanks.

 --- If you specify columns, the number of columns must equal the number of columns selected by the query. 
If you do not specify any columns, the copied columns will have the same names in the destination table as 
they had in the source if COPY creates destination_table.

USING query
 --- Specifies a SQL query (SELECT command) determining which rows and columns COPY copies.
-------------------------------------------------------------------------------------------------------------------

-- The following command copies the entire EMPLOYEES table to a table named 
-- WESTEMPLOYEES. Note that the tables are located in two different databases. 
-- If WESTEMPLOYEES already exists, SQL*Plus replaces the table and its contents. The columns 
-- in WESTEMPLOYEES have the same names as the columns in the source table, EMPLOYEES.

COPY FROM HR/your_password@HQ TO JOHN/your_password@WEST -
REPLACE WESTEMPLOYEES -
USING SELECT * FROM EMPLOYEES

-- The following command copies selected records from EMPLOYEES to the database to which SQL*Plus 
-- is connected. SQL*Plus creates SALESMEN through the copy. SQL*Plus copies only the columns EMPLOYEE_ID 
-- and LAST_NAME, and at the destination names them EMPLOYEE_ID and SA_MAN.

COPY FROM HR/your_password@ORACLE01 -
CREATE SALESMEN (EMPLOYEE_ID, SA_MAN) -
USING SELECT EMPLOYEE_ID, LAST_NAME FROM EMPLOYEES -
WHERE JOB_ID='SA_MAN';


COPY FROM HR/your_password@MYDATABASE -
INSERT EMPLOYEE_COPY2 -
USING SELECT * FROM EMPLOYEE_COPY 


copy from cae0748p@clmedip -
to cae0748p@clmedir -
insert wcedi.edi_bus_edt_lku -
using select * from wcedi.edi_bus_edt_lku;

copy from cae0748p@clmedip -
to cae0748p@clmedir -
insert wcedi.edi_actv_req_lku -
using select * from wcedi.edi_actv_req_lku;

copy from cae0748p@clmedip -
to cae0748p@clmedir -
insert wcedi.edi_bus_edt_lku -
using select * from wcedi.edi_bus_edt_lku;

-- replace : if the table already exists, then it will be replace with all contents
copy from cae0748p@winc -
to cae0748p@winr -
replace com.com_producer -
using select * from com.com_producer;

<end node> 5P9i0s8y19Z
dt=Text
<node>
ACL Networks
2

---- script to generate the ACLs backup
set serveroutput on
declare
	v_param_list varchar2(2000);
	cursor rec_c ( i_ACLID dba_network_acl_privileges.ACLID%type, i_ACL dba_network_acl_privileges.ACL%type ) is
	select rownum POSITION, ACL, PRINCIPAL,
		decode(privilege,'use-cli','use-client-certificates','use-pas','use-passwords',privilege) PRIVILEGE,
		IS_GRANT,INVERT,
		decode(START_DATE,null,'null','to_timestamp_tz('''||to_char(START_DATE,'YYYYMMDDHH24MISSXFFTZR')||''',''YYYYMMDDHH24MISSXFF TZR'')') START_DATE,
		decode(END_DATE,null,'null','to_timestamp_tz('''||to_char(END_DATE,'YYYYMMDDHH24MISSXFFTZR'||''',''YYYYMMDDHH24MISSXFF TZR'')')) END_DATE
	  from dba_network_acl_privileges a 
	 where a.ACLID = i_ACLID and a.ACL = i_ACL ;

	rec rec_c%rowtype ;
begin
	--- comments here
	DBMS_OUTPUT.PUT_LINE(' ');
	DBMS_OUTPUT.PUT_LINE('--- MerlineRef DR WareHouse MERWHR ACL Networks Backup  ');
	DBMS_OUTPUT.PUT_LINE('ACL Network Backups for Date : ' || to_char(sysdate,'mm/dd/yyyy hh24:mi:ss'));
	DBMS_OUTPUT.PUT_LINE(' ');
	DBMS_OUTPUT.PUT_LINE(' ');
	
   for i in ( select distinct ACLID,ACL from dba_network_acl_privileges ) loop
     open rec_c ( i.ACLID , i.acl ) ;
     fetch rec_c into rec;
      v_param_list:='acl=>'''||substr(rec.acl,instr(rec.acl,'/',-1)+1)||'''';
      v_param_list:=v_param_list||',description=>'''||substr(rec.acl,11,length(rec.acl))||'''';
      v_param_list:=v_param_list||',principal=>'''||rec.principal||'''';
      v_param_list:=v_param_list||',privilege=>'''||rec.privilege||'''';
      v_param_list:=v_param_list||',is_grant=>'||rec.is_grant;
      v_param_list:=v_param_list||',start_date=>'||rec.END_DATE;
      v_param_list:=v_param_list||',end_date=>'||rec.END_DATE||');';
      dbms_output.put_line('exec dbms_network_acl_admin.create_acl('||v_param_list);
      -- fetch rec_c into rec ; NOT FETCHING HERE TO AVOID DUPLICATES 
         while rec_c%FOUND loop
             v_param_list:='acl=>'''||substr(rec.acl,instr(rec.acl,'/',-1)+1)||'''';
             v_param_list:=v_param_list||',principal=>'''||rec.principal||'''';
             v_param_list:=v_param_list||',is_grant=>'||rec.is_grant;
             v_param_list:=v_param_list||',privilege=>'''||rec.privilege||'''';
             v_param_list:=v_param_list||',position=>'||rec.POSITION;
             v_param_list:=v_param_list||',start_date=>'||rec.END_DATE;
             v_param_list:=v_param_list||',end_date=>'||rec.END_DATE||');';
             dbms_output.put_line('exec DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE('||v_param_list);
             fetch rec_c into rec ;
         end loop;
       close rec_c ;

    for rec2 in (select HOST,decode(LOWER_PORT,null,'null',to_char(LOWER_PORT))LOWER_PORT,decode(UPPER_PORT,null,'null',to_char(UPPER_PORT))UPPER_PORT,ACL,ACLID
                 from dba_network_acls 
                 where acl = i.acl and ACLID= i.aclid) loop
                    v_param_list:='acl=>'''||substr(rec2.acl,instr(rec2.acl,'/',-1)+1)||''',host=>'''||rec2.host||''',lower_port=>'||rec2.lower_port||',upper_port=>'||rec2.upper_port||');';
                    dbms_output.put_line('exec DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL('||v_param_list);
    end loop;

  end loop;
end;
/








BEGIN
  DBMS_NETWORK_ACL_ADMIN.drop_acl (acl => 'dba_smtp.xml');
  COMMIT;
END;
/


exec dbms_network_acl_admin.unassign_acl(acl=>'/sys/acls/utl_smtp_acl_file.xml',host=>'mail.cnasurety.net');

begin
 DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE 
  (
    ACL => 'dba.xml',
    PRINCIPAL => 'RAHULC',
    IS_GRANT => TRUE,
    PRIVILEGE => 'connect',
    START_DATE => null, -- if the time interval is defined,
    END_DATE => null
 ); -- the ACE will expire after the specified date range
end;
/


BEGIN
  DBMS_NETWORK_ACL_ADMIN.delete_privilege ( 
    acl         => 'dba1.xml', 
    principal   => 'RAHULC',
    is_grant    => TRUE, 
    privilege   => 'execute');


  COMMIT;
END;
/

BEGIN
    DBMS_NETWORK_ACL_ADMIN.CREATE_ACL (
    ACL => 'dba.xml', -- case sensitive
    DESCRIPTION=> 'Network Access Control for the DBAs',
    PRINCIPAL => 'SNOX', -- user or role the privilege is granted or denied (upper case)
    IS_GRANT => TRUE, -- privilege is granted or denied
    PRIVILEGE => 'connect', -- or 'resolve' (case sensitive)
    START_DATE => NULL, -- when the access control entity ACE will be valid
    END_DATE => NULL); -- ACE expiration date (TIMESTAMP WITH TIMEZONE format)
END;
/

 


BEGIN
  DBMS_NETWORK_ACL_ADMIN.ASSIGN_ACL (
    acl         => '/sys/acls/utl_smtp_acl_file.xml',
    HOST        => 'mailhost.cna.com', 
    lower_port  => 25,
    upper_port  => 25); 
    COMMIT;
END;
/



BEGIN
 DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE 
  (
    ACL => '/sys/acls/utl_smtp_acl_file.xml',
    PRINCIPAL => 'CMJOB',
    IS_GRANT => TRUE,
    PRIVILEGE => 'connect',
    START_DATE => NULL, -- if the time interval is defined,
    END_DATE => NULL
 ); -- the ACE will expire after the specified date range
END;
/


BEGIN
 DBMS_NETWORK_ACL_ADMIN.ADD_PRIVILEGE 
  (
    ACL => '/sys/acls/utl_smtp_acl_file.xml',
    PRINCIPAL => 'OLTP',
    IS_GRANT => TRUE,
    PRIVILEGE => 'connect',
    START_DATE => NULL, -- if the time interval is defined,
    END_DATE => NULL
 ); -- the ACE will expire after the specified date range
END;
/


SELECT ANY_PATH
FROM RESOURCE_VIEW
WHERE ANY_PATH LIKE '/sys/acls/dba%';


SELECT dna.host, dna.acl, dnap.principal, dnap.privilege
FROM dba_network_acls dna, dba_network_acl_privileges dnap
where dna.acl = dnap.acl
 --and host='mail.cnasurety.net'
order by host desc;

select * from dba_network_acls;

SELECT *
FROM   dba_network_acl_privileges;


-- Check which host is having the access
SELECT HOST,
       LOWER_PORT,
       UPPER_PORT,
       ACL,
       ACLID,
       ACL_OWNER
FROM   dba_host_acls
ORDER BY host;


SELECT host,
       lower_port,
       upper_port,
       ace_order,
       TO_CHAR(start_date, 'DD-MON-YYYY') AS start_date,
       TO_CHAR(end_date, 'DD-MON-YYYY') AS end_date,
       grant_type,
       inverted_principal,
       principal,
       principal_type,
       privilege
FROM   dba_host_aces
ORDER BY host, ace_order;


grant execute on UTL_SMTP to public

<end node> 5P9i0s8y19Z
dt=Text
<node>
Own-Help scrpt
2
-- Licensed under the Apache License, Version 2.0. See LICENSE.txt for terms & conditions.


--------------------------------------------------------------------------------
--
-- File name:   help.sql
-- Purpose:     Help
-- Author:      Tomasz Sroka
-- Usage:       @help <string>
--
-- SQL> @help help
-- SQL> @help latch|lock
-- SQL> @help ash

-- regular expression to find only the .sql files
-- @help seg.*\.sql$
--------------------------------------------------------------------------------
--ACCEPT search_string CHAR PROMPT "Search: [%] "

DEFINE amp=chr(38)
DEFINE nl=chr(10)
DEFINE search_string=&1

COLUMN name FORMAT A25 TRUNC
COLUMN description FORMAT A60 WORD_WRAP
COLUMN usage FORMAT A110

WITH q AS (
SELECT name, description, usage
FROM (
  SELECT 'ash_wait_chains.sql' AS name, 'Display ASH wait chains (multi-session wait signature, a session waiting for another session etc.)' AS description, '@ash/ash_wait_chains <grouping_cols> <filters> <from_time> <to_time>'||&nl||'@ash/ash_wait_chains username||''-''||program2 "wait_class=''Application''" sysdate-1/24 sysdate' AS usage FROM dual UNION ALL
  SELECT 'asqlmon.sql' AS name, 'Report SQL-monitoring-style drill-down into where in an execution plan the execution time is spent (ASH based)' AS description, '@ash/asqlmon <sql_id> <child#> <from_time> <to_time>'||&nl||'@ash/asqlmon 7q729nhdgtsqq 0 sysdate-1/24 sysdate'||&nl||'@ash/asqlmon 7q729nhdgtsqq % sysdate-1 sysdate' AS usage FROM dual UNION ALL
  SELECT 'aw.sql' AS name, 'Display last minute database activity' AS description, '@aw <filter_expression>'||&nl||'@aw 1=1' AS usage FROM dual UNION ALL
  SELECT 'awr_sqlid.sql' AS name, 'Display SQL text from AWR' AS description, '@awr/awr_sqlid <sql_id>'||&nl||'@awr/awr_sqlid 7q729nhdgtsqq' AS usage FROM dual UNION ALL
  SELECT 'awr_sqlstats.sql' AS name, 'Display SQL statistics from AWR' AS description, '@awr/awr_sqlstats <sql_id> <plan_hash_value> <from_time> <to_time>'||&nl||'@awr/awr_sqlstats 0sh0fn7r21020 1541789278 sysdate-7 sysdate'||&nl||'@awr/awr_sqlstats 0sh0fn7r21020 % sysdate-7 sysdate' AS usage FROM dual UNION ALL
  SELECT 'awr_sqlstats_per_exec.sql' AS name, 'Display SQL statistics per execution from AWR' AS description, '@awr/awr_sqlstats_per_exec <sql_id> <plan_hash_value> <from_time> <to_time>'||&nl||'@awr/awr_sqlstats_per_exec 0sh0fn7r21020 1541789278 sysdate-7 sysdate'||&nl||'@awr/awr_sqlstats_per_exec 0sh0fn7r21020 % sysdate-7 sysdate' AS usage FROM dual UNION ALL
  SELECT 'awr_sqlstats_unstable.sql' AS name, 'Display unstable SQL execution plans from AWR' AS description, '@awr/awr_sqlstats_unstable <sql_id> <plan_hash_value> <from_time> <to_time>'||&nl||'@awr/awr_sqlstats_unstable 0sh0fn7r21020 % sysdate-7 sysdate' AS usage FROM dual UNION ALL
  SELECT 'bg.sql' AS name, 'Display background processes' AS description, '@bg <process_name|process_description>'||&nl||'@bg dbw'||&nl||'@bg writer'||&nl||'@bg %' AS usage FROM dual UNION ALL
  SELECT 'bhobjects.sql' AS name, 'Display top objects in buffer cache' AS description, '@bhobjects' AS usage FROM dual UNION ALL
  SELECT 'bhobjects2.sql' AS name, 'Display buffer cache statistics' AS description, '@bhobjects2' AS usage FROM dual UNION ALL
  SELECT 'cancel.sql' AS name, 'Generate commands for canceling selected SQL' AS description, '@cancel <filter_expression>'||&nl||'@cancel sid=150'||&nl||'@cancel username=''SYSTEM'''||&nl||'@cancel "username=''APP'' and program like ''sqlplus%''"' AS usage FROM dual UNION ALL
  SELECT 'col.sql' AS name, 'Display column' AS description, '@col <column_name>'||&nl||'@col open_mode' AS usage FROM dual UNION ALL
  SELECT 'colusage.sql' AS name, 'Display column usage' AS description, '@colusage [<owner>.]<table_name>'||&nl||'@colusage soe.orders'||&nl||'@colusage soe.%' AS usage FROM dual UNION ALL
  SELECT 'create_sql_baseline.sql' AS name, 'Create SQL Plan Baseline from an existing "good" cursor' AS description, '@create_sql_baseline <good_sqlid> <good_plan_hash_value> <to_bad_sqlid>'||&nl||'@create_sql_baseline g5tuxh82pk3qf 2966233522 d7khnbh6c9qas' AS usage FROM dual UNION ALL
  SELECT 'create_sql_patch.sql' AS name, 'Create SQL patch' AS description, '@create_sql_patch <sql_id> <hint>'||&nl||'@create_sql_patch g4pkmrqrgxg3b GATHER_PLAN_STATISTICS'||&nl||q'[@create_sql_patch b9dmj0ahu6xgc 'NO_INDEX_SS(@"SEL$26CA4453" "STORE_SALES"@"SEL$1")']' AS usage FROM dual UNION ALL
  SELECT 'd.sql' AS name, 'Display data dictionary views and x$ tables' AS description, '@d <object_name>'||&nl||'@d sql'||&nl||'@d %' AS usage FROM dual UNION ALL
  SELECT 'dash_wait_chains.sql' AS name, 'Display ASH (based on DBA_HIST) wait chains (multi-session wait signature, a session waiting for another session etc.)' AS description, '@ash/dash_wait_chains <grouping_cols> <filters> <from_time> <to_time>'||&nl||'@ash/dash_wait_chains username||''-''||program2 "wait_class=''Application''" sysdate-1/24 sysdate' AS usage FROM dual UNION ALL
  SELECT 'dasqlmon.sql' AS name, 'Report SQL-monitoring-style drill-down into where in an execution plan the execution time is spent (AWR based)' AS description, '@ash/dasqlmon <sqlid> <plan_hash_value> <from_time> <to_time>'||&nl||'@ash/dasqlmon 7q729nhdgtsqq 0 "timestamp''2019-10-07 07:00:00''" "timestamp''2019-10-07 07:00:00''"'||&nl||'@ash/dasqlmon 7q729nhdgtsqq % sysdate-1 sysdate' AS usage FROM dual UNION ALL
  SELECT 'date.sql' AS name, 'Display current date' AS description, '@date'||&nl||'@d sql'||&nl||'@d %' AS usage FROM dual UNION ALL
  SELECT 'ddl.sql' AS name, 'Extracts DDL statements for specified objects' AS description, '@ddl [<owner>.]<object_name>'||&nl||'@ddl sys.dba_users'||&nl||'@ddl sys.%tab%' AS usage FROM dual UNION ALL
  SELECT 'desc.sql' AS name, 'Describe object' AS description, '@desc <object_name>'||&nl||'@desc dba_tables' AS usage FROM dual UNION ALL
  SELECT 'devent_hist.sql' AS name, 'Display a histogram of the number of waits from AWR (milliseconds)' AS description, '@ash/devent_hist.sql <event> <filter_expression> <from_time> <to_time>'||&nl||'@ash/devent_hist.sql log_file 1=1 sysdate-1/24 sysdate'||&nl||'@ash/devent_hist.sql log.file|db.file "wait_class=''User I/O'' AND session_type=''FOREGROUND''" sysdate-1/24 sysdate' AS usage FROM dual UNION ALL
  SELECT 'df.sql' AS name, 'Display tablespace usage (GB)' AS description, '@df' AS usage FROM dual UNION ALL
  SELECT 'dfm.sql' AS name, 'Display tablespace usage (MB)' AS description, '@dfm' AS usage FROM dual UNION ALL
  SELECT 'dirs.sql' AS name, 'Display database directories' AS description, '@dirs' AS usage FROM dual UNION ALL
  SELECT 'drop_sql_patch.sql' AS name, 'Drop SQL patch' AS description, '@drop_sql_patch <patch_name>'||&nl||'@drop_sql_patch SQL_PATCH_g4pkmrqrgxg3b' AS usage FROM dual UNION ALL
  SELECT 'drop_sql_baseline.sql' AS name, 'Drop SQL Plan Baseline' AS description, '@drop_sql_baseline <sql_handle>   (get sql_handle from DBMS_XPLAN notes or DBA_SQL_PLAN_BASELINES)'||&nl||'@drop_sql_baseline SQL_52cb74b7097edbbd' AS usage FROM dual UNION ALL
  SELECT 'ev.sql' AS name, 'Set session event' AS description, '@ev <event> <level>'||&nl||'@ev 10046 12' AS usage FROM dual UNION ALL
  SELECT 'event_hist.sql' AS name, 'Display a histogram of the number of waits from ASH (milliseconds)' AS description, '@ash/event_hist.sql <event> <filter_expression> <from_time> <to_time>'||&nl||'@ash/event_hist.sql log.file 1=1 sysdate-1/24 sysdate'||&nl||'@ash/event_hist.sql log.file|db.file "wait_class=''User I/O'' AND session_type=''FOREGROUND''" sysdate-1/24 sysdate' AS usage FROM dual UNION ALL
  SELECT 'event_hist_micro.sql' AS name, 'Display a histogram of the number of waits from ASH (microseconds)' AS description, '@ash/event_hist_micro <event> <filter_expression> <from_time> <to_time>'||&nl||'@ash/event_hist_micro log.file 1=1 sysdate-1/24 sysdate'||&nl||'@ash/event_hist_micro log.file|db.file "wait_class=''User I/O'' AND session_type=''FOREGROUND''" sysdate-1/24 sysdate' AS usage FROM dual UNION ALL
  SELECT 'evh.sql' AS name, 'Display a histogram of the number of waits' AS description, '@evh <event>'||&nl||'@evh log.file'||&nl||'@evh log.file|db.file' AS usage FROM dual UNION ALL
  SELECT 'evo.sql' AS name, 'Disable session event' AS description, '@evo <event>'||&nl||'@evo 10046' AS usage FROM dual UNION ALL
  SELECT 'fix.sql' AS name, 'Display session fix controls' AS description, '@fix <bugno|description|optimizer_feature_enable|sql_feature>'||&nl||'@fix 13836796'||&nl||'@fix adaptive' AS usage FROM dual UNION ALL
  SELECT 'grp.sql' AS name, 'Group function wrapper' AS description, '@grp <column_name> <table_name>'||&nl||'@grp owner dba_tables'||&nl||'@grp owner,object_type dba_objects' AS usage FROM dual UNION ALL
  SELECT 'help.sql' AS name, 'Display TPT script help' AS description, '@help <search_expression>'||&nl||'@help explain'||&nl||'@help lock|latch.*hold'||&nl||'@help ^ind.*sql|^tab.*sql' AS usage FROM dual UNION ALL
  SELECT 'hash.sql' AS name, 'Display the hash value, sql_id, and child number of the last SQL in session' AS description, '@hash' AS usage FROM dual UNION ALL
  SELECT 'hint.sql' AS name, 'Display all available hints' AS description, '@hint <name>'||&nl||'@hint full' AS usage FROM dual UNION ALL
  SELECT 'hintclass.sql' AS name, 'Display all available hints with hint class info' AS description, '@hintclass <hint_name>'||&nl||'@hintclass merge' AS usage FROM dual UNION ALL
  SELECT 'hintfeature.sql' AS name, 'Display all available hints with SQL feature info' AS description, '@hintfeature <feature_name>'||&nl||'@hintfeature transformation' AS usage FROM dual UNION ALL
  SELECT 'hinth.sql' AS name, 'Display hint hierarchy' AS description, '@hinth <hint_name>'||&nl||'@hinth merge' AS usage FROM dual UNION ALL
  SELECT 'ind.sql' AS name, 'Display indexes' AS description, '@ind [<owner>.]<index_name|table_name>'||&nl||'@ind orders'||&nl||'@ind soe.ord_customer_ix'||&nl||'@ind soe.%' AS usage FROM dual UNION ALL
  SELECT 'indf.sql' AS name, 'Display function-based index expressions' AS description, '@indf [<owner>.]<index_name|table_name>'||&nl||'@indf orders'||&nl||'@indf soe.ord_customer_ix'||&nl||'@indf soe.%' AS usage FROM dual UNION ALL
  SELECT 'kill.sql' AS name, 'Generate command to for killing user session' AS description, '@kill <filter_expression>'||&nl||'@kill sid=284'||&nl||'@kill username=''SYSTEM'''||&nl||'@kill "username=''APP'' AND program LIKE ''sqlplus%''"' AS usage FROM dual UNION ALL
  SELECT 'latchprof.sql' AS name, 'Profile top latch holders (V$ version)' AS description, '@latchprof <grouping_columns> <sid> <latch_name> <samples>'||&nl||'@latchprof name,sqlid 123 % 10000'||&nl||'@latchprof sid,name,sqlid % "shared pool" 10000' AS usage FROM dual UNION ALL
  SELECT 'latchprofx.sql' AS name, 'Profile top latch holders eXtended (X$ version)' AS description, '@latchprofx <grouping_columns> <sid> <latch_name> <samples>'||&nl||'@latchprofx sid,name 123 % 10000'||&nl||'@latchprofx sid,name,timemodel,hmode,func % "shared pool" 10000' AS usage FROM dual UNION ALL
  SELECT 'lock.sql' AS name, 'Display current locks' AS description, '@lock <filter_expression>'||&nl||'@lock 1=1'||&nl||'@lock type=''TM''' AS usage FROM dual UNION ALL
  SELECT 'log.sql' AS name, 'Display redo log layout' AS description, '@log' AS usage FROM dual UNION ALL
  SELECT 'long.sql' AS name, 'Display session long operations' AS description, '@long <filter_expression>'||&nl||'@long 1=1'||&nl||'@long username=''SOE''' AS usage FROM dual UNION ALL
  SELECT 'ls.sql' AS name, 'Display tablespace' AS description, '@ls <tablespace_name>'||&nl||'@ls system'||&nl||'@ls %' AS usage FROM dual UNION ALL
  SELECT 'lt.sql' AS name, 'Display lock type info' AS description, '@lt <lock_name>'||&nl||'@lt TM' AS usage FROM dual UNION ALL
  SELECT 'mem.sql' AS name, 'Display information about the dynamic SGA components' AS description, '@mem' AS usage FROM dual UNION ALL
  SELECT 'memres.sql' AS name, 'Display information about the last completed memory resize operations' AS description, '@memres' AS usage FROM dual UNION ALL
  SELECT 'nonshared.sql' AS name, 'Display reasons for non-shared child cursors from v$shared_cursor', '@nonshared <sql_id>'||&nl||'@nonshared 7q729nhdgtsqq' AS usage FROM dual UNION ALL
  SELECT 'o.sql' AS name, 'Display database object based on object owner and name', '@o [<owner>.]<object_name>'||&nl||'@o sys.dba_users'||&nl||'@o %.%files' AS usage FROM dual UNION ALL
  SELECT 'oerr.sql' AS name, 'Display Oracle error decription' AS description, '@oerr <error_number>'||&nl||'@oerr 7445' AS usage FROM dual UNION ALL
  SELECT 'oi.sql' AS name, 'Display invalid objects' AS description, '@oi' AS usage FROM dual UNION ALL
  SELECT 'oid.sql' AS name, 'Display database objects based on object id' AS description, '@oid <object_id>'||&nl||'@oid 10'||&nl||'@oid 10,20' AS usage FROM dual UNION ALL
  SELECT 'otherxml.sql' AS name, 'Display outline hints from library cache' AS description, '@otherxml <sql_id> <child#>'||&nl||'@otherxml 1fbwxvngasv1f 1' AS usage FROM dual UNION ALL
  SELECT 'p.sql' AS name, 'Display parameter name and value' AS description, '@p <parameter_name>'||&nl||'@pd optimizer' AS usage FROM dual UNION ALL
  SELECT 'partkeys.sql' AS name, 'Display table partition keys' AS description, '@partkeys [<owner>.]<table_name>'||&nl||'@partkeys soe.orders'||&nl||'@partkeys soe.%' AS usage FROM dual UNION ALL
  SELECT 'pd.sql' AS name, 'Display parameter name, description and value' AS description, '@pd <parameter_description>'||&nl||'@pd optimizer' AS usage FROM dual UNION ALL
  SELECT 'pmem.sql' AS name, 'Display process memory usage' AS description, '@pmem <spid>'||&nl||'@pmem 1000' AS usage FROM dual UNION ALL
  SELECT 'proc.sql' AS name, 'Display functions and procedures' AS description, '@proc <object_name> <procedure_name>'||&nl||'@proc dbms_stats table'||&nl||'@proc dbms_stats %' AS usage FROM dual UNION ALL
  SELECT 'procid.sql' AS name, 'Display functions and procedures' AS description, '@procid <object_id> <subprogram_id>'||&nl||'@procid 13615 84' AS usage FROM dual UNION ALL
  SELECT 'pv.sql' AS name, 'Display parameters based on the current value' AS description, '@pv <value>'||&nl||'@pv MANUAL' AS usage FROM dual UNION ALL
  SELECT 'pvalid.sql' AS name, 'Display valid parameter values' AS description, '@pvalid <parameter_name>'||&nl||'@pvalid optimizer' AS usage FROM dual UNION ALL
  SELECT 's.sql' AS name, 'Display current session wait and SQL_ID info (10g+)' AS description, '@s <sid>'||&nl||'@s 52,110,225'||&nl||'@s "select sid from v$session where username = ''XYZ''"'||&nl||'@s '||&amp||'mysid' AS usage FROM dual UNION ALL
  SELECT 'sdr.sql' AS name, 'Control direct read in serial (_serial_direct_read)' AS description, '@sdr <TRUE|FALSE>' AS usage FROM dual UNION ALL
  SELECT 'se.sql' AS name, 'Display session events' AS description, '@se <sid>'||&nl||'@se 10' AS usage FROM dual UNION ALL
  SELECT 'sed.sql' AS name, 'Display wait events description' AS description, '@sed <event>'||&nl||'@sed log_file'||&nl||'@sed "enq: TX"' AS usage FROM dual UNION ALL
  SELECT 'seg.sql' AS name, 'Display segment information' AS description, '@seg [<owner>.]<segment_name>'||&nl||'@seg soe.customers'||&nl||'@seg soe.%' AS usage FROM dual UNION ALL
  SELECT 'segcached.sql' AS name, 'Display number of buffered blocks of a segment' AS description, '@segcached [<owner>.]<object_name>'||&nl||'@segcached soe.orders'||&nl||'@segcached soe.%' AS usage FROM dual UNION ALL
  SELECT 'seq.sql' AS name, 'Display sequence information' AS description, '@seq [<owner>.]<sequence_name>'||&nl||'@seq sys.jobseq'||&nl||'@seq %.jobseq' AS usage FROM dual UNION ALL
  SELECT 'ses.sql' AS name, 'Display session statistics for given sessions, filter by statistic name' AS description, '@ses <sid> <statname>'||&nl||'@ses 10 %'||&nl||'@ses 10 parse'||&nl||'@ses 10,11,12 redo'||&nl||'@ses "select sid from v$session where username = ''APPS''" parse' AS usage FROM dual UNION ALL
  SELECT 'ses2.sql' AS name, 'Display session statistics for given sessions, filter by statistic name and show only stats with value > 0' AS description, '@ses2 <sid> <statname>'||&nl||'@ses2 10 %'||&nl||'@ses2 10 parse'||&nl||'@ses2 10,11,12 redo'||&nl||'@ses2 "select sid from v$ses2sion where username = ''APPS''" parse' AS usage FROM dual UNION ALL
  SELECT 'settings.sql' AS name, 'Display AWR configuration' AS description, '@awr/settings' AS usage FROM dual UNION ALL
  SELECT 'sga.sql' AS name, 'Display instance memory usage breakdown from v$memory_dynamic_components' AS description, '@sga' AS usage FROM dual UNION ALL
  SELECT 'sgai.sql' AS name, 'Display instance memory usage breakdown from v$sgainfo' AS description, '@sgai' AS usage FROM dual UNION ALL
  SELECT 'sgares.sql' AS name, 'Display information about the last completed SGA resize operations from v$sga_resize_ops' AS description, '@sgares' AS usage FROM dual UNION ALL
  SELECT 'sgastat.sql' AS name, 'Display detailed information on the SGA from v$sgastat' AS description, '@sgastat <name|pool>'||&nl||'@sgastat %'||&nl||'@sgastat result' AS usage FROM dual UNION ALL
  SELECT 'sgastatx.sql' AS name, 'Display shared pool stats by sub-pool from X$KSMSS' AS description, '@sgastatx <statistic_name>'||&nl||'@sgastatx "free memory"'||&nl||'@sgastatx cursor' AS usage FROM dual UNION ALL
  SELECT 'sys.sql' AS name, 'Display system statistics' AS description, '@sys <statistic_name>'||&nl||'@sys redo'||&nl||'@sys ''redo write''' AS usage FROM dual UNION ALL
  SELECT 'uu.sql' AS name, 'Display user sessions' AS description, '@uu <username>'||&nl||'@uu %'||&nl||'@uu username'||&nl||'@uu %username%' AS usage FROM dual UNION ALL
  SELECT 'us.sql' AS name, 'Display database usernames from dba_users' AS description, '@us <username>'||&nl||'@us username' AS usage FROM dual UNION ALL
  SELECT 'sl.sql' AS name, 'Set statistics level' AS description, '@sl <statistics_level>'||&nl||'@sl all' AS usage FROM dual UNION ALL
  SELECT 'smem.sql' AS name, 'Display process memory usage' AS description, '@smem <sid>'||&nl||'@smem 1000' AS usage FROM dual UNION ALL
  SELECT 'sqlbinds.sql' AS name, 'Display captured SQL bind variable values' AS description, '@sqlbinds <sql_id> <child_number>'||&nl||'@sqlbinds 2swu3tn1ujzq7 0'||&nl||'@sqlbinds 2swu3tn1ujzq7 %' AS usage FROM dual UNION ALL
  SELECT 'sqlid.sql' AS name, 'Display SQL: text, child cursors and execution statistics' AS description, '@sqlid <sql_id> <child_number>'||&nl||'@sqlid 7q729nhdgtsqq 0'||&nl||'@sqlid 7q729nhdgtsqq %' AS usage FROM dual UNION ALL
  SELECT 'sqlf.sql' AS name, 'Display full sql text from memory' AS description, '@sqlf <sql_id>'||&nl||'@sqlf 7q729nhdgtsqq' AS usage FROM dual UNION ALL
  SELECT 'sqlfn.sql' AS name, 'Display SQL functions' AS description, '@sqlf <name>'||&nl||'@sqlfn date' AS usage FROM dual UNION ALL
  SELECT 'sqlmon.sql' AS name, 'Run SQL Monitor report' AS description, '@sqlmon <sid>'||&nl||'@sqlmon 1019' AS usage FROM dual UNION ALL
  SELECT 'syn.sql' AS name, 'Display synonym information' AS description, '@syn [<owner>.]<synonym_name>'||&nl||'@syn system.tab'||&nl||'@syn system.%' AS usage FROM dual UNION ALL
  SELECT 't.sql' AS name, 'Display default trace file' AS description, '@t' AS usage FROM dual UNION ALL
  SELECT 'tab.sql' AS name, 'Display table information' AS description, '@tab [<owner>.]<table_name>'||&nl||'@tab soe.orders'||&nl||'@tab soe.%' AS usage FROM dual UNION ALL
  SELECT 'tabhist.sql' AS name, 'Display column histograms' AS description, '@tabhist [<owner>.]<table_name> <column_name>'||&nl||'@tabhist soe.orders order_mode'||&nl||'@tabhist soe.orders %' AS usage FROM dual UNION ALL
  SELECT 'tabpart.sql' AS name, 'Display table partitions' AS description, '@tabpart [<owner>.]<table_name>'||&nl||'@tabpart soe.orders'||&nl||'@tabpart soe.%' AS usage FROM dual UNION ALL
  SELECT 'tabsubpart' AS name, 'Display table subpartitions' AS description, '@tabsubpart [<owner>.]<table_name>'||&nl||'@tabsubpart soe.orders'||&nl||'@tabsubpart soe.%' AS usage FROM dual UNION ALL
  SELECT 'ti.sql' AS name, 'Force new trace file' AS description, '@ti' AS usage FROM dual UNION ALL
  SELECT 'topseg.sql' AS name, 'Display top space users per tablespace' AS description, '@topseg <tablespace_name>'||&nl||'@topseg soe'||&nl||'@topseg %' AS usage FROM dual UNION ALL
  SELECT 'topsegstat.sql' AS name, 'Display information about top segment-level statistics' AS description, '@topsegstat <statistic_name>'||&nl||'@topsegstat reads'||&nl||'@topsegstat %' AS usage FROM dual UNION ALL
  SELECT 'trace.sql' AS name, 'Enable tracing' AS description, '@trace <filter_expression>'||&nl||'@trace sid=123'||&nl||'@trace username=''SOE''' AS usage FROM dual UNION ALL
  SELECT 'traceme.sql' AS name, 'Enable tracing for the current session' AS description, '@traceme' AS usage FROM dual UNION ALL
  SELECT 'traceoff.sql' AS name, 'Disable tracing' AS description, '@traceoff <filter_expression>'||&nl||'@traceoff sid=123'||&nl||'@traceoff username=''SOE''' AS usage FROM dual UNION ALL
  SELECT 'trans.sql' AS name, 'Display active transactions' AS description, '@trans' AS usage FROM dual UNION ALL
  SELECT 'ts.sql' AS name, 'Display tablespaces' AS description, '@ts <tablespace_name>'||&nl||'@ts soe'||&nl||'@ts %' AS usage FROM dual UNION ALL
  SELECT 'uds.sql' AS name, 'Display undo statistics' AS description, '@uds' AS usage FROM dual UNION ALL
  SELECT 'wrka.sql' AS name, 'Display PGA and TEMP usage' AS description, '@wrka <fileter_expression>'||&nl||'@wrka 1=1'||&nl||'@wrka sid=1000' AS usage FROM dual UNION ALL
  SELECT 'wrkasum.sql' AS name, 'Display summary of SQL workareas groupbed by opertion type (PGA and TEMP)' AS description, '@wrkasum <filter_expression>'||&nl||'@wrkasum sql_id=''7q729nhdgtsqq''' AS usage FROM dual UNION ALL
  SELECT 'x.sql' AS name, 'Display SQL execution plan for the last SQL statement' AS description, '@x' AS usage FROM dual UNION ALL
  SELECT 'xa.sql' AS name, 'Display SQL execution plan for the last SQL statement - alias' AS description, '@xa' AS usage FROM dual UNION ALL
  SELECT 'xall.sql' AS name, 'Display SQL execution plan for the last SQL statement - advanced' AS description, '@xall' AS usage FROM dual UNION ALL
  SELECT 'xawr.sql' AS name, 'Display SQL execution plan from AWR' AS description, '@xawr <sql_id> <plan_hash_value>'||&nl||'@xawr 0sh0fn7r21020 1541789278'||&nl||'@xawr 0sh0fn7r21020 %' AS usage FROM dual UNION ALL
  SELECT 'xb.sql' AS name, 'Explain a SQL statements execution plan with execution profile directly from library cache - for the last SQL executed in current session' AS description, '@xb' AS usage FROM dual UNION ALL
  SELECT 'xbi.sql' AS name, 'Explain a SQL statements execution plan with execution profile directly from library cache - look up by SQL ID' AS description, '@xbi <sql_id> <sql_child_number>'||&nl||'@xbi a5ks9fhw2v9s1 0' AS usage FROM dual UNION ALL
  SELECT 'xi.sql' AS name, 'Display SQL execution plan from library cache' AS description, '@xi <sql_id> <child#>'||&nl||'@xi 7q729nhdgtsqq 0'||&nl||'@xi 7q729nhdgtsqq %' AS usage FROM dual UNION ALL
  SELECT 'xia.sql' AS name, 'Display SQL execution plan from library cache: ADVANCED' AS description, '@xia <sql_id>'||&nl||'@xia 7q729nhdgtsqq' AS usage FROM dual UNION ALL
  SELECT 'xprof.sql' AS name, 'Run DBMS_SQLTUNE.REPORT_SQL_MONITOR for session' AS description, '@xprof <report_level> <type> <sql_id|session_id> <sql_id|sid>' AS usage FROM dual UNION ALL
  SELECT 'xplto.sql' AS name, 'Display execution plan operations' AS description, '@xplto <name>'||&nl||'@xplto full' AS usage FROM dual UNION ALL
  SELECT '' AS name, '' AS description, '' AS usage FROM dual UNION ALL
  SELECT '' AS name, '' AS description, '' AS usage FROM dual
  ) 
)
SELECT * FROM q
WHERE
   (upper(name)        LIKE upper ('%&search_string%') OR regexp_like(name, '&search_string', 'i'))
OR (upper(description) LIKE upper ('%&search_string%') OR regexp_like(description, '&search_string', 'i'))
-- OR (upper(usage)       LIKE upper ('%&search_string%') OR regexp_like(usage, '&search_string', 'i'))
ORDER BY
    name
/

UNDEFINE search_string
CLEAR COLUMNS

<end node> 5P9i0s8y19Z
dt=Text
<node>
Audits
2
-- disable audit
NOAUDIT ALL;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Init Params
2

--If you wish, however, it is still possible to revert to case insensitivity by 
--altering a system parameter, SEC_CASE_SENSITIVE_LOGON, as shown in the example 
--below.
-- in oracle 11G
SQL> conn / as sysdba
Connected.
SQL>  alter system set sec_case_sensitive_logon = false;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Scheduler/Cronjobs
2
-- https://crontab.guru

30 * * * * sh /archivelogs/goldengate/scripts/chkc_process.sh

30 06 * * * sh  /recovery/oracle/dpump/expdp_uat_migration_11Oct2015.sh

-- cronjob
#minute (0-59)
#|   hour (0-23)
#|   |    day of the month (1-31)
#|   |    |   month of the year (1-12 or Jan-Dec)
#|   |    |   |   day of the week (0-6 with 0=Sun or Sun-Sat,,... 0=Sunday, 1=Monday, 2=Tuesday, 3=Wednesday 4=Thursday 5=Fri, 6=Saturday)
#|   |    |   |   |   commands or scripts
#|   |    |   |   |   |
00   0    *   *   0   /usr/bin/newsyslog 
#### above cronjob will rotate logs weekly (Sunday at midnight)

-- Event table Archiving from snox4transnox_gca schema
-- The CronJob will run on 1130AM o n Monday (1) and Friday (5) of every Month
30 12 * * 1,5 sh /oradata4/arc_cronjob/event_archiving.sh

30 03 * * 0,1,3,5 sh /home/oracle/cronjobs/del_1day_older_archfiles.sh > /home/oracle/cronjobs/del_1day_older_archfiles_logs.log

-- run it every 15 min
*/15 * * * *  sh /ora4/arc_cronjob/delete_arch_1day_older.sh

-- run it every 5 hrs
* */5 * * *  sh /home/oracle/cronjobs/delete_arch_1day_older.sh > /home/oracle/cronjobs/delete_arch_1day_older_logs.log


--- TransIT statitics collection
00 02 * * * sh /home/oracle/scripts/trans_settlement_stats.sql > /home/oracle/scripts/log_trans_settlement_stats.log


# GoldenGate ggserr.log rotation cron job
00 02 * * * sh /acfs/goldengate/scripts/log_rotation.sh > /acfs/goldengate/scripts/log_rotation.log


-- set job to drop the SN_TEMP and SC_TEMP tables

00 05 * * * sh /home/oracle/cronjobs/cronjob_srpt_2_drop_SNtemp_tbls.sh

cat /home/oracle/cronjobs/cronjob_srpt_2_drop_SNtemp_tbls.sh

#!/bin/sh
export ORACLE_BASE=/home/oracle/app/oracle
export ORACLE_HOME=$ORACLE_BASE/product/11.1.0/db_1
export ORACLE_SID=devdb

PATH=$PATH:$HOME/bin:$ORACLE_HOME/bin

export PATH

sqlplus -s / as sysdba << eof
set pagesize 0;
set head off
set echo off
set feedback off
set serveroutput on
spool /home/oracle/cronjobs/drop_tbls_srpt.log
BEGIN
    FOR i IN (SELECT owner, object_name FROM dba_objects
              WHERE (object_name LIKE 'SC_TEMP%' OR object_name LIKE 'SN_TEMP%')
                AND object_type='TABLE' AND created < SYSDATE-50/1440)
    LOOP
        dbms_utility.exec_ddl_statement('drop table '||i.owner||'.'||i.object_name||' purge');
    END LOOP;
END;
/
show errors;
spool off
eof

<end node> 5P9i0s8y19Z
dt=Text
<node>
redo logs
2

-- Check the redo log size
SELECT a.group#, substr(b.member,1,50) name,
   a.members, dbms_xplan.format_size2(a.bytes)bytes,
   a.status
FROM
   v$log a, v$logfile b
WHERE a.group# = b.group#
;

<end node> 5P9i0s8y19Z
dt=Text
<node>
DB Size
2
-- Check db size – large database
col "Database Size" format a20
col "Free space" format a20
col "Used space" format a20
select round(sum(used.bytes) / 1024 / 1024 / 1024 ) || ' GB' "Database Size", 
    round(sum(used.bytes) / 1024 / 1024 / 1024 ) - round(free.p / 1024 / 1024 / 1024) || ' GB' "Used space", 
    round(free.p / 1024 / 1024 / 1024) || ' GB' "Free space"
from 
    (select bytes from v$datafile
    union all
     select bytes from v$tempfile
    union all
     select bytes from v$log) used, 
    (select sum(bytes) as p from dba_free_space) free
group by free.p
;
 

-- The size of the database is the space the files physically consume on disk. You can find this with
select
"Reserved_Space(GB)", "Reserved_Space(GB)" - "Free_Space(GB)" "Used_Space(GB)",
"Free_Space(GB)"
from(
select 
(select sum(bytes/(1014*1024*1024)) from dba_data_files) "Reserved_Space(GB)",
(select sum(bytes/(1024*1024*1024)) from dba_free_space) "Free_Space(GB)"
from dual
);
 

-- Check user sapce
select owner, sum(bytes)/1024/1024 Size_MB 
from dba_segments 
where owner='CVS'
group  by owner;

12c

select owner, dbms_xplan.format_size2(sum(bytes)) DB_Size
from dba_segments 
where owner='CVS'
group by owner
;

-- calculates the over all size of database
SELECT (A.data_size+b.temp_size+c.redo_size)/1024/1024/1024 "total_GB_size"
FROM ( SELECT SUM(bytes) data_size FROM dba_data_files ) A,
	( SELECT NVL(SUM(bytes),0) temp_size FROM dba_temp_files ) b,
	( SELECT SUM(bytes) redo_size FROM sys.v_$log ) c;
===============================================================================================

--- Work Around to Calculate the size of stored procedures
SELECT  ds.owner,ds.name,status,sum(length(REPLACE(REPLACE(replace(text,chr(10),''),' ',''),'"',''))) proc_size
FROM DBA_OBJECTS do, dba_source ds
WHERE  do.object_type=ds.type
            and ds.name=do.object_name 
            and ds.owner=do.owner 
            and  ds.type ='PROCEDURE'
            and ds.owner='TRANSNOX_CPASS'  
group by ds.name,do.status,ds.owner;

<end node> 5P9i0s8y19Z
dt=Text
<node>
Exadata info
1

--- exadata information
https://docs.oracle.com/cd/E80920_01/index.html
https://docs.oracle.com/en/engineered-systems/


http://www.dbaexpert.com/blog/category/vmware/
https://stefanpanek.wordpress.com/2015/04/21/exadata-faked-storage-server-setup/
https://www.dba.bg/forum/oracle-rdbms-server/server-database-administration/exadata/5055-install-exadata-12-1-2-1-1-150316-2-on-oracle-linux-7-with-oracle-vm-server-manager-3-3-1-for-own-testing-and-preparation-for-exadata-exam-oracle-linux-7-0-installation
https://dbaesp.wordpress.com/2014/01/25/exadata-simulator-2way-rac-1-storage-cell/
http://oracletechdba.blogspot.com/2014/07/oracle-11gr2-installation-in-standalone.html
http://oracletechdba.blogspot.com/2014/06/building-exadata-in-vm-for-learning.html#more
http://oracletechdba.blogspot.com/2014/06/building-exadata-in-vm-for-learning.html

https://oraclegurukul.blogspot.com/2016/11/oracle-exa-data-simulation-setup.html
http://oraclequestionsanswers.blogspot.com/2016/10/steps-to-create-exadata-cell-on-oracle.html

-- exadata software download
http://epd-akam-us.oracle.com/adcarurepos/vol/patch36/EPD/V776455-01.zip?FilePath=/adcarurepos/vol/patch36/EPD/V776455-01.zip&File=V776455-01.zip¶ms=d21OOUpIaTMwMVRsOFFmYmMycHJldzphcnU9MjA0NDUwMjEmZW1haWw9YXV0b21hdGVkX2Rvd25sb2FkQG9yYWNsZS5jb20mZmlsZV9pZD04OTU1NDAxMSZwYXRjaF9maWxlPVY3NzY0NTUtMDEuemlwJnVzZXJpZD1hdXRvbWF0ZWRfZG93bmxvYWRAb3JhY2xlLmNvbSZzaXplPTEuM0cmY29udGV4dD1jb250ZXh0PUFAMTUrSEBhYXJ1MjAxLm9yYWNsZS5jb20rUEAmZG93bmxvYWRfaWQ9&AuthParam=1535925219_33e4d5a41ffce8f067b77a64b61dffca <http://epd-akam-us.oracle.com/adcarurepos/vol/patch36/EPD/V776455-01.zip?FilePath=/adcarurepos/vol/patch36/EPD/V776455-01.zip&File=V776455-01.zip&params=d21OOUpIaTMwMVRsOFFmYmMycHJldzphcnU9MjA0NDUwMjEmZW1haWw9YXV0b21hdGVkX2Rvd25sb2FkQG9yYWNsZS5jb20mZmlsZV9pZD04OTU1NDAxMSZwYXRjaF9maWxlPVY3NzY0NTUtMDEuemlwJnVzZXJpZD1hdXRvbWF0ZWRfZG93bmxvYWRAb3JhY2xlLmNvbSZzaXplPTEuM0cmY29udGV4dD1jb250ZXh0PUFAMTUrSEBhYXJ1MjAxLm9yYWNsZS5jb20rUEAmZG93bmxvYWRfaWQ9&AuthParam=1535925219_33e4d5a41ffce8f067b77a64b61dffca> 

<end node> 5P9i0s8y19Z
dt=Text
<node>
Exadata Patching
2

----- exadata patching example and help
https://blog.pythian.com/patch-exadata-part-1-introduction-prerequisites/
http://teymur-hajiyev.blogspot.com/2014/04/patching-oracle-exadata-quarterly-full.html

-----------------------------------------------------------------------------------------
-- Exadata Patching - Cell Server 

Cell storage patching can be done by patchmgr utility which is used to do a patching in rolling 
as well in non-rolling fashion.

Syntax: ./patchmgr -cells cell_group -patch [-rolling] [-ignore_alerts] [- smtp_from "addr" -smtp_to "addr1 addr2 addr3 ..."]


Here addr is the sending mail id which is used to send status of patching and 
addr1,addr2,addr3 are receiving mail id to receive the status of patching.

Step-1  First note down the current image version of cell by executing 

 #imageinfo

Step-2  Go to cell patch directory where patch has been copied

/19625719/Infrastructure/11.2.3.3.1/ExadataStorageServer_InfiniBandSwitch/patch_11.2.3.3.1.140708

Step-3  Reset the server to a known state using the following command

 ./patchmgr -cells cell_group -reset_force 

Step-4  Clean up any previous patchmgr utility runs using the following command

./patchmgr -cells cell_group -cleanup 

Step-5 Verify that the cells meet prerequisite checks using the following command

(Rolling)

 ./patchmgr -cells ~/cellgroup -patch_check_prereq -rolling 

 or

 (Non-rolling)

 ./patchmgr -cells ~/cellgroup -patch_check_prereq 

Here cellgroup file contains IPs of all cell server.
 

Step-6  Output should not have any error, If any error than resolve it first than re-execute above command

Step-7 Patch cell server

 (Rolling)

 ./patchmgr -cells ~/cellgroup -patch -rolling

 or

 (Non-rolling)

 ./patchmgr -cells ~/cellgroup -patch

Step-8  Check logs if any error in patchmgr.stdout file.

How it works?

 Entire patching activity done by patchmgr utility automatically.

•To ensure good backup exists, USB recovery media is recreated 
•Check cells have ssh equivalence for root user
•Initialize files, check space and state of cell services
•Copy, extract prerequisite check archive to cells 
•Check prerequisites on cell
•Copy the patch to cell
•Execute plug-in check for Patch Check Prereq
•Initiate patch on cell
•Reboot the cell
•Execute plug-in check for Patching
•Finalize patch
•Reboot the cell
•Check the state of patch
•Execute plug-in check for Post Patch
•Done
After completion of patching you can check the image version, it should be changed to new version


-- Rollback Patch

Step-1  Disable writeback flash cache (You can refer Oracle DOC ID - 1500257.1)

Step-2  Check rollback pre-requisites

 (Rolling)

./patchmgr -cells ~/cellgroup -rollback_check_prereq -rolling -ignore_alerts

 or

 (non-rolling) 

./patchmgr -cells ~/cellgroup -rollback_check_prereq -ignore_alerts  

Step-3  Perform the rollback

 (Rolling) 


 ./patchmgr -cells ~/cellgroup -rollback -rolling -ignore_alerts  

 or 

 (Non-Rolling)

 ./patchmgr -cells ~/cellgroup -rollback -ignore_alerts 

 

Step-4  Clean up the cells using the -cleanup option to clean up all the temporary patch or rollback files on the cells

./patchmgr -cells ~/cellgroup -cleanup

-----------------------------------------------------------------------------------------

<end node> 5P9i0s8y19Z
dt=Text
<node>
exadata version
2
-- root account
cat /opt/oracle.SupportTools/onecommand/databasemachine.xml|grep -i MACHINETYPE

How to find Exadata database machine version
 
Are you really curious to see which version of Exadata you are using. Just follow the step and you are ready with the information
 
$cd /opt/oracle.SupportTools/onecommand
 
$ cat databasemachine.xml |grep -i MACHINETYPE

                X5-2 Eighth Rack HC 8TB

Note:

HP => High Performance
HC => High Capcity

the difference between high capacity and high-performance disk?
- The high capacity disk comes with more storage space and less rpm (7.5k)
- High-Performance disk comes with less storage and high rpm (15k)

<end node> 5P9i0s8y19Z
dt=Text
<node>
Exadata ans
2
1. What is Exadata?
- Exadata is a pre-configured combination of hardware and software which provides a platform to run the Oracle Database.

2. Key components of Exadata?
- DB Server
- Cell Storage
- Infiniband Switch
- Cisco Switch
- PDU

3. Features of Exadata?
- Smart Scan
- Smart Flash Cache
- IORM
- Storage Index
- EHCC (Exadata Hybrid Columnar Compression)

4. Exadata Sizing? Exadata comes in the following configuration
- Full Rack
- Half Rack
- Quater Rack
- 1/8th Rack

**. How many database servers come in 1/8th rack and quarter rack?
- 2

21. How many cell storage comes in full rack Exadata machine?
- 14

**. Where we can define which cell storage can be used by a particular database server?
- CELLIP.ORA file contains the list of storage server which is accessed by DB server.

What is the difference between cellcli and dcli?
- Cellcli can be used on respective cell storage only.
- DCLi (Distributed Command Line Utility) – DCLI can be used to replicate commands on multiple storages as well as DB servers.

35 How many networks are required in Exadata?
- Public/Client Network: For Application Connectivity
- Management Network: For Exadata H/W management
- Private Network: For cluster interconnectivity and Storage connectivity

36. What is the command to enable query high compression on the table?
- SQL>alter table table_name move compress for query high;

**. What is the capacity of the Infiniband port?
- 40 Gbps

41. What is the difference between high capacity and high-performance disk?
- The high capacity disk comes with more storage space and less rpm (7.5k)
- High-Performance disk comes with less storage and high rpm (15k)

43. What is a grid disk?
- Grid Disks are created on top of Cell Disks and are presented to Oracle ASM as ASM disks.
- Space is allocated in chunks from the outer tracks of the Cell disk and moving inwards. One can have multiple Grid Disks per Cell disk.

44. Which network is used for RAC inter-connectivity?
- Infiniband Network

**. What is a Cell and Grid Disk?
- Cell and Grid Disk are logical components of the physical Exadata storage. A cell or Exadata Storage 
- server cell is a combination of Disk Drives put together to store user data. Each Cell Disk corresponds 
- to a LUN (Logical Unit) which has been formatted by the Exadata Storage Server Software. 
- Typically, each cell has 12 disk drives mapped to it.

<end node> 5P9i0s8y19Z
dt=Text
<node>
smart scan
2
--hind on smart scan
select /* NO_SMART_SCAN */

select /* WITH_SMART_SCAN */

<end node> 5P9i0s8y19Z
dt=Text
<node>
Oracle 12c
1
https://community.toadworld.com/platforms/oracle/b/weblog/archive/2016/04/17/oracle-12c-know-and-understand-your-pdb-s-history


http://www.oracle.com/webfolder/technetwork/tutorials/obe/db/12c/r1/pdb/pdb_unplug_plug/pdb_unplug_plug.html

<end node> 5P9i0s8y19Z
dt=Text
<node>
Ora Errors
1
-- Error in USMGENQ
ORA-06553: PLS-103: Encountered the symbol "RO" when expecting one of the following:

-- To resolve the issue check if there is any column created in new line, if so copy the code and drop it
-- and recreate the code/object.

select owner , table_name , column_name from dba_tab_columns where column_name LIKE '%'||CHR(10)||'%';

select owner , table_name from dba_tables where table_name LIKE '%'||CHR(10)||'%';
=======================================================================================================

<end node> 5P9i0s8y19Z
dt=Text
<node>
Password Extend
1
SELECT username, account_status, lock_date, expiry_date, su.PASSWORD, PROFILE
FROM dba_users du, sys.user$ su
WHERE du.username = su.NAME
  AND du.username IN 
('FINREP_USER','EPM_BIPLATFORM','HYP_ODI_WORK','EPM_MDS','EPM_SOAINFRA',
'EPM_ORASDPM','EPM_FCM','EPM_EAL','HYP_ODI_MASTER','FDWLOAD','EPM_REPORTING',
'PLINT_USER','EPM_FOUNDATION','EPM_EPMA','EPM_WORKSPACE','EPM_DRM',
'EPM_CALC_MGR','EPM_FDMEE','EPM_HFM','EPM_EAS','EPM_ESS_STUDIO',
'EPM_PLAN_SYSTEM')
ORDER BY username ASC;



SELECT
  ' ALTER USER '||USERNAME|| ' PROFILE '||dp.profile||'; '||CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' IDENTIFIED BY VALUES '''||SU.PASSWORD||''';' ||CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' PROFILE '||du.PROFILE||'; '|| CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' ACCOUNT UNLOCK;' RESET_CMD
FROM dba_users du, sys.user$ su, 
    (SELECT PROFILE 
       FROM (
              SELECT  PROFILE, RANK() OVER(ORDER BY PROFILE) AS rn
                FROM dba_profiles 
               WHERE resource_name='PASSWORD_VERIFY_FUNCTION'
                 AND LIMIT='NULL' 
            )WHERE rn=1) dp
WHERE du.username = su.NAME
  AND du.username = 'CAE0748P'
ORDER BY username ASC;


-- password rest/extend sql query
SELECT SYS_CONTEXT('USERENV','DB_NAME')Database_Name,
       username, account_status, lock_date, expiry_date, 
       su.PASSWORD, du.PROFILE profile_set, dp.PROFILE Null_Pass_Profile,
  ' ALTER USER '||USERNAME|| ' PROFILE '||dp.profile||'; '||CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' IDENTIFIED BY VALUES '''||SU.PASSWORD||''';' ||CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' PROFILE '||du.PROFILE||'; '|| CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' ACCOUNT UNLOCK;' RESET_CMD
FROM dba_users du, sys.user$ su, 
    (SELECT PROFILE 
       FROM (
              SELECT  PROFILE, RANK() OVER(ORDER BY PROFILE) AS rn
                FROM dba_profiles 
               WHERE resource_name='PASSWORD_VERIFY_FUNCTION'
                 AND LIMIT='NULL' 
            )WHERE rn=1) dp
WHERE du.username = su.NAME
  AND du.username = 'CAE0748P'
ORDER BY username ASC;  

SELECT username, account_status, lock_date, expiry_date, su.PASSWORD, PROFILE,
  ' ALTER USER '||USERNAME|| ' PROFILE DEFAULT; '||CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' IDENTIFIED BY VALUES '''||SU.PASSWORD||''';' ||CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' PROFILE '||PROFILE||'; '|| CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' ACCOUNT UNLOCK;' RESET_CMD
FROM dba_users du, sys.user$ su
WHERE du.username = su.NAME
  AND du.username = 'PEOPLE'
ORDER BY username ASC;

SELECT username, account_status, lock_date, expiry_date, su.PASSWORD, PROFILE,
  ' ALTER USER '||USERNAME|| ' PROFILE DEFAULT; '||CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' IDENTIFIED BY VALUES '''||SU.PASSWORD||''';' ||CHR(10)||CHR(10)||
  ' ALTER USER '||USERNAME|| ' PROFILE '||PROFILE||'; ' RESET_CMD
FROM dba_users du, sys.user$ su
WHERE du.username = su.NAME
  AND du.username IN ('ODI_HYPODI_DATA','ODI_HYPINT','ODI_HYPODIW','ODI_HYPODI','ODI_HYPODI_EXE','ODI_HYPODI_REP')
ORDER BY username ASC;


BEGIN
    FOR i IN (SELECT USERNAME, ACCOUNT_STATUS, LOCK_DATE, EXPIRY_DATE, SU.PASSWORD PASSWORD, PROFILE
                FROM DBA_USERS DU, SYS.USER$ SU
               WHERE DU.USERNAME = SU.NAME
                 AND DU.USERNAME IN  ('FINREP_USER','EPM_BIPLATFORM','HYP_ODI_WORK','EPM_MDS','EPM_SOAINFRA',
										'EPM_ORASDPM','EPM_FCM','EPM_EAL','HYP_ODI_MASTER','FDWLOAD','EPM_REPORTING',
										'PLINT_USER','EPM_FOUNDATION','EPM_EPMA','EPM_WORKSPACE','EPM_DRM',
										'EPM_CALC_MGR','EPM_FDMEE','EPM_HFM','EPM_EAS','EPM_ESS_STUDIO',
										'EPM_PLAN_SYSTEM')
               ORDER BY USERNAME ASC
              )
    LOOP
--      First check for one user if profile default is working on not else take
--	   another profile from DBA_Profiles table where password function should be null
        DBMS_UTILITY.EXEC_DDL_STATEMENT ('ALTER USER '|| i.USERNAME ||' PROFILE DEFAULT ');

        DBMS_UTILITY.EXEC_DDL_STATEMENT ('ALTER USER '|| i.USERNAME ||' IDENTIFIED BY VALUES '''||i.PASSWORD||'''');
        DBMS_UTILITY.EXEC_DDL_STATEMENT ('ALTER USER '|| i.USERNAME ||' PROFILE '|| i.PROFILE);
        
        DBMS_OUTPUT.PUT_LINE ('ALTER USER '|| i.USERNAME ||' PROFILE DEFAULT ;');       
        DBMS_OUTPUT.PUT_LINE ('ALTER USER '|| i.USERNAME ||' IDENTIFIED BY VALUES '''||i.PASSWORD||''';');        
        DBMS_OUTPUT.PUT_LINE ('ALTER USER '|| i.USERNAME ||' PROFILE '|| i.PROFILE||';');
     END LOOP;
     COMMIT;
--EXECUTE 
--    WHEN OTHERS THEN 
--        DBMS_OUTPUT.PUT_LINE ('SQL Error : '|| SUBSTR(SQLERRM,1,100));
END;
/

<end node> 5P9i0s8y19Z
dt=Text
<node>
- Auto script
1
DB_NAME=`cat /etc/oratab|grep -v "^#"|grep -v "N$"|cut -f1 -d: -s`
SPOOL_FILE_LOGS=
for DB in $DB_NAME
do
   export ORACLE_SID=$DB
   export ORACLE_HOME=`grep "^${DB}:" /etc/oratab|cut -d: -f2 -s`
   export PATH=$ORACLE_HOME/bin:$PATH
   echo "---> Database $ORACLE_SID, using home $ORACLE_HOME"
   sqlplus -s "/as sysdba" <<EOF
select to_char(sysdate,'mm/dd/yyyy hh24:mi:ss')Start_Timestamp from dual;

-- any script in between here and will be running for all DBs on server
-- startup6765;
spool 
select inst_id, inst_name, to_char(startup_time,'mm/dd/yyyy hh24:mi:ss') DB_Startup_Timestamp from gv$instance;


select to_char(sysdate,'mm/dd/yyyy hh24:mi:ss')End_Timestamp from dual;
EOF
done 

<end node> 5P9i0s8y19Z
dt=Text
<node>
SYSBASE
1
sudo su - sybase
showserver --- similar as cat /etc/oratab

ps -ef |grep dataserver
--- entries will -s which denodes as sybase instance name

isql -Ucae0748 -SSCH1P001 -W299999 ---- like sqlplus connectivity

sp_who
go --- like a simi colon to execute the commands in sybase
-- sp_who will tell you the session details


reset -- is command to run new commands-- like every query will
-- end with go and if you want to start new command then reset commands help


sp_who '256'
go --- spid is 256 to check session info for 256 spid


sp_displaylogin
go --- gives you the info about the current session


sp_helpdb
go -- database related information


sp_helpdb <DB_Name>
go --- will show th size of the device used inside the DB (usage of the database)

 
use <DB_NAME>
go --- like a mysql use command to enter into DB

 
use master 
go --- is like sys/system schemas which will have detail information of all DBs inside th sybase instance

 
sp_helpdevice
go --- info about the devices/storage



sp_helpsegment
go -- information related to segments


sp_helpsegment <segment_name>
go -- information related to log segments


disk init
name='logical name'
physname='physical disk location with filename'
size='1024M'
go --- you are creating a space into logical disk

 
SYB_BACKUP...sp_who
go
-- gives the information related to backups


reset

 shutdown SYB_BACKUP
go
--- reboot backup server 
reset

 
---- refresh steps
-- on source server
-- to table the backup of the table for refresh purpose
bcp dbname..tablename out output.out -Usa -Sservername -t "::~::"

 
--- on target server
bcpout >> target server
sysusers
sysalternates

 
load database

 
online database databasename

 

login to target  DB

 

use DBName
delete from sysusers

 

-- save the delete
commit;
or
checkpoint;

 

then start refresh on target DB

 

-- import the table into mentioned -S servername
bcp dbname..tablename in output.out -Usa -Sservername -t "::~::"

<end node> 5P9i0s8y19Z
dt=Text
<node>
DB Level
2
account  = cae0748
loginfo  =  btqgxt.21#@

<end node> 5P9i0s8y19Z
